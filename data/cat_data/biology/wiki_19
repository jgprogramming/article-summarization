{"url": "https://en.wikipedia.org/wiki?curid=196121", "text": "Platelet\n\nPlatelets, also called thrombocytes (thromb- + -cyte, \"blood clot cell\"), are a component of blood whose function (along with the coagulation factors) is to stop bleeding by clumping and clotting blood vessel injuries. Platelets have no cell nucleus: they are fragments of cytoplasm that are derived from the megakaryocytes of the bone marrow, and then enter the circulation. Maximum part of cytoplasm is composed of a contractile protein called Thrombosthenin. These unactivated platelets are biconvex discoid (lens-shaped) structures, 2–3 µm in greatest diameter. Platelets are found only in mammals, whereas in other animals (e.g. birds, amphibians) thrombocytes circulate as intact mononuclear cells.\n\nOn a stained blood smear, platelets appear as dark purple spots, about 20% the diameter of red blood cells. The smear is used to examine platelets for size, shape, qualitative number, and clumping. The ratio of platelets to red blood cells in a healthy adult ranges from 1:10 to 1:20.\n\nThe main function of platelets is to contribute to hemostasis: the process of stopping bleeding at the site of interrupted endothelium. They gather at the site and unless the interruption is physically too large, they plug the hole. First, platelets attach to substances outside the interrupted endothelium: \"adhesion\". Second, they change shape, turn on receptors and secrete chemical messengers: \"activation\". Third, they connect to each other through receptor bridges: \"aggregation\". Formation of this platelet plug (primary hemostasis) is associated with activation of the coagulation cascade with resultant fibrin deposition and linking (secondary hemostasis). These processes may overlap: the spectrum is from a predominantly platelet plug, or \"white clot\" to a predominantly fibrin clot, or \"red clot\" or the more typical mixture. The final result is the \"clot\". Some would add the subsequent \"clot retraction\" and \"platelet inhibition\" as fourth and fifth steps to the completion of the process and still others a sixth step \"wound repair\".\n\nLow platelet concentration is thrombocytopenia and is due to either \"decreased production\" or \"increased destruction\". Elevated platelet concentration is thrombocytosis and is either \"congenital\", \"reactive\" (to cytokines), or due to \"unregulated production\": one of the \"myeloproliferative neoplasms\" or certain other myeloid neoplasms. A disorder of platelet function is a thrombocytopathy.\n\nNormal platelets can respond to an \"abnormality on the vessel wall\" rather than to hemorrhage, resulting in inappropriate platelet adhesion/activation and thrombosis: the formation of a clot within an intact vessel. This type of thrombosis arises by mechanisms different than those of a normal clot: namely, extending the fibrin clot of venous thrombosis; extending an unstable or ruptured arterial plaque, causing arterial thrombosis; and microcirculatory thrombosis. An arterial thrombus may partially obstruct blood flow, causing downstream ischemia, or may completely obstruct it, causing downstream tissue death.\nGeorge Gulliver in 1841 drew pictures of platelets using the twin lens (compound) microscope invented in 1830 by Joseph Jackson Lister.\nThis microscope improved resolution sufficiently to make it possible to see platelets for the first time. William Addison in 1842 drew pictures of a platelet-fibrin clot. Lionel Beale in 1864 was the first to publish a drawing showing platelets. Max Schultze in 1865 described what he called \"spherules\", which he noted were much smaller than red blood cells, occasionally clumped, and were sometimes found in collections of fibrin material. Giulio Bizzozero in 1882 studied the blood of amphibians microscopically \"in vivo\". He named Schultz's spherules (It.) \"piastrine\": little plates. William Osler observed them and, in published lectures in 1886, called them a \"third corpuscle\" and a blood \"plaque\" and described them as a colorless protoplasmic disc. James Wright examined blood smears using the stain named for him, and used the term \"plates\" in his 1906 publication but changed to \"platelets\" in his 1910 publication which has become the universally accepted term.\n\nThe term \"thrombocyte\" (clot cell) came into use in the early 1900s and is sometimes used as a synonym for platelet; but not generally in the scientific literature, except as a root word for other terms related to platelets (e.g. \" thrombocytopenia\" meaning low platelets). Thrombocytes are cells found in the blood of non-mammalian vertebrates. They are the functional equivalents of platelets, but circulate as intact mononuclear cells, and are not simply cytoplasmic fragments of bone marrow megakaryocytes.\n\nIn some contexts, the word \"thrombus\" is used interchangeably with the word \"clot\", regardless of its composition (white, red, or mixed). In other contexts it is used to contrast a normal from an abnormal clot: \"thrombus\" arises from physiologic hemostasis, \"thrombosis\" arises from a pathologic and excessive quantity of clot. In a third context it is used to contrast the result from the process: \"thrombus\" is the result, \"thrombosis\" is the process.\n\nPlatelet concentration is measured either manually using a hemocytometer, or by placing blood in an automated platelet analyzer using electrical impedance, such as a Coulter counter. The normal range (99% of population analyzed) for platelets in healthy Caucasians is 150,000 to 450,000 per cubic millimeter (a mm equals a microliter). or 150–400 × 10 per liter. The normal range has been confirmed to be the same in the elderly and Spanish populations.\n\nStructurally the platelet can be divided into four zones, from peripheral to innermost:\n\n\"Spontaneous and excessive bleeding\" can occur because of platelet disorders. This bleeding can be caused by deficient numbers of platelets, dysfunctional platelets, or very excessive numbers of platelets: over 1.0 million/microliter. (The excessive numbers create a relative von Willebrand factor deficiency due to sequestration.)\n\nOne can get a clue as to whether bleeding is due to a platelet disorder or a coagulation factor disorder by the characteristics and location of the bleeding. All of the following suggest platelet bleeding, not coagulation bleeding: the bleeding from a skin cut such as a razor nick is prompt and excessive, but can be controlled by pressure; spontaneous bleeding into the skin which causes a purplish stain named by its size: petechiae, purpura, ecchymoses; bleeding into mucous membranes causing bleeding gums, nose bleed, and gastrointestinal bleeding; menorrhagia; and intraretinal and intracranial bleeding.\n\nExcessive numbers of platelets, and/or normal platelets responding to abnormal vessel walls, can result in venous thrombosis and arterial thrombosis. The symptoms depend on the site of thrombosis.\n\n\n\nAn overview summarizing platelet dynamics, the complex process of converting inactive platelets into a platelet plug, is essential. Complicating any verbal description is the fact that at least 193 proteins and 301 interactions are involved in platelet dynamics. The separation of platelet dynamics into three stages is useful in this regard, but it is artificial: in fact, each stage is initiated in rapid succession, and each continues until the trigger for that stage is no longer present, so there is overlap.\n\nThrombus formation on an intact endothelium is prevented by nitric oxide, prostacyclin, and CD39.\n\nEndothelial cells are attached to the subendothelial collagen by von Willebrand factor (VWF) which these cells produce. VWF is also stored in the Weibel-Palade bodies of the endothelial cells and secreted constitutively into the blood. Platelets store vWF in their alpha granules.\n\nWhen the endothelial layer is disrupted, collagen and VWF anchor platelets to the subendothelium. Platelet GP1b-IX-V receptor binds with VWF; and GPVI receptor and integrin alpha2beta1 bind with collagen.\n\nThe intact endothelial lining \"inhibits\" platelet activation by producing nitric oxide, endothelial-ADPase, and PGI (Prostacyclin). Endothelial-ADPase degrades the platelet activator ADP.\n\nResting platelets maintain active calcium efflux via a cyclic AMP activated calcium pump. Intracellular calcium concentration determines platelet activation status, as it is the second messenger that drives platelet conformational change and degranulation (see below). Endothelial prostacyclin binds to prostanoid receptors on the surface of resting platelets. This event stimulates the coupled Gs protein to increase adenylate cyclase activity and increases the production of cAMP, further promoting the efflux of calcium and reducing intracellular calcium availability for platelet activation.\n\nADP on the other hand binds to purinergic receptors on platelet surface. Since the thrombocytic purinergic receptor P2Y12 is coupled to Gi proteins, ADP reduces platelet adenylate cyclase activity and cAMP production, leading to accumulation of calcium inside the platelet by inactivating the cAMP calcium efflux pump. The other ADP-receptor P2Y1 couples to Gq that activates phospholipase C-beta 2 PLCB2, resulting in inositol 1,4,5-trisphosphate (IP3)generation and intracellular release of more calcium. This together induces platelet activation. Endothelial ADPase degrades ADP and prevents this from happening. Clopidogrel and related antiplatelet medications also work as purinergic receptor P2Y12 antagonists.\n\nPlatelet activation begins seconds after adhesion occurs. It is triggered when \"collagen\" from the subendothelium binds with its receptors on the platelet. GPVI is associated with the Fc receptor gamma chain and leads via the activation of a tyrosine kinase cascade finally to the activation of PLC-gamma2 PLCG2 and more calcium release.\n\nTissue factor also binds to factor VII in the blood, which initiates the extrinsic coagulation cascade to increase thrombin production. Thrombin is a potent platelet activator, acting through Gq and G12. These are G protein coupled receptors and they turn on calcium mediated signaling pathways within the platelet, overcoming the baseline calcium efflux. Families of three G proteins (Gq, Gi, G12) operate together for full activation. Thrombin also promotes secondary fibrin-reinforcement of the platelet plug. Platelet activation in turn degranulates and releases factor V and fibrinogen, potentiating the coagulation cascade. So in reality the process of platelet plugging and coagulation are occurring simultaneously rather than sequentially, with each inducing the other to form the final clot.\n\nCollagen-mediated GPVI signalling increases the platelet production of thromboxane A2 (TXA2) and decreases the production of prostacyclin. This occurs by altering the metabolic flux of platelet's eicosanoid synthesis pathway, which involves enzymes phospholipase A2, cyclo-oxygenase 1, and thromboxane-A synthase. Platelets secrete thromboxane A2, which acts on the platelet's own thromboxane receptors on the platelet surface (hence the so-called \"out-in\" mechanism), and those of other platelets. These receptors trigger intraplatelet signaling, which converts GPIIb/IIIa receptors to their active form to initiate \"aggregation\".\n\nPlatelets contain dense granules, lambda granules and alpha granules. Activated platelets secrete the contents of these granules through their canalicular systems to the exterior. Simplistically, bound and activated platelets degranulate to release platelet chemotactic agents to attract more platelets to the site of endothelial injury. Granule characteristics:\n\nMitochondria hyperpolarization is a key event in initiating changes in morphology. Intraplatelet calcium concentration increases, stimulating the interplay between microtubule/actin filament complex. The continuous changes in shape from the unactivated to the fully activated platelet is best seen on scanning electron microscopy. Three steps along this path are named \"early dendritic\", \"early spread\" and \"spread\". The surface of the unactivated platelet looks very similar to the surface of the brain, with a wrinkled appearance from numerous shallow folds to increase the surface area; \"early dendritic\", an octopus with multiple arms and legs; \"early spread\", an uncooked frying egg in a pan, the \"yolk\" being the central body; and the \"spread\", a cooked fried egg with a denser central body. These changes are all brought about by the interaction of the microtubule/actin complex with the platelet cell membrane and open canalicular system (OCS), which is an extension and invagination of that membrane. This complex runs just beneath these membranes, and is the chemical motor which literally pulls the invaginated OCS out of the interior of the platelet like turning pants pockets inside out, creating the dendrites. and then spreads each dendrite until the entire OCS becomes indistinguishable from the initial platelet membrane as it forms the \"fried egg\". This dramatic increase in surface area comes about with neither stretching nor adding phospholipids to the platelet membrane.\n\nPlatelet activation causes its membrane surface to become negatively charged. One of the signaling pathways turns on scramblase, which moves negatively charged phospholipids from the inner to the outer platelet membrane surface. These phospholipids then bind the tenase and prothrombinase complexes, two of the sites of interplay between platelets and the coagulation cascade. Calcium ions are essential for the binding of these coagulation factors.\n\nAggregation begins minutes after activation, and occurs as a result of turning on the GPIIb/IIIa receptor, allowing these receptors to bind with vWF or fibrinogen. There are around 60 000 of these receptors per platelet. When any one or more of at least nine different platelet surface receptors are turned on during activation, intraplatelet signaling pathways cause existing GpIIb/IIIa receptors to \"change shape\" – curled to straight – and thus become capable of binding.\n\nSince fibrinogen is a rod-like protein with nodules on either end capable of binding GPIIb/IIIa, activated platelets with exposed GPIIb/IIIa can bind fibrinogen to aggregate. GPIIb/IIIa may also further anchor the platelets to subendothelial vWF for additional clot structural stabilisation.\n\nClassically it was thought that this was the only mechanism involved in aggregation, but three new mechanisms have been identified which can initiate aggregation, depending on the velocity of blood flow (i.e. shear range).\n\nThe blood clot is only a temporary solution to stop bleeding; tissue repair is needed. Small interruptions in the endothelium are handled by physiological mechanisms; large interruptions by the trauma surgeon.\n\nIn addition to interacting with vWF and fibrin, platelets interact with thrombin, Factors X, Va, VIIa, XI, IX, and prothrombin to complete clot formation via the coagulation cascade.\nSix studies suggested platelets express tissue factor: the definitive study shows they do not. The platelets from rats were conclusively shown to express tissue factor protein and also it was proved that the rat platelets carry both the tissue factor pre-mRNA and mature mRNA.\n\nIn addition to being the cellular effector of hemostasis, platelets are rapidly deployed to sites of injury or infection, and potentially modulate inflammatory processes by interacting with leukocytes and by secreting cytokines, chemokines, and other inflammatory mediators.\nPlatelets also secrete platelet-derived growth factor (PDGF).\n\nInstead of having platelets, non-mammalian vertebrates have thrombocytes, which have a nucleus and resemble B lymphocytes in morphology. They aggregate in response to thrombin, but not to ADP, serotonin, nor adrenaline, as platelets do.\n\nDeveloped by Duke in 1910 and bearing his name, it measured the time for bleeding to stop from a standardized wound in the ear lobe which is blotted each 30 seconds. Normal was less than 3 minutes. More modern techniques are now used. A normal bleeding time reflects sufficient platelet numbers and function plus normal microvasculature.\n\nIn the Multiplate analyzer, anticoagulated whole blood is mixed with saline and a platelet agonist in a single use cuvette with two pairs of electrodes. The increase in impedance between the electrodes as platelets aggregate onto them, is measured and visualized as a curve.\n\nThe PFA-100 (Platelet Function Assay-100) is a system for analysing platelet function in which citrated whole blood is aspirated through a disposable cartridge containing an aperture within a membrane coated with either collagen and epinephrine or collagen and ADP. These agonists induce platelet adhesion, activation and aggregation leading to rapid occlusion of the aperture and cessation of blood flow termed the closure time (CT). An elevated CT with EPI and collagen can indicate intrinsic defects such as von Willebrand disease, uremia, or circulating platelet inhibitors. The follow up test involving collagen and ADP is used to indicate if the abnormal CT with collagen and EPI was caused by the effects of acetyl sulfosalicylic acid (aspirin) or medications containing inhibitors.\n\nAdapted from\n\nThe three broad categories of platelet disorders are \"not enough\"; \"dysfunctional\"; and \"too many\".\n\n\n\nCritical count of platelets is 40,000/mm^3. If number is less than critical count then red spots or rashes appears on the skin called purpura disease.\n\nSome drugs used to treat inflammation have the unwanted side effect of suppressing normal platelet function. These are the non-steroidal anti-inflammatory drugs (NSAIDS). Aspirin irreversibly disrupts platelet function by inhibiting cyclooxygenase-1 (COX1), and hence normal hemostasis. The resulting platelets are unable to produce new cyclooxygenase because they have no DNA. Normal platelet function will not return until the use of aspirin has ceased and enough of the affected platelets have been replaced by new ones, which can take over a week. Ibuprofen, another NSAID, does not have such a long duration effect, with platelet function usually returning within 24 hours, and taking ibuprofen before aspirin prevents the irreversible effects of aspirin.\n\nThese drugs are used to prevent thrombus formation.\n\n\n\n\nPlatelet transfusion is most frequently used to correct unusually low platelet counts, either to prevent spontaneous bleeding (typically at counts below 10×10/L) or in anticipation of medical procedures that will necessarily involve some bleeding. For example, in patients undergoing surgery, a level below 50×10/L is associated with abnormal surgical bleeding, and regional anaesthetic procedures such as epidurals are avoided for levels below 80×10/L. Platelets may also be transfused when the platelet count is normal but the platelets are dysfunctional, such as when an individual is taking aspirin or clopidogrel. Finally, platelets may be transfused as part of a massive transfusion protocol, in which the three major blood components (red blood cells, plasma, and platelets) are transfused to address severe hemorrhage. Platelet transfusion is contraindicated in thrombotic thrombocytopenic purpura (TTP), as it fuels the coagulopathy.\n\nPlatelets are either isolated from collected units of whole blood and pooled to make a therapeutic dose, or collected by platelet apheresis: blood is taken from the donor, passed through a device which removes the platelets, and the remainder is returned to the donor in a closed loop. The industry standard is for platelets to be tested for bacteria before transfusion to avoid septic reactions, which can be fatal. Recently the AABB Industry Standards for Blood Banks and Transfusion Services (5.1.5.1) has allowed for use of pathogen reduction technology as an alternative to bacterial screenings in platelets.\n\nPooled whole-blood platelets, sometimes called “random” platelets, are separated by one of two methods. In the US, a unit of whole blood is placed into a large centrifuge in what is referred to as a “soft spin.” At these settings, the platelets remain suspended in the plasma. The platelet-rich plasma (PRP) is removed from the red cells, then centrifuged at a faster setting to harvest the platelets from the plasma. In other regions of the world, the unit of whole blood is centrifuged using settings that cause the platelets to become suspended in the “buffy coat” layer, which includes the platelets and the white blood cells. The “buffy coat” is isolated in a sterile bag, suspended in a small amount of red blood cells and plasma, then centrifuged again to separate the platelets and plasma from the red and white blood cells. Regardless of the initial method of preparation, multiple donations may be combined into one container using a sterile connection device to manufacture a single product with the desired therapeutic dose.\n\nApheresis platelets are collected using a mechanical device that draws blood from the donor and centrifuges the collected blood to separate out the platelets and other components to be collected. The remaining blood is returned to the donor. The advantage to this method is that a single donation provides at least one therapeutic dose, as opposed to the multiple donations for whole-blood platelets. This means that a recipient is not exposed to as many different donors and has less risk of transfusion-transmitted disease and other complications. Sometimes a person such as a cancer patient who requires routine transfusions of platelets will receive repeated donations from a specific donor to further minimize the risk. Pathogen reduction of platelets using for example, riboflavin and UV light treatments can also be carried out to reduce the infectious load of pathogens contained in donated blood products, thereby reducing the risk of transmission of transfusion transmitted diseases. Another photochemical treatment process utilizing amotosalen and UVA light has been developed for the inactivation of viruses, bacteria, parasites, and leukocytes that can contaminate blood components intended for transfusion. In addition, apheresis platelets tend to contain fewer contaminating red blood cells because the collection method is more efficient than “soft spin” centrifugation at isolating the desired blood component.\n\nPlatelets collected by either method have a very short shelf life, typically five days. This results in frequent problems with short supply, as testing the donations often requires up to a full day. Since there are no effective preservative solutions for platelets, they lose potency quickly and are best when fresh.\n\nPlatelets are stored under constant agitation at 20–24 °C (68–75.2 °F). Units can not be refrigerated as this causes platelets to change shape and lose function. Storage at room temperature provides an environment where any bacteria that are introduced to the blood component during the collection process may proliferate and subsequently cause bacteremia in the patient. Regulations are in place in the United States that require products to be tested for the presence of bacterial contamination before transfusion.\n\nPlatelets do not need to belong to the same A-B-O blood group as the recipient or be cross-matched to ensure immune compatibility between donor and recipient unless they contain a significant amount of red blood cells (RBCs). The presence of RBCs imparts a reddish-orange color to the product, and is usually associated with whole-blood platelets. An effort is sometimes made to issue type specific platelets, but this is not critical as it is with RBCs.\n\nPrior to issuing platelets to the recipient, they may be irradiated to prevent transfusion-associated graft versus host disease or they may be washed to remove the plasma if indicated.\n\nThe change in the recipient's platelet count after transfusion is termed the \"increment\" and is calculated by subtracting the pre-transfusion platelet count from the post-transfusion platelet count. Many factors affect the increment including the recipient's body size, the number of platelets transfused, and clinical features that may cause premature destruction of the transfused platelets. When recipients fail to demonstrate an adequate post-transfusion increment, this is termed platelet transfusion refractoriness.\n\nPlatelets, either apheresis-derived or random-donor, can be processed through a \"volume reduction\" process. In this process, the platelets are spun in a centrifuge and the excess plasma is removed, leaving 10 to 100 mL of platelet concentrate. Such volume-reduced platelets are normally transfused only to neonatal and pediatric patients, when a large volume of plasma could overload the child's small circulatory system. The lower volume of plasma also reduces the chances of an adverse transfusion reaction to plasma proteins. Volume reduced platelets have a shelf life of only four hours.\n\nPlatelets release platelet-derived growth factor (PDGF), a potent chemotactic agent; and TGF beta, which stimulates the deposition of extracellular matrix; fibroblast growth factor, insulin-like growth factor 1, platelet-derived epidermal growth factor, and vascular endothelial growth factor. Local application of these factors in increased concentrations through Platelet-rich plasma (PRP) is used as an adjunct in wound healing.\n\n", "id": "196121", "title": "Platelet"}
{"url": "https://en.wikipedia.org/wiki?curid=18776997", "text": "Chloragogen cell\n\nChloragogen cells, also called as \"y cells\", are cells in annelids that function similarly to the liver in vertebrates.\n\nThe cells store glycogen and neutralize toxins, are yellowish in colour due to the presence of yellow granules called chloragosomes and are present in coelomic fluid of some annelids.\n\nThese cells are derived from the inner coelomic epithelium, and help in excretory functions, as most commonly demonstrated in earthworms.\n\nThey have characteristic vesicular bulging which store and transport substances like glycogen and nitrogenous wastes. They take part in the deamination of amino acids and synthesis of urea.\n\nSilicates taken in along with food are deposited in the chloragogen cells.\n", "id": "18776997", "title": "Chloragogen cell"}
{"url": "https://en.wikipedia.org/wiki?curid=4630125", "text": "Artificial cell\n\nAn artificial cell or minimal cell is an engineered particle that mimics one or many functions of a biological cell. The term does not refer to a specific physical entity, but rather to the idea that certain functions or structures of biological cells can be replaced or supplemented with a synthetic entity. Often, artificial cells are biological or polymeric membranes which enclose biologically active materials. As such, nanoparticles, liposomes, polymersomes, microcapsules and a number of other particles have qualified as artificial cells. Micro-encapsulation allows for metabolism within the membrane, exchange of small molecules and prevention of passage of large substances across it. The main advantages of encapsulation include improved mimicry in the body, increased solubility of the cargo and decreased immune responses. Notably, artificial cells have been clinically successful in hemoperfusion.\n\nIn the area of synthetic biology, a \"living\" artificial cell has been defined as a completely synthetically made cell that can capture energy, maintain ion gradients, contain macromolecules as well as store information and have the ability to mutate. Such a cell is not technically feasible yet, but a variation of an artificial cell has been created in which a completely synthetic genome was introduced to genomically emptied host cells. Although not completely artificial because the cytoplasmic components as well as the membrane from the host cell are kept, the engineered cell is under control of a synthetic genome and is able to replicate.\n\nThe first artificial cells were developed by Thomas Chang at McGill University in the 1960s. These cells consisted of ultrathin membranes of nylon, collodion or crosslinked protein whose semipermeable properties allowed diffusion of small molecules in and out of the cell. These cells were micron-sized and contained cell, enzymes, hemoglobin, magnetic materials, adsorbents and proteins.\n\nLater artificial cells have ranged from hundred-micrometer to nanometer dimensions and can carry microorganisms, vaccines, genes, drugs, hormones and peptides. The first clinical use of artificial cells was in hemoperfusion by the encapsulation of activated charcoal.\n\nIn the 1970s, researchers were able to introduce enzymes, proteins and hormones to biodegradable microcapsules, later leading to clinical use in diseases such as Lesch-Nyhan syndrome. Although Chang's initial research focused on artificial red blood cells, only in the mid-1990s were biodegradable artificial red blood cells developed. Artificial cells in biological cell encapsulation were first used in the clinic in 1994 for treatment in a diabetic patient and since then other types of cells such as hepatocytes, adult stem cells and genetically engineered cells have been encapsulated and are under study for use in tissue regeneration.\n\nOn December 29, 2011, chemists at Harvard University reported the creation of an artificial cell membrane.\n\nBy 2014, self-replicating, synthetic bacterial cells with cell walls and synthetic DNA had been produced. In January of that year researchers produce an artificial eukaryotic cell capable of undertaking multiple chemical reactions through working organelles.\n\nMembranes for artificial cells be made of simple polymers, crosslinked proteins, lipid membranes or polymer-lipid complexes. Further, membranes can be engineered to present surface proteins such as albumin, antigens, Na/K-ATPase carriers, or pores such as ion channels.\nCommonly used materials for the production of membranes include hydrogel polymers such as alginate, cellulose and thermoplastic polymers such as hydroxyethyl methacrylate-methyl methacrylate (HEMA- MMA), polyacrylonitrile-polyvinyl chloride (PAN-PVC), as well as variations of the above-mentioned. The material used determines the permeability of the cell membrane, which for polymer depends on the molecular weight cut off (MWCO). The MWCO is the maximum molecular weight of a molecule that may freely pass through the pores and is important in determining adequate diffusion of nutrients, waste and other critical molecules.\nHydrophilic polymers have the potential to be biocompatible and can be fabricated into a variety of forms which include polymer micelles, sol-gel mixtures, physical blends and crosslinked particles and nanoparticles. Of special interest are stimuli-responsive polymers that respond to pH or temperature changes for the use in targeted delivery. These polymers may be administered in the liquid form through a macroscopic injection and solidify or gel \"in situ\" because of the difference in pH or temperature. Nanoparticle and liposome preparations are also routinely used for material encapsulation and delivery. A major advantage of liposomes is their ability to fuse to cell and organelle membranes.\n\nMany variations for artificial cell preparation and encapsulation have been developed. Typically, vesicles such as a nanoparticle, polymersome or liposome are synthesized. An emulsion is typically made through the use of high pressure equipment such as a high pressure homogenizer or a Microfluidizer. Two micro-encapsulation methods for nitrocellulose are also described below.\n\nIn a high-pressure homogenizer, two liquids in oil/liquid suspension are forced through a small orifice under very high pressure. This process shears the products and allows the creation of extremely fine particles, as small as 1 nm.\n\nThis technique uses a patented Microfluidizer to obtain a greater amount of homogenous suspensions that can create smaller particles than homogenizers. A homogenizer is first used to create a coarse suspension which is then pumped into the microfluidizer under high pressure. The flow is then split into two streams which will react at very high velocities in an interaction chamber until desired particle size is obtained. This technique allows for large scale production of phospholipid liposomes and subsequent material nanoencapsulations.\n\nIn this method, a cell solution is incorporated dropwise into a collodion solution of cellulose nitrate. As the drop travels through the collodion, it is coated with a membrane thanks to the interfacial polymerization properties of the collodion. The cell later settles into paraffin where the membrane sets and is finally suspended a saline solution. The drop method is used for the creation of large artificial cells which encapsulate biological cells, stem cells and genetically engineered stem cells.\n\nThe emulsion method differs in that the material to be encapsulated is usually smaller and is placed in the bottom of a reaction chamber where the collodion is added on top and centrifuged, or otherwise disturbed in order to create an emulsion. The encapsulated material is then dispersed and suspended in saline solution.\n\nArtificial cells used for drug delivery differ from other artificial cells since their contents are intended to diffuse out of the membrane, or be engulfed and digested by a host target cell. Often used are submicron, lipid membrane artificial cells that may be referred to as nanocapsules, nanoparticles, polymersomes, or other variations of the term.\n\nEnzyme therapy is being actively studied for genetic metabolic diseases where an enzyme is over-expressed, under-expressed, defective, or not at all there. In the case of under-expression or expression of a defective enzyme, an active form of the enzyme is introduced in the body to compensate for the deficit. On the other hand, an enzymatic over-expression may be counteracted by introduction of a competing non-functional enzyme; that is, an enzyme which metabolizes the substrate into non-active products. When placed within an artificial cell, enzymes can carry out their function for a much longer period compared to free enzymes and can be further optimized by polymer conjugation.\n\nThe first enzyme studied under artificial cell encapsulation was asparaginase for the treatment of lymphosarcoma in mice. This treatment delayed the onset and growth of the tumor. These initial findings led to further research in the use of artificial cells for enzyme delivery in tyrosine dependent melanomas. These tumors have a higher dependency on tyrosine than normal cells for growth, and research has shown that lowering systemic levels of tyrosine in mice can inhibit growth of melanomas. The use of artificial cells in the delivery of tyrosinase; and enzyme that digests tyrosine, allows for better enzyme stability and is shown effective in the removal of tyrosine without the severe side-effects associated with tyrosine depravation in the diet.\n\nArtificial cell enzyme therapy is also of interest for the activation of prodrugs such as ifosfamide in certain cancers. Artificial cells encapsulating the cytochrome p450 enzyme which converts this prodrug into the active drug can be tailored to accumulate in the pancreatic carcinoma or implanting the artificial cells close to the tumor site. Here, the local concentration of the activated ifosfamide will be much higher than in the rest of the body thus preventing systemic toxicity. The treatment was successful in animals and showed a doubling in median survivals amongst patients with advanced-stage pancreatic cancer in phase I/II clinical trials, and a tripling in one-year survival rate.\n\nIn treatment of genetic diseases, gene therapy aims to insert, alter or remove genes within an afflicted individual's cells. The technology relies heavily on viral vectors which raises concerns about insertional mutagenesis and systemic immune response that have led to human deaths and development of leukemia in clinical trials. Circumventing the need for vectors by using naked or plasmid DNA as its own delivery system also encounters problems such as low transduction efficiency and poor tissue targeting when given systemically.\n\nArtificial cells have been proposed as a non-viral vector by which genetically modified non-autologous cells are encapsulated and implanted to deliver recombinant proteins \"in vivo\". This type of immuno-isolation has been proven efficient in mice through delivery of artificial cells containing mouse growth hormone which rescued a growth-retardation in mutant mice. A few strategies have advanced to human clinical trials for the treatment of pancreatic cancer, lateral sclerosis and pain control.\n\nThe first clinical use of artificial cells was in hemoperfusion by the encapsulation of activated charcoal. Activated charcoal has the capability of adsorbing many large molecules and has for a long time been known for its ability to remove toxic substances from the blood in accidental poisoning or overdose. However, perfusion through direct charcoal administration is toxic as it leads to embolisms and damage of blood cells followed by removal by platelets. Artificial cells allow toxins to diffuse into the cell while keeping the dangerous cargo within their ultrathin membrane.\n\nArtificial cell hemoperfusion has been proposed as a less costly and more efficient detoxifying option than hemodialysis, in which blood filtering takes place only through size separation by a physical membrane. In hemoperfusion, thousands of adsorbent artificial cells are retained inside a small container through the use of two screens on either end through which patient blood perfuses. As the blood circulates, toxins or drugs diffuse into the cells and are retained by the absorbing material. The membranes of artificial cells are much thinner those used in dialysis and their small size means that they have a high membrane surface area. This means that a portion of cell can have a theoretical mass transfer that is a hundredfold higher than that of a whole artificial kidney machine. The device has been established as a routine clinical method for patients treated for accidental or suicidal poisoning but has also been introduced as therapy in liver failure and kidney failure by carrying out part of the function of these organs.\nArtificial cell hemoperfusion has also been proposed for use in immunoadsorption through which antibodies can be removed from the body by attaching an immunoadsorbing material such as albumin on the surface of the artificial cells. This principle has been used to remove blood group antibodies from plasma for bone marrow transplantation and for the treatment of hypercholesterolemia through monoclonal antibodies to remove low-density lipoproteins. Hemoperfusion is especially useful in countries with a weak hemodialysis manufacturing industry as the devices tend to be cheaper there and used in kidney failure patients.\n\nThe most common method of preparation of artificial cells is through cell encapsulation. Encapsulated cells are typically achieved through the generation of controlled-size droplets from a liquid cell suspension which are then rapidly solidified or gelated to provide added stability. The stabilization may be achieved through a change in temperature or via material crosslinking. The microenvironment that a cell sees changes upon encapsulation. It typically goes from being on a monolayer to a suspension in a polymer scaffold within a polymeric membrane. A drawback of the technique is that encapsulating a cell decreases its viability and ability to proliferate and differentiate. Further, after some time within the microcapsule, cells form clusters that inhibit the exchange of oxygen and metabolic waste, leading to apoptosis and necrosis thus limiting the efficacy of the cells and activating the host's immune system.\nArtificial cells have been successful for transplanting a number of cells including islets of Langerhans for diabetes treatment, parathyroid cells and adrenal cortex cells.\n\nShortage of organ donors make artificial cells key players in alternative therapies for liver failure. The use of artificial cells for hepatocyte transplantation has demonstrated feasibility and efficacy in providing liver function in models of animal liver disease and bioartificial liver devices. Research stemmed off experiments in which the hepatocytes were attached to the surface of a micro-carriers and has evolved into hepatocytes which are encapsulated in a three-dimensional matrix in alginate microdroplets covered by an outer skin of polylysine. A key advantage to this delivery method is the circumvention of immunosuppression therapy for the duration of the treatment. Hepatocyte encapsulations have been proposed for use in a bioartifical liver. The device consists of a cylindrical chamber imbedded with isolated hepatocytes through which patient plasma is circulated extra-corporeally in a type of hemoperfusion. Because microcapsules have a high surface area to volume ratio, they provide large surface for substrate diffusion and can accommodate a large number of hepatocytes. Treatment to induced liver failure mice showed a significant increase in the rate of survival. Artificial liver systems are still in early development but show potential for patients waiting for organ transplant or while a patient's own liver regenerates sufficiently to resume normal function. So far, clinical trials using artificial liver systems and hepatocyte transplantation in end-stage liver diseases have shown improvement of health markers but have not yet improved survival. The short longevity and aggregation of artificial hepatocytes after transplantation are the main obstacles encountered.\nHepatocytes co-encapsulated with stem cells show greater viability in culture and after implantation and implantation of artificial stem cells alone have also shown liver regeneration. As such interest has arisen in the use of stem cells for encapsulation in regenerative medicine.\n\nThe oral ingestion of live bacterial cell colonies has been proposed and is currently in therapy for the modulation of intestinal microflora, prevention of diarrheal diseases, treatment of \"H. Pylori\" infections, atopic inflammations, lactose intolerance and immune modulation, amongst others. The proposed mechanism of action is not fully understood but is believed to have two main effects. The first is the nutritional effect, in which the bacteria compete with toxin producing bacteria. The second is the sanitary effect, which stimulates resistance to colonization and stimulates immune response. The oral delivery of bacterial cultures is often a problem because they are targeted by the immune system and often destroyed when taken orally. Artificial cells help address these issues by providing mimicry into the body and selective or long term release thus increasing the viability of bacteria reaching the gastrointestinal system. In addition, live bacterial cell encapsulation can be engineered to allow diffusion of small molecules including peptides into the body for therapeutic purposes. Membranes that have proven successful for bacterial delivery include cellulose acetate and variants of alginate. Additional uses that have arosen from encapsulation of bacterial cells include protection against challenge from \"M. Tuberculosis\" and upregulation of Ig secreting cells from the immune system. The technology is limited by the risk of systemic infections, adverse metabolic activities and the risk of gene transfer. However, the greater challenge remains the delivery of sufficient viable bacteria to the site of interest.\n\nNano sized oxygen carriers are used as a type of red blood cell substitutes, although they lack other components of red blood cells. They are composed of a synthetic polymersome or an artificial membrane surrounding purified animal, human or recombinant hemoglobin.\nOverall, hemoglobin delivery continues to be a challenge because it is highly toxic when delivered without any modifications. In some clinical trials, vasopressor effects have been observed for first generation hemoglobin blood substitutes.\n\nResearch interest in the use of artificial cells for blood arose after the AIDS scare of the 1980s. Besides bypassing the potential for disease transmission, artificial red blood cells are desired because they eliminate drawbacks associated with allogenic blood transfusions such as blood typing, immune reactions and its short storage life of 42 days. A hemoglobin substitute may be stored at room temperature and not under refrigeration for more than a year. Attempts have been made to develop a complete working red blood cell which comprises carbonic not only an oxygen carrier but also the enzymes associated with the cell. The first attempt was made in 1957 by replacing the red blood cell membrane by an ultrathin polymeric membrane which was followed by encapsulation through a lipid membrane and more recently a biodegradable polymeric membrane.\nAn biological red blood cell membrane including lipids and associated proteins can also be used to encapsulate nanoparticles and increase residence time in vivo by bypassing macrophage uptake and systemic clearance.\n\nA leuko-polymersome is a polymersome engineered to have the adhesive properties of a leukocyte. Polymersomes are vesicles composed of a bilayer sheet that can encapsulate many active molecules such as drugs or enzymes. By adding the adhesive properties of a leukocyte to their membranes, they can be made to slow down, or roll along epithelial walls within the quickly flowing circulatory system.\n\nThe German pathologist Rudolf Virchow brought forward the idea that not only does life arise from cells, but every cell comes from another cell; \"\"Omnis cellula e cellula\"\". Until now, most attempts to create an artificial cell have only created a package that can mimic certain tasks of the cell. Advances in cell-free transcription and translation reactions allow the expression of many genes, but these efforts are far from producing a fully operational cell.\n\nThe future is in the creation of a protocell, or a cell which has all the minimum requirements for life. Members from the J. Craig Venter Institute have used a top-down computational approach to knock out genes in a living organism to a minimum set of genes. In 2010, the team succeeded in creating a replicating strain of \"Mycoplasma mycoides\" (Mycoplasma laboratorium) using synthetically created DNA deemed to be the minimum requirement for life which was inserted into a genomically empty bacterium. It is hoped that the process of top-down biosynthesis will enable the insertion of new genes that would perform profitable functions such as generation of hydrogen for fuel or capturing excess carbon dioxide in the atmosphere. the myriad regulatory, metabolic, and signaling networks are not completely characterized. These top-down approaches have limitations for the understanding of fundamental molecular regulation, since the host organisms have a complex and incompletely defined molecular composition.\n\nA bottom-up approach to build an artificial cell would involve creating a protocell \"de novo\", entirely from non-living materials. It is proposed to create a phospholipid bilayer vesicle with DNA capable of self-reproducing using synthetic genetic information. The three primary elements of such artificial cells are the formation of a lipid membrane, DNA and RNA replication through a template process and the harvesting of chemical energy for active transport across the membrane. The main hurdles foreseen and encountered with this proposed protocell are the creation of a minimal synthetic DNA that holds all sufficient information for life, and the reproduction of non-genetic components that are integral in cell development such as molecular self-organization. However, it is hoped that this kind of bottom-up approach would provide insight into the fundamental questions of organizations at the cellular level and the origins of biological life. So far, no completely artificial cell capable of self-reproduction has been synthesized using the molecules of life, and this objective is still in a distant future although various groups are currently working towards this goal.\n\nAnother method proposed to create a protocell more closely resembles the conditions believed to have been present during evolution known as the primordial soup. Various RNA polymers could be encapsulated in vesicles and in such small boundary conditions, chemical reactions would be tested for.\n\nHeavy investing in biology has been done by large companies such as ExxonMobil, who has partnered with Synthetic Genomics Inc; Craig Venter's own biosynthetics company in the development of fuel from algae.\n\nThe concept of an Electronic Artificial Cell has been expanded in a series of 3 EU projects coordinated by John McCaskill from 2004-2015.\n\nThe European Commission sponsored the development of the \"Programmable Artificial Cell Evolution\" (PACE) program from 2004-2008 whose goal was to lay the foundation for the creation of \"microscopic self-organizing, self-replicating, and evolvable autonomous entities built from simple organic and inorganic substances that can be genetically programmed to perform specific functions\" for the eventual integration into information systems. The PACE project developed the first Omega Machine, a microfluidic life support system for artificial cells that could complement chemically missing functionalities (as originally proposed by Norman Packard, Steen Rasmussen, Mark Beadau and John McCaskill). The ultimate aim was to attain an evolvable hybrid cell in a complex microscale programmable environment. The functions of the Omega Machine could then be removed stepwise, posing a series of solvable evolution challenges to the artificial cell chemistry. The project achieved chemical integration up to the level of pairs of the three core functions of artificial cells (a genetic subsystem, a containment system and a metabolic system), and generated novel spatially resolved programmable microfluidic environments for the integration of containment and genetic amplification.\"Programmable Artificial Cell Evolution\" (PACE) The project led to the creation of the European center for living technology] which is now continuing similar research.\n\nFollowing this research, in 2007, John McCaskill proposed to concentrate on an electronically complemented artificial cell, called the Electronic Chemical Cell. The key idea was to use a massively parallel array of electrodes coupled to locally dedicated electronic circuitry, in a two-dimensional thin film, to complement emerging chemical cellular functionality. Local electronic information defining the electrode switching and sensing circuits could serve as an electronic genome, complementing the molecular sequential information in the emerging protocols. A research proposal was successful with the European Commission and an international team of scientists partially overlapping with the PACE consortium commenced work 2008-2012 on the project Electronic Chemical Cells. The project demonstrated among other things that electronically controlled local transport of specific sequences could be used as an artificial spatial control system for the genetic proliferation of future artificial cells, and that core processes of metabolism could be delivered by suitably coated electrode arrays.\n\nThe major limitation of this approach, apart from the initial difficulties in mastering microscale electrochemistry and electrokinetics, is that the electronic system is interconnected as a rigid non-autonomous piece of macroscopic hardware. In 2011, McCaskill proposed to invert the geometry of electronics and chemistry : instead of placing chemicals in an active electronic medium, to place microscopic autonomous electronics in a chemical medium. He organized a project to tackle a third generation of Electronic Artificial Cells at the 100 µm scale that could self-assemble from two half-cells \"lablets\" to enclose an internal chemical space, and function with the aid of active electronics powered by the medium they are immersed in. Such cells can copy both their electronic and chemical contents and will be capable of evolution within the constraints provided by their special pre-synthesized microscopic building blocks. In Sep 2012 work commenced on this project Microscale Chemically Reactive Electronic Agents.\n\nProtocell research has created controversy and opposing opinions, including critics of the vague definition of \"artificial life\". The creation of a basic unit of life is the most pressing ethical concern, although the most widespread worry about protocells is their potential threat to human health and the environment through uncontrolled replication.\n\n\n", "id": "4630125", "title": "Artificial cell"}
{"url": "https://en.wikipedia.org/wiki?curid=42262844", "text": "Centralspindlin\n\nCentralspindlin is a motor complex implicated in cell division. It contributes to virtually every step in Cytokinesis, It is highly conserved in animal cells as a component of the spindle midzone and midbody. Centralspindlin is required for the assembly of the mitotic spindle as well as for microtubule bundling and anchoring of midbody microtubules to the plasma membrane. This complex is also implicated in tethering the spindle apparatus to the plasma membrane during cytokinesis This interaction permits cleavage furrow ingression. In addition, centralspindlin's interaction with the ESCRT III allows for abscission to occur.\n\nCentralspindlin is a heteroteramer consisting of two different subunit proteins:\nBoth KIF23 and RacGAP1 dimerize via their parallel coiled coil domain.\nCentralspindlin oligomerizes in order to link the mitotic spindle with the plasma membrane The sequences mediating interactions between KIF23 and RacGAP1 are highly variable between species. However, a high affinity interaction between these subunits is essential for the proper functioning of the Centralspindlin complex.\n\nKIF23 interacts with microtubules at sites of overlap, linking the centraspindlin complex to the mitotic spindle.\nRacGAP1 recruits ECT2 to the central spindle. ECT2 is a Guanine nucleotide-exchange factor for RhoA. Cytokinesis is initiated when RhoA is activated by ECT2.\nRacGAP1 is also involved in tethering the central spindle to the plasma membrane. Without this interaction, cytokinesis cannot occur.\n\n", "id": "42262844", "title": "Centralspindlin"}
{"url": "https://en.wikipedia.org/wiki?curid=42261204", "text": "Bacterial senescence\n\nBacterial senescence or bacterial aging refers to the gradual decrease in cellular function in individual bacterium as they increase in age. Indicators of senescence include a decelerated division rate and an increase likelihood of death.\n\nThe fundamental cause of aging in bacteria is thought to be the accumulation of deleterious components (aging factors). Asymmetrically dividing bacteria, such as \"Caulobacter crescentus\", show signs of replicative aging. The results for symmetrically dividing bacteria are more nuanced. For example, \"Escherichia coli\", under certain experimental conditions, may exhibit signs of replicative aging caused by subtle asymmetries in its division.\n\nAging factors can be defined as irreparable damages to cellular components which ultimately contribute to the decreased fitness of the individual harbouring them. Putative aging factors include damaged DNA strands, old cell-surface material, and mis-folded or aggregated protein. The cell poles of replicating E. \"coli\" are often used as a proxy for aging factors as each bacterium inherits an old cell-pole (mother’s pole) and a newly synthesized new cell-pole. Inclusion bodies, masses of aggregated damaged or mis-folded proteins, have recently been shown to contribute to the aging of cellular organisms.\nSenescence in single celled organisms is thought to arise via the asymmetric partitioning of aging factors between daughter cells. It has long been argued that, on theoretical grounds, the preferential segregation of damage in unicellular organisms would contribute to the fitness of the overall population. The single celled eukaryotic organism, Sacchoaromyces \"cerevisiae\", retains deleterious aging factors in the mother cell leading to rejuvenation of the daughter.\n\n A well established example of bacterial aging is Caulobacter crescentus. This bacteria begins its life as a motile swarmer cell. Once it has found a suitable substrate, the swarmer cell will differentiate into a non-motile stalked cell. The stalked cell then becomes reproductively active and gives rise to new swarmer cells. The number of progeny produced per hour by individual swarmer cells was shown to decrease with age. This was the first evidence of bacterial aging.\n\nOrganisms which replicate via symmetric division, such as E. \"coli\", are thought to be immortal. However, by tracking the inheritance of both the new and old cell pole, evidence of aging was found in \"E. coli\". A cell which has consecutively inherited the old cell pole has been shown to exhibit a significantly decreased growth rate. The decline in growth rate in Stewart et al. appears to be at least partially attributed to the preferential localization of inclusion bodies near the old cell wall. This localization is thought to be the passive result of the slow diffusion of the large aggregate, and the exclusion of the aggregate by the nucleoid. A similar mechanism of aging has been found to occur in Schizosaccharomyces Pombe, which divides via symmetrical binary fission.\n\nHowever, the original findings of \"E. coli\" aging have been partially refuted by more recent microfluidics-based studies, in which individual \"E. coli\" showed a constant growth rate for hundreds of consecutive cell divisions, although the death rate increased in each cell division. This discrepancy may be due to the different culturing methods used in the two studies, i.e., growth on agar pads vs. in a microfludic device.\n", "id": "42261204", "title": "Bacterial senescence"}
{"url": "https://en.wikipedia.org/wiki?curid=23183669", "text": "Homogenization (biology)\n\nIn cell biology or molecular biology research, homogenization is a process whereby a biological sample is brought to a state such that all fractions of the sample are equal in composition. A homogenized sample is equal in composition throughout, so that removing a fraction does not alter the overall molecular make-up of the sample remaining, and is identical to the fraction removed. Homogenization in biology is often followed by molecular extraction and various analytical techniques, including ELISA and western blot.\n\nHomogenization of tissue in solution is often performed simultaneously with cell lysis. To prevent lysis however, the tissue (or collection of cells, e.g. from cell culture) can be kept at temperatures slightly above zero to prevent autolysis, and in an isotonic solution to prevent osmotic damage.\n\nIf freezing the tissue is possible, cryohomogenization can be performed under \"dry\" conditions, and is often the method of choice whenever it is desirable to collect several distinct molecular classes (e.g. both protein and RNA) from a single sample, or combined set of samples, or when long-term storage of part of the sample is desired. Cryohomogenization can be carried out using a supercooled mortar and pestle (classic approach), or the tissue can be homogenized by crushing it into a fine powder inside a clean plastic bag resting against a supercooled solid metal block (more recently developed and more efficient technique).\n\nHigh-pressure homogenization is used to isolate the contents of Gram-positive bacteria, since these cells are exceptionally resistant to lysis, and may be combined with high-temperature sterilization.\n", "id": "23183669", "title": "Homogenization (biology)"}
{"url": "https://en.wikipedia.org/wiki?curid=39515134", "text": "Mass cytometry\n\nMass cytometry is a mass spectrometry technique based on inductively coupled plasma mass spectrometry and time of flight mass spectrometry used for the determination of the properties of cells (cytometry). In this approach, antibodies are conjugated with isotopically pure elements, and these antibodies are used to label cellular proteins. Cells are nebulized and sent through an argon plasma, which ionizes the metal-conjugated antibodies. The metal signals are then analyzed by a time-of-flight mass spectrometer. The approach overcomes limitations of spectral overlap in flow cytometry by utilizing discrete isotopes as a reporter system instead of traditional fluorophores which have broad emission spectra.\n\nTagging technology and instrument development occurred at the University of Toronto and DVS Sciences, Inc. CyTOF (Cytometry by Time of Flight) was initially commercialized by DVS Sciences in 2009. In 2014, Fluidigm acquired DVS Sciences to become a reference company in single cell technology. The CyTOF, CyTOF2, and Helios (CyTOF3) have been commercialized up to now. Fluidigm sells a variety of commonly used metal-antibody conjugates, and an antibody conjugation kit.\n\nMass cytometry data is recorded in tables that list, for each cell, the signal detected per channel, which is proportional to the number of antibodies tagged with the corresponding channel's isotope bound to that cell. These data are formatted as FCS files, which are compatible with traditional flow cytometry software. Due to the high-dimensional nature of mass cytometry data, novel data analysis tools have been developed as well.\n\n\n\nMass cytometry has research applications in medical fields including immunology, hematology, and oncology. It has been used in studies of hematopoiesis, cell cycle, cytokine expression, and differential signaling responses.\n\nHigh efficiency cell introduction system (HECIS) has been recently developed.\n", "id": "39515134", "title": "Mass cytometry"}
{"url": "https://en.wikipedia.org/wiki?curid=42213076", "text": "Biomolecular gradient\n\nA Biomolecular Gradient is established by a difference in the concentration of molecules in a biological system such as individual cells, groups of cells, or an entire organism. A biomolecular gradient can exist intracellularly (within a cell) or extracellularly (between groups of cells). The purposes of such gradients in biological systems vary, but include chemotaxis and functions in development. These types of gradients play a role in many different types of signaling as well as recently being implicated in cancer metastasis.\n\nCells themselves can create biomolecular gradients by releasing signaling molecules that diffuse outwardly. These gradients are critical for cellular identity and cell relocation. Similarly, the gradients produced by cells may influence cellular fate by their temporal and spatial characteristics. In certain organisms, the choice of cell fate can be determined by a gradient, a binary choice, or through a relay of molecules released by a cell. If cell fate is binary, the identity of the cell is influenced by the presence or absence of a signaling molecule; consequently, these signals can also induce cell fate acting in a relay. The relay functions by the source cell releasing a signaling molecule into the environment. Adjacent cells possessing similar cell identities respond to these signals and can release different signaling molecules to cells in their surrounding area, promoting additional new cell fates. This process continues to all cells in the developing organism. In contrast, a signal can act in a gradient, which induces a specific cell fate as a function of the concentration of the molecule in the gradient. These types of molecules are known as morphogens.\n\nAn example of this phenomenon is observed in the neural tube with varying concentrations of the Sonic Hedgehog (Shh) protein. Shh is characterized as a morphogen and possesses spatial and temporal characteristics that make it well suited for study.\n\nBiomolecular gradients have been shown to facilitate the invasion of cancer cells into different types of tissues in the body. Cancer metastasis is thought to be directly coupled to growth factor gradients that facilitate chemotaxis of cancer promoter factors. These chemoattractants promote tumour \"angiogenesis\", namely increased blood flow to tissues allowing the cancer to thrive in different areas of the body. Therefore, this pathway allows for the movement of tumour-promoting molecules toward healthy tissues in the body. Further study is required to quantify pathways involved in the above response and may provide insight into more effective treatment for cancer patients.\n\nIn a similar way, biomolecular gradients can function as signal antagonists that have the potential to drastically affect the cell's characteristics and in turn, the organism's response. This includes allowing the cell to distinguish its orientation or shift the barrier of cell differentiation in a group of cells. For instance, such mechanisms can be used to help the body defend against infection. Specifically, the afflicted area of the body acts as an attractant through ligand-receptor binding. This can occur through the polarity that is established by signal antagonists. In addition, this type of ligand-receptor interaction can lead to a signal cascade that trigger mitosis. A type of gradient molecule that accomplishes the aforementioned mechanism is \"Pom1\".\n", "id": "42213076", "title": "Biomolecular gradient"}
{"url": "https://en.wikipedia.org/wiki?curid=1106830", "text": "Cell culture\n\nCell culture is the process by which cells are grown under controlled conditions, generally outside their natural environment. After the cells of interest have been isolated from living tissue, they can subsequently be maintained under carefully controlled conditions. These conditions vary for each cell type, but generally consist of a suitable vessel with a substrate or medium that supplies the essential nutrients (amino acids, carbohydrates, vitamins, minerals), growth factors, hormones, and gases (CO, O), and regulates the physio-chemical environment (pH buffer, osmotic pressure, temperature). Most cells require a surface or an artificial substrate (adherent or monolayer culture) whereas others can be grown free floating in culture medium (suspension culture). The lifespan of most cells is genetically determined, but some cell culturing cells have been “transformed” into immortal cells which will reproduce indefinitely if the optimal conditions are provided.\n\nIn practice, the term \"cell culture\" now refers to the culturing of cells derived from multicellular eukaryotes, especially animal cells, in contrast with other types of culture that also grow cells, such as plant tissue culture, fungal culture, and microbiological culture (of microbes). The historical development and methods of cell culture are closely interrelated to those of tissue culture and organ culture. Viral culture is also related, with cells as hosts for the viruses.\n\nThe laboratory technique of maintaining live cell lines (a population of cells descended from a single cell and containing the same genetic makeup) separated from their original tissue source became more robust in the middle 20th century.\n\nThe 19th-century English physiologist Sydney Ringer developed salt solutions containing the chlorides of sodium, potassium, calcium and magnesium suitable for maintaining the beating of an isolated animal heart outside the body. In 1885, Wilhelm Roux removed a portion of the medullary plate of an embryonic chicken and maintained it in a warm saline solution for several days, establishing the principle of tissue culture. Ross Granville Harrison, working at Johns Hopkins Medical School and then at Yale University, published results of his experiments from 1907 to 1910, establishing the methodology of tissue culture.\n\nCell culture techniques were advanced significantly in the 1940s and 1950s to support research in virology. Growing viruses in cell cultures allowed preparation of purified viruses for the manufacture of vaccines. The injectable polio vaccine developed by Jonas Salk was one of the first products mass-produced using cell culture techniques. This vaccine was made possible by the cell culture research of John Franklin Enders, Thomas Huckle Weller, and Frederick Chapman Robbins, who were awarded a Nobel Prize for their discovery of a method of growing the virus in monkey kidney cell cultures.\n\nCells can be isolated from tissues for \"ex vivo\" culture in several ways. Cells can be easily purified from blood; however, only the white cells are capable of growth in culture. Cells can be isolated from solid tissues by digesting the extracellular matrix using enzymes such as collagenase, trypsin, or pronase, before agitating the tissue to release the cells into suspension. Alternatively, pieces of tissue can be placed in growth media, and the cells that grow out are available for culture. This method is known as explant culture.\n\nCells that are cultured directly from a subject are known as primary cells. With the exception of some derived from tumors, most primary cell cultures have limited lifespan.\n\nAn established or immortalized cell line has acquired the ability to proliferate indefinitely either through random mutation or deliberate modification, such as artificial expression of the telomerase gene.\nNumerous cell lines are well established as representative of particular cell types.\n\nFor the majority of isolated primary cells, they undergo the process of senescence and stop dividing after a certain number of population doublings while generally retaining their viability (described as the Hayflick limit).\n\nCells are grown and maintained at an appropriate temperature and gas mixture (typically, 37 °C, 5% CO for mammalian cells) in a cell incubator. Culture conditions vary widely for each cell type, and variation of conditions for a particular cell type can result in different phenotypes.Aside from temperature and gas mixture, the most commonly varied factor in culture systems is the cell growth medium. Recipes for growth media can vary in pH, glucose concentration, growth factors, and the presence of other nutrients. The growth factors used to supplement media are often derived from the serum of animal blood, such as fetal bovine serum (FBS), bovine calf serum, equine serum, and porcine serum. One complication of these blood-derived ingredients is the potential for contamination of the culture with viruses or prions, particularly in medical biotechnology applications. Current practice is to minimize or eliminate the use of these ingredients wherever possible and use human platelet lysate (hPL). This eliminates the worry of cross-species contamination when using FBS with human cells. hPL has emerged as a safe and reliable alternative as a direct replacement for FBS or other animal serum. In addition, chemically defined media can be used to eliminate any serum trace (human or animal), but this cannot always be accomplished with different cell types. Alternative strategies involve sourcing the animal blood from countries with minimum BSE/TSE risk, such as The United States, Australia and New Zealand, and using purified nutrient concentrates derived from serum in place of whole animal serum for cell culture.\n\nPlating density (number of cells per volume of culture medium) plays a critical role for some cell types. For example, a lower plating density makes granulosa cells exhibit estrogen production, while a higher plating density makes them appear as progesterone-producing theca lutein cells.\n\nCells can be grown either in suspension or adherent cultures. Some cells naturally live in suspension, without being attached to a surface, such as cells that exist in the bloodstream. There are also cell lines that have been modified to be able to survive in suspension cultures so they can be grown to a higher density than adherent conditions would allow. Adherent cells require a surface, such as tissue culture plastic or microcarrier, which may be coated with extracellular matrix (such as collagen and laminin) components to increase adhesion properties and provide other signals needed for growth and differentiation. Most cells derived from solid tissues are adherent. Another type of adherent culture is organotypic culture, which involves growing cells in a three-dimensional (3-D) environment as opposed to two-dimensional culture dishes. This 3D culture system is biochemically and physiologically more similar to \"in vivo\" tissue, but is technically challenging to maintain because of many factors (e.g. diffusion).\n\nCell line cross-contamination can be a problem for scientists working with cultured cells. Studies suggest anywhere from 15–20% of the time, cells used in experiments have been misidentified or contaminated with another cell line. Problems with cell line cross-contamination have even been detected in lines from the NCI-60 panel, which are used routinely for drug-screening studies. Major cell line repositories, including the American Type Culture Collection (ATCC), the European Collection of Cell Cultures (ECACC) and the German Collection of Microorganisms and Cell Cultures (DSMZ), have received cell line submissions from researchers that were misidentified by them. Such contamination poses a problem for the quality of research produced using cell culture lines, and the major repositories are now authenticating all cell line submissions. ATCC uses short tandem repeat (STR) DNA fingerprinting to authenticate its cell lines.\n\nTo address this problem of cell line cross-contamination, researchers are encouraged to authenticate their cell lines at an early passage to establish the identity of the cell line. Authentication should be repeated before freezing cell line stocks, every two months during active culturing and before any publication of research data generated using the cell lines. Many methods are used to identify cell lines, including isoenzyme analysis, human lymphocyte antigen (HLA) typing, chromosomal analysis, karyotyping, morphology and STR analysis.\n\nOne significant cell-line cross contaminant is the immortal HeLa cell line.\n\nAs cells generally continue to divide in culture, they generally grow to fill the available area or volume. This can generate several issues:\n\n\nAmong the common manipulations carried out on culture cells are media changes, passaging cells, and transfecting cells.\nThese are generally performed using tissue culture methods that rely on aseptic technique. Aseptic technique aims to avoid contamination with bacteria, yeast, or other cell lines. Manipulations are typically carried out in a biosafety hood or laminar flow cabinet to exclude contaminating micro-organisms. Antibiotics (e.g. penicillin and streptomycin) and antifungals (e.g.amphotericin B) can also be added to the growth media.\n\nAs cells undergo metabolic processes, acid is produced and the pH decreases. Often, a pH indicator is added to the medium to measure nutrient depletion.\n\nIn the case of adherent cultures, the media can be removed directly by aspiration, and then is replaced. Media changes in non-adherent cultures involve centrifuging the culture and resuspending the cells in fresh media.\n\nPassaging (also known as subculture or splitting cells) involves transferring a small number of cells into a new vessel. Cells can be cultured for a longer time if they are split regularly, as it avoids the senescence associated with prolonged high cell density. Suspension cultures are easily passaged with a small amount of culture containing a few cells diluted in a larger volume of fresh media. For adherent cultures, cells first need to be detached; this is commonly done with a mixture of trypsin-EDTA; however, other enzyme mixes are now available for this purpose. A small number of detached cells can then be used to seed a new culture. Some cell cultures, such as RAW cells are mechanically scraped from the surface of their vessel with rubber scrapers.\n\nAnother common method for manipulating cells involves the introduction of foreign DNA by transfection. This is often performed to cause cells to express a gene of interest. More recently, the transfection of RNAi constructs have been realized as a convenient mechanism for suppressing the expression of a particular gene/protein. DNA can also be inserted into cells using viruses, in methods referred to as transduction, infection or transformation. Viruses, as parasitic agents, are well suited to introducing DNA into cells, as this is a part of their normal course of reproduction.\n\nCell lines that originate with humans have been somewhat controversial in bioethics, as they may outlive their parent organism and later be used in the discovery of lucrative medical treatments. In the pioneering decision in this area, the Supreme Court of California held in \"Moore v. Regents of the University of California\" that human patients have no property rights in cell lines derived from organs removed with their consent.\nIt is possible to fuse normal cells with an immortalised cell line. This method is used to produce monoclonal antibodies. In brief, lymphocytes isolated from the spleen (or possibly blood) of an immunised animal are combined with an immortal myeloma cell line (B cell lineage) to produce a hybridoma which has the antibody specificity of the primary lymphocyte and the immortality of the myeloma. Selective growth medium (HA or HAT) is used to select against unfused myeloma cells; primary lymphoctyes die quickly in culture and only the fused cells survive. These are screened for production of the required antibody, generally in pools to start with and then after single cloning.\n\nA cell strain is derived either from a primary culture or a cell line by the selection or cloning of cells having specific properties or characteristics which must be defined. Cell strains are cells that have been adapted to culture but, unlike cell lines, have a finite division potential. Non-immortalized cells stop dividing after 40 to 60 population doublings and, after this, they lose their ability to proliferate (a genetically determined event known as senescence).\n\nMass culture of animal cell lines is fundamental to the manufacture of viral vaccines and other products of biotechnology. Culture of human stem cells is used to expand the number of cells and differentiate the cells into various somatic cell types for transplantation. Stem cell culture is also used to harvest the molecules and exosomes that the stem cells release for the purposes of therapeutic development.\n\nBiological products produced by recombinant DNA (rDNA) technology in animal cell cultures include enzymes, synthetic hormones, immunobiologicals (monoclonal antibodies, interleukins, lymphokines), and anticancer agents. Although many simpler proteins can be produced using rDNA in bacterial cultures, more complex proteins that are glycosylated (carbohydrate-modified) currently must be made in animal cells. An important example of such a complex protein is the hormone erythropoietin. The cost of growing mammalian cell cultures is high, so research is underway to produce such complex proteins in insect cells or in higher plants, use of single embryonic cell and somatic embryos as a source for direct gene transfer via particle bombardment, transit gene expression and confocal microscopy observation is one of its applications. It also offers to confirm single cell origin of somatic embryos and the asymmetry of the first cell division, which starts the process.\n\nCell culture is also a key technique for cellular agriculture, which aims to provide both new products and new ways of producing existing agricultural products like milk, (cultured) meat, fragrances, and rhino horn from cells and microorganisms. It is therefore considered one means of achieving animal-free agriculture. It is also a central tool for teaching cell biology.\n\nResearch in tissue engineering, stem cells and molecular biology primarily involves cultures of cells on flat plastic dishes. This technique is known as two-dimensional (2D) cell culture, and was first developed by Wilhelm Roux who, in 1885, removed a portion of the medullary plate of an embryonic chicken and maintained it in warm saline for several days on a flat glass plate. From the advance of polymer technology arose today's standard plastic dish for 2D cell culture, commonly known as the Petri dish. Julius Richard Petri, a German bacteriologist, is generally credited with this invention while working as an assistant to Robert Koch. Various researchers today also utilize culturing laboratory flasks, conicals, and even disposable bags like those used in single-use bioreactors.\n\nAside from Petri dishes, scientists have long been growing cells within biologically derived matrices such as collagen or fibrin, and more recently, on synthetic hydrogels such as polyacrylamide or PEG. They do this in order to elicit phenotypes that are not expressed on conventionally rigid substrates. There is growing interest in controlling matrix stiffness, a concept that has led to discoveries in fields such as:\n\n\nCell culture in three dimensions has been touted as \"Biology's New Dimension\". At present, the practice of cell culture remains based on varying combinations of single or multiple cell structures in 2D. Currently, there is an increase in use of 3D cell cultures in research areas including drug discovery, cancer biology, regenerative medicine and basic life science research. 3D cell cultures can be grown using a scaffold or matrix, or in a scaffold-free manner. Scaffold based cultures utilize an acellular 3D matrix or a liquid matrix. Scaffold-free methods are normally generated in suspensions. There are a variety of platforms used to facilitate the growth of three-dimensional cellular structures including scaffold systems such as hydrogel matrices and solid scaffolds, and scaffold-free systems such as low-adhesion plates, nanoparticle facilitated magnetic levitation, and hanging drop plates.\n\n3D cell culture in scaffolds\n\nEric Simon, in a 1988 NIH SBIR grant report, showed that electrospinning could be used to produced nano- and submicron-scale polystyrene and polycarbonate fibrous scaffolds specifically intended for use as \"in vitro\" cell substrates. This early use of electrospun fibrous lattices for cell culture and tissue engineering showed that various cell types including Human Foreskin Fibroblasts (HFF), transformed Human Carcinoma (HEp-2), and Mink Lung Epithelium (MLE) would adhere to and proliferate upon polycarbonate fibers. It was noted that, as opposed to the flattened morphology typically seen in 2D culture, cells grown on the electrospun fibers exhibited a more histotypic rounded 3-dimensional morphology generally observed \"in vivo\".\n\nAs the natural extracellular matrix (ECM) is important in the survival, proliferation, differentiation and migration of cells, different hydrogel culture matrices mimicking natural ECM structure are seen as potential approaches to in vivo –like cell culturing. Hydrogels are composed of interconnected pores with high water retention, which enables efficient transport of substances such as nutrients and gases. Several different types of hydrogels from natural and synthetic materials are available for 3D cell culture, including animal ECM extract hydrogels, protein hydrogels, peptide hydrogels, polymer hydrogels, and wood-based nanocellulose hydrogel.\n\nThe 3D Cell Culturing by Magnetic Levitation method (MLM) is the application of growing 3D tissue by inducing cells treated with magnetic nanoparticle assemblies in spatially varying magnetic fields using neodymium magnetic drivers and promoting cell to cell interactions by levitating the cells up to the air/liquid interface of a standard petri dish. The magnetic nanoparticle assemblies consist of magnetic iron oxide nanoparticles, gold nanoparticles, and the polymer polylysine. 3D cell culturing is scalable, with the capability for culturing 500 cells to millions of cells or from single dish to high-throughput low volume systems.\n\nCell culture is a fundamental component of tissue culture and tissue engineering, as it establishes the basics of growing and maintaining cells \"in vitro\".\nThe major application of human cell culture is in stem cell industry, where mesenchymal stem cells can be cultured and cryopreserved for future use. Tissue engineering potentially offers dramatic improvements in low cost medical care for hundreds of thousands of patients annually.\n\nVaccines for polio, measles, mumps, rubella, and chickenpox are currently made in cell cultures. Due to the H5N1 pandemic threat, research into using cell culture for influenza vaccines is being funded by the United States government. Novel ideas in the field include recombinant DNA-based vaccines, such as one made using human adenovirus (a common cold virus) as a vector,\nand novel adjuvants.\n\nBesides the culture of well-established immortalised cell lines, cells from primary explants of a plethora of organisms can be cultured for a limited period of time before sensecence occurs (see Hayflick's limit). Cultured primary cells have been extensively used in research, as is the case of fish keratocytes in cell migration studies.\n\nPlant cell cultures are typically grown as cell suspension cultures in a liquid medium or as callus cultures on a solid medium. The culturing of undifferentiated plant cells and calli requires the proper balance of the plant growth hormones auxin and cytokinin.\n\nCells derived from Drosophila melanogaster (most prominently, Schneider 2 cells) can be used for experiments which may be hard to do on live flies or larvae, such as biochemical studies or studies using siRNA. Cell lines derived from the army worm \"Spodoptera frugiperda\", including Sf9 and Sf21, and from the cabbage looper \"Trichoplusia ni\", High Five cells, are commonly used for expression of recombinant proteins using baculovirus.\n\nFor bacteria and yeasts, small quantities of cells are usually grown on a solid support that contains nutrients embedded in it, usually a gel such as agar, while large-scale cultures are grown with the cells suspended in a nutrient broth.\n\nThe culture of viruses requires the culture of cells of mammalian, plant, fungal or bacterial origin as hosts for the growth and replication of the virus. Whole wild type viruses, recombinant viruses or viral products may be generated in cell types other than their natural hosts under the right conditions. Depending on the species of the virus, infection and viral replication may result in host cell lysis and formation of a viral plaque.\n\n\n\n\n\n\n\n\n", "id": "1106830", "title": "Cell culture"}
{"url": "https://en.wikipedia.org/wiki?curid=42067494", "text": "Neuronal tiling\n\nNeuronal tiling is a phenomenon in which multiple arbors of neurons innervate the same surface or tissue in a nonredundant and tiled pattern that maximizes coverage of the surface while minimizing overlap between neighboring arbors. Hence, dendrites of the same neuron spread out by avoiding one another (self-avoidance). Moreover, dendrites of certain types of neurons such as class III and class IV dendritic arborization neurons avoid dendrites of neighboring neurons of the same type (tiling), whereas dendrites of different neuronal types can cover the same territory (coexistence).\n\nOne good example of this organization is the cell bodies of virtually all retinal cell types which are arranged as independent, nonrandom mosaics that maximize the distance between neighbouring cells.\n\nElucidating the mechanisms of process spacing during development is therefore relevant for understanding principles of tissue organization inside and outside of the nervous system.\n", "id": "42067494", "title": "Neuronal tiling"}
{"url": "https://en.wikipedia.org/wiki?curid=169270", "text": "Macrophage\n\nMacrophages (pronunciation: /ˈmakrə(ʊ)feɪdʒ/ | , from Greek \"μακρός\" (\"makrós\") = large, \"φαγείν\" (\"phageín\") = to eat) are a type of white blood cell that engulfs and digests cellular debris, foreign substances, microbes, cancer cells, and anything else that does not have the types of proteins specific to healthy body cells on its surface in a process called phagocytosis. These large phagocytes are found in essentially all tissues, where they patrol for potential pathogens by amoeboid movement. They take various forms (with various names) throughout the body (e.g., histiocytes, Kupffer cells, alveolar macrophages, microglia, and others), but all are part of the mononuclear phagocyte system. Besides phagocytosis, they play a critical role in nonspecific defense (innate immunity) and also help initiate specific defense mechanisms (adaptive immunity) by recruiting other immune cells such as lymphocytes. For example, they are important as antigen presenters to T cells. In humans, dysfunctional macrophages cause severe diseases such as chronic granulomatous disease that result in frequent infections.\n\nBeyond increasing inflammation and stimulating the immune system, macrophages also play an important anti-inflammatory role and can decrease immune reactions through the release of cytokines. Macrophages that encourage inflammation are called M1 macrophages, whereas those that decrease inflammation and encourage tissue repair are called M2 macrophages. This difference is reflected in their metabolism; M1 macrophages have the unique ability to metabolize arginine to the \"killer\" molecule nitric oxide, whereas rodent M2 macrophages have the unique ability to metabolize arginine to the \"repair\" molecule ornithine. However, this dichotomy has been recently questioned as further complexity has been discovered.\n\nHuman macrophages are about in diameter and are produced by the differentiation of monocytes in tissues. They can be identified using flow cytometry or immunohistochemical staining by their specific expression of proteins such as CD14, CD40, CD11b, CD64, F4/80 (mice)/EMR1 (human), lysozyme M, MAC-1/MAC-3 and CD68.\n\nMacrophages were first discovered by Élie Metchnikoff, a Russian zoologist, in 1884.\n\nWhen a monocyte enters damaged tissue through the endothelium of a blood vessel, a process known as the leukocyte extravasation, it undergoes a series of changes to become a macrophage. Monocytes are attracted to a damaged site by chemical substances through chemotaxis, triggered by a range of stimuli including damaged cells, pathogens and cytokines released by macrophages already at the site. At some sites such as the testis, macrophages have been shown to populate the organ through proliferation. Unlike short-lived neutrophils, macrophages survive longer in the body, up to several months.\n\nMacrophages are professional phagocytes and are highly specialized in removal of dying or dead cells and cellular debris. This role is important in chronic inflammation, as the early stages of inflammation are dominated by neutrophils, which are ingested by macrophages if they come of age (see CD31 for a description of this process).\n\nThe neutrophils are at first attracted to a site, where they proliferate, before they are phagocytized by the macrophages. When at the site, the first wave of neutrophils, after the process of aging and after the first 48 hours, stimulate the appearance of the macrophages whereby these macrophages will then ingest the aged neutrophils.\n\nThe removal of dying cells is, to a greater extent, handled by \"fixed macrophages\", which will stay at strategic locations such as the lungs, liver, neural tissue, bone, spleen and connective tissue, ingesting foreign materials such as pathogens and recruiting additional macrophages if needed.\n\nWhen a macrophage ingests a pathogen, the pathogen becomes trapped in a phagosome, which then fuses with a lysosome. Within the phagolysosome, enzymes and toxic peroxides digest the pathogen. However, some bacteria, such as \"Mycobacterium tuberculosis\", have become resistant to these methods of digestion. Typhoidal \"Salmonellae\" induce their own phagocytosis by host macrophages in vivo, and inhibit digestion by lysosomal action, thereby using macrophages for their own replication and causing macrophage apoptosis. Macrophages can digest more than 100 bacteria before they finally die due to their own digestive compounds.\n\nMacrophages are versatile cells that play many roles. As scavengers, they rid the body of worn-out cells and other debris. Along with dendritic cells, they are foremost among the cells that present antigens, a crucial role in initiating an immune response. As secretory cells, monocytes and macrophages are vital to the regulation of immune responses and the development of inflammation; they produce a wide array of powerful chemical substances (monokines) including enzymes, complement proteins, and regulatory factors such as interleukin-1. At the same time, they carry receptors for lymphokines that allow them to be \"activated\" into single-minded pursuit of microbes and tumour cells.\n\nAfter digesting a pathogen, a macrophage will present the antigen (a molecule, most often a protein found on the surface of the pathogen and used by the immune system for identification) of the pathogen to the corresponding helper T cell. The presentation is done by integrating it into the cell membrane and displaying it attached to an MHC class II molecule (MHCII), indicating to other white blood cells that the macrophage is not a pathogen, despite having antigens on its surface.\n\nEventually, the antigen presentation results in the production of antibodies that attach to the antigens of pathogens, making them easier for macrophages to adhere to with their cell membrane and phagocytose. In some cases, pathogens are very resistant to adhesion by the macrophages.\n\nThe antigen presentation on the surface of infected macrophages (in the context of MHC class II) in a lymph node stimulates TH1 (type 1 helper T cells) to proliferate (mainly due to IL-12 secretion from the macrophage). When a B-cell in the lymph node recognizes the same unprocessed surface antigen on the bacterium with its surface bound antibody, the antigen is endocytosed and processed. The processed antigen is then presented in MHCII on the surface of the B-cell. T cells that express the T cell receptor which recognizes the antigen-MHCII complex (with co-stimulatory factors- CD40 and CD40L) cause the B-cell to produce antibodies that help opsonisation of the antigen so that the bacteria can be better cleared by phagocytes.\n\nMacrophages provide yet another line of defense against tumor cells and somatic cells infected with fungus or parasites. Once a T cell has recognized its particular antigen on the surface of an aberrant cell, the T cell becomes an activated effector cell, producing chemical mediators known as lymphokines that stimulate macrophages into a more aggressive form.\n\nThere are several activated forms of macrophages. In spite of a spectrum of ways to activate macrophages, there are two main groups designated M1 and M2. M1 macrophages: as mentioned earlier (previously referred to as classically activated macrophages), M1 \"killer\" macrophages are activated by LPS and IFN-gamma, and secrete high levels of IL-12 and low levels of IL-10. In contrast, the M2 \"repair\" designation (also referred to as alternatively activated macrophages) broadly refers to macrophages that function in constructive processes like wound healing and tissue repair, and those that turn off damaging immune system activation by producing anti-inflammatory cytokines like IL-10. M2 is the phenotype of resident tissue macrophages, and can be further elevated by IL-4. M2 macrophages produce high levels of IL-10, TGF-beta and low levels of IL-12. Tumor-associated macrophages are mainly of the M2 phenotype, and seem to actively promote tumor growth.\n\nBoth M1 and M2 macrophages play a role in promotion of atherosclerosis. M1 macrophages promote atherosclerosis by inflammation. M2 macrophages can remove cholesterol from blood vessels, but when the cholesterol is oxidized, the M2 macrophages become apoptotic foam cells contributing to the atheromatous plaque of atherosclerosis.\n\nThe first step to understanding the importance of macrophages in muscle repair, growth, and regeneration is that there are two \"waves\" of macrophages with the onset of damageable muscle use – subpopulations that do and do not directly have an influence on repairing muscle. The initial wave is a phagocytic population that comes along during periods of increased muscle use that are sufficient to cause muscle membrane lysis and membrane inflammation, which can enter and degrade the contents of injured muscle fibers. These early-invading, phagocytic macrophages reach their highest concentration about 24 hours following the onset of some form of muscle cell injury or reloading. Their concentration rapidly declines after 48 hours. The second group is the non-phagocytic types that are distributed near regenerative fibers. These peak between two and four days and remain elevated for several days during the hopeful muscle rebuilding. The first subpopulation has no direct benefit to repairing muscle, while the second non-phagocytic group does.\n\nIt is thought that macrophages release soluble substances that influence the proliferation, differentiation, growth, repair, and regeneration of muscle, but at this time the factor that is produced to mediate these effects is unknown. It is known that macrophages' involvement in promoting tissue repair is not muscle specific; they accumulate in numerous tissues during the healing process phase following injury.\n\nMacrophages are essential for wound healing. They replace polymorphonuclear neutrophils as the predominant cells in the wound by day two after injury. Attracted to the wound site by growth factors released by platelets and other cells, monocytes from the bloodstream enter the area through blood vessel walls. Numbers of monocytes in the wound peak one to one and a half days after the injury occurs. Once they are in the wound site, monocytes mature into macrophages. The spleen contains half the body's monocytes in reserve ready to be deployed to injured tissue.\n\nThe macrophage's main role is to phagocytize bacteria and damaged tissue, and they also debride damaged tissue by releasing proteases. Macrophages also secrete a number of factors such as growth factors and other cytokines, especially during the third and fourth post-wound days. These factors attract cells involved in the proliferation stage of healing to the area. Macrophages may also restrain the contraction phase. Macrophages are stimulated by the low oxygen content of their surroundings to produce factors that induce and speed angiogenesis and they also stimulate cells that reepithelialize the wound, create granulation tissue, and lay down a new extracellular matrix. By secreting these factors, macrophages contribute to pushing the wound healing process into the next phase.\n\nScientists have elucidated that as well as eating up material debris, macrophages are involved in the typical limb regeneration in the salamander. They found that removing the macrophages from a salamander resulted in failure of limb regeneration and a scarring response.\n\nAs described above, macrophages play a key role in removing dying or dead cells and cellular debris. Erythrocytes have a lifespan on average of 120 days and so are constantly being destroyed by macrophages in the spleen and liver. Macrophages will also engulf macromolecules, and so play a key role in the pharmacokinetics of parenteral irons.\n\nThe iron that is released from the haemoglobin is either stored internally in ferritin or is released into the circulation via ferroportin. In cases where systemic iron levels are raised, or where inflammation is present, raised levels of hepcidin act on macrophage ferroportin channels, leading to iron remaining within the macrophages.\n\nA majority of macrophages are stationed at strategic points where microbial invasion or accumulation of foreign particles is likely to occur. These cells together as a group are known as the mononuclear phagocyte system and were previously known as the reticuloendothelial system. Each type of macrophage, determined by its location, has a specific name:\n\nInvestigations concerning Kupffer cells are hampered because in humans, Kupffer cells are only accessible for immunohistochemical analysis from biopsies or autopsies. From rats and mice, they are difficult to isolate, and after purification, only approximately 5 million cells can be obtained from one mouse.\n\nMacrophages can express paracrine functions within organs that are specific to the function of that organ. In the testis for example, macrophages have been shown to be able to interact with Leydig cells by secreting 25-hydroxycholesterol, an oxysterol that can be converted to testosterone by neighbouring Leydig cells. Also, testicular macrophages may participate in creating an immune privileged environment in the testis, and in mediating infertility during inflammation of the testis.\n\nCardiac resident macrophages participate in electrical conduction via gap junction communication with cardiac myocytes.\n\nMacrophages can be classified on basis of the fundamental function and activation. According to this grouping there are classically activated macrophages, wound-healing macrophages (alternatively activated macrophages) and regulatory macrophages (Mregs).\n\nDue to their role in phagocytosis, macrophages are involved in many diseases of the immune system. For example, they participate in the formation of granulomas, inflammatory lesions that may be caused by a large number of diseases. Some disorders, mostly rare, of ineffective phagocytosis and macrophage function have been described, for example.\n\nIn their role as a phagocytic immune cell macrophages are responsible for engulfing pathogens to destroy them. Some pathogens subvert this process and instead live inside the macrophage. This provides an environment in which the pathogen is hidden from the immune system and allows it to replicate.\n\nDiseases with this type of behaviour include tuberculosis (caused by \"Mycobacterium tuberculosis\") and leishmaniasis (caused by \"Leishmania\" species).\n\nIn order to minimize the possibility of becoming the host of an intracellular bacteria, macrophages have evolved defense mechanisms such as induction of nitric oxide and reactive oxygen intermediates, which are toxic to microbes. Macrophages have also evolved the ability to restrict the microbe's nutrient supply and induce autophagy. \n\nOnce engulfed by a macrophage, the causative agent of tuberculosis, \"Mycobacterium tuberculosis\", avoids cellular defenses and uses the cell to replicate.\n\nUpon phagocytosis by a macrophage, the \"Leishmania\" parasite finds itself in a phagocytic vacuole. Under normal circumstances, this phagocytic vacuole would develop into a lysosome and its contents would be digested. \"Leishmania\" alter this process and avoid being destroyed; instead, they make a home inside the vacuole.\n\nInfection of macrophages in joints is associated with local inflammation during and after the acute phase of \"Chikungunya\" (caused by CHIKV or Chikungunya virus).\n\nAdenovirus (most common cause of pink eye) can remain latent in a host macrophage, with continued viral shedding 6–18 months after initial infection.\n\n\"Brucella spp.\" can remain latent in a macrophage via inhibition of phagosome–lysosome fusion; causes brucellosis (undulant fever).\n\n\"Legionella pneumophila\", the causative agent of Legionnaires' disease, also establishes residence within macrophages.\n\nMacrophages are the predominant cells involved in creating the progressive plaque lesions of atherosclerosis.\n\nFocal recruitment of macrophages occurs after the onset of acute myocardial infarction. These macrophages function to remove debris, apoptotic cells and to prepare for tissue regeneration.\n\nMacrophages also play a role in human immunodeficiency virus (HIV) infection. Like T cells, macrophages can be infected with HIV, and even become a reservoir of ongoing virus replication throughout the body. HIV can enter the macrophage through binding of gp120 to CD4 and second membrane receptor, CCR5 (a chemokine receptor). Both circulating monocytes and macrophages serve as a reservoir for the virus. Macrophages are better able to resist infection by HIV-1 than CD4+ T cells, although susceptibility to HIV infection differs among macrophage subtypes.\n\nMacrophages contribute to tumor growth and progression. Attracted to oxygen-starved (hypoxic) and necrotic tumor cells they promote chronic inflammation. Inflammatory compounds such as tumor necrosis factor (TNF)-alpha released by the macrophages activate the gene switch nuclear factor-kappa B. NF-κB then enters the nucleus of a tumor cell and turns on production of proteins that stop apoptosis and promote cell proliferation and inflammation. Moreover, macrophages serve as a source for many pro-angiogenic factors including vascular endothelial factor (VEGF), tumor necrosis factor-alpha (TNF-alpha), macrophage colony-stimulating factor (M-CSF/CSF1) and IL-1 and IL-6 contributing further to the tumor growth. Macrophages have been shown to infiltrate a number of tumors. Their number correlates with poor prognosis in certain cancers including cancers of breast, cervix, bladder and brain. Tumor-associated macrophages (TAMs) are thought to acquire an M2 phenotype, contributing to tumor growth and progression. Research in various study models suggests that the co-operation of T-cells and macrophages is important to suppress tumors. This co-operation involves not only the direct contact of T-cell and macrophage, with antigen presentation, but also includes the secretion of adequate combinations of cytokines, which enhance T-cell antitumor activity. Recent study findings suggest that by forcing IFN-α expression in tumor-infiltrating macrophages, it is possible to blunt their innate protumoral activity and reprogram the tumor microenvironment toward more effective dendritic cell activation and immune effector cell cytotoxicity.\n\nIncreased number of pro-inflammatory macrophages within obese adipose tissue contributes to obesity complications including insulin resistance and diabetes type 2.\n\nWithin the fat (adipose) tissue of CCR2 deficient mice, there is an increased number of eosinophils, greater alternative Macrophage activation, and a propensity towards type 2 cytokine expression. Furthermore, this effect was exaggerated when the mice became obese from a high fat diet.\n\n\n", "id": "169270", "title": "Macrophage"}
{"url": "https://en.wikipedia.org/wiki?curid=42637669", "text": "List of countries by stem cell research trials\n\nThis is a list of countries by stem cell research trials for the purpose of commercializing treatments as of March 2014, using data from ClinicalTrials.gov.\n", "id": "42637669", "title": "List of countries by stem cell research trials"}
{"url": "https://en.wikipedia.org/wiki?curid=18952443", "text": "Osmoregulation\n\nOsmoregulation is the active regulation of the osmotic pressure of an organism's body fluids, detected by osmoreceptors, to maintain the homeostasis of the organism's water content; that is, it maintains the fluid balance and the concentration of electrolytes (salts in solution) to keep the fluids from becoming too diluted or concentrated. Osmotic pressure is a measure of the tendency of water to move into one solution from another by osmosis. The higher the osmotic pressure of a solution, the more water tends to move into it. Pressure must be exerted on the hypertonic side of a selectively permeable membrane to prevent diffusion of water by osmosis from the side containing pure water.\n\nOrganisms in aquatic and terrestrial environments must maintain the right concentration of solutes and amount of water in their body fluids; this involves excretion (getting rid of metabolic nitrogen wastes and other substances such as hormones that would be toxic if allowed to accumulate in the blood) through organs such as the skin and the kidneys.\n\nTwo major types of osmoregulation are osmoconformers and osmoregulators. Osmoconformers match their body osmolarity to their environment actively or passively. Most marine invertebrates are osmoconformers, although their ionic composition may be different from that of seawater.\n\nOsmoregulators tightly regulate their body osmolarity, maintaining constant internal conditions. They are more common in the animal kingdom. Osmoregulators actively control salt concentrations despite the salt concentrations in the environment. An example is freshwater fish. The gills actively uptake salt from the environment by the use of mitochondria-rich cells. Water will diffuse into the fish, so it excretes a very hypotonic (dilute) urine to expel all the excess water. A marine fish has an internal osmotic concentration lower than that of the surrounding seawater, so it tends to lose water and gain salt. It actively excretes salt out from the gills. Most fish are stenohaline, which means they are restricted to either salt or fresh water and cannot survive in water with a different salt concentration than they are adapted to. However, some fish show a tremendous ability to effectively osmoregulate across a broad range of salinities; fish with this ability are known as euryhaline species, e.g., Flounder. Flounder have been observed to inhabit two utterly disparate environments—marine and fresh water—and it is inherent to adapt to both by bringing in behavioral and physiological modifications.\n\nSome marine fish, like sharks, have adopted a different, efficient mechanism to conserve water, i.e., osmoregulation. They retain urea in their blood in relatively higher concentration. Urea damages living tissues so, to cope with this problem, some fish retain trimethylamine oxide. This provides a better solution to urea's toxicity. Sharks, having slightly higher solute concentration (i.e., above 1000 mOsm which is sea solute concentration), do not drink water like fresh water fish.\n\nWhile there are no specific osmoregulatory organs in higher plants, the stomata are important in regulating water loss through evapotranspiration, and on the cellular level the vacuole is crucial in regulating the concentration of solutes in the cytoplasm. Strong winds, low humidity and high temperatures all increase evapotranspiration from leaves. Abscisic acid is an important hormone in helping plants to conserve water—it causes stomata to close and stimulates root growth so that more water can be absorbed.\n\nPlants share with animals the problems of obtaining water but, unlike in animals, the loss of water in plants is crucial to create a driving force to move nutrients from the soil to tissues. Certain plants have evolved methods of water conservation.\n\nXerophytes are plants that can survive in dry habitats, such as deserts, and are able to withstand prolonged periods of water shortage. Succulent plants such as the cacti store water in the vacuoles of large parenchyma tissues. Other plants have leaf modifications to reduce water loss, such as needle-shaped leaves, sunken stomata, and thick, waxy cuticles as in the pine. The sand-dune marram grass has rolled leaves with stomata on the inner surface.\n\nHydrophytes are plants in water habitats. They mostly grow in water or in wet or damp places. In these plants the water absorption occur through the whole surface of the plant, e.g., the water lily.\n\nHalophytes are plants living in marshy areas (close to sea). They have to absorb water from such a soil which has higher salt concentration and therefore lower water potential(higher osmotic pressure). Halophytes cope with this situation by activating salts in their roots. As a consequence, the cells of the roots develop lower water potential which brings in water by osmosis. The excess salt can be stored in cells or excreted out from salt glands on leaves. The salt thus secreted by some species help them to trap water vapours from the air, which is absorbed in liquid by leaf cells. Therefore, this is another way of obtaining additional water from air, e.g., glasswort and cord-grass.\n\nMesophytes are plants living in lands of temperate zone, which grow in well-watered soil. They can easily compensate the water lost by transpiration through absorbing water from the soil. To prevent excessive transpiration they have developed a waterproof external covering called cuticle.\n\nKidneys play a very large role in human osmoregulation by regulating the amount of water reabsorbed from glomerular filtrate in kidney tubules, which is controlled by hormones such as antidiuretic hormone (ADH), aldosterone, and angiotensin II. For example, a decrease in water potential is detected by osmoreceptors in the hypothalamus, which stimulates ADH release from the pituitary gland to increase the permeability of the walls of the collecting ducts in the kidneys. Therefore, a large proportion of water is reabsorbed from fluid in the kidneys to prevent too much water from being excreted.\n\nA major way animals have evolved the ability to osmoregulate is by controlling the amount of water lost through the excretory system.\n\nAmoeba makes use of contractile vacuoles to collect excretory wastes, such as ammonia, from the intracellular fluid by diffusion and active transport. As osmotic action pushes water from the environment into the cytoplasm, the vacuole moves to the surface and disposes the contents into the environment.\n\nBacteria respond to osmotic stress by rapidly accumulating electrolytes or small organic solutes via transporters whose activities are stimulated by increases in osmolarity. The bacteria may also turn on genes encoding transporters of osmolytes and enzymes that synthesize osmoprotectants. The EnvZ/OmpR two-component system, which regulates the expression of porins, is well characterized in the model organism \"E. coli\".\n\nAmmonia is a toxic by-product of protein metabolism and is generally converted to less toxic substances after it is produced then excreted; mammals convert ammonia to urea, whereas birds and reptiles form uric acid to be excreted with other wastes via their cloacas.\n\nFour processes occur:\n\n\n\n", "id": "18952443", "title": "Osmoregulation"}
{"url": "https://en.wikipedia.org/wiki?curid=42419777", "text": "CellSqueeze\n\nCellSqueeze is the commercial name for a method for deforming a cell as it passes through a small opening, disrupting the cell membrane and allowing material to be inserted into the cell. It is an alternative method to electroporation or cell-penetrating peptides and operates similarly to a french cell press that temporarily disrupts cells, rather than completely bursting them.\n\nThe cell-disrupting change in pressure is achieved by passing cells through a narrow opening in a microfluidic device. The device is made up of channels etched into a wafer through which cells initially flow freely. As they move through the device, the channel width gradually narrows. The cell's flexible membrane allows it to change shape and become thinner and longer, allowing it to squeeze through. As the cell becomes more and more narrow, it shrinks in width by about 30 to 80 times its original size and the forced rapid change in cell shape temporarily creates holes in the membrane, without damaging or killing the cell.\n\nWhile the cell membrane is disrupted, target molecules that pass by can enter the cell through the holes in the membrane. As the cell returns to its normal shape, the holes in the membrane close. Virtually any type of molecule can be delivered into any type of cell. The throughput is approximately one million per second. Mechanical disruption methods can cause fewer gene expression changes than electrical or chemical methods. This can be preferable in studies that require the gene expression to be controlled at all times.\n\nLike other cell permeablisation techniques, it enables intracellular delivery materials, such as proteins, siRNA, or carbon nanotubes. The technique has been used for over 20 cell types, including embryonic stem cells and naïve immune cells. Initial applications focused on immune cells, for example delivering:\n\n\nThe process was originally developed in 2013 by Armon Sharei and Andrea Adamo, in the lab of Langer and Jensen at Massachusetts Institute of Technology. In 2014 Sharei founded SQZ Biotech to demonstrate the technology. That year, SQZ Biotech won the $100,000 grand prize in the annual startup competition sponsored by Boston-based accelerator MassChallenge.\n\nBoeing and the Center for the Advancement of Science in Space CASIS awarded the company the CASIS-Boeing Prize for Technology in Space to support the use of CellSqueeze on the International Space Station (ISS).\n\n", "id": "42419777", "title": "CellSqueeze"}
{"url": "https://en.wikipedia.org/wiki?curid=43010228", "text": "WormBase\n\nWormBase is an online biological database about the biology and genome of the nematode model organism \"Caenorhabditis elegans\" and contains information about other related nematodes. WormBase is used by the \"C. elegans\" research community both as an information resource and as a place to publish and distribute their results. The database is regularly updated with new versions being released every two months. WormBase is one of the organizations participating in the Generic Model Organism Database (GMOD) project.\n\nWormBase comprises the following main data sets:\n\n\nIn addition, WormBase contains an up-to-date searchable bibliography of \"C. elegans\" research and is linked to the WormBook project.\n\nWormBase offers many ways of searching and retrieving data from the database:\n\nSequence curation at WormBase refers to the maintenance and annotation of the primary genomic sequence and a consensus gene set.\n\nEven though the \"C. elegans\" genome sequence is the most accurate and complete eukaryotic genome sequence, it has continually needed refinement as new evidence has been created. Many of these changes were single nucleotide insertions or deletions, however several large mis-assemblies have been uncovered. For example, in 2005 a 39 kb cosmid had to be inverted. Other improvements have come from comparing genomic DNA to cDNA sequences and analysis of RNASeq high-throughput data. When differences between the genomic sequence and transcripts are identified, re-analysis of the original genomic data often leads to modifications of the genomic sequence. \nThe changes in the genomic sequence pose difficulties when comparing chromosomal coordinates of data derived from different releases of WormBase. To aid these comparisons, a coordinate re-mapping program and data are available from: \nhttp://wiki.wormbase.org/index.php/Converting_Coordinates_between_releases\n\nAll the gene-sets of the WormBase species were initially generated by gene prediction programs. Gene prediction programs give a reasonable set of gene structures, but the best of them only predict about 80% of the complete gene structures correctly. They have difficulty predicting genes with unusual structures, as well as those with a weak translation start signal, weak splice sites or single exon genes. They can incorrectly predict a coding gene model where the gene is a pseudogene and they predict the isoforms of a gene poorly, if at all.\n\nThe gene models of \"C. elegans\", \"C. briggsae\", \"C. remanei\", and \"C. brenneri\" genes are manually curated. The majority of gene structure changes have been based on transcript data from large scale projects such as Yuji Kohara’s EST libraries, Mark Vidal’s Orfeome project (worfdb.dfci.harvard.edu/) Waterston and Hillier’s Illumina data and Makedonka Mitreva’s 454 data. However, other data types (e.g. protein alignments, \"ab initio\" prediction programs, trans-splice leader sites, poly-A signals and addition sites, SAGE and TEC-RED transcript tags, mass-spectroscopic peptides, and conserved protein domains) are useful in refining the structures, especially where expression is low and so transcripts are not sufficiently available. When genes are conserved between the available nematode species, comparative analysis can also be very informative.\n\nWormBase encourages researchers to inform them via the help-desk if they have evidence for an incorrect gene structure. Any cDNA or mRNA sequence evidence for the change should be submitted to EMBL/GenBank/DDBJ; this helps in the confirmation and evidence for the gene model as WormBase routinely retrieve sequence data from these public databases. This also makes the data public, allowing appropriate reference and acknowledgement to the researchers.\n\nWhen any change is made to a CDS (or Pseudogene), the old gene model is preserved as a ‘history’ object. This will have a suffix name like: “AC3.5:wp119”, where ‘AC3.5’ is the name of the CDS and the ‘119’ refers to the database release in which the change was made. The reason for the change and the evidence for the change are added to the annotation of the CDS – these can be seen in the Visible/Remark section of the CDS’s ‘Tree Display’ section on the WormBase web site.\n\nIn WormBase, a Gene is a region that is expressed or a region that has been expressed and is now a Pseudogene. Genes have unique identifiers like ‘WBGene00006415’. All C. elegans WormBase genes also have a Sequence Name, which is derived from the cosmid, fosmid or YAC clone on which they reside, for instance F38H4.7, indicating it is on the cosmid ‘F38H4’, and there are at least 6 other genes on that cosmid. If a gene produces a protein that can be classified as a member of a family, the gene may also be assigned a CGC name like tag-30 indicating that this is the 30th member of the tag gene family. Assignment of gene family names is controlled by WormBase and requests for names should be made, before publication, via the form at: http://tazendra.caltech.edu/~azurebrd/cgi-bin/forms/gene_name.cgi\n\nThere are a few exceptions to this format, like the genes cln-3.1, cln-3.2, and cln-3.3 which all are equally similar to the human gene CLN3.\nGene GCG names for non-elegans species in WormBase have the 3-letter species code prepended, like Cre-acl-5, Cbr-acl-5, Cbn-acl-5.\n\nA gene can be a Pseudogene, or can express one or more non-coding RNA genes (ncRNA) or protein-coding sequences (CDS).\n\nPseudogenes are genes that do not produce a reasonable, functional transcript. They may be pseudogenes of coding genes or of non-coding RNA and may be whole or fragments of a gene and may or may not express a transcript. The boundary between what is considered a \"reasonable\" coding transcript is sometimes subjective as, in the absence of other evidence, the use of weak splice sites or short exons can often produce a putative, though unsatisfactory, model of a CDS. Pseudogenes and genes with a problematic structure are constantly under review in WormBase and new evidence is used to try to resolve their status.\n\nCoding Sequences (CDSs) are the only part of a Gene's structure that is manually curated in WormBase. The structure of the Gene and its transcripts are derived from the structure of their CDSs.\n\nCDSs have a Sequence Name that is derived from the same Sequence Name as their parent Gene object, so the gene ‘F38H4.7’ has a CDS called ‘F38H4.7’. The CDS specifies coding exons in the gene from the START (Methionine) codon up to (and including) the STOP codon.\n\nAny gene can code for multiple proteins as a result of alternative splicing. These isoforms have a name that is formed from the Sequence Name of the gene with a unique letter appended. In the case of the gene bli-4 there are 6 known CDS isoforms, called K04F10.4a, K04F10.4b, K04F10.4c, K04F10.4d, K04F10.4e and K04F10.4f.\n\nIt is common to refer to isoforms in the literature using the CGC gene family name with a letter appended, for example pha-4a, however this has no meaning within the WormBase database and searches for pha-4a in WormBase will not return anything. The correct name of this isoform is either the CDS/Transcript name: F38A6.1a, or even better, the Protein name: WP:CE15998.\n\nThe transcripts of a gene in WormBase are automatically derived by mapping any available cDNA or mRNA alignments onto the CDS model. These gene transcripts will therefore often include the UTR exons surrounding the CDS. If there are no available cDNA or mRNA transcripts, then the gene transcripts will have exactly the same structure as the CDS that they are modelled on.\n\nGene transcripts are named after the Sequence Name of the CDS used to create them, for example, F38H4.7 or K04F10.4a.\n\nHowever if there is alternative splicing in the UTRs, which would not change the protein sequence, the alternatively spliced transcripts are named with a digit appended, for example: K04F10.4a.1 and K04F10.4a.2. If there are no isoforms of the coding gene, for example AC3.5, but there is alternative splicing in the UTRs, there will be multiple transcripts named AC3.5.1 and AC3.5.2, etc. If there are no alternate UTR transcripts the single coding_transcript is named the same as the CDS and does not have the .1 appended, as in the case of K04F10.4f.\n\nGroups of genes which are co-transcribed as operons are curated as Operon objects. These have names like CEOP5460 and are manually curated using evidence from the SL2 trans-spliced leader sequence sites.\n\nThere are several classes of non-coding RNA gene classes in WormBase:\n\n\nThere is also one scRNA gene.\n\nTransposons are not classed as genes and so do not have a parent gene object. Their structure is curated as a Transposon_CDS object with a name like C29E6.6.\n\nThe non-elegans species in WormBase have genomes that have been assembled from sequencing technologies that do not involve sequencing cosmids or YACs. These species therefore do not have sequence names for CDSs and gene transcripts that are based on cosmid names. Instead they have unique alphanumeric identifiers constructed like the names in the table below.\n\nThe protein products of gene are created by translating the CDS sequences. Each unique protein sequence is given a unique identifying name like WP:CE40440. Examples of the protein identifier names for each species in WormBase is given in the table, below.\n\nIt is possible for two CDS sequences from separate genes, within a species, to be identical and so it is possible to have identical proteins coded for by separate genes. When this happens, a single, unique identifying name is used for the protein even though it is produced by two genes.\n\nWormBase ParaSite is a sub-portal for approximately 100 draft genomes of parasitic helminths (nematodes and platyhelminthes) developed at the European Bioinformatics Institute and Wellcome Trust Sanger Institute. All genomes are assembled and annotated. Additional information such as protein domains and Gene Ontology terms are also available. Gene trees allow the alignment of orthologues between parasitic worms, other nematodes and non-worm comparator species. A BioMart data-mining tool is offered to permit large scale access to the data.\n\nWormBase is a collaboration among the European Bioinformatics Institute, Wellcome Trust Sanger Institute, Ontario Institute for Cancer Research, Washington University in St. Louis, and the California Institute of Technology. It is supported by the grant P41-HG002223 from the National Institutes of Health and the grant G0701197 from the British Medical Research Council . Caltech carries out the biological curation and develops the underlying ontologies, the EBI carries out sequence curation and computation as well as database builds, the Sanger is primarily involved in curation and display of parasitic nematode genomes and genes, and the OICR develops the website and main data mining tools.\n\n\n", "id": "43010228", "title": "WormBase"}
{"url": "https://en.wikipedia.org/wiki?curid=1526870", "text": "Heterokaryon\n\nA heterokaryon is a multinucleate cell that contains genetically different nuclei. Heterokaryotic and heterokaryosis are derived terms. This is a special type of syncytium. This can occur naturally, such as in the mycelium of fungi during sexual reproduction, or artificially as formed by the experimental fusion of two genetically different cells, as e.g., in hybridoma technology.\n\nA medical example is a heterokaryon composed of nuclei from Hurler syndrome and Hunter syndrome. Both of these diseases result in problems in mucopolysaccharide metabolism. However, a heterokaryon of nuclei from both of these diseases exhibits normal mucopolysaccharide metabolism, proving that the two syndromes affect different proteins and so can correct each other in the heterokaryon.\n\nHeterokaryons are found in the life cycle of yeasts, for example \"Saccharomyces cerevisiae\", a genetic model organism. The heterokaryon stage is produced from the fusion of two haploid cells. This \"transient\" heterokaryon can produce further haploid buds, or cell nuclei can fuse and produce a diploid cell, which can then undergo mitosis.\n\nThe term \"heterokaryon\" was coined in 1965, independently by B. Ephrussi and M. Weiss, by H. Harris and J. F. Watkins, and by Y. Okada and F. Murayama.\n\nThe term was first used for ciliate protozoans such as \"Tetrahymena\". This has two types of cell nuclei, a large, somatic macronucleus and a small, germline micronucleus. Both exist in a single cell at the same time and carry out different functions with distinct cytological and biochemical properties.\n\nMany fungi (notably the arbuscular mycorrhizal fungi) exhibit heterokaryosis. The haploid nuclei within a mycelium may differ from one another not merely by accumulating mutations, but by the non-sexual fusion of genetically distinct fungal hyphae, although a self/non self recognition system exists in Fungi and usually prevents fusions with non-self. Heterokaryosis is also common upon mating, as, in Dikarya (Ascomycetes and Basidiomycetes) mating requires the encounter of haploid nuclei of opposite mating types. The nuclei do not immediately fuse, and remain haploid in a n+n state until the very onset of meiosis: this phenomenon is called delayed karyogamy. Heterokaryosis can lead to individuals that have different nuclei in different parts of their mycelium, although in ascomycetes, particularly in \"Neurospora\", nuclei have been shown to flow and mix throughout the mycelium. In heterokaryons, the notion of \"individual\" itself becomes vague since the rule of one genome = one individual does not apply any more. Genetic heterogeneity within individual is indeed usually considered to be detrimental, as selfish variants may be selected for and disrupt the integrity of the individual level.\n\nHeterokaryosis is most common in fungi, but also occurs in slime molds. This happens because the nuclei in the 'plasmodium' form are the products of many pairwise fusions between amoeboid haploid individuals. When genetically divergent nuclei come together in the plasmodium form, cheaters have been shown to emerge. However, genetic homogeneity among fusing amoeboid serves to maintain the multicellular plasmodium.\n\n\n", "id": "1526870", "title": "Heterokaryon"}
{"url": "https://en.wikipedia.org/wiki?curid=2978009", "text": "Cytochemistry\n\nCytochemistry is the biochemistry of cells, especially that of the macromolecules responsible for cell structure and function. The term is also used to describe a process of identification of the biochemical content of cells. \"Cytochemistry\" is a science of localizing chemical components of cells and cell organelles on thin histological sections by using several techniques like enzyme localization, micro-incineration, micro-spectrophotometry, radioautography, cryo-electron microscopy, X-ray microanalysis by energy-dispersive X-ray spectroscopy, immunohistochemistry and cytochemistry, etc.\n", "id": "2978009", "title": "Cytochemistry"}
{"url": "https://en.wikipedia.org/wiki?curid=42947694", "text": "Cell lineage\n\nCell lineage denotes the developmental history of a tissue or organ from the fertilized embryo. Cell lineage can be studied by marking a cell (with fluorescent molecules or other traceable markers) and following its progeny after cell division. Some organisms such as \"C. elegans\" have a predetermined pattern of cell progeny and the adult male will always consist of 1031 cells, this is because cell division in \"C. elegans\" is genetically determined and known as eutely. This causes the cell lineage and cell fate to be highly correlated. Other organisms, such as humans, have variable lineages and somatic cell numbers.\n\nAs one of the first pioneers of cell lineage, in the 1960s Dr. Sydney Brenner first began observing cell differentiation and succession in the nematode \"Caenorhabditis elegans\". Dr. Brenner chose this organism due to its transparent body, quick reproduction, ease of access, and small size which made it ideal for following cell lineage under a microscope.\n\nBy 1976, Dr. Brenner and his associate, Dr. John Sulston, had identified part of the cell lineage in the developing nervous system of \"C. elegans\". Recurring results showed that the nematode was eutelic (each individual experiences the same differentiation pathways). This research led to the initial observations of programmed cell death, or apoptosis.\n\nAfter mapping various sections of the \"C. elegans\"' cell lineage, Dr. Brenner and his associates were able to piece together the first complete and reproducible fate map of cell lineage. They later received the 2002 Nobel prize for their work in genetic regulation of organ development and programmed cell death.\n\nOne of the first studies of cell lineages took place in the 1870s by Whitman who studied cleavage patterns in leeches and small invertebrates. He found that some groups, such as nematode worms and ascidians form a pattern of cell division which is identical between individuals and invariable. This high correlation between cell lineage and cell fate was thought to be determined by segregating factors within the dividing cells. Other organisms had stereotyped patterns of cell division and produced sublineages which were the progeny of particular precursor cells. These more variable cell fates are thought to be due to the cells' interaction with the environment.\n\nCell lineage can be determined by two methods, either through direct observation or through clonal analysis. During the early 19th century direct observation was used however it was highly limiting as only small transparent samples could be studied. With the invention of the confocal microscope this allowed larger more complicated organisms to be studied.\n\nPerhaps the most popular method of cell fate mapping in the genetic era is through site-specific recombination mediated by the Cre-Lox or FLP-FRT systems. By utilizing the Cre-Lox or FLP-FRT recombination systems, a reporter gene (usually encoding a fluorescent protein) is activated and permanently labels the cell of interest and its offspring cells, thus the name cell lineage tracing. With the system, researchers could investigate the function of their favorite gene in determining cell fate by designing a genetic model where within a cell one recombination event is designed for manipulating the gene of interest and the other recombination event is designed for activating a reporter gene. One minor issue is that the two recombination events may not occur simultaneously thus the results need to be interpreted with caution. \n\nMore recently, researchers have begun using synthetic biology approaches and the CRISPR/Cas9 system to engineer new genetic systems that enable cells to autonomously record lineage information in their own genome. These systems are based on engineered, targeted mutation of defined genetic elements. By generating new, random genomic alterations in each cell generation these approaches facilitate reconstruction of lineage trees. These approaches promise to provide more comprehensive analysis of lineage relationships in model organisms.\n", "id": "42947694", "title": "Cell lineage"}
{"url": "https://en.wikipedia.org/wiki?curid=21317821", "text": "Mitophagy\n\nMitophagy is the selective degradation of mitochondria by autophagy. It often occurs to defective mitochondria following damage or stress. The term was coined by J.J. Lemasters in 2005. Mitochondrial fragments had been seen in liver lysosomes as early as 1962, and a 1977 report suggested that \"mitochondria develop functional alterations which would activate autophagy\".\n\nMitophagy is key in keeping the cell healthy. It promotes turnover of mitochondria and prevents accumulation of dysfunctional mitochondria which can lead to cellular degeneration. It is mediated by Atg32 (in yeast) and NIX and its regulator BNIP3 in mammals. Mitophagy is regulated by PINK1 and parkin proteins. In addition to the selective removal of damaged mitochondria, mitophagy is also required to adjust mitochondrial numbers to changing cellular metabolic needs, for steady-state mitochondrial turnover, and during certain cellular developmental stages, such as during cellular differentiation of red blood cells.\n\nOrganelles and bits of cytoplasm are sequestered and targeted for degradation by the lysosome for hydrolytic digestion by a process known as autophagy. Mitochondria metabolism leads to the creation of by-products that lead to DNA damage and mutations. Therefore, a healthy population of mitochondria is critical for the well-being of cells. Previously it was thought that targeted degradation of mitochondria was a stochastic event, but accumulating evidence suggest that mitophagy is a selective process.\n\nGeneration of ATP by oxidative phosphorylation leads to the production of various reactive oxygen species (ROS) in the mitochondria, and submitochondrial particles. Formation of ROS as a mitochondrial waste product will eventually lead to cytotoxicity and cell death. Because of their role in metabolism, mitochondria are very susceptible to ROS damage. Damaged mitochondria cause a depletion in ATP and a release of cytochrome \"c\", which leads to activation of caspases and onset of apoptosis. Mitochondrial damage is not caused solely by oxidative stress or disease processes; normal mitochondria will eventually accumulate oxidative damage hallmarks overtime, which can be deleterious to mitochondria as well as to the cell. These faulty mitochondria can further deplete the cell from ATP, increase production of ROS, and release proapoptopic proteins such as caspases.\n\nBecause of the danger of having damaged mitochondria in the cell, the timely elimination of damaged and aged mitochondria is essential for maintaining the integrity of the cell. This turnover process consists of the sequestration and hydrolytic degradation by the lysosome, a process also known as mitophagy.\n\nMitochondrial depletion reduces a spectrum of senescence effectors and phenotypes while preserving ATP production via enhanced glycolysis.\n\nThere are several pathways by which mitophagy is induced in mammalian cells. The PINK1 and Parkin pathway is, so far, the best characterized. This pathway starts in by deciphering the difference between healthy mitochondria and damaged mitochondria. A 64-kDa protein, PTEN-induced kinase 1 (PINK1), has been implicated to detect mitochondrial quality. PINK1 contains a mitochondrial targeting sequence (MTS) and is recruited to the mitochondria. In healthy mitochondria, PINK1 is imported through the outer membrane via the TOM complex, and partially through the inner mitochondrial membrane via the TIM complex, so it then spans the inner mitochondrial membrane. The process of import into the inner membrane is associated with the cleavage of PINK1 from 64-kDa into 60-kDa. PINK1 is then cleaved by PARL into 52-kDa. This new form of PINK1 is degraded by proteases within the mitochondria. This keeps the concentration of PINK1 in check in healthy mitochondria.\n\nIn unhealthy mitochondria, the inner mitochondrial membrane becomes depolarized. This membrane potential is necessary for the TIM-mediated protein import. In depolarized mitochondria, PINK1 is no longer imported into the inner membrane, is not cleaved by PARL and PINK1 concentration increases in the outer mitochondrial membrane. PINK1 can then recruit Parkin. It is thought that PINK1 phosphorylates Parkin ubiquitin ligase at S65 which initiates Parkin recruitment at the mitochondria. Parkin is a cytosolic E3 ubiquitin ligase. Once localized at the mitochondria, PINK1 phosphorylates Parkin at S65, homologous to the site where ubiquitin was phosphorylated, which activates Parkin by inducing dimerization and an active state. This allows for Parkin mediated ubiquitination on other proteins.\n\nBecause of the PINK1 mediated recruitment to the mitochondrial surface, Parkin can ubiquitylate proteins in the outer mitochondrial membrane. Some of these proteins include Mfn1/Mfn2 and mitoNEET. The ubiquitylation of mitochondrial surface proteins brings in mitophagy initiating factors. Parkin promotes ubiquitin chain linkages on both K63 and K48. K48 ubiquitination initiates degradation of the proteins, and could allow for passive mitochondrial degradation. K63 ubiquitination is thought to recruit autophagy adaptors LC3/GABARAP which will then lead to mitophagy. It is still unclear which proteins are necessary and sufficient for mitophagy, and how these proteins, once ubiquitylated, initiate mitophagy.\n\nOther pathways that can induce mitophagy includes mitophagy receptors on the outer mitochondrial membrane surface. These receptors include NIX1, BNIP3 and FUNDC1. All of these receptors contain LIR consensus sequences that bind LC3/GABARAP which can lead to the degradation of the mitochondria. In hypoxic conditions BNIP3 is upregulated by HIF1α. BNIP3 is then phosphorylated at its serine residues near the LIR sequence which promotes LC3 binding. FUNDCI is also hypoxia sensitive, although it is constitutively present at the outer mitochondrial membrane during normal conditions \n\nIn neurons, mitochondria are distributed unequally throughout the cell to areas where energy demand is high, like at synapses and Nodes of Ranvier. This distribution is maintained largely by motor protein-mediated mitochondrial transport along the axon. While neuronal mitophagy is thought to occur primarily in the cell body, it also occurs locally in the axon at sites distant from the cell body; in both the cell body and the axon, neuronal mitophagy occurs via the PINK1-Parkin pathway. Mitophagy in the nervous system may also occur transcellularly, where damaged mitochondria in retinal ganglion cell axons can be passed to neighboring astrocytes for degradation. This process is known as transmitophagy.\n\nMitophagy in yeast was first presumed after the discovery of Yeast Mitochondrial Escape genes (yme), specifically yme1. Yme1 like other genes in the family showed increase escapes of mtDNA, but was the only one that showed in increase in mitochondrial degradation. Through work on this gene that mediates the escape of mtDNA, researchers discovered that mitochondrial turnover is triggered by proteins.\n\nMore was discovered about genetic control of mitophagy after studies done of UTH1. After doing a screen for genes that regulate longevity. It was found in ΔUTH1 strains there was an inhibition of mitophagy, which occurred without affecting autophagy mechanisms. It also showed that Uth1p protein is necessary to move mitochondria to the vacuole. This suggested there is a specialized system for mitophagy. Other studies looked at AUP1, a mitochondrial phosphatase, and found Aup1 marks mitochondria for elimination.\n\nAnother yeast protein associated with mitophagy is a mitochondrial inner membrane protein, Mdm38p/Mkh1p. This protein is part of the complex that exchanges K+/H+ ions across the inner membrane. Deletions to this protein causes swelling, a loss of membrane potential, and mitochondrial fragmentation.\n\nRecently, it has been shown that ATG32 (autophagy related gene 32) plays a crucial role in yeast mitophagy. It is localized to the mitochondria. Once mitophagy is initiated, Atg32 binds to Atg11 and the Atg32-associated mitochondria is transported to the vacuole. Atg32 silencing stops recruitment of autophagy machinery and mitochondrial degradation. Atg32 is not necessary for other forms of autophagy.\n\nAll of these proteins likely play a role in maintaining a healthy mitochondria, but mutations have shown that dysregulation can lead to a selective degradation of mitochondria. Whether these proteins work in concert, are main players in mitophagy, or the networks controlled still remain to be elucidated\n\nIn 1920 Otto Warburg observed that certain cancerous tumors display a metabolic shift towards glycolysis. This hypothesis is referred to as the \"Warburg effect\", in which cancer cells produce energy via the conversion of glucose into lactate, even in the presence of oxygen (aerobic glycolysis). Despite nearly a century since it was first described, a lot of questions remained unanswered regarding the Warburg effect. Initially, Warburg attributed this metabolic shift to mitochondrial dysfunction in cancer cells. Further studies in tumor biology have shown that the increased growth rate in cancer cells is due to an overdrive in glycolysis (glycolytic shift), which leads to a decrease in oxidative phosphorylation and mitochondrial density. As a consequence of the Warburg effect, cancer cells would produce large amounts of lactate. The excess lactate is then released to the extracellular environment which results in a decrease in extracellular pH. This micro-environment acidification can lead to cellular stress, which would lead to autophagy. Autophagy is activated in response to a range of stimuli, including nutrient depletion, hypoxia, and activated oncogenes. However, it appears that autophagy can help in cancer cell survival under conditions of metabolic stress and it may confer resistance to anti-cancer therapies such as radiation and chemotherapy. Additionally, in the microenvironment of cancer cells, there is an increase in hypoxia-inducible transcription factor 1-alpha (HIF1A), which promotes expression of BNIP3, an essential factor for mitophagy.\n\nParkinson's disease is a neurodegenerative disorder pathologically characterized by death of the dopamine-producing neurons in the substantia nigra. There are several genetic mutations implicated in Parkinson's disease, including loss of function PINK1 and Parkin. Loss of function in either of these genes results in accumulation of damaged mitochondria and aggregation of proteins – eventually leading to neuronal death.\n\nMitochondria dysfunction is thought to be involved in Parkinson's disease pathogenesis. In spontaneous, usually aging related Parkinson's disease (non-genetically linked), the disease is commonly caused by dysfunctional mitochondria, cellular oxidative stress, autophagic alterations and the aggregation of proteins. These can lead to mitochondrial swelling and depolarization. It is important to keep the dysfunctional mitochondria regulated, because all of these traits could be induced by mitochondrial dysfunction and can induce cell death. Disorders in energy creation by mitochondria can cause cellular degeneration, like those seen in the substantia nigra.\n", "id": "21317821", "title": "Mitophagy"}
{"url": "https://en.wikipedia.org/wiki?curid=1076110", "text": "Protein sequencing\n\nProtein sequencing is the practical process of determining the amino acid sequence of all or part of a protein or peptide. This may serve to identify the protein or characterize its post-translational modifications. Typically, partial sequencing of a protein provides sufficient information (one or more sequence tags) to identify it with reference to databases of protein sequences derived from the conceptual translation of genes.\nThe two major direct methods of protein sequencing are mass spectrometry and Edman degradation using a protein sequenator (sequencer). Mass spectrometry methods are now the most widely used for protein sequencing and identification but Edman degradation remains a valuable tool for characterizing a protein's \"N\"-terminus.\n\nIt is often desirable to know the unordered amino acid composition of a protein prior to attempting to find the ordered sequence, as this knowledge can be used to facilitate the discovery of errors in the sequencing process or to distinguish between ambiguous results. Knowledge of the frequency of certain amino acids may also be used to choose which protease to use for digestion of the protein. The misincorporation of low levels of non-standard amino acids (e.g. norleucine) into proteins may also be determined. A generalized method often referred to as \"amino acid analysis\" for determining amino acid frequency is as follows:\n\nHydrolysis is done by heating a sample of the protein in 6 M hydrochloric acid to 100–110 °C for 24 hours or longer. Proteins with many bulky hydrophobic groups may require longer heating periods. However, these conditions are so vigorous that some amino acids (serine, threonine, tyrosine, tryptophan, glutamine, and cysteine) are degraded. To circumvent this problem, Biochemistry Online suggests heating separate samples for different times, analysing each resulting solution, and extrapolating back to zero hydrolysis time. Rastall suggests a variety of reagents to prevent or reduce degradation, such as thiol reagents or phenol to protect tryptophan and tyrosine from attack by chlorine, and pre-oxidising cysteine. He also suggests measuring the quantity of ammonia evolved to determine the extent of amide hydrolysis.\n\nThe amino acids can be separated by ion-exchange chromatography then derivatized to facilitate their detection. More commonly, the amino acids are derivatized then resolved by reversed phase HPLC.\n\nAn example of the ion-exchange chromatography is given by the NTRC using sulfonated polystyrene as a matrix, adding the amino acids in acid solution and passing a buffer of steadily increasing pH through the column. Amino acids are eluted when the pH reaches their respective isoelectric points. Once the amino acids have been separated, their respective quantities are determined by adding a reagent that will form a coloured derivative. If the amounts of amino acids are in excess of 10 nmol, ninhydrin can be used for this; it gives a yellow colour when reacted with proline, and a vivid purple with other amino acids. The concentration of amino acid is proportional to the absorbance of the resulting solution. With very small quantities, down to 10 pmol, fluorescent derivatives can be formed using reagents such as ortho-phthaldehyde (OPA) or fluorescamine.\n\nPre-column derivatization may use the Edman reagent to produce a derivative that is detected by UV light. Greater sensitivity is achieved using a reagent that generates a fluorescent derivative. The derivatized amino acids are subjected to reversed phase chromatography, typically using a C8 or C18 silica column and an optimised elution gradient. The eluting amino acids are detected using a UV or fluorescence detector and the peak areas compared with those for derivatised standards in order to quantify each amino acid in the sample.\n\nDetermining which amino acid forms the \"N\"-terminus of a peptide chain is useful for two reasons: to aid the ordering of individual peptide fragments' sequences into a whole chain, and because the first round of Edman degradation is often contaminated by impurities and therefore does not give an accurate determination of the \"N\"-terminal amino acid. A generalised method for \"N\"-terminal amino acid analysis follows:\n\nThere are many different reagents which can be used to label terminal amino acids. They all react with amine groups and will therefore also bind to amine groups in the side chains of amino acids such as lysine - for this reason it is necessary to be careful in interpreting chromatograms to ensure that the right spot is chosen. Two of the more common reagents are Sanger's reagent (1-fluoro-2,4-dinitrobenzene) and dansyl derivatives such as dansyl chloride. Phenylisothiocyanate, the reagent for the Edman degradation, can also be used. The same questions apply here as in the determination of amino acid composition, with the exception that no stain is needed, as the reagents produce coloured derivatives and only qualitative analysis is required. So the amino acid does not have to be eluted from the chromatography column, just compared with a standard. Another consideration to take into account is that, since any amine groups will have reacted with the labelling reagent, ion exchange chromatography cannot be used, and thin layer chromatography or high-pressure liquid chromatography should be used instead.\n\nThe number of methods available for C-terminal amino acid analysis is much smaller than the number of available methods of N-terminal analysis. The most common method is to add carboxypeptidases to a solution of the protein, take samples at regular intervals, and determine the terminal amino acid by analysing a plot of amino acid concentrations against time. This method will be very useful in the case of polypeptides and protein-blocked N termini. C-terminal sequencing would greatly help in verifying the primary structures of proteins predicted from DNA sequences and to detect any postranslational processing of gene products from known codon sequences.\n\nThe Edman degradation is a very important reaction for protein sequencing, because it allows the ordered amino acid composition of a protein to be discovered. Automated Edman sequencers are now in widespread use, and are able to sequence peptides up to approximately 50 amino acids long. A reaction scheme for sequencing a protein by the Edman degradation follows; some of the steps are elaborated on subsequently.\n\nPeptides longer than about 50-70 amino acids long cannot be sequenced reliably by the Edman degradation. Because of this, long protein chains need to be broken up into small fragments that can then be sequenced individually. Digestion is done either by endopeptidases such as trypsin or pepsin or by chemical reagents such as cyanogen bromide. Different enzymes give different cleavage patterns, and the overlap between fragments can be used to construct an overall sequence.\n\nThe peptide to be sequenced is adsorbed onto a solid surface. One common substrate is glass fibre coated with polybrene, a cationic polymer. The Edman reagent, phenylisothiocyanate (PITC), is added to the adsorbed peptide, together with a mildly basic buffer solution of 12% trimethylamine. This reacts with the amine group of the N-terminal amino acid.\n\nThe terminal amino acid can then be selectively detached by the addition of anhydrous acid. The derivative then isomerises to give a substituted phenylthiohydantoin, which can be washed off and identified by chromatography, and the cycle can be repeated. The efficiency of each step is about 98%, which allows about 50 amino acids to be reliably determined.\n\nA protein sequenator is a machine that performs Edman degradation in an automated manner. A sample of the protein or peptide is immobilized in the reaction vessel of the protein sequenator and the Edman degradation is performed. Each cycle releases and derivatises one amino acid from the protein or peptide's \"N\"-terminus and the released amino-acid derivative is then identified by HPLC. The sequencing process is done repetitively for the whole polypeptide until the entire measurable sequence is established or for a pre-determined number of cycles.\n\nProtein identification is the process of assigning a name to a protein of interest (POI), based on its amino-acid sequence. Typically, only part of the protein’s sequence needs to be determined experimentally in order to identify the protein with reference to databases of protein sequences deduced from the DNA sequences of their genes. Further protein characterization may include confirmation of the actual N- and C-termini of the POI, determination of sequence variants and identification of any post-translational modifications present.\n\nA general scheme for protein identification is described.\n\nThe pattern of fragmentation of a peptide allows for direct determination of its sequence by \"de novo\" sequencing. This sequence may be used to match databases of protein sequences or to investigate post-translational or chemical modifications. It may provide additional evidence for protein identifications performed as above.\n\nThe peptides matched during protein identification do not necessarily include the N- or C-termini predicted for the matched protein. This may result from the N- or C-terminal peptides being difficult to identify by MS (e.g. being either too short or too long), being post-translationally modified (e.g. N-terminal acetylation) or genuinely differing from the prediction. Post-translational modifications or truncated termini may be identified by closer examination of the data (i.e. \"de novo\" sequencing). A repeat digest using a protease of different specificity may also be useful.\n\nWhilst detailed comparison of the MS data with predictions based on the known protein sequence may be used to define post-translational modifications, targeted approaches to data acquisition may also be used. For instance, specific enrichment of phosphopeptides may assist in identifying phosphorylation sites in a protein. Alternative methods of peptide fragmentation in the mass spectrometer, such as ETD or ECD, may give complementary sequence information.\n\nThe protein’s whole mass is the sum of the masses of its amino-acid residues plus the mass of a water molecule and adjusted for any post-translational modifications. Although proteins ionize less well than the peptides derived from them, a protein in solution may be able to be subjected to ESI-MS and its mass measured to an accuracy of 1 part in 20,000 or better. This is often sufficient to confirm the termini (thus that the protein’s measured mass matches that predicted from its sequence) and infer the presence or absence of many post-translational modifications.\n\nProteolysis does not always yield a set of readily analyzable peptides covering the entire sequence of the POI. The fragmentation of peptides in the mass spectrometer often does not yield ions corresponding to cleavage at each peptide bond. Thus, the deduced sequence for each peptide is not necessarily complete. The standard methods of fragmentation do not distinguish between leucine and isoleucine residues since they are isomeric.\n\nBecause the Edman degradation proceeds from the N-terminus of the protein, it will not work if the N-terminus has been chemically modified (e.g. by acetylation or formation of Pyroglutamic acid). Edman degradation is generally not useful to determine the positions of disulfide bridges. It also requires peptide amounts of 1 picomole or above for discernible results, making it less sensitive than mass spectrometry.\n\nIn biology, proteins are produced by translation of messenger RNA (mRNA) with the protein sequence deriving from the sequence of codons in the mRNA. The mRNA is itself formed by the transcription of genes and may be further modified. These processes are sufficiently understood to use computer algorithms to automate predictions of protein sequences from DNA sequences, such as from whole-genome DNA-sequencing projects, and have led to the generation of large databases of protein sequences such as UniProt. Predicted protein sequences are an important resource for protein identification by mass spectrometry.\n\nHistorically, short protein sequences (10 to 15 residues) determined by Edman degradation were back-translated into DNA sequences that could be used as probes or primers to isolate molecular clones of the corresponding gene or complementary DNA. The sequence of the cloned DNA was then determined and used to deduce the full amino-acid sequence of the protein.\n\nBioinformatics tools exist to assist with interpretation of mass spectra (see De novo peptide sequencing), to compare or analyze protein sequences (see Sequence analysis), or search databases using peptide or protein sequences (see BLAST).\n\n", "id": "1076110", "title": "Protein sequencing"}
{"url": "https://en.wikipedia.org/wiki?curid=44235126", "text": "Megamitochondria\n\nMegamitochondria is extremely large and abnormal shapes of mitochondria seen in hepatocytes in alcoholic liver disease and in nutritional deficiencies. It can be seen in conditions of hypertrophy in cell death.\n\n", "id": "44235126", "title": "Megamitochondria"}
{"url": "https://en.wikipedia.org/wiki?curid=44405111", "text": "Nanoinjection\n\nNanoinjection is the process of using a microscopic lance and electrical forces to deliver DNA to a cell. It is claimed to be more effective than microinjection because the lance used is ten times smaller than a micropipette and the method uses no fluid.\n\nBecause DNA has a negative electric charge, a small lance, or nanopipette, with a positive electric charge will attract the DNA. The DNA can then be inserted into a cell by inserting the pipette and reversing the charge. The process is controlled by a computer, and the method is so precise it allows molecules to inserted into the cell's nucleus. Trials of the method produced a survival rate of 92% in nanoinjected cells, as opposed to a rate of 40% in microinjected cells.\n\nNanoinjection is used in transgenic research. It may help with discovering cures for Alzheimers and cancer, and in helping to treat diabetes. Because some animals have cloudy or opaque embryos, nanoinjection can be more effective in implanting DNA into their cells.\n", "id": "44405111", "title": "Nanoinjection"}
{"url": "https://en.wikipedia.org/wiki?curid=254062", "text": "Mast cell\n\nA mast cell (also known as a mastocyte or a labrocyte) is a type of white blood cell. Specifically, it is a type of granulocyte derived from the myeloid stem cell that is a part of the immune and neuroimmune systems and contains many granules rich in histamine and heparin. Although best known for their role in allergy and anaphylaxis, mast cells play an important protective role as well, being intimately involved in wound healing, angiogenesis, immune tolerance, defense against pathogens, and blood–brain barrier function.\n\nThe mast cell is very similar in both appearance and function to the basophil, another type of white blood cell. Although mast cells were once thought to be tissue resident basophils, it has been shown that the two cells develop from different hematopoietic lineages and thus cannot be the same cells.\n\nMast cells were first described by Paul Ehrlich in his 1878 doctoral thesis on the basis of their unique staining characteristics and large granules. These granules also led him to the incorrect belief that they existed to nourish the surrounding tissue, so he named them \"Mastzellen\" (, as of animals). They are now considered to be part of the immune system.\n\nMast cells are very similar to basophil granulocytes (a class of white blood cells) in blood. Both are granulated cells that contain histamine and heparin, an anticoagulant. The Fc region of immunoglobulin E (IgE) becomes bound to mast cells and basophils and when IgE's paratopes bind to an antigen, it causes the cells to release histamine and other inflammatory mediators. These similarities have led many to speculate that mast cells are basophils that have \"homed in\" on tissues. Furthermore, they share a common precursor in bone marrow expressing the CD34 molecule. Basophils leave the bone marrow already mature, whereas the mast cell circulates in an immature form, only maturing once in a tissue site. The site an immature mast cell settles in probably determines its precise characteristics. The first in vitro differentiation and growth of a pure population of mouse mast cells has been carried out using conditioned medium derived from concanavalin A-stimulated splenocytes. Later, it was discovered that T cell-derived interleukin 3 was the component present in the conditioned media that was required for mast cell differentiation and growth.\n\nMast cells in rodents are classically divided into two subtypes: connective tissue-type mast cells and mucosal mast cells. The activities of the latter are dependent on T-cells.\n\nMast cells are present in most tissues characteristically surrounding blood vessels and nerves, and are especially prominent near the boundaries between the outside world and the internal milieu, such as the skin, mucosa of the lungs, and digestive tract, as well as the mouth, conjunctiva, and nose.\n\nMast cells play a key role in the inflammatory process. When activated, a mast cell can either selectively release (piecemeal degranulation) or rapidly release (anaphylactic degranulation) \"mediators\", or compounds that induce inflammation, from storage granules into the local microenvironment. Mast cells can be stimulated to degranulate by allergens through cross-linking with immunoglobulin E receptors (e.g., FcεRI), physical injury through pattern recognition receptors for damage-associated molecular patterns (DAMPs), microbial pathogens through pattern recognition receptors for pathogen-associated molecular patterns (PAMPs), and various compounds through their associated G-protein coupled receptors (e.g., morphine through opioid receptors) or ligand-gated ion channels. Complement proteins can activate membrane receptors on mast cells to exert various functions as well.\n\nMast cells express a high-affinity receptor (FcεRI) for the Fc region of IgE, the least-abundant member of the antibodies. This receptor is of such high affinity that binding of IgE molecules is in essence irreversible. As a result, mast cells are coated with IgE, which is produced by plasma cells (the antibody-producing cells of the immune system). IgE molecules, like all antibodies, are specific to one particular antigen.\n\nIn allergic reactions, mast cells remain inactive until an allergen binds to IgE already coated upon the cell. Other membrane activation events can either prime mast cells for subsequent degranulation or act in synergy with FcεRI signal transduction. In general, allergens are proteins or polysaccharides. The allergen binds to the antigen-binding sites, which are situated on the variable regions of the IgE molecules bound to the mast cell surface. It appears that binding of two or more IgE molecules (cross-linking) is required to activate the mast cell. The clustering of the intracellular domains of the cell-bound Fc receptors, which are associated with the cross-linked IgE molecules, causes a complex sequence of reactions inside the mast cell that lead to its activation. Although this reaction is most well understood in terms of allergy, it appears to have evolved as a defense system against parasites and bacteria.\n\nA unique, stimulus-specific set of mast cell mediators is released through degranulation following the activation of cell surface receptors on mast cells. Examples of mediators that are released into the extracellular environment during mast cell degranulation include:\nHistamine dilates post-capillary venules, activates the endothelium, and increases blood vessel permeability. This leads to local edema (swelling), warmth, redness, and the attraction of other inflammatory cells to the site of release. It also depolarizes nerve endings (leading to itching or pain). Cutaneous signs of histamine release are the \"flare and wheal\"-reaction. The bump and redness immediately following a mosquito bite are a good example of this reaction, which occurs seconds after challenge of the mast cell by an allergen.\n\nThe other physiologic activities of mast cells are much less-understood. Several lines of evidence suggest that mast cells may have a fairly fundamental role in innate immunity: They are capable of elaborating a vast array of important cytokines and other inflammatory mediators such as TNFa; they express multiple \"pattern recognition receptors\" thought to be involved in recognizing broad classes of pathogens; and mice without mast cells seem to be much more susceptible to a variety of infections.\n\nMast cell granules carry a variety of bioactive chemicals. These granules have been found to be transferred to adjacent cells of the immune system and neurons in a process of transgranulation via mast cell pseudopodia.\n\nFcεR1 is a high affinity IgE-receptor that is expressed on the surface of the mast cell. FcεR1 is a tetramer made of one alpha (α) chain, one beta (β) chain, and two identical, disulfide-linked gamma (γ) chains. The binding site for the IgE is formed by the extracellular portion of the α chain that contains two domains that are similar to Ig. One transmembrane domain contains an aspartic acid residue, and one contains a short cytoplasmic tail. The β chain contains, a single immunoreceptor tyrosine-based activation motif ITAM, in the cytoplasmic region. Each γ chain has one ITAM on the cytoplasmic region. The signaling cascade from the receptor is initiated when the ITAMs of the β and γ chains are phosphorylated by tyrosine. This signal is required for the activation of mast cells. Type 2 helper T cells,(Th2) and many other cell types lack the β chain, so signaling is mediated only by the γ chain. This is due to the α chain containing endoplasmic reticulum retention signals that causes the α-chains to remain degraded in the ER. The assembly of the α chain with the co-transfected β and γ chains mask the ER retention and allows the α β γ complex to be exported to the golgi apparatus to the plasma membrane in rats. In humans, only the γ complex is needed to counterbalance the α chain ER retention.\n\nAllergen-mediated FcεR1 cross-linking signals are very similar to the signaling event resulting in antigen binding to lymphocytes. The Lyn tyrosine kinase is associated with the cytoplasmic end of the FcεR1 β chain. The antigen cross-links the FcεR1 molecules, and Lyn tyrosine kinase phosphorylates the ITAMs in the FcεR1 β and γ chain in the cytoplasm. Upon phosphorylation, the Syk tyrosine kinase gets recruited to the ITAMs located on the γ chains. This causes activation of the Syk tyrosine kinase, causing it to phosphorylate. Syk functions as a signal amplifying kinase activity due to the fact that it targets multiple proteins and causes their activation. This antigen stimulated phosphorylation causes the activation of other proteins in the FcεR1-mediated signaling cascade.\n\nAn important adaptor protein activated by the Syk phosphorylation step is the linker for activation of T cells (LAT). LAT can be modified by phosphorylation to create novel binding sites. Phospholipase C gamma (PLCγ) becomes phosphorylated once bound to LAT, and is then used to catalyze phosphatidylinositol bisphosphate breakdown to yield inositol trisphosphate (IP3) and diacyglycerol (DAG). IP3 elevates calcium levels, and DAG activates protein kinase C (PKC). This is not the only way that PKC is made. The tyrosine kinase FYN phosphorylates Grb2-associated-binding protein 2 (Gab2), which binds to phosphoinositide 3-kinase, which activates PKC. PKC leads to the activation of myosin light-chain phosphorylation granule movements, which disassembles the actin–myosin complexes to allow granules to come into contact with the plasma membrane. The mast cell granule can now fuse with the plasma membrane. Soluble N-ethylmaleimide sensitive fusion attachment protein receptor SNARE complex mediates this process. Different SNARE proteins interact to form different complexes that catalyze fusion. Rab3 guanosine triphosphatases and Rab-associated kinases and phosphatases regulate granule membrane fusion in resting mast cells.\n\nMast cells are activated in response to infection by pathogenic parasites, such as certain helminths and protozoa, through IgE signaling.\n\nMast cell activation disorders are a spectrum of immune disorders that are unrelated to pathogenic infection and involve similar symptoms that arise from secreted mast cell intermediates, but differ slightly in their pathophysiology, treatment approach, and distinguishing symptoms. The classification of mast cell activation disorders was laid out in 2010.\n\nAllergies are mediated through IgE signaling which triggers mast cell degranulation.\n\nMany forms of cutaneous and mucosal allergy are mediated in large part by mast cells; they play a central role in asthma, eczema, itch (from various causes), and allergic rhinitis and allergic conjunctivitis. Antihistamine drugs act by blocking histamine action on nerve endings. Cromoglicate-based drugs (sodium cromoglicate, nedocromil) block a calcium channel essential for mast cell degranulation, stabilizing the cell and preventing release of histamine and related mediators. Leukotriene antagonists (such as montelukast and zafirlukast) block the action of leukotriene mediators and are being used increasingly in allergic diseases.\n\nCalcium triggers the secretion of histamine from mast cells after previous exposure to sodium fluoride. The secretory process can be divided into a fluoride-activation step and a calcium-induced secretory step. It was observed that the fluoride-activation step is accompanied by an elevation of cyclic adenosine monophosphate (cAMP) levels within the cells. The attained high levels of cAMP persist during histamine release. It was further found that catecholamines do not markedly alter the fluoride-induced histamine release. It was also confirmed that the second, but not the first, step in sodium fluoride-induced histamine secretion is inhibited by theophylline. Vasodilation and increased permeability of capillaries are a result of both H1 and H2 receptor types.\n\nStimulation of histamine activates a histamine (H2)-sensitive adenylate cyclase of oxyntic cells, and there is a rapid increase in cellular [cAMP] that is involved in activation of H+ transport and other associated changes of oxyntic cells.\n\nIn anaphylaxis (a severe systemic reaction to allergens, such as nuts, bee stings, or drugs), the body-wide degranulation of mast cells leads to vasodilation and, if severe, symptoms of life-threatening shock.\n\nHistamine is a vasodilatory substance released during anaphylaxis.\n\nMast cells may be implicated in the pathology associated with autoimmune, inflammatory disorders of the joints. They have been shown to be involved in the recruitment of inflammatory cells to the joints (e.g., rheumatoid arthritis) and skin (e.g., bullous pemphigoid), and this activity is dependent on antibodies and complement components.\n\nMastocytosis is a rare clonal mast cell disorder involving the presence of too many mast cells (\"mastocytes\") and CD34+ mast cell precursors. Mutations in c-Kit are associated with mastocytosis.\n\nMastocytomas, or mast cell tumors, can secrete excessive quantities of degranulation products. They are often seen in dogs and cats. Other neoplastic disorders associated with mast cells include mast cell sarcoma and mast cell leukemia.\n\nMast cell activation syndrome (MCAS) is an idiopathic immune disorder that involves recurrent and excessive mast cell degranulation and which produces symptoms that are similar to other mast cell activation disorders. The syndrome is diagnosed based upon four sets of criteria involving treatment response, symptoms, a differential diagnosis, and biomarkers of mast cell degranulation.\n\nUnlike other hematopoietic cells of the immune system, mast cells naturally occur in the human brain where they interact with the neuroimmune system. In the brain, mast cells are located in a number of structures that mediate visceral sensory (e.g., pain) or neuroendocrine functions or that are located along the blood–cerebrospinal fluid barrier, including the pituitary stalk, pineal gland, thalamus, and hypothalamus, area postrema, choroid plexus, and in the dural layer of the meninges near meningeal nociceptors. Mast cells serve the same general functions in the body and central nervous system, such as effecting or regulating allergic responses, innate and adaptive immunity, autoimmunity, and inflammation. Across systems, mast cells serve as the main effector cell through which pathogens can affect the gut–brain axis.\n\nIn the gastrointestinal tract, mucosal mast cells are located in close proximity to sensory nerve fibres, which communicate bidirectionally. When these mast cells initially degranulate, they release mediators (e.g., histamine, tryptase, and serotonin) which activate, sensitize, and upregulate membrane expression of nociceptors (i.e., TRPV1) on visceral afferent neurons via their receptors (respectively, HRH1, HRH2, HRH3, PAR2, 5-HT3); in turn, neurogenic inflammation, visceral hypersensitivity, and intestinal dysmotility (i.e., impaired peristalsis) result. Neuronal activation induces neuropeptide (substance P and calcitonin gene-related peptide) signaling to mast cells where they bind to their associated receptors and trigger degranulation of a distinct set of mediators (β-Hexosaminidase, cytokines, chemokines, PGD2, leukotrienes, and eoxins).\n\nResearch into an immunological contribution to autism suggests that autism spectrum disorder (ASD) children may present with \"allergic-like\" problems in the absence of elevated serum IgE and chronic urticaria, suggesting non-allergic mast cell activation in response to environmental and stress triggers. This mast cell activation could contribute to brain inflammation and neurodevelopmental problems.\n\nToluidine blue: one of the most common stains for acid mucopolysaccharides and glycoaminoglycans, components of mast cells granules.\n\nSurface markers: cell surface markers of mast cells were discussed in detail by Heneberg, claiming that mast cells may be inadvertently included in the stem or progenitor cell isolates, since part of them is positive for the CD34 antigen. The classical mast cell markers include the high-affinity IgE receptor, CD117 (c-Kit), and CD203c (for most of the mast cell populations). Expression of some molecules may change in course of the mast cell activation.\n\n", "id": "254062", "title": "Mast cell"}
{"url": "https://en.wikipedia.org/wiki?curid=44273187", "text": "Interchromatin granule\n\nAn interchromatin granule is a cluster in the nucleus of a mammal cell which is enriched in pre-mRNA splicing factors. Interchromatin granules are located in the interchromatin regions of the mammalian Cell nuclei. They usually appear as irregularly shaped structures that vary in size and number. They can be observed by immunofluorescence microscopy.\n\nInterchromatin granules are structures undergoing constant change, and their components exchange continuously with the nucleoplasm, active transcription sites and other nuclear locations.\n\nResearch on dynamics of interchromatin granules has provided new insight into the functional organisation of the nucleus and gene expression.\n\nInterchromatin granule clusters vary in size anywhere between one and several micrometers in diameter. They are composed of 20–25 nm granules that are connected in a beaded chain fashion appearance by thin fibrils.\n\nInterchromatin granule clusters (IGCs) have been proposed to be stockpiles of fully mature snRNPs and other RNA processing components that are ready to be used in the production of mRNA.\n\n", "id": "44273187", "title": "Interchromatin granule"}
{"url": "https://en.wikipedia.org/wiki?curid=44419868", "text": "Single-cell variability\n\nIn cell biology, single-cell variability occurs when individual cells in an otherwise similar population differ in shape, size, position in the cell cycle, or molecular-level characteristics. Such differences can be detected using modern single-cell analysis techniques. Investigation of variability within a population of cells contributes to understanding of developmental and pathological processes,\n\nA sample of cells may appear similar, but the cells can vary in their individual characteristics, such as shape and size, mRNA expression levels, genome, or individual counts of metabolites. In the past, the only methods available for investigating such properties required a population of cells and provided an estimate of the characteristic of interest, averaged over the population, which could obscure important differences among the cells. Single-cell analysis allows scientists to study the properties of a single cell of interest with high accuracy, revealing individual differences among populations and offering new insights in molecular biology. These individual differences are important in fields such as developmental biology, where individual cells can take on different “fates” - become specialized cells such as neurons or organ tissue - during the growth of an embryo; in cancer research, where individual malignant cells can vary in their response to therapy; or in infectious disease, where only a subset of cells in a population become infected by a pathogen.\n\nPopulation-level views of cells can offer a distorted view of the data by averaging out the properties of distinct subsets of cells. For example, if half the cells of a particular group are expressing high levels of a given gene, and the rest are expressing low levels, results from a population-wide analysis may appear as if all cells are expressing a medium level of the given gene. Thus, single-cell analysis allows researchers to study biological processes in finer detail and answer questions that could not have been addressed otherwise.\n\nCells with identical genomes may vary in the expression of their genes due to differences in their specialized function in the body, their timepoint in the cell cycle, their environment, and also noise and stochastic factors. Thus, accurate measurement of gene expression in individual cells allows researchers to better understand these critical aspects of cellular biology. For example, early study of gene expression in individual cells in fruit fly embryos allowed scientists to discover regularized patterns or gradients of specific gene transcription during different stages of growth, allowing for a more detailed understanding of development at the level of location and time. Another phenomenon in gene expression which could only be identified at the single cell level is oscillatory gene expression, in which a gene is expressed on and off periodically.\n\nSingle-cell gene expression is typically assayed using RNA-seq. After the cell has been isolated, the RNA-seq protocol typically consists of three steps: the RNA is reverse transcribed into cDNA, the cDNA is amplified to make more material available for the sequencer, and the cDNA is sequenced.\n\nA population of single celled organisms like bacteria typically vary slightly in their DNA sequence due to mutations acquired during reproduction. Within a single human, individual cells typically have identical genomes, though there are interesting exceptions, such as B-cells, which have variation in their DNA enabling them to generate different antibodies to bind to the variety of pathogens that can attack the body. Measuring the differences and the rate of change in DNA content at the single-cell level can help scientists better understand how pathogens develop antibiotic resistance, why the immune system often cannot produce antibodies for rapidly mutating viruses like HIV, and other important phenomena.\n\nMany technologies exist for sequencing genomes, but they are designed to use DNA from a population of cells rather than a single cell. The primary challenge for single-cell genome sequencing is to make multiple copies of (amplify) the DNA so that there is enough material available for the sequencer, a process called whole genome amplification (WGA). Typical methods for WGA consist of: (1) Multiple Displacement Amplification (MDA) in which multiple primers anneal to the DNA, polymerases copy the DNA, and knock off other polymerases, freeing strands that can be processed by the sequencer, (2) PCR-based methods, or (3) some combination of both.\n\nCells vary in the metabolites they contain, which are the intermediary compounds and end products of complex biochemical reactions that sustain the cell. Genetically identical cells in different conditions and environments can use different metabolic pathways to sustain themselves. By measuring the metabolites present, scientists can infer the metabolic pathways used, and infer useful information about the state of the cell. An example of this is found in the immune system, where CD4+ cells can differentiate into Th17 or TReg cells (among other possibilities), both of which direct the immune system’s response in different ways. Th17 cells stimulate a strong inflammatory response, whereas TReg cells stimulate the opposite effect. The former tend to rely much more on glycolysis, due to their increased energy demands.\n\nIn order to profile the metabolic content of a cell, researchers must identify the cell of interest in the larger population, isolate it for analysis, quickly inhibit enzymes and halt the metabolic processes in the cell, and then use techniques such as NMR, mass-spec, microfluidics, and other methods to analyze the contents of the cell.\n\nSimilar to variation in the metabolome, the proteins present in a cell and their abundances can vary from cell to cell in an otherwise similar population. While transcription and translation determine the amount and variety of proteins produced, these processes are imprecise, and cells have a number of mechanisms which can change or degrade proteins, allowing for variance in the proteome that may not be accounted for by variance in gene expression. Also, proteins have many other important features besides simply being present or absent, such as whether have undergone posttranslational modifications such as phosphorylation, or are bound to molecules of interest. The variation in abundance and characteristics of proteins has implications for fields such as cancer research, where a drug targeting a particular protein may vary in its impact due to variability in the proteome.\n\nCytometry, surface methods, and microfluidics technologies are the three classes of tools commonly used to profile the proteomes of individual cells. Cytometry allows researchers to isolate cells of interest, and stain 15-30 proteins to measure their location and/or relative abundance. For surface methods, researchers place a single cell on a surface coated with antibodies, which then bind to proteins secreted by the cell and allow them to be measured. Microfluidics methods for proteome analysis immobilize single cells on a microchip and use staining to measure the proteins of interest, or antibodies to bind to the proteins of interest.\n\nCells in an otherwise similar population can vary in their size and morphology due to differences in function, changes in metabolism, or simply being in different phases of the cell cycle or some other factor. For example, stem cells can divide asymmetrically, which means the two resultant daughter cells may have different fates (specialized functions), and can differ from each other in size or shape. Researchers who study development may be interested in tracking the physical characteristics of the individual progeny in a growing population in order to understand how stem cells differentiate into a complex tissue or organism over time.\n\nMicroscopy can be used to analyze cell size and morphology by obtaining high-quality images over time. These pictures will typically contain a population of cells, but algorithms can be applied to identify and track individual cells across multiple images. The algorithms must be able to process gigabytes of data to remove noise and summarize the relevant characteristics for the given research question.\n\nIndividual cells in a population will often be at different points in the cell cycle. Scientists who wish to understand characteristics of the cell at a particular point in the cycle would have difficulty using population-level estimates, since they would average measurements from cells at different stages. Also, understanding the cell cycle in individual diseased cells, like those in a tumor, is also important, since they will often have a very different cycle than healthy cells. Single-cell analysis of characteristics of the cell cycle allow scientists to understand these properties in greater detail.\n\nVariability in cell cycle can be studied using several of the methods previously described. For example, cells in G2 will be quite large in size (as they are a just at the point where they are about to divide in two), and can be identified using protocols for cell size and shape. Cells in S phase copy their genomes, and could be identified using protocols for staining DNA and measuring its content by flow cytometry or quantitative fluorescence microscopy, or by using probes for genes expressed highly at specific phases of the cell cycle.\n", "id": "44419868", "title": "Single-cell variability"}
{"url": "https://en.wikipedia.org/wiki?curid=33993737", "text": "Decellularization\n\nDecellularization (also spelt decellularisation in British English) is the process used in biomedical engineering to isolate the extracellular matrix (ECM) of a tissue from its inhabiting cells, leaving an ECM scaffold of the original tissue, which can be used in artificial organ and tissue regeneration. Organ and tissue transplantation treat a variety of medical problems, ranging from end organ failure to cosmetic surgery. One of the greatest limitations to organ transplantation derives from organ rejection caused by antibodies of the transplant recipient reacting to donor antigens on cell surfaces within the donor organ. Because of unfavorable immune responses, transplant patients suffer a lifetime taking immunosuppressing medication. Stephen F. Badylak pioneered the process of decellularization at the McGowan Institute for Regenerative Medicine at the University of Pittsburgh. This process creates a natural biomaterial to act as a scaffold for cell growth, differentiation and tissue development. By recellularizing an ECM scaffold with a patient’s own cells, the adverse immune response is eliminated. Nowadays, commercially available ECM scaffolds are available for a wide variety of tissue engineering.\n\nWith a wide variety of decellularization-inducing treatments available, combinations of physical, chemical, and enzymatic treatments are carefully monitored to ensure that the ECM scaffold maintains the structural and chemical integrity of the original tissue. Scientists can use the acquired ECM scaffold to reproduce a functional organ by introducing progenitor cells, or adult stem cells (ASCs), and allowing them to differentiate within the scaffold to develop into the desired tissue. The produced organ or tissue can be transplanted into a patient. In contrast to cell surface antibodies, the biochemical components of the ECM are conserved between hosts, so the risk of a hostile immune response is minimized. Proper conservation of ECM fibers, growth factors, and other proteins is imperative to the progenitor cells differentiating into the proper adult cells. The success of decellularization varies based on the components and density of the applied tissue and its origin. The applications to the decellularizing method of producing a biomaterial scaffold for tissue regeneration are present in cardiac, dermal, pulmonary, renal, and other types of tissues. Complete organ reconstruction is still in the early levels of development.\n\nResearchers are able to take the tissue from a donor or cadaver, lyse and kill the cells within the tissue without damaging the extracellular components, and finish with a product that is the natural ECM scaffold that has the same physical and biochemical functions of the natural tissue. After acquiring the ECM scaffold, scientists can recellularize the tissue with potent stem or progenitor cells that will differentiate into the original type of tissue. By removing the cells from a donor tissue, the immunogenic antibodies from the donor will be removed. The progenitor cells can be taken from the host, therefore they will not have an adverse response to the tissue. This process of decellularizing tissues and organs is still being developed, but the exact process of taking a tissue from a donor and removing all the cellular components is considered to be the decellularization process. The steps to go from a decellularized ECM scaffold to a functional organ is under the umbrella of recellularization. Because of the diverse applications of tissue in the human body, decellularization techniques have to be tailored to the specific tissue being exercised on. The researched methods of decellularization include physical, chemical, and enzymatic treatments. Though some methods are more commonly used, the exact combination of treatments is variable based on the tissue’s origin and what it is needed for.\n\nAs far as introducing the different liquidized chemicals and enzymes to an organ or tissue, perfusion and immersion decellularization techniques have been used. Perfusion decellularization is applicable when an extensive vasculature system is present in the organ or tissue. It is crucial for the ECM scaffold to be decellularized at all levels, and evenly throughout the structure. Because of this requirement, vascularized tissues can have chemicals and enzymes perfused through the present arteries, veins, and capillaries. Under this mechanism and proper physiological conditions, treatments can diffuse equally to all of the cells within the organ. The treatments can be removed through the veins at the end of the process. Cardiac and pulmonary decellularization often uses this process of decellularization to introduce the treatments because of their heavily vascularized networks. Immersion decellularization is accomplished through the submersion of a tissue in chemical and enzymatic treatments. This process is more easily accomplished than perfusion, but is limited to thin tissues with a limited vascular system.\n\nThe most common physical methods used to lyse, kill, and remove cells from the matrix of a tissue through the use of temperature, force and pressure, and electrical disruption. Temperature methods are often used in a rapid freeze-thaw mechanism. By quickly freezing a tissue, microscopic ice crystals form around the plasma membrane and the cell is lysed. After lysing the cells, the tissue can be further exposed to liquidized chemicals that degrade and wash out the undesirable components. Temperature methods conserve the physical structure of the ECM scaffold, but are best handled by thick, strong tissues.\n\nDirect force of pressure to a tissue will guarantee disruption of the ECM structure, so pressure is commonly used. Pressure decellularization involves the controlled use of hydrostatic pressure applied to a tissue or organ. This is done best at high temperatures to avoid unmonitored ice crystal formation that could damage the scaffold. Electrical disruption of the plasma membrane is another option to lyse the cells housed in a tissue or organ. By exposing a tissue to electrical pulses, micropores are formed at the plasma membrane. The cells eventually turn to death after their homeostatic electrical balance is ruined through the applied stimulus. This electrical process is documented as Non-thermal irreversible electroporation (NTIRE) and is limited to small tissues and the limited possibilities of inducing an electric current \"in vivo\".\n\nThe proper combination of chemicals is selected for decellularization depending on the thickness, extracellular matrix composition, and intended use of the tissue or organ. For example, enzymes would not be used on a collagenous tissue because they disrupt the connective tissue fibers. However, when collagen is not present in a high concentration or needed in the tissue, enzymes can be a viable option for decellularization. The chemicals used to kill and remove the cells include acids, alkaline treatments, ionic detergents, non-ionic detergents, and zwitterionic detergents.\n\nThe ionic detergent, sodium dodecyl sulfate (SDS), is commonly used because of its high efficacy for lysing cells without significant damage to the ECM. Detergents act effectively to lyse the cell membrane and expose the contents to further degradation. After SDS lyses the cell membrane, endonucleases and exonucleases degrade the genetic contents, while other components of the cell is solubilized and washed out of the matrix. SDS is commonly used even though it has a tendency to slightly disrupt the ECM structure. Akaline and acid treatments can be effective companions with an SDS treatment due to their ability to degrade nucleic acids and solubilize cytoplasmic inclusions.\n\nThe most well known non-ionic detergent is Triton X-100, which is popular because of its ability to disrupt the interactions between lipids and between lipids and proteins. Triton X-100 does not disrupt protein-protein interactions, which is beneficial to keeping the ECM intact. EDTA is a chelating agent that binds calcium, which is a necessary component for proteins to interact with one another. By making calcium unavailable, EDTA prevents the integral proteins between cells from binding to one another. EDTA is often used with trypsin, an enzyme that acts as a protease to cleave the already existing bonds between integral proteins of neighboring cells within a tissue. Together, the EDTA-Trypsin combination make a good team for decellularizing tissues.\n\nEnzymes used in decellularization treatments are used to break the bonds and interactions between nucleic acids, interacting cells through neighboring proteins, and other cellular components. Lipases, thermolysin, galactosidase, nucleases, and trypsin have all been used in the removal of cells. After a cell is lysed with a detergent, acid, physical pressure, etc., endonucleases and exonucleases can begin the degradation of the genetic material. Endonucleases cleave DNA and RNA in the middle of sequences. Benzoase, an endonuclease, produces multiple small nuclear fragments that can be further degraded and removed from the ECM scaffold. Exonucleases act at the end of DNA sequences to cleave the phosphodiester bonds and further degrade the nucleic acid sequences.\n\nEnzymes such as trypsin act as proteases that cleave the interactions between proteins. Although trypsin can have adverse effects of collagen and elastin fibers of the ECM, using it in a time-sensitive manner controls any potential damage it could cause on the extracellular fibers. Dispase is used to prevent undesired aggregation of cells, which is beneficial in promoting their separating from the ECM scaffold. Experimentation has shown dispase to be most effective on the surface of a thin tissue, such as a lung in pulmonary tissue regeneration. To successfully remove deep cells of a tissue with dispase, mechanical agitation is often included in the process.\n\nCollagenase is only used when the ECM scaffold product does not require an intact collagen structure. Lipases are commonly used when decellularized skin grafts are needed. Lipase acids function in decellularizing dermal tissues through delipidation and cleaving the interactions between heavily lipidized cells. The enzyme, α-galactosidase is a relevant treatment when removing the Gal epitope antigen from cell surfaces.\n\nA natural ECM scaffold provides the necessary physical and biochemical environment to facilitate the growth and specialization of potent progenitor and stem cells. Acellular matrices have been isolated \"in vitro\" and \"in vivo\" in a number of different tissues and organs. The most applicable success from decellularized tissues has come from symmetrical tissues that have less specialization, such as bone and dermal grafts; however, research and success is ongoing at the organ level.\n\nAcellular dermal matrices have been successful in a number of different applications. For example, skin grafts are used in cosmetic surgery and burn care. The decellularized skin graft provides mechanical support to the damaged area while supporting the development of host-derived connective tissue. Cardiac tissue has clinical success in developing human valves from natural ECM matrices. A technique known as the Ross procedure uses an acellular heart valve to replace a defective valve, allowing native cells to repopulate a newly functioning valve. Decellularized allografts have been critical in bone grafts that function in bone reconstruction and replacing of deformed bones in patients.\n\nThe limits to myocardial tissue engineering come from the ability to immediately perfuse and seed and implemented heart into a patient. Though the ECM scaffold maintains the protein and growth factors of the natural tissue, the molecular level specialization has not yet been harnessed by researchers using decellularized heart scaffolds. Better success at using a whole organ from decellularization techniques has been found in pulmonary research. Scientists have been able to regenerate whole lungs \"in vitro\" from rat lungs using perfusion-decellularization. By seeding the matrix with fetal rat lung cells, a functioning lung was produced. The \"in vitro\"-produced lung was successfully implemented into a rat, which attests to the possibilities of translating an \"in vitro\" produced organ into a patient.\n\nOther success for decellularization has been found in small intestinal submucosa (SIS), renal, hepatic, and pancreatic engineering. Because it is a thin material, the SIS matrix can be decellularized through immersing the tissue in chemical and enzymatic treatments. Renal tissue engineering is still developing, but cadaveric kidney matrices have been able to support development of potent fetal kidney cells. Pancreatic engineering is a testament to the molecular specificity of organs. Scientists have not yet been able to produce an entirely functioning pancreas, but they have had success in producing an organ that functions at specific segments. For example, diabetes in rats was shown to decrease by seeding a pancreatic matrix at specific sites. The future applications of decellularized tissue matrix is still being discovered and is considered one of the most hopeful areas in regenerative research.\n\n", "id": "33993737", "title": "Decellularization"}
{"url": "https://en.wikipedia.org/wiki?curid=13222629", "text": "ADP-ribosylation\n\nADP-ribosylation is the addition of one or more ADP-ribose moieties to a protein. It is a reversible post-translational modification that is involved in many cellular processes, including cell signaling, DNA repair, gene regulation and apoptosis.\nImproper ADP-ribosylation has been implicated in some forms of cancer. It is also the basis for the toxicity of bacterial compounds such as cholera toxin, diphtheria toxin, and others.\n\nThe first suggestion of ADP-ribosylation surfaced during the early 1960s. At this time, Pierre Chambon and coworkers observed the incorporation of ATP into hen liver nuclei extract. After extensive studies on the acid insoluble fraction, several different research laboratories were able to identify ADP-ribose, derived from NAD+, as the incorporated group. Several years later, the enzymes responsible for this incorporation were identified and given the name poly (ADP-ribose) polymerase. Originally, this group was thought to be a linear sequence of ADP-ribose units covalently bonded through a ribose glycosidic bond. It was later reported that branching can occur every 20 to 30 ADP residues.\n\nThe first appearance of mono-ADP-ribosylation occurred a year later during a study of toxins: corynebacterium diphtheria diphtheria toxin was shown to be dependent on NAD+ in order for it to be completely effective, leading to the discovery of enzymatic conjugation of a single ADP-ribose group by mono-ADP-ribosyl transferase.\n\nIt was initially thought that ADP-ribosylation was a post translational modification involved solely in gene regulation. However, as more enzymes with the ability to ADP-ribosylate proteins were discovered, the multifunctional nature of ADP-ribosylation became apparent. The first mammalian enzyme with poly-ADP-ribose transferase activity was discovered during the late 1980s. For the next 15 years, it was thought to be the only enzyme capable of adding a chain of ADP-ribose in mammalian cells. During the late 1980s, ADP-ribosyl cyclases, which catalyze the addition of cyclic-ADP-ribose groups to proteins, were discovered. Finally, sirtuins, a family of enzymes that also possess NAD+-dependent deacylation activity, were discovered to also possess mono-ADP-ribosyl transferase activity.\n\nThe source of ADP-ribose for most enzymes that perform this modification is the redox cofactor NAD. In this transfer reaction, the N-glycosidic bond of NAD that bridges the ADP-ribose molecule and the nicotinamide group is cleaved, followed by nucleophilic attack by the target amino acid side chain. ADP-ribosyltransferases can perform two types of modifications: mono-ADP ribosylation and poly-ADP ribosylation.\n\nMono-ADP ribosyltransferases commonly catalyze the addition of ADP-ribose to arginine side chains using a highly conserved R-S-EXE motif. The reaction proceeds by breaking the bond between nicotinamide and ribose to form an oxonium ion. Next, the arginine side chain of the target protein then acts a nucleophile, attacking the electrophilic carbon adjacent to the oxonium ion. In order for this step to occur, the arginine nucleophile is deprotonated by a glutamate residue on the catalyzing enzyme. Another conserved glutamate residue forms a hydrogen bond with one of the hydroxyl groups on the ribose chain to further facilitate this nucleophilic attack. As a result of the cleavage reaction, nicotinamide is released. The modification can be reversed by ADP-ribosylhydrolases, which cleave the N-glycosidic bond between arginine and ribose to release ADP-ribose and unmodified protein; NAD+ is not restored by the reverse reaction.\n\nPoly-(ADP-ribose) polymerases (PARPs) are found mostly in eukaryotes and catalyze the transfer of multiple ADP-ribose molecules to target proteins. As with mono-ADP ribosylation, the source of ADP-ribose is NAD. PARPs use a catalytic triad of His-Tyr-Glu to facilitate binding of NAD and positioning of the end of the existing poly-ADP ribose chain on the target protein; the Glu facilitates catalysis and formation of a (1->2) O-glycosidic linkage between two ribose molecules. \nThere are several other enzymes that recognize poly-ADP ribose chains, hydrolyse them or form branches; over 800 proteins have been annotated to contain the loosely defined poly ADP-ribose binding motif; therefore, in addition to this modification altering target protein conformation and structure, it may also be used as a tag to recruit other proteins or for regulation of the target protein.\n\nDuring DNA damage or cellular stress PARPs are activated, leading to an increase in the amount of poly-ADP-ribose and a decrease in the amount of NAD+. For over a decade it was thought that PARP1 was the only poly-ADP-ribose polymerase in mammalian cells, therefore this enzyme has been the most studied. Caspases are a family of cysteine proteases that are known to play an essential role in programmed cell death. This protease cleaves PARP-1 into two fragments, leaving it completely inactive, to limit poly-ADP-ribose production. One of its fragments migrates from the nucleus to the cytoplasm and is thought to become a target of autoimmunity.\n\nDuring caspase-independent apoptosis, also called parthanatos, poly-ADP-ribose accumulation can occur due to activation of PARPs or inactivation of poly(ADP-ribose) glycohydrolase, an enzyme that hydrolyses poly(ADP-ribose) to produce free ADP-ribose. Studies have shown poly-ADP-ribose drives the translocation of the apoptosis inducing factor protein to the nucleus where it will mediate DNA fragmentation. It has been suggested that if a failure of caspase activation under stress conditions were to occur, necroptosis would take place. Overactivation of PARPs has led to a necrotic cell death regulated by the tumor necrosis factor protein. Though the mechanism is not yet understood, PARP inhibitors have been shown to affect necroptosis.\n\nADP-ribosylation can affect gene expression at nearly every level of regulation, including chromatin organization, transcription factor recruitment and binding, and mRNA processing.\n\nThe organization of nucleosomes is key to regulation of gene expression: the spacing and organization of nucleosomes changes what regions of DNA are available for transcription machinery to bind and transcribe DNA. PARP1, a poly-ADP ribose polymerase, has been shown to affect chromatin structure and promote changes in the organization of nucleosomes through modification of histones. \nPARPs have been shown to affect transcription factor structure and cause recruitment of many transcription factors to form complexes at DNA and elicit transcription.Mono ADP-ribosyltransferases are also shown to affect transcription factor binding at promoters. For example, PARP14, a mono ADP-ribosyltransferase, has been shown to affect STAT transcription factor binding.\n\nOther ADP-ribosyltransferases have been shown to modify proteins that bind mRNA, which can cause silencing of that gene transcript.\n\nPoly-ADP-ribose polymerases (PARPs) can function in DNA repair of single strand breaks as well as double strand breaks. In single-strand break repair (base excision repair) the PARP can either facilitate removal of an oxidized sugar or strand cleavage. PARP1 binds the single-strand breaks and pulls any nearby base excision repair intermediates close. These intermediates include XRCC1 and APLF and they can be recruited directly or through the PBZ domain of the APLF. This leads to the synthesis of poly-ADP ribose. The PBZ domain is present in many proteins involved in DNA repair and allows for the binding of the PARP and thus ADP-ribosylation which recruits repair factors to interact at the break site. PARP2 is a secondary responder to DNA damage but serves to provide functional redundancy in DNA repair.\n\nThere are many mechanisms for the repair of damaged double stranded DNA. PARP1 may function as a synapsis factor in alternative non-homologous end joining. Additionally, It has been proposed that PARP1 is required to slow replication forks following DNA damage and promotes homologous recombination at replication forks that may be dysfunctional. It is possible that PARP1 and PARP3 work together in repair of double-stranded DNA and it has been shown that PARP3 is critical for double-stranded break resolution. There are two hypotheses by which PARP1 and PARP3 coincide. The first hypothesis states that the two ADP-ribosyltransferases serve to function for each other's inactivity. If PARP3 is lost, this results in single-strand breaks, and thus the recruitment of PARP1. A second hypothesis suggests that the two enzyme work together; PARP3 catalyzes mono-ADP ribosylation and short poly-ADP ribosylation and serves to activate PARP1.\n\nThe PARPs have many protein targets at the site of DNA damage. KU protein and DNA-PKcs are both double-stranded break repair components with unknown sites of ADP-ribosylation. Histones are another protein target of the PARPs. All core histones and linker histone H1 are ADP-ribosylated following DNA damage. The function of these modifications is still unknown, but it has been proposed that ADP-ribosylation modulates higher-order chromatin structure in efforts to facilitate more accessible sites for repair factors to migrate to the DNA damage.\n\nThe ubiquitin-proteasome system (UPS) figures prominently in protein degradation. The 26S proteasome consists of a catalytic subunit (the 20S core particle), and a regulatory subunit (the 19S cap). Poly-ubiquitin chains tag proteins for degradation by the proteasome, which causes hydrolysis of tagged proteins into smaller peptides.\n\nTankyrase (TNKS), an ADP-ribosyltransferase, interacts with proteasome regulator PI31. Evidence in \"Drosophila\" and human cell lines demonstrates that the Ankyrin domain (ANK) of TNKS facilitates interaction with the N-terminal TNKS-binding motif and C-terminal HbYX domain of PI31. This promotes ADP-ribosylation of PI31 by the PARP domain of TNKS. In addition, it was shown that treatment of \"Drosophila\" cells with a TNKS inhibitor, XAV939, attenuated 26S proteasome activity. Moreover, ADP-ribosylation of PI31 has been demonstrated to block PI31-mediated inhibition of α-subunits of the 20S particle. Therefore, a working hypothesis is that tankyrase-mediated ADP-ribosylation reduces PI31's activity, which in turn decreases protein degradation performed by the proteasome.\n\nPARP1 is involved in base excision repair (BER), single- and double-strand break repair, and chromosomal stability. It is also involved in transcriptional regulation through its facilitation of protein–protein interactions. PARP1 uses NAD+ in order to perform its function in apoptosis. If a PARP becomes overactive the cell will have decreased levels of NAD+ cofactor as well as decreased levels of ATP and thus will undergo necrosis. This is important in carcinogenesis because it could lead to the selection of PARP1 deficient cells (but not depleted) due to their survival advantage during cancer growth.\n\nSusceptibility to carcinogenesis under PARP1 deficiency depends significantly on the type of DNA damage incurred. There are many implications that various PARPs are involved in preventing carcinogenesis. As stated previously, PARP1 and PARP2 are involved in BER and chromosomal stability. PARP3 is involved in centrosome regulation. Tankyrase is another ADP-ribose polymerase that is involved in telomere length regulation.\n\nPARP1 inhibition has also been widely studied in anticancer therapeutics. The mechanism of action of a PARP1 inhibitor is to enhance the damage done by chemotherapy on the cancerous DNA by disallowing the reparative function of PARP1.\n\nPARP14 is another ADP-ribosylating enzyme that has been well-studied in regards to cancer therapy targets; it is a signal transducer and activator of STAT6 transcription-interacting protein, and was shown to be associated with the aggressiveness of B-cell lymphomas.\n\nBacterial ADP-ribosylating exotoxins (bAREs) covalently transfer an ADP-Ribose moiety of NAD+ to target proteins of infected eukaryotes, to yield nicotinamide and a free hydrogen ion. bAREs are produced as enzyme precursors, consisting of a \"A\" and \"B\" domains: the \"A\" domain is responsible for ADP-Ribosylation activity; and, the \"B\" domain for translocation of the enzyme across the membrane of the cell. These domains can exist in concert in three forms: first, as single polypeptide chains with A and B domains covalently linked; second, in multi-protein complexes with A and B domains bound by non-covalent interactions; and, third, in multi-protein complexes with A and B domains not directly interacting, prior to processing.\n\nUpon activation, bAREs ADP-ribosylate any number of eukaryotic proteins; such mechanism is crucial to the instigation of the diseased states associated with ADP-ribosylation. GTP-binding proteins, in particular, are well-established in bAREs pathophysiology. For examples, cholera and heat-labile enterotoxin target the α-subunit of Gs of heterotrimeric GTP-binding proteins. As the α-subunit is ADP-ribosylated, it is permanently in an \"active\", GTP-bound state; subsequent activation of intracellular cyclic AMP stimulates the release of fluid and ions from intestinal epithelial cells. Furthermore, C3 ADP-ribosylates GTP-binding proteins Rho and Ras, and Pertussis ADP-Ribosylates Gi, Go, and Gt. In diphtheria, ADP-ribosylates ribosomal elongation factor EF-2, which attenuates protein synthesis.\n\nThere are a variety of bacteria which employ bAREs in infection: cholera of vibrio cholera; heat-labile enterotoxin of E.Coli; Exotoxin A of Pseudomonas aeruginosa; Pertussis toxin of B. Pertussis; C3 toxin of C. botulinum; and Diphtheria toxin of Corynebacterium diphtheriae.\n\n", "id": "13222629", "title": "ADP-ribosylation"}
{"url": "https://en.wikipedia.org/wiki?curid=4109042", "text": "Cell signaling\n\nCell signaling (cell signalling in British English) is part of any communication process that governs basic activities of cells and coordinates all cell actions. The ability of cells to perceive and correctly respond to their microenvironment is the basis of development, tissue repair, and immunity, as well as normal tissue homeostasis. Errors in signaling interactions and cellular information processing are responsible for diseases such as cancer, autoimmunity, and diabetes. By understanding cell signaling, diseases may be treated more effectively and, theoretically, artificial tissues may be created.\n\nTraditional work in biology has focused on studying individual parts of cell signaling pathways. Systems biology research helps us to understand the underlying structure of cell signaling networks and how changes in these networks may affect the transmission and flow of information (signal transduction). Such networks are complex systems in their organization and may exhibit a number of emergent properties including bistability and ultrasensitivity. Analysis of cell signaling networks requires a combination of experimental and theoretical approaches including the development and analysis of simulations and modeling. Long-range allostery is often a significant component of cell signaling events.\n\nCell signaling has been most extensively studied in the context of human diseases and signaling between cells of a single organism. However, cell signaling may also occur between the cells of two different organisms. In many mammals, early embryo cells exchange signals with cells of the uterus. In the human gastrointestinal tract, bacteria exchange signals with each other and with human epithelial and immune system cells. For the yeast \"Saccharomyces cerevisiae\" during mating, some cells send a peptide signal (mating factor pheromones) into their environment. The mating factor peptide may bind to a cell surface receptor on other yeast cells and induce them to prepare for mating.\n\nCell signaling can be classified to be mechanical and biochemical based on the type of the signal.\nMechanical signals are the forces exerted on the cell and the forces produced by the cell. These forces can both be sensed and responded by the cells.\nBiochemical signals are the biochemical molecules such as proteins, lipids, ions and gases. These signals can be categorized based on the distance between signaling and responder cells. Signaling within, between, and amongst cells is subdivided into the following classifications:\n\nCells communicate with each other via direct contact (juxtacrine signaling), over short distances (paracrine signaling), or over large distances and/or scales (endocrine signaling).\n\nSome cell–cell communication requires direct cell–cell contact. Some cells can form gap junctions that connect their cytoplasm to the cytoplasm of adjacent cells. In cardiac muscle, gap junctions between adjacent cells allows for action potential propagation from the cardiac pacemaker region of the heart to spread and coordinately cause contraction of the heart.\n\nThe notch signaling mechanism is an example of juxtacrine signaling (also known as contact-dependent signaling) in which two adjacent cells must make physical contact in order to communicate. This requirement for direct contact allows for very precise control of cell differentiation during embryonic development. In the worm \"Caenorhabditis elegans\", two cells of the developing gonad each have an equal chance of terminally differentiating or becoming a uterine precursor cell that continues to divide. The choice of which cell continues to divide is controlled by competition of cell surface signals. One cell will happen to produce more of a cell surface protein that activates the Notch receptor on the adjacent cell. This activates a feedback loop or system that reduces Notch expression in the cell that will differentiate and that increases Notch on the surface of the cell that continues as a stem cell.\n\nMany cell signals are carried by molecules that are released by one cell and move to make contact with another cell. \"Endocrine\" signals are called hormones. Hormones are produced by endocrine cells and they travel through the blood to reach all parts of the body. Specificity of signaling can be controlled if only some cells can respond to a particular hormone. \"Paracrine\" signals such as retinoic acid target only cells in the vicinity of the emitting cell. Neurotransmitters represent another example of a paracrine signal. Some signaling molecules can function as both a hormone and a neurotransmitter. For example, epinephrine and norepinephrine can function as hormones when released from the adrenal gland and are transported to the heart by way of the blood stream. Norepinephrine can also be produced by neurons to function as a neurotransmitter within the brain. Estrogen can be released by the ovary and function as a hormone or act locally via paracrine or autocrine signaling. Active species of oxygen and nitric oxide can also act as cellular messengers. This process is dubbed redox signaling.\n\nIn a multicellular organism, signaling between cells occurs either through release into the extracellular space, divided in paracrine signaling (over short distances) and endocrine signaling (over long distances), or by direct contact, known as juxtacrine signaling. Autocrine signaling is a special case of paracrine signaling where the secreting cell has the ability to respond to the secreted signaling molecule. Synaptic signaling is a special case of paracrine signaling (for chemical synapses) or juxtacrine signaling (for electrical synapses) between neurons and target cells. Signaling molecules interact with a target cell as a ligand to cell surface receptors, and/or by entering into the cell through its membrane or endocytosis for intracrine signaling. This generally results in the activation of second messengers, leading to various physiological effects.\n\nA particular molecule is generally used in diverse modes of signaling, and therefore a classification by mode of signaling is not possible. At least three important classes of signaling molecules are widely recognized, although non-exhaustive and with imprecise boundaries, as such membership is non-exclusive and depends on the context:\n\nSignaling molecules can belong to several chemical classes: lipids, phospholipids, amino acids, monoamines, proteins, glycoproteins, or gases. Signaling molecules binding surface receptors are generally large and hydrophilic (e.g. TRH, Vasopressin, Acetylcholine), while those entering the cell are generally small and hydrophobic (e.g. glucocorticoids, thyroid hormones, cholecalciferol, retinoic acid), but important exceptions to both are numerous, and a same molecule can act both via surface receptor or in an intracrine manner to different effects. In intracrine signaling, once inside the cell, a signaling molecule can bind to intracellular receptors, other elements, or stimulate enzyme activity (e.g. gasses). The intracrine action of peptide hormones remains a subject of debate.\n\nHydrogen sulfide is produced in small amounts by some cells of the human body and has a number of biological signaling functions. Only two other such gases are currently known to act as signaling molecules in the human body: nitric oxide and carbon monoxide.\n\nCells receive information from their neighbors through a class of proteins known as receptors. Notch is a cell surface protein that functions as a receptor. Animals have a small set of genes that code for signaling proteins that interact specifically with Notch receptors and stimulate a response in cells that express Notch on their surface. Molecules that activate (or, in some cases, inhibit) receptors can be classified as hormones, neurotransmitters, cytokines, and growth factors, in general called receptor ligands. Ligand receptor interactions such as that of the Notch receptor interaction, are known to be the main interactions responsible for cell signaling mechanisms and communication.\n\nAs shown in Figure 2 (above; left), notch acts as a receptor for ligands that are expressed on adjacent cells. While some receptors are cell surface proteins, others are found inside cells. For example, estrogen is a hydrophobic molecule that can pass through the lipid bilayer of the membranes. As part of the endocrine system, intracellular estrogen receptors from a variety of cell types can be activated by estrogen produced in the ovaries.\n\nA number of transmembrane receptors for small molecules and peptide hormones, as well as intracellular receptors for steroid hormones exist, giving cells the ability to respond to a great number of hormonal and pharmacological stimuli. In diseases, often, proteins that interact with receptors are aberrantly activated, resulting in constitutively activated downstream signals.\n\nFor several types of intercellular signaling molecules that are unable to permeate the hydrophobic cell membrane due to their hydrophilic nature, the target receptor is expressed on the membrane. When such a signaling molecule activates its receptor, the signal is carried into the cell usually by means of a second messenger such as cAMP.\n\nIn some cases, receptor activation caused by ligand binding to a receptor is directly coupled to the cell's response to the ligand. For example, the neurotransmitter GABA can activate a cell surface receptor that is part of an ion channel. GABA binding to a GABA receptor on a neuron opens a chloride-selective ion channel that is part of the receptor. GABA receptor activation allows negatively charged chloride ions to move into the neuron, which inhibits the ability of the neuron to produce action potentials. However, for many cell surface receptors, ligand-receptor interactions are not directly linked to the cell's response. The activated receptor must first interact with other proteins inside the cell before the ultimate physiological effect of the ligand on the cell's behavior is produced. Often, the behavior of a chain of several interacting cell proteins is altered following receptor activation. The entire set of cell changes induced by receptor activation is called a signal transduction mechanism or pathway.\n\nIn the case of Notch-mediated signaling, the signal transduction mechanism can be relatively simple. As shown in Figure 2, activation of Notch can cause the Notch protein to be altered by a protease. Part of the Notch protein is released from the cell surface membrane and takes part in gene regulation. Cell signaling research involves studying the spatial and temporal dynamics of both receptors and the components of signaling pathways that are activated by receptors in various cell types.\n\nA more complex signal transduction pathway is shown in Figure 3. This pathway involves changes of protein–protein interactions inside the cell, induced by an external signal. Many growth factors bind to receptors at the cell surface and stimulate cells to progress through the cell cycle and divide. Several of these receptors are kinases that start to phosphorylate themselves and other proteins when binding to a ligand. This phosphorylation can generate a binding site for a different protein and thus induce protein–protein interaction. In Figure 3, the ligand (called epidermal growth factor (EGF)) binds to the receptor (called EGFR). This activates the receptor to phosphorylate itself. The phosphorylated receptor binds to an adaptor protein (GRB2), which couples the signal to further downstream signaling processes. For example, one of the signal transduction pathways that are activated is called the mitogen-activated protein kinase (MAPK) pathway. The signal transduction component labeled as \"MAPK\" in the pathway was originally called \"ERK,\" so the pathway is called the MAPK/ERK pathway. The MAPK protein is an enzyme, a protein kinase that can attach phosphate to target proteins such as the transcription factor MYC and, thus, alter gene transcription and, ultimately, cell cycle progression. Many cellular proteins are activated downstream of the growth factor receptors (such as EGFR) that initiate this signal transduction pathway.\n\nSome signaling transduction pathways respond differently, depending on the amount of signaling received by the cell. For instance, the hedgehog protein activates different genes, depending on the amount of hedgehog protein present.\n\nComplex multi-component signal transduction pathways provide opportunities for feedback, signal amplification, and interactions inside one cell between multiple signals and signaling pathways.\n\nMolecular signaling can occur between different organisms, whether unicellular or multicellular. The emitting organism produces the signaling molecule, secretes it into the environment, where it diffuses, and it is sensed or internalized by the receiving organism. In some cases of interspecies signaling, the emitting organism can actually be a host of the receiving organism, or vice versa.\n\nIntraspecies signaling occurs especially in bacteria, yeast, social insects, but also many vertebrates. The signaling molecules used by multicellular organisms are often called pheromones. They can have such purposes as alerting against danger, indicating food supply, or assisting in reproduction. In unicellular organisms such as bacteria, signaling can be used to 'activate' peers from a dormant state, enhance virulence, defend against bacteriophages, etc. In quorum sensing, which is also found in social insects, the multiplicity of individual signals has the potentiality to create a positive feedback loop, generating coordinated response. In this context, the signaling molecules are called autoinducers. This signaling mechanism may have been involved in evolution from unicellular to multicellular organisms. Bacteria also use contact-dependent signaling, notably to limit their growth.\n\nMolecular signaling can also occur between individuals of different species. This has been particularly studied in bacteria. Different bacterial species can coordinate to colonize a host and participate in common quorum sensing. Therapeutic strategies to disrupt this phenomenon are being investigated. Interactions mediated through signaling molecules are also thought to occur between the gut flora and their host, as part of their commensal or symbiotic relationship. Gram negative microbes deploy bacterial outer membrane vesicles for intra- and inter-species signaling in natural environments and at the host-pathogen interface.\n\nAdditionally, interspecies signaling occurs between multicellular organisms. In \"Vespa mandarinia\", individuals release a scent that directs the colony to a food source.\n\n\n", "id": "4109042", "title": "Cell signaling"}
{"url": "https://en.wikipedia.org/wiki?curid=46226557", "text": "Ball and chain inactivation\n\nIn neuroscience, ball and chain inactivation is a model to explain the fast inactivation mechanism of voltage-gated ion channels. The process is also called hinged-lid inactivation or N-type inactivation. A voltage-gated ion channel can be in three states: open, closed, or inactivated. The inactivated state is mainly achieved through fast inactivation, by which a channel transitions rapidly from an open to an inactivated state. The model proposes that the inactivated state, which is stable and non-conducting, is caused by the physical blockage of the pore. The blockage is caused by a \"ball\" of amino acids connected to the main protein by a string of residues on the cytoplasmic side of the membrane. The ball enters the open channel and binds to the hydrophobic inner vestibule within the channel. This blockage causes inactivation of the channel by stopping the flow of ions. This phenomenon has mainly been studied in potassium channels and sodium channels.\n\nThe initial evidence for a ball and chain inactivation came in 1977 with Clay Armstrong and Francisco Bezanilla's work. \nThe suggestion of a physical basis for non-conductance came from experiments in squid giant axons, showing that internal treatment with pronase disrupted the inactivation phenomenon. This suggested a physical, tethered mechanism for inactivation as the pronase was inferred to degrade the channel blocker and abolish the inactivation process. These experiments also showed that inactivation can only occur after the opening of the channel. This was done by hyperpolarising the membrane, causing the channel to open, and observing a delay in inactivation. Inactivation was not observed when the membrane was depolarised (closed). Introducing tetraethylammonium (TEA) on the intracellular side of the channel was found to mimic inactivation in non-inactivating channels. Blockage of the channel by TEA is mutually exclusive with peptide-mediate blockage, suggesting that TEA competes for an inactivation binding site.\n\nMutagenesis experiments have identified an intracellular string of amino acids as prime candidates for the pore blocker. The precise sequence of amino acids that makes up the channel-blocking ball in potassium channels was identified through the creation a synthetic peptide. The peptide was built based on the sequence of a 20 amino acid residue from the \"Drosophila melanogaster\" 's Shaker ShB protein and applied on the intracellular side of a non-inactivating channel in \"Xenopus\" oocytes. The peptide restored inactivation to the channel, giving further support to the ball and chain model. In β proteins, the first three residues after the initial methionine have been identified as essential for inactivation. The initial residues have a sequence motif of phenylalanine, isoleucine and tryptophan without which inactivation does not occur. Modifying the subsequent residues alters the speed and efficacy of inactivation without abolishing it.\n\nMore recently, nuclear magnetic resonance studies in \"Xenopus\" oocyte BK channels have shed further light on the structural properties of the ball and chain domain. The introduction of the KCNMB2 β subunit to the cytoplasmic side of a non-inactivating channel restored inactivation, conforming to the expected behaviour of a ball and chain-type protein. NMR analysis showed that the ball domain is composed of residues 1–17 and the chain region of residues 20–45. The three amino acids in the middle constitute a flexible linker region between the two functional regions. The ball is at the N-terminus of the β subunit and consists of a disordered part (residues 1–10) and a loop-helix motif formed by a block of amino acids spanning from serine at position 11 to aspartate at position 16. The structure of the chain domain is 4-turn alpha helix structure.\n\nThe ball and chain domains are on the cytoplasmic side of the channel. The most precise structural studies have been carried out in Shaker potassium channels, in which the precise residues involved in the process have been identified. The first 19 amino acids of the N-terminus constitute the ball domain. This is made up of 11 hydrophobic amino acids, 8 hydrophilic ones and 4 positively charged ones. The following 60 amino acids constitute the chain domain. Modifying the amino acids of the ball while preserving their chemical properties does not disrupt the inactivation mechanism. This suggests that the ball occludes the channel by binding electrostatically rather than covalently. Structural studies have shown that the inner pore of the potassium channel is accessible only through side slits between the cytoplasmic domains of the four α-subunits, rather than from a central route as previously thought. The ball domain enters the channel through the side slits and attaches to a binding site deep in the central cavity. This process involves a conformational change, which allows the ball and chain blocker to elongate and reach the inner center of the channel.\n\nA positively charged region between the III and IV domains of sodium channels is thought to act in a similar way. The essential region for inactivation in sodium channels is four amino acid sequence made up of isoleucine, phenylalanine, methionine and threonine (IFMT). The T and F interact directly with the docking site in the channel pore. When voltage-gated sodium channels open, the S4 segment moves outwards from the channel and into the extracellular side. This exposes hydrophobic residues in the S4 and S5 segments which interact with the inactivation ball. The phenylalanine of the ball interacts with the\nalanine in domain III's S4-S5 segments and the asparagine in domain IV's S4-S5 segments. This explains why inactivation can only occur once the channel is open.\n\nLateral slits are also present in sodium channels, suggesting that the access route for the ball domain may be similar.\n\nThere is a distinction between direct inactivation and two-step inactivation. Direct inactivation, which occurs in Shaker potassium channels results from the direct blockage of the channel by the ball protein, while two-step inactivation, thought to occur in BK channels, requires an intermediate binding step.\n\nThe mechanism of ball-and-chain inactivation is also distinct from that of voltage-dependent blockade by intracellular molecules or peptide regions of beta4 subunits in sodium channels. When these blocks contribute to sodium channel inactivation after channel opening, repolarization of the membrane reverses the block and can causes a resurgent current: a flow of ions between unblocking and closure of the channel.\n\nPotassium channels have an additional feature in the N-terminus which makes the channels unable to inactivate. The N-type inactivation-prevention (NIP) domain counteracts the effect of the peptide ball. Channels containing the NIP domain behave as mutated non-inactivating channels, as they have no inactivation activity. The effect is thought be stoichiometric, as the gradual introduction of un-tethered synthetic balls to the cytoplasm eventually restores inactivation.\n\nThe interplay between opening and inactivation controls the firing pattern of a neuron by changing the rate and amount of ion flow though the channels. Voltage-gated ion channels open upon depolarization of the cell membrane. This creates a current caused by the flow of ions through the channel. Shortly after opening, the channel is blocked by the peptide ball. The β1 subunit aids recovery from inactivation, while β2 accelerates inactivation. The β subunits can also interfere with ball and chain domains by blocking their entry into the channel. This leads to persistent currents, caused by the continued influx of ions. The β3 subunit can increase persistent current in certain sodium channels.\n\nDifferences in persistent and resurgent currents have been implicated in certain human neurological and neuromuscular disorders. In epilepsy, mutations in sodium channels genes delay inactivation. This leads to the channel staying open for longer and thus longer-lasting neuronal firing. Higher levels of persistent current are observed in epilepsy. This constant, low-level neuronal stimulation has been linked to the seizures typical of this disorder.\n\nInactivation anomalies have also been linked to Brugada syndrome. Mutations in genes encoding the α subunit in cardiac sodium channels affect inactivation. These increase persistent current by interfering with inactivation, though different mutations have opposite effects in inactivation speed.\n\nMutations in the α subunit of skeletal muscles are also associated with myotonia. The characteristic muscular hyperexcitation of mytonia is mainly caused by the presence sodium channels which do not inactivate, causing high levels of persistent current in the muscles.\n", "id": "46226557", "title": "Ball and chain inactivation"}
{"url": "https://en.wikipedia.org/wiki?curid=17756980", "text": "Hypersegmented neutrophil\n\nA hypersegmented neutrophil is a clinical laboratory finding. It is visualized by drawing blood from a patient and viewing the blood smeared on a slide under a microscope. Normally, the number of segments in the nucleus of a neutrophil increases as it matures and ages after the neutrophil is released into the blood from the bone marrow. Although normal neutrophils only contain three or four nuclear lobes (the \"segments\"), hypersegmented neutrophils contain six or more lobes. \n\nHypersegmented neutrophils have classically been thought to be pathognomonic of the class of anemias called megaloblastic anemias (anemias caused by failure of bone marrow blood-forming cells to make DNA, often caused by vitamin B or folate deficiencies, or DNA-replication poisons). However, in seeming contradiction to this, several studies have strongly associated neutrophil hypersegmentation with iron deficiency anemia. In one study 81% of children with iron deficiency had hypersegmented neutrophils, vs. 9% of controls. The mechanism for hypersegmentation in iron deficiency is not yet clear, but has been suggested to be concurrent iron and vitamin deficiency.\n\nOne of the earliest, notable changes in the peripheral blood in \"megaloblastic processes\" is the appearance of hypersegmented neutrophils. Because of the short life-span of neutrophils, these abnormal hypersegmented neutrophils characteristically appear even before the onset of anemia in megaloblastic processes. Such neutrophils are less often seen in the other classes of anemia, which together are far more common than megaloblastic types of anemia. However, as noted, the use of hypersegmented neutrophils to diagnose type of anemia is limited by the fact that different types of nutrient deficiency anemia may coexist.\n\nNote that pernicious anemia is a type of megaloblastic anemia, and as such, is expected to show hypersegmented neutrophils.\n", "id": "17756980", "title": "Hypersegmented neutrophil"}
{"url": "https://en.wikipedia.org/wiki?curid=44305878", "text": "Directed differentiation\n\nDirected differentiation is a bioengineering methodology at the interface of stem cell biology, developmental biology and tissue engineering. It is essentially harnessing the potential of stem cells by constraining their differentiation in vitro toward a specific cell type or tissue of interest. Stem cells are by definition pluripotent, able to differentiate into several cell types such as neurons, cardiomyocytes, hepatocytes, etc. Efficient \"directed differentiation\" requires a detailed understanding of the lineage and cell fate decision, often provided by developmental biology.\n\nDuring differentiation, pluripotent cells make a number of developmental decisions to generate first the three germ layers (ectoderm, mesoderm and endoderm) of the embryo and intermediate progenitors, followed by subsequent decisions or check points, giving rise to all the body's mature tissues. The differentiation process can be modeled as sequence of binary decisions based on probabilistic or stochastic models. Developmental biology and embryology provides the basic knowledge of the cell types' differentiation through mutation analysis, lineage tracing, embryo micro-manipulation and gene expression studies. Cell differentiation and tissue organogenesis involve a limited set of developmental signaling pathways. It is thus possible to direct cell fate by controlling cell decisions through extracellular signaling, mimicking developmental signals.\n\n\"Directed differentiation\" is primarily applied to pluripotent stem cells (PSCs) of mammalian origin, in particular mouse and human cells for biomedical research applications. Since the discovery of embryonic stem (ES) cells (1981) and induced pluripotent stem (iPS) cells (2006), source material is potentially unlimited.\nHistorically, embryonic carcinoma (EC) cells have also been used. Fibroblasts or other differentiated cell types have been used for direct reprogramming strategies.\n\nCell differentiation involves a transition from a proliferative mode toward differentiation mode. \"Directed differentiation\" consists in mimicking developmental (embryo's development) decisions in vitro using the stem cells as source material. For this purpose, pluripotent stem cells (PSCs) are cultured in controlled conditions involving specific substrate or extracellular matrices promoting cell adhesion and differentiation, and define culture media compositions. A limited number of signaling factors such as growth factors or small molecules, controlling cell differentiation, is applied sequentially or in a combinatorial manner, at varying dosage and exposure time. Proper differentiation of the cell type of interest is verified by analyzing cell type specific markers, gene expression profile, and functional assays.\n\nsupport cells and matrices provide developmental-like environmental signals.\n\nThis method consists in exposing the cells to specific signaling pathways modulators and manipulating cell culture conditions (environmental or exogenous) to mimick the natural sequence of developmental decisions to produce a given cell type/tissue. A drawback of this approach is the necessity to have a good understanding of how the\ncell type of interest is formed.\n\nThis method, also known as transdifferentiation or direct conversion, consists in overexpressing one or several factors, usually transcription factors, introduced in the cells. The starting material can be either pluripotent stem cells (PSCs), or either differentiated cell type such as fibroblasts. The principle was first demonstrated in 1987 with the myogenic factors MyoD.\nA drawback of this approach is the introduction of foreign nucleic acid in the cells and the forced expression of transcription factors which effects are not fully understood.\n\nThis methods consists in selecting the cell type of interest, usually with antibiotic resistance. For this purpose, the source material cells are modified to contain antibiotic resistance cassette under a target cell type specific promoter. Only cells committed to the lineage of interest is surviving the selection.\n\n\"Directed differentiation\" provides a potentially unlimited and manipulable source of cell and tissues.\nSome applications are impaired by the immature phenotype of the pluripotent stem cells (PSCs)-derived cell type, which limits the physiological and functional studies possible.\nSeveral application domains emerged:\n\nFor basic science, notably developmental biology and cell biology, PSC-derived cells allow to study at the molecular and cellular levels fundamental questions in vitro, that would have been otherwise extremely difficult or impossible to study for technical and ethical reasons in vivo such as embryonic development of human. In particular, differentiating cells are amenable for quantitative and qualitative studies.\nMore complex processes can also be studied in vitro and formation of organoids, including cerebroids, optic cup and kidney have been described.\n\nCell types differentiated from pluripotent stem cells (PSCs) are being evaluated as preclinical in vitro models of Human diseases. Human cell types in a dish provide an alternative to traditional preclinical assays using animal, human immortalized cells or primary cultures from biopsies, which their limitations. Clinically-relevant cell types i.e. cell type affected in diseases are a major focus of research, this includes hepatocytes, Langerhans islet beta-cells, cardiomyocytes and neurons. Drug screen are performed on miniaturized cell culture in multiwell-plates or on a chip.\n\nPSCs-derived cells from patients are used in vitro to recreate specific pathologies. The specific cell type affected in the pathology is at the base of the model. For example, motoneurons are used to study spinal muscular atrophy (SMA) and cardiomyocytes are used to study arrythmia. This can allow for a better understanding of the pathogenesis and the development of new treatments through drug discovery. Immature PSC-derived cell types can be matured in vitro by various strategies, such as in vitro ageing, to modelize age-related disease in vitro.\nMajor diseases being modelized with PSCs-derived cells are amyotrophic lateral sclerosis (ALS), Alzheimer's (AD), Parkinson's (PD), fragile X syndrome (FXS), Huntington disease (HD), Down syndrome, Spinal muscular atrophy (SMA), muscular dystrophies, cystic fibrosis, Long QT syndrome, and Type I diabetes.\n\nThe potentially unlimited source of cell and tissues may have direct application for tissue engineering, cell replacement and transplantation following acute injuries and reconstructive surgery. These applications are limited to the cell types that can be differentiated efficiently and safely from human PSCs with the proper organogenesis. Decellularized organs are also being used as tissue scaffold for organogenesis. Source material can be normal healthy cells from another donor (heterologous transplantation) or genetically corrected from the same patient (autologous).\nConcerns on patient safety have been raised due to the possibility of contaminating undifferentiated cells. The first clinical trial using hESC-derived cells was in 2011. The first clinical trial using hiPSC-derived cells started in 2014 in Japan.\n", "id": "44305878", "title": "Directed differentiation"}
{"url": "https://en.wikipedia.org/wiki?curid=11763579", "text": "Microvesicles\n\nMicrovesicles (sometimes called, circulating microvesicles, or microparticles) are a type of extracellular vesicle (EV), between 50 and 1,000 nanometers (nm) in diameter, found in many types of body fluids as well as the interstitial space between cells. Microvesicles are circular fragments of plasma membrane ranging from 100 nm to 1000 nm shed from almost all cell types. Not to be confused with smaller intracellularly generated extracellular vesicles known as exosomes. Microvesicles play a role in intercellular communication and can transport mRNA, miRNA, and proteins between cells.<ref name=\"doi10.1038/ncomms1180\"></ref> Microvesicles have been implicated in the process of a remarkable anti-tumor reversal effect in cancer, tumor immune suppression, metastasis, tumor-stroma interactions and angiogenesis along with having a primary role in tissue regeneration. They originate directly from the plasma membrane of the cell and reflect the antigenic content of the cells from which they originate.\nThey remove misfolded proteins, cytotoxic agents and metabolic waste from the cell.\n\nThough initially dismissed as cellular debris, microvesicles have a role in cell signaling and the process of molecular communication between cells, and are released by a number of cell types. Although a consistent and precise definition is lacking, microvesicles are generally considered to be a heterogeneous population of exosomes (<100 nm) and shed microvesicles (100-1000 nm), which are similar but have distinct mechanisms of formation. Through these mechanisms, microvesicles are released into the extracellular space and interact with specific target cells, delivering bioactive molecules. Changes in microvesicle levels are implicated in a variety of diseases, including cancer. These changes can be used as biomarkers in a variety of diagnostic assays.\n\nDifferent cells can release microvesicles from the plasma membrane. Sources of microvesicles include megakaryocytes, blood platelets, monocytes, neutrophils, tumor cells and placenta.\n\nPlatelets play an important role in maintaining hemostasis: they promote thrombus growth, and thus they prevent loss of blood. Moreover, they enhance immune response, since they express the molecule CD154 (CD40L). Platelets are activated by inflammation, infection, or injury, and after their activation microvesicles containing CD154 are released from platelets. CD154 is a crucial molecule in the development of T cell-dependent humoral immune response. CD154 knockout mice are incapable of producing IgG, IgE, or IgA as a response to antigens. Microvesicles can also transfer prions and molecules CD41 and CXCR4.\n\nEndothelial microparticles are small vesicles that are released from endothelial cells and can be found circulating in the blood.\n\nThe microparticle consists of a plasma membrane surrounding a small amount of cytosol. The membrane of the endothelial microparticle contains receptors and other cell surface molecules which enable the identification of the endothelial origin of the microparticle, and allow it to be distinguished from microparticles from other cells, such as platelets.\n\nAlthough circulating endothelial microparticles can be found in the blood of normal individuals, increased numbers of circulating endothelial microparticles have been identified in individuals with certain diseases, including hypertension and cardiovascular disorders,\nand pre-eclampsia and various forms of vasculitis. The endothelial microparticles in some of these disease states have been shown to have arrays of cell surface molecules reflecting a state of endothelial dysfunction. Therefore, endothelial microparticles may be useful as an indicator or index of the functional state of the endothelium in disease, and may potentially play key roles in the pathogenesis of certain diseases, including rheumatoid arthritis.\n\nMicrovesicles and exosomes are formed and released by two slightly different mechanisms. These processes result in the release of intercellular signaling vesicles. Microvesicles are small, plasma membrane-derived particles that are released into the extracellular environment by the outward budding and fission of the plasma membrane. This budding process involves multiple signaling pathways including the elevation of intracellular calcium and reorganization of the cell's structural scaffolding. The formation and release of microvesicles involve contractile machinery that draws opposing membranes together before pinching off the membrane connection and launching the vesicle into the extracellular space.\n\nMicrovesicle budding takes place at unique locations on the cell membrane that are enriched with specific lipids and proteins reflecting their cellular origin. At these locations, proteins, lipids, and nucleic acids are selectively incorporated into microvesicles and released into the surrounding environment.\n\nExosomes are membrane-covered vesicles, formed intracellularly are considered to be smaller than 100 nm. In contrast to microvesicles, which are formed through a process of membrane budding, or exocytosis, exosomes are initially formed by endocytosis. Exosomes are formed by invagination within a cell to create an intracellular vesicle called an endosome, or an endocytic vesicle. In general, exosomes are formed by segregating the cargo (e.g., lipids, proteins, and nucleic acids) within the endosome. Once formed, the endosome combines with a structure known as a multivesicular body (MVB). The MVB containing segregated endosomes ultimately fuses with the plasma membrane, resulting in exocytosis of the exosomes.\n\nOnce formed, both microvesicles and exosomes (collectively called microvesicles) circulate in the extracellular space near the site of release, where they can be taken up by other cells or gradually deteriorate. In addition, some vesicles migrate significant distances by diffusion, ultimately appearing in biological fluids such as cerebrospinal fluid, blood, and urine.\n\nThere are three mechanisms which lead to release of vesicles into the extracellular space. First of these mechanisms is exocytosis from multivesicular bodies and the formation of exosomes. Another mechanism is budding of microvesicles directly from a plasma membrane. And the last one is cell death leading to the blebbing of apoptotic bodies. These are all energy-requiring processes.\n\nUnder physiologic conditions, the plasma membrane of cells has an asymmetric distribution of phospholipids. Aminophospholipids, phosphatidylserine, and phosphatidylethanolamine are specifically sequestered in the inner leaflet of the membrane. The transbilayer lipid distribution is under the control of three phospholipidic pumps: an inward-directed pump, or flippase; an outward-directed pump, or floppase; and a lipid scramblase, responsible for non-specific redistribution of lipids across the membrane.\nAfter cell stimulation, including apoptosis, a subsequent cytosolic Ca increase promotes the loss of phospholipid asymmetry of the plasma membrane, subsequent phosphatidylserine exposure, and a transient phospholipidic imbalance between the external leaflet at the expense of the inner leaflet, leading to budding of the plasma membrane and microvesicle release.\n\nThe lipid and protein content of microvesicles have been analyzed using various biochemical techniques. microvesicles display a spectrum of molecules enclosed within the vesicles and their plasma membranes. Both the membrane molecular pattern and the internal contents of the vesicle depend on the cellular origin and the molecular processes triggering their formation. Because microvesicles are not intact cells, they do not contain mitochondria, Golgi, endoplasmic reticulum, or a nucleus with its associated DNA.\n\nmicrovesicle membranes consist mainly of lipids and proteins. Regardless of their cell type of origin, nearly all microvesicles contain proteins involved in membrane transport and fusion. They are surrounded by a phospholipid bilayer composed of several different lipid molecules. The protein content of each microvesicle reflects the origin of the cell from which it was released. For example, those released from antigen-presenting cells (APCs), such as B cells and dendritic cells, are enriched in proteins necessary for adaptive immunity, while microvesicles released from tumors contain proapoptotic molecules and oncogenic receptors (e.g. EGFR).\n\nIn addition to the proteins specific to the cell type of origin, some proteins are common to most microvesicles. For example, nearly all contain the cytoplasmic proteins tubulin, actin and actin-binding proteins, as well as many proteins involved in signal transduction, cell structure and motility, and transcription. Most microvesicles contain the so-called \"heat-shock proteins\" hsp70 and hsp90, which can facilitate interactions with cells of the immune system. Finally, tetraspanin proteins, including CD9, CD37, CD63 and CD81 are one of the most abundant protein families found in microvesicle membranes. Many of these proteins may be involved in the sorting and selection of specific cargos to be loaded into the lumen of the microvesicle or its membrane.\n\nOther than lipids and proteins, microvesicles are enriched with nucleic acids (e.g., messenger RNA (mRNA) and microRNA (miRNA). The identification of RNA molecules in microvesicles supports the hypothesis that they are a biological vehicle for the transfer of nucleic acids and subsequently modulate the target cell's protein synthesis. Messenger RNA transported from one cell to another through microvesicles can be translated into proteins, conferring new function to the target cell. The discovery that microvesicles may shuttle specific mRNA and miRNA suggests that this may be a new mechanism of genetic exchange between cells. Exosomes produced by cells exposed to oxidative stress can mediate protective signals, reducing oxidative stress in recipient cells, a process which is proposed to depend on exosomal RNA transfer. These RNAs are specifically targeted to microvesicles, in some cases containing detectable levels of RNA that is not found in significant amounts in the donor cell.\n\nBecause the specific proteins, mRNAs, and miRNAs in microvesicles are highly variable, it is likely that these molecules are specifically packaged into vesicles using an active sorting mechanism. At this point, it is unclear exactly which mechanisms are involved in packaging soluble proteins and nucleic acids into microvesicles.\n\nOnce released from their cell of origin, microvesicles interact specifically with cells they recognize by binding to cell-type specific, membrane-bound receptors. Because microvesicles contain a variety of surface molecules, they provide a mechanism for engaging different cell receptors and exchanging material between cells. This interaction ultimately leads to fusion with the target cell and release of the vesicles' components, thereby transferring bioactive molecules, lipids, genetic material, and proteins. The transfer of microvesicle components includes specific mRNAs and proteins, contributing to the proteomic properties of target cells. microvesicles can also transfer miRNAs that are known to regulate gene expression by altering mRNA turnover.\n\nIn some cases, the degradation of microvesicles is necessary for the release of signaling molecules. During microvesicle production, the cell can concentrate and sort the signaling molecules which are released into the extracellular space upon microvesicle degradation. Dendritic cells, macrophage and microglia derived microvesicles contain proinflammatory cytokines and neurons and endothelial cells release growth factors using this mechanism of release.\n\nProteins on the surface of the microvesicle will interact with specific molecules, such as integrin, on the surface of its target cell. Upon binding, the microvesicle can fuse with the plasma membrane. This results in the delivery of nucleotides and soluble proteins into the cytosol of the target cell as well as the integration of lipids and membrane proteins into its plasma membrane.\n\nmicrovesicle can be endocytosed upon binding to their targets, allowing for additional steps of regulation by the target cell. The microvesicle may fuse, integrating lipids and membrane proteins into the endosome while releasing its contents into the cytoplasm. Alternatively, the endosome may mature into a lysosome causing the degradation of the microvesicle and its contents, in which case the signal is ignored.\n\nAfter internalization of microvesicle via endocytosis, the endosome may move across the cell and fuse with the plasma membrane, a process called transcytosis. This results in the ejection of the microvesicle back into the extracellular space or may result in the transportation of the microvesicle into a neighboring cell. This mechanism might explain the ability of microvesicle to cross biological barriers, such as the blood brain barrier, by moving from cell to cell.\n\nIn this form of signaling, the microvesicle does not fuse with the plasma membrane or engulfed by the target cell. Similar to the other mechanisms of signaling, the microvesicle has molecules on its surface that will interact specifically with its target cell. There are additional surface molecules, however, that can interact with receptor molecules which will interact with various signaling pathways. This mechanism of action can be used in processes such as antigen presentation, where MHC molecules on the surface of microvesicle can stimulate an immune response. Alternatively, there may be molecules on microvesicle surfaces that can recruit other proteins to form extracellular protein complexes that may be involved in signaling to the target cell.\n\nThe oncogenic receptor ECGFvIII, which is located in a specific type of aggressive glioma tumor, can be transferred to a non-aggressive population of tumor cells via microvesicles. After the oncogenic protein is transferred, the recipient cells become transformed and show characteristic changes in the expression levels of target genes. It is possible that transfer of other mutant oncogenes, such as HER2, may be a general mechanism by which malignant cells cause cancer growth at distant sites. microvesicles from non-cancer cells can signal to cancer cells to become more aggressive. Upon exposure to microvesicles from tumor-associated macrophages, breast cancer cells become more invasive \"in vitro\".\n\nAngiogenesis, which is essential for tumor survival and growth, occurs when endothelial cells proliferate to create a matrix of blood vessels that infiltrate the tumor, supplying the nutrients and oxygen necessary for tumor growth. A number of reports have demonstrated that tumor-associated microvesicles release proangiogenic factors that promote endothelial cell proliferation, angiogenesis, and tumor growth. microvesicles shed by tumor cells and taken up by endothelial cells also facilitate angiogenic effects by transferring specific mRNAs and miRNAs.\n\nWhen anticancer drugs such as doxorubicin accumulate in microvesicles, the drug's cellular levels decrease. This can ultimately contribute to the process of drug resistance. Similar processes have been demonstrated in microvesicles released from cisplatin-insensitive cancer cells. Vesicles from these tumors contained nearly three times more cisplatin than those released from cisplatin-sensitive cells. For example, tumor cells can accumulate drugs into microvesicles. Subsequently, the drug-containing microvesicles are released from the cell into the extracellular environment, thereby mediating resistance to chemotherapeutic agents and resulting in significantly increased tumor growth, survival, and metastasis.\n\nmicrovesicles from various tumor types can express specific cell-surface molecules (e.g. FasL or CD95) that induce T-cell apoptosis and reduce the effectiveness of other immune cells. microvesicles released from lymphoblastoma cells express the immune-suppressing protein latent membrane protein-1 (LMP-1), which inhibits T-cell proliferation and prevents the removal of circulating tumor cells (CTCs). As a consequence, tumor cells can turn off T-cell responses or eliminate the antitumor immune cells altogether by releasing microvesicles.\n\nDegradation of the extracellular matrix is a critical step in promoting tumor growth and metastasis. Tumor-derived microvesicles often carry protein-degrading enzymes, including matrix metalloproteinase 2 (MMP-2), MMP-9, and urokinase-type plasminogen activator (uPA). By releasing these proteases, tumor cells can degrade the extracellular matrix and invade surrounding tissues. Likewise, inhibiting MMP-2, MMP-9, and uPA prevents microvesicles from facilitating tumor metastasis. Matrix digestion can also facilitate angiogenesis, which is important for tumor growth and is induced by the horizontal transfer of RNAs from microvesicles.\n\nThe release of microvesicles has been shown from endothelial cells, vascular smooth muscle cells, platelets, white blood cells (e.g. leukocytes and lymphocytes), and red blood cells. Although some of these microvesicle populations occur in the blood of healthy individuals and patients, there are obvious changes in number, cellular origin, and composition in various disease states. It has become clear that microvesicles play important roles in regulating the cellular processes that lead to disease pathogenesis. Moreover, because microvesicles are released following apoptosis or cell activation, they have the potential to induce or amplify disease processes. Some of the inflammatory and pathological conditions that microvesicles are involved in include cardiovascular disease, hypertension, neurodegenerative disorders, diabetes, and rheumatic diseases.\n\nCirculating microvesicles isolated from cardiac surgery patients were found to be thrombogenic in both in vitro assays and in rats. Microvesicles isolated from healthy individuals did not have the same effects and may actually have a role in reducing clotting. Tissue factor, an initiator of coagulation, is found in high levels within microvesicles, indicating their role in clotting. Additionally, microvesicles can induce clotting by binding to clotting factors or by inducing the expression of clotting factors in other cells. microvesicles and tissue factor are associated with diabetic vasculopathy in a mechanism affected by hyperglycemia in diabetic patients. Renal mesangial cells exposed to high glucose media release microvesicles containing tissue factor, having an angiogenic effect on endothelial cells. Atherosclerosis has also been linked with circulating microvesicles originating from platelets and macrophages. These microvesicles are found in high levels within atherosclerotic plaques, and their presence results in communication with clotting machinery that exacerbates the condition.\n\nMicrovesicles contain cytokines that can induce inflammation via numerous different pathways. These cells will then release more microvesicles, which have an additive effect. This can call neutrophils and leukocytes to the area, resulting in the aggregation of cells. However, microvesicles also seem to be involved in a normal physiological response to disease, as there are increased levels of microvesicles that result from pathology.\n\nMicrovesicles seem to be involved in a number of neurological diseases. Since they are involved in numerous vascular diseases and inflammation, strokes and multiple sclerosis seem to be other diseases for which microvesicles are involved. Circulating microvesicles seem to have an increased level of phosphorylated tau proteins during early stage Alzheimer's disease. Similarly, increased levels of CD133 are an indicator of epilepsy.\n\nTumor-associated microvesicles are abundant in the blood, urine, and other body fluids of patients with cancer, and are likely involved in tumor progression. They offer a unique opportunity to noninvasively access the wealth of biological information related to their cells of origin. The quantity and molecular composition of microvesicles released from malignant cells varies considerably compared with those released from normal cells. Thus, the concentration of plasma microvesicles with molecular markers indicative of the disease state may be used as an informative blood-based biosignature for cancer. microvesicles express many membrane-bound proteins, some of which can be used as tumor biomarkers. Several tumor markers accessible as proteins in blood or urine have been used to screen and diagnose various types of cancer. In general, tumor markers are produced either by the tumor itself or by the body in response to the presence of cancer or some inflammatory conditions. If a tumor marker level is higher than normal, the patient is examined more closely to look for cancer or other conditions. For example, CA19-9, CA-125, and CEA have been used to help diagnose pancreatic, ovarian, and gastrointestinal malignancies, respectively. However, although they have proven clinical utility, none of these tumor markers are highly sensitive or specific. Clinical research data suggest that tumor-specific markers exposed on microvesicles are useful as a clinical tool to diagnose and monitor disease. Research is also ongoing to determine if tumor-specific markers exposed on microvesicles are predictive for therapeutic response.\n\nEvidence produced by independent research groups has demonstrated that microvesicles from the cells of healthy tissues, or selected miRNAs from these microvesicles, can be employed to reverse many tumors in pre-clinical cancer models, and may be used in combination with chemotherapy.\n\nConversely, microvesicles processed from a tumor cell are involved in the transport of cancer proteins and in delivering microRNA to the surrounding healthy tissue. It leads to a change of healthy cell phenotype and creates a tumor-friendly environment. Microvesicles play an important role in tumor angiogenesis and in the degradation of matrix due to the presence of metalloproteases, which facilitate metastasis. They are also involved in intensification of the function of regulatory T-lymphocytes and in the induction of apoptosis of cytotoxic T-lymphocytes, because microvesicles released from a tumor cell contain Fas ligand and TRAIL. They prevent differentiation of monocytes to dendritic cells.\n\nTumor microvesicles also carry tumor antigen, so they can be an instrument for developing tumor vaccines. Circulating miRNA and segments of DNA in all body fluids can be potential markers for tumor diagnostics.\n\nRheumatoid arthritis is a chronic systemic autoimmune disease characterized by inflammation of joints. In the early stage there are abundant Th17 cells producing proinflammatory cytokines IL-17A, IL-17F, TNF, IL-21, and IL-22 in the synovial fluid. regulatory T-lymphocytes have a limited capability to control these cells. In the late stage, the extent of inflammation correlates with numbers of activated macrophages that contribute to joint inflammation and bone and cartilage destruction, because they have the ability to transform themselves into osteoclasts that destroy bone tissue. Synthesis of reactive oxygen species, proteases, and prostaglandins by neutrophils is increased. Activation of platelets via collagen receptor GPVI stimulates the release of microvesicles from platelet cytoplasmic membranes. These microparticles are detectable at a high level in synovial fluid, and they promote joint inflammation by transporting proinflammatory cytokine IL-1.\n\nIn addition to detecting cancer, it is possible to use microvesicles as biological markers to give prognoses for various diseases. Many types of neurological diseases are associated with increased level of specific types of circulating microvesicles. For example, elevated levels of phosphorylated tau proteins can be used to diagnose patients in early stages of Alzheimer's. Additionally, it is possible to detect increased levels of CD133 in microvesicles of patients with epilepsy.\n\nCirculating microvesicles may be useful for the delivery of drugs to very specific targets. Using electroporation or centrifugation to insert drugs into microvesicles targeting specific cells, it is possible to target the drug very efficiently. This targeting can help by reducing necessary doses as well as prevent off-target side effects. They can target anti-inflammatory drugs to specific tissues. Additionally, circulating microvesicles can bypass the blood–brain barrier and deliver their cargo to neurons while not having an effect on muscle cells. The blood-brain barrier is typically a difficult obstacle to overcome when designing drugs, and microvesicles may be a means of overcoming it. Current research is looking into efficiently creating microvesicles synthetically, or isolating them from patient or engineered cell lines.\n\n\n\n", "id": "11763579", "title": "Microvesicles"}
{"url": "https://en.wikipedia.org/wiki?curid=351914", "text": "Self-assembly\n\nSelf-assembly is a process in which a disordered system of pre-existing components forms an organized structure or pattern as a consequence of specific, local interactions among the components themselves, without external direction. When the constitutive components are molecules, the process is termed molecular self-assembly.\n\nSelf-assembly can be classified as either static or dynamic. In \"static\" self-assembly, the ordered state forms as a system approaches equilibrium, reducing its free energy. However, in \"dynamic\" self-assembly, patterns of pre-existing components organized by specific local interactions are not commonly described as \"self-assembled\" by scientists in the associated disciplines. These structures are better described as \"self-organized\", although these terms are often used interchangeably.\n\nSelf-assembly (SA) in the classic sense can be defined as \"the spontaneous and reversible organization of molecular units into ordered structures by non-covalent interactions\". The first property of a self-assembled system that this definition suggests is the spontaneity of the self-assembly process: the interactions responsible for the formation of the self-assembled system act on a strictly local level—in other words, \"the nanostructure builds itself\".\n\nSelf-assembled nano-structure is an object that appears as a result of ordering and aggregation of individual nano-scale objects guided by some physical principle.\n\nSelf-assembled nanostructure arises in the strong non-equilibrium conditions. The most famous example of self-assembly phenomenon is the occurrence of the life on Earth. It is plausible to hypothesize that it happens because the sun generates a strong temperate gradient in its environment. This general idea has been confirmed in the experiment of self-assembly of carbon nanotubes.\n\nAnother interesting example of self-assembly is the phenomenon of electrostatic trapping. In this case an electric field is applied between two metallic nano-electrodes. The particles present in the environment are polarized by the applied electric field. Due to dipole interaction with the electric field gradient the particles are attracted to the gap between the electrodes.\n\nFabricating a crystal by placing atom after atom is not realistic. However self-assembly of crystals works well. Similarly fabricating a 3D nano-structure is not realistic as well. Self-assembly of 3D nano-structure becomes an easy and inexpensive way to fabricate them.\n\nNano-structures such as nano-vacuum gaps are used for storing energy and nuclear energy conversion. Self-assembled tunable materials are promising candidates for large surface area electrodes in batteries and organic photovoltaic cells, as well as for microfluidic sensors and filters.\n\nAt this point, one may argue that any chemical reaction driving atoms and molecules to assemble into larger structures, such as precipitation, could fall into the category of SA. However, there are at least three distinctive features that make SA a distinct concept.\n\nFirst, the self-assembled structure must have a higher order than the isolated components, be it a shape or a particular task that the self-assembled entity may perform. This is generally not true in chemical reactions, where an ordered state may proceed towards a disordered state depending on thermodynamic parameters.\n\nThe second important aspect of SA is the key role of slack interactions (e.g. Van der Waals, capillary, formula_1, hydrogen bonds) with respect to more \"traditional\" covalent, ionic, or metallic bonds. Although typically less energetic by a factor of 10, these weak interactions play an important role in materials synthesis. It can be instructive to note how slack interactions hold a prominent place in materials, especially in biological systems, although they are often considered marginal with respect to \"strong\" (i.e. covalent, etc.) interactions. For instance, they determine the physical properties of liquids, the solubility of solids, and the organization of molecules in biological membranes.\n\nThe third distinctive feature of SA is that the building blocks are not only atoms and molecules, but span a wide range of nano- and mesoscopic structures, with different chemical compositions, shapes and functionalities. Research into possible three-dimensional shapes of self-assembling micrites examines Platonic solids (regular polyhedral). The term ‘micrite’ was created by DARPA to refer to sub-millimeter sized microrobots, whose self-organizing abilities may be compared with those of slime mold. Recent examples of novel building blocks include polyhedra and patchy particles. Examples also included microparticles with complex geometries, such as hemispherical, dimer, discs, rods, molecules\n, as well as multimers. These nanoscale building blocks (NBBs) can in turn be synthesised through conventional chemical routes or by other SA strategies such as Directional Entropic Forces.\n\nImportant examples of SA in materials science include the formation of molecular crystals, colloids, lipid bilayers, phase-separated polymers, and self-assembled monolayers. The folding of polypeptide chains into proteins and the folding of nucleic acids into their functional forms are examples of self-assembled biological structures. Recently, the three-dimensional macroporous structure was prepared via self-assembly of diphenylalanine derivative under cryoconditions, the obtained material can find the application in the field of regenerative medicine or drug delivery system. P. Chen et al. demonstrated a microscale self-assembly method using the air-liquid interface established by Faraday wave as a template. This self-assembly method can be used for generation of diverse sets of symmetrical and periodic patterns from microscale materials such as hydrogels, cells, and cell spheroids.\n\nSA extends the scope of chemistry aiming at synthesising products with order and functionality properties, extending chemical bonds to weak interactions and encompassing the self-assembly of NBBs on all length scales. In covalent synthesis and polymerisation, the scientist links atoms together in any desired conformation, which does not necessarily have to be the energetically most favoured position; self-assembling molecules, on the other hand, adopt a structure at the thermodynamic minimum, finding the best combination of interactions between subunits but not forming covalent bonds between them. In self-assembling structures, the scientist must predict this minimum, not merely place the atoms in the location desired.\n\nAnother characteristic common to nearly all self-assembled systems is their thermodynamic stability. For SA to take place without intervention of external forces, the process must lead to a lower Gibbs free energy, thus self-assembled structures are thermodynamically more stable than the single, unassembled components. A direct consequence is the general tendency of self-assembled structures to be relatively free of defects. An example is the formation of two-dimensional superlattices composed of an orderly arrangement of micrometre-sized polymethylmethacrylate (PMMA) spheres, starting from a solution containing the microspheres, in which the solvent is allowed to evaporate slowly in suitable conditions. In this case, the driving force is capillary interaction, which originates from the deformation of the surface of a liquid caused by the presence of floating or submerged particles.\n\nThese two properties—weak interactions and thermodynamic stability—can be recalled to rationalise another property often found in self-assembled systems: the \"sensitivity to perturbations\" exerted by the external environment. These are small fluctuations that alter thermodynamic variables that might lead to marked changes in the structure and even compromise it, either during or after SA. The weak nature of interactions is responsible for the flexibility of the architecture and allows for rearrangements of the structure in the direction determined by thermodynamics. If fluctuations bring the thermodynamic variables back to the starting condition, the structure is likely to go back to its initial configuration. This leads us to identify one more property of SA, which is generally not observed in materials synthesised by other techniques: \"reversibility\".\n\nSA is a process which is easily influenced by external parameters. This can make synthesis more problematic due to the many free parameters that require control. On the other hand, self assembly has the exciting advantage that a large variety of shapes and functions on many length scales can be obtained.\n\nGenerally speaking, the fundamental condition needed for NBBs to self-assemble into an ordered structure is the simultaneous presence of long-range repulsive and short-range attractive forces.\n\nBy choosing precursors with suitable physicochemical properties, it is possible to exert a fine control on the formation processes that produce complex structures. Clearly, the most important tool when it comes to designing a synthesis strategy for a material, is the knowledge of the chemistry of the building units. For example, it was demonstrated that it was possible to use diblock copolymers with different block reactivities in order to selectively embed maghemite nanoparticles and generate periodic materials with potential use as waveguides.\n\nIn 2008, \"Advances in Colloid and Interface Science\" published a study in which it was concluded that every self-assembly process in reality presents a co-assembly, which makes the former term a misnomer of a kind. The thesis is built on the concept of mutual ordering of the self-assembling system and its environment.\n\nSelf-assembly processes can be observed in systems of macroscopic building blocks. These building blocks can be externally propelled or self-propelled. Since the 1950s, scientists have built self-assembly systems exhibiting centimeter-sized components ranging from passive mechanical parts to mobile robots. For systems at this scale, the component design can be precisely controlled. For some systems, the components' interaction preferences are programmable. The self-assembly processes can be easily monitored and analyzed by the components themselves or by external observers.\n\nIn April 2014, Skylar Tibbits of the Massachusetts Institute of Technology, demonstrated a combination of 3D printed plastic with a \"smart material\" that self-assembles in water.\nTibbits refers to this as \"4D printing\".\n\nPeople regularly use the terms \"self-organization\" and \"self-assembly\" interchangeably. As complex system science becomes more popular though, there is a higher need to clearly distinguish the differences between the two mechanisms to understand their significance in physical and biological systems. Both processes explain how collective order develops from \"dynamic small-scale interactions\", according to an article in a November/December 2008 issue of the journal \"Complexity\". Self-organization is a non-equilibrium process where self-assembly is a spontaneous process that leads toward equilibrium. Self-assembly requires components to remain essentially unchanged throughout the process. Besides the thermodynamic difference between the two, there is also a difference in formation. The first difference is what \"encodes the global order of the whole\" in self-assembly whereas in self-organization these initial encodings are not necessary. Another slight contrast refers to the minimum number of units needed to make an order. Self-organization appears to have a minimum number of units whereas self-assembly does not. The concepts may have particular application in connection with natural selection.\nEventually, these patterns may form one theory of pattern formation in nature.\n\n\n", "id": "351914", "title": "Self-assembly"}
{"url": "https://en.wikipedia.org/wiki?curid=47152640", "text": "Mitotic cell rounding\n\nMitotic cell rounding is a shape change that occurs in most animal cells that undergo mitosis. Cells abandon the spread or elongated shape characteristic of interphase and contract into a spherical morphology during mitosis. The phenomena is seen both in artificial cultures \"in vitro\" and naturally forming tissue \"in vivo\".\n\nIn 1935, one of the first published accounts of mitotic rounding in live tissue described cell rounding in the pseudostratified epithelium of the mammalian neural tube. Sauer noticed that cells in mitosis rounded up to the apical, or luminal, surface of the columnar epithelium before dividing and returning to their elongated morphology.\n\nFor a long time it was not clear why cells became round in mitosis. Recent studies in the epithelia and epidermis of various organisms, however, show that mitotic cell rounding might serve several important functions.\nThus mitotic cell rounding is involved in tissue organization and homeostasis.\n\nTo understand the physical mechanisms of how cells round up in mitosis researchers have conducted mechanical measurements with cultured cells \"in vitro\". The forces that drive cell rounding have recently been characterized by researchers from the groups of Professors Tony Hyman and Daniel Muller, who used flat atomic force microscopy cantilevers to constrain mitotic cells and measure the response force. More than 90% of the forces are generated by the collective activity of myosin II molecular motors in the actin cortex. As a result, the surface tension and effective stiffness of the actin cortex increase as has been consistently observed in mitotic cells. This in turn yields an increase in intracellular hydrostatic pressure due to the Law of Laplace, which relates surface tension of a fluid interface to the differential pressure sustained across that interface. The increase in hydrostatic pressure is important because it produces the outward force necessary to push and rounds up against external objects or impediments, such as flexible cantilever or soft gel (\"in vitro\" examples), or surrounding extracellular matrix and neighboring cells (\"in vivo\" examples). In HeLa cells \"in vitro\", the force generated by a half-deformed mitotic cell is on the order of 50 to 100 nanonewtons. Internal hydrostatic pressure has been measured to increase from below 100 pascals in interphase to 3 to 10 fold that in mitosis.\n\nIn similar \"in vitro\" experiments, it was found that the threshold forces required to prevent mitosis are in excess of 100 nN. At threshold forces the cell suffers a loss of cortical F-actin uniformity, which further amplifies the susceptibility to applied force. These effects potentiate distortion of cell dimensions and subsequent perturbation of mitotic progression via spindle defects.\n\nRelease of stable focal adhesions is another important aspect of mitotic rounding. Cells that are genetically perturbed to manifest constitutively active adhesion regulators are unable to properly remodel their focal adhesions and facilitate the generation of a uniform actomyosin cortex. Overall, the biochemical events governing the morphological and mechanical changes in mitotic cells are orchestrated by the mitotic master regulator Cdk1.\n\nApart from actomyosin-related genes, several disease genes have recently been implicated in mitotic cell rounding. These include Parkinson’s disease associated DJ-1/Park7 and FAM134A/RETREG2.\n\n", "id": "47152640", "title": "Mitotic cell rounding"}
{"url": "https://en.wikipedia.org/wiki?curid=4170290", "text": "Cell cortex\n\nThe cell cortex, also known as the actin cortex or actomyosin cortex, is a specialized layer of cytoplasmic protein on the inner face of the plasma membrane of the cell periphery. It functions as a modulator of plasma membrane behavior and cell surface properties. In most eukaryotic cells lacking a cell wall, the cortex is an actin-rich network consisting of F-actin filaments, myosin motors, and actin-binding proteins. The actomyosin cortex is attached to the cell membrane via membrane-anchoring proteins called ERM proteins and it plays a central role in cell shape control. The protein constituents of the cortex undergo rapid turnover, making the cortex both mechanically rigid and highly plastic, two properties essential to its function. In most cases, the cortex is in the range of 100 to 1000 nanometers thick.\n\nIn some animal cells, the protein spectrin may be present in the cortex. Spectrin helps to create a network by cross-linked actin filaments. The proportions of spectrin and actin vary with cell type. Spectrin proteins and actin microfilaments are attached to transmembrane proteins by attachment proteins between them and the transmembrane proteins. The cell cortex is attached to the inner (cytosolic) face of the plasma membrane in cells where the spectrin proteins and actin microfilaments form a mesh-like structure much like a fishnet except that it can be broken and reformed.\n\nIn plant cells, the cell cortex is reinforced by cortical microtubules underlying the plasma membrane. The direction of these cortical microtubules determines which way the cell elongates when it grows.\n\n\n", "id": "4170290", "title": "Cell cortex"}
{"url": "https://en.wikipedia.org/wiki?curid=47181909", "text": "Pulsatile secretion\n\nPulsatile secretion is a biochemical phenomenon in which a chemical, such as a hormone, is secreted in a burst-like or episodic manner rather than constantly. Examples of hormones that are secreted pulsatilely include gonadotropin-releasing hormone (GnRH) and growth hormone (GH). Pulsatile secretion can be critical to hormone function, as evidenced by the case of GnRH agonists, which cause functional inhibition of the receptor for GnRH due to profound downregulation in response to constant stimulation.\n", "id": "47181909", "title": "Pulsatile secretion"}
{"url": "https://en.wikipedia.org/wiki?curid=22120746", "text": "Mitochondrial biogenesis\n\nMitochondrial biogenesis is the process by which cells increase their individual mitochondrial mass and copy number to increase the production of ATP as a response to greater energy expenditure. It was first described by John Holloszy in the 1960s, when it was discovered that physical endurance training induced higher mitochondrial content levels, leading to greater glucose uptake by muscles. Mitochondrial biogenesis is activated by numerous different signals during times of cellular stress or in response to environmental stimuli, such as aerobic exercise.\n\nThe ability for a mitochondrion to self-replicate is rooted in its evolutionary history. As mitochondria are known to be descendants from cells that formed endosymbiotic relationships with α-protobacteria, they have their own genome for replication. The mitochondrion is a key regulator of the metabolic activity of the cell, and is also an important organelle in both production and degradation of free radicals. It is reckoned that higher mitochondrial copy number (or higher mitochondrial mass) is protective for the cell.\n\nMitochondria are produced from the transcription and translation of genes both in the nuclear genome and in the mitochondrial genome. The majority of mitochondrial protein comes from the nuclear genome, while the mitochondrial genome encodes parts of the electron transport chain along with mitochondrial rRNA and tRNA. A major adaptation to mitochondrial biogenesis results in more mitochondrial tissues which increases metabolic enzymes for glycolysis, oxidative phosphorylation and ultimately a greater mitochondrial metabolic capacity. However, depending on the energy substrates available and the REDOX state of the cell, the cell may increase or decrease the number and size of mitochondria. Critically, mitochondrial number and morphology varies according to cell type and context-specific demand, whereby the balance between mitochondrial fusion/fission regulates mitochondrial distribution, morphology, and function.\n\nSince the majority of mitochondrial protein comes from the nuclear genome, the proteins need to be properly targeted and transported into the mitochondria to perform their functions. First, mRNA is translated in the cell’s cytosol. The resulting unfolded precursor proteins will then be able to reach their respective mitochondrial compartments. Precursor proteins will be transported to one of four areas of the mitochondria, which include the outer membrane, inner membrane, intermembrane space, and matrix. All proteins will enter the mitochondria by a translocase on the outer mitochondrial membrane (TOM). Some proteins will have an N-terminal targeting signal, and these proteins will be detected and transported into the matrix, where they will then be cleaved and folded. Other proteins may have targeting information in their sequences and will not include an N-terminal signal. During the past two decades, researchers have discovered over thirty proteins that participate in mitochondrial protein import. As researchers learn more about these proteins and how they reach the respective mitochondrial compartments that utilize them, it becomes evident that there is a multitude of processes that work together in the cell to allow for mitochondrial biogenesis.\n\nMitochondria are highly versatile and are able to change their shape through fission and fusion events. Definitively, fission is the event of a single entity breaking apart, whereas fusion is the event of two or more entities joining to form a whole. The processes of fission and fusion oppose each other and allow the mitochondrial network to constantly remodel itself. If a stimulus induces a change in the balance of fission and fusion in a cell, it could significantly alter the mitochondrial network. For example, an increase in mitochondrial fission would create many fragmented mitochondria, which has been shown to be useful for eliminating damaged mitochondria and for creating smaller mitochondria for efficient transporting to energy-demanding areas. Therefore, achieving a balance between these mechanisms allow a cell to have the proper organization of its mitochondrial network during biogenesis and may have an important role in muscle adaptation to physiological stress.\n\nIn mammals, mitochondrial fusion and fission are both controlled by GTPases of the dynamin family. The process of mitochondrial fission is directed by Drp1, a member of the cytosolic dynamin family. This protein forms a spiral around mitochondria and constricts to break apart both the outer and inner membranes of the organelle. On the other hand, the process of fusion is directed by different membrane-anchored dynamin proteins at different levels of the mitochondria. Fusion at the level of the outer mitochondrial membrane is mediated by Mfn1 and Mfn2 (Mitofusins 1 and 2), and fusion at the level of the inner mitochondrial membrane is mediated by Opa1. Multiple research studies have observed correlated increases between mitochondrial respiratory capacity with Mfn1, Mnf2, and Drp1 gene expression after endurance exercises. Therefore, it is supported that reorganization of the mitochondrial network in muscle cells plays an important role in response to exercise.\n\nPGC-1α, a member of the peroxisome proliferator-activated receptor gamma (PGC) family of transcriptional coactivators, is the master regulator of mitochondrial biogenesis. It is known to co-activate nuclear respiratory factor 2 (NRF2/GABPA), and together with NRF-2 coactivates nuclear respiratory factor 1 (NRF1). The NRFs, in turn, activate the mitochondrial transcription factor A (tfam), which is directly responsible for transcribing nuclear-encoded mitochondrial proteins. This includes both structural mitochondrial proteins as well as those involved in mtDNA transcription, translation, and repair. PGC- 1β, a protein that is structurally similar to PGC-1α, is also involved in regulating mitochondrial biogenesis, but differs in that it does not get increased in response to exercise. While there have been significant increases in mitochondria found in tissues where PGC-1α is overexpressed, as the cofactor interacts with these key transcription factors, knockout mice with disrupted PGC-1α are still viable and show normal mitochondrial abundance. Thus, PGC-1α is not required for normal development of mitochondria in mice, but when put under physiological stress, these mice exhibit diminished tolerance compared to mice with normal levels of PGC-1α. Similarly, in knockout mice with disrupted PGC-1β, the mice showed mostly normal levels of mitochondrial function with decreased ability to adapt to physiological stress. However, a double knockout experiment of PGC-1α/β created mice that died mostly within 24 hours by defects in mitochondrial maturation of cardiac tissue. These findings suggest that while both PGC-1α and PGC- 1β do not each solely establish a cell’s ability to perform mitochondrial biogenesis, together they are able to complement each other for optimal mitochondrial maturation and function during periods of physiological stress.\n\nAMP-activated kinase (AMPK) also regulates mitochondrial biogenesis by phosphorylating and activating PGC-1α upon sensing an energy deficiency in muscle. In mice with reduced ATP/AMP ratios that would occur during exercise, the energy depletion has been shown to correlate with AMPK activation. AMPK activation then continued to activate PGC- 1α and NRFs in these mice, and mitochondrial biogenesis was stimulated.\n\nThe capacity for mitochondrial biogenesis has been shown to decrease with age, and such decreased mitochondrial function has been associated with diabetes and cardiovascular disease. Aging and disease can induce changes in the expression levels of proteins involved in the fission and fusion mechanisms of mitochondria, thus creating dysfunctional mitochondria. One hypothesis for the detrimental results of aging is associated with the loss of telomeres, the end segments of chromosomes that protect genetic information from degradation. Telomere loss has also been associated with decreased mitochondrial function. Deficiency of telomerase reverse transcriptase (TERT), an enzyme that plays a role in preserving telomeres, has been correlated with activated p53, a protein that suppresses PGC-1α. Therefore, the loss of telomeres and TERT that comes with aging has been associated with impaired mitochondrial biogenesis. AMPK expression has also been shown to diminish with age, which may also contribute to suppressing mitochondrial biogenesis.\n\n", "id": "22120746", "title": "Mitochondrial biogenesis"}
{"url": "https://en.wikipedia.org/wiki?curid=47299893", "text": "Paramural body\n\nParamural bodies are membranous or vesicular structures located between the cell walls and cell membranes of plant and fungal cells. When these are continuous with the cell wall, they are termed lomasomes, while they are referred to as plasmalemmasomes if associated with the plasmalemma.\n\nWhile their function has not yet been studied in great detail, it has been speculated due to the morphological similarity of paramural bodies to the exosomes produced by mammalian cells that they may perform similar functions, such as membrane vesicle trafficking between cells. Current evidence suggests that -like exosomes- paramural bodies are derived from multivesicular bodies.\n\n", "id": "47299893", "title": "Paramural body"}
{"url": "https://en.wikipedia.org/wiki?curid=47375191", "text": "Dyadic space (cell biology)\n\nThe dyadic space is the name for the volume of cytoplasm between pairs (dyads) of areas where the cell membrane and an organelle such as the endoplasmic reticulum (or sarcoplasmic reticulum) come into close contact (within 10-12 nanometers) of each other, creating what are known as \"dyadic clefts\".\nThe space is important for ionic signalling. For example, the phenomenon of \"calcium-induced calcium release\", when extracellular calcium enters the cell through ion channels in T-Tubules, leading to a rapidly increased calcium concentration in the dyadic space, triggering ryanodine receptors on the sarcoplasmic reticulum to release more calcium and trigger cardiac myocyte contraction - the heart beat.\n", "id": "47375191", "title": "Dyadic space (cell biology)"}
{"url": "https://en.wikipedia.org/wiki?curid=47211647", "text": "Alain Viel\n\nAlain Viel is the director of Northwest Undergraduate Laboratories and senior lecturer in the Department of Molecular and Cellular Biology at Harvard University. \n\nViel received a PhD in Molecular and Cellular Biology of Development from Pierre and Marie Curie University in Paris, France (Paris VI) and did his postdoctoral work at Harvard University.\n\nViel teaches research-based courses as well as courses in molecular biology and biochemistry. \n\nHis main research is on tumor suppressor hDlg which includes an in-depth characterization of the combinations of hDlg isoforms present in multiple tissues and cell lines to correlate the presence of specific alternatively spliced insertions with a specific function of this tumor suppressor. He also studies the perturbation of hDlg distribution in two skin disease: psoriasis, characterized by a hyper-proliferation of basal cells, and Darier's disease, characterized by blisters resulting from the loss of cell adhesion in the supra-basal layers.\n\nHe is a founding member of BioVisions, a collaboration between scientists, teaching faculty, students, and multimedia professionals that focuses on science visualization.\n\nIn 2015, Viel started to teach an online course \"MCB63X - Principles of Biochemistry\" with Rachelle Gaudet on edX which received great popularity and high praises from his students worldwide.\n\nViel is a co-author of the book - Biology: How Life Works. It is published by Macmillan Education and is the first project to develop three pillars: the text, the visual program, and the assessment at the same time.\n\nViel is the co-author of the award winning animation series “The Inner Life of the Cell”.\n\nThe Inner Life of the Cell is an 8.5-minute 3D computer graphics animation illustrating the molecular mechanisms that occur when a white blood cell in the blood vessels of the human body is activated by inflammation (Leukocyte extravasation). It shows how a white blood cell rolls along the inner surface of the capillary, flattens out, and squeezes through the cells of the capillary wall to the site of inflammation where it contributes to the immune reaction.\n\n", "id": "47211647", "title": "Alain Viel"}
{"url": "https://en.wikipedia.org/wiki?curid=222320", "text": "Interphase\n\nInterphase is the phase of the cell cycle in which a typical cell spends most of its life.\nDuring this phase, the cell copies its DNA in preparation for mitosis. Interphase is the 'daily living' or metabolic phase of the cell, in which the cell obtains nutrients and metabolizes them, grows, reads its DNA, and conducts other \"normal\" cell functions. The majority of eukaryotic cells spend most of their time in interphase. This phase was formerly called the resting phase. However, interphase does not describe a cell that is merely resting; rather, the cell is living, and preparing for later cell division, so the name was changed. A common misconception is that interphase is the first stage of mitosis. However, since mitosis is the division of the nucleus, prophase is actually the first stage.\n\nIn interphase, the cell gets itself ready for mitosis or meiosis. Somatic cells, or normal diploid cells of the body, go through mitosis in order to reproduce themselves through cell division, whereas diploid germ cells (i.e., primary spermatocytes and primary oocytes) go through meiosis in order to create haploid gametes (i.e., sperm and ova) for the purpose of sexual reproduction. Chromosomes are copied.\n\nThere are three stages of cellular interphase, with each phase ending when a cellular checkpoint checks the accuracy of the stage's completion before proceeding to the next. The stages of interphase are:\n\nThe duration of time spent in interphase and in each stage of interphase is variable and depends on both the type of cell and the species of organism it belongs to. Most cells of adult mammals spend about 20 hours in interphase; this accounts for about 90% of the total time involved in cell division.\nInterphase includes G1, S, and G2 phases. Mitosis and cytokinesis, however, are separate from interphase.\n\nWhen G is completed, the cell enters a relatively brief period of nuclear and cellular division, composed of mitosis and cytokinesis, respectively. After the successful completion of mitosis and cytokinesis, both resulting daughter cells re-enter G of interphase.\n\nIn the cell cycle, interphase is preceded by telophase and cytokinesis of the M phase. In alternative fashion, interphase is sometimes interrupted by G phase, which, in some circumstances, may then end and be followed by the remaining stages of interphase. After the successful completion of the G checkpoint, the final checkpoint in interphase, the cell proceeds to prophase, or in plants to preprophase, which is the first stage of mitosis.\n\nG phase is viewed as either an extended G phase where the cell is neither dividing nor preparing to divide and or as a distinct quiescent stage which occurs outside of the cell cycle.\n\nIn gamete production interphase is succeeded by meiosis. In programmed cell death, interphase is followed or preempted by apoptosis.\n\n", "id": "222320", "title": "Interphase"}
{"url": "https://en.wikipedia.org/wiki?curid=48309405", "text": "TNP-ATP\n\nTNP-ATP is a fluorescent molecule that is able to determine whether or not a protein binds to ATP, and the constants associated with that binding. It is primarily used in fluorescence spectroscopy, but is also very useful as an acceptor molecule in FRET, and as a fluorescent probe in fluorescence microscopy and X-ray crystallography. \n\nTNP refers to the chemical compound 2,4,6-trinitrophenol, also known as Picric acid. It is a primary constituent of many unexploded landmines, and is a cousin to TNT, but less stable. It is recognized as an environmental contaminant and is toxic to many organisms. It is still commonly used in the manufacturing of fireworks, explosives, and rocket fuels, as well as in leather, pharmaceutical, and dye industries.\n\nATP is an essential mediator of life. It is used to overcome unfavorable energy barriers to initiate and fuel chemical reactions. It is also used to drive biological machinery and regulate a number of processes via protein-phosphorylation. However, the proteins that bind ATP for both regulation and enzymatic reactions are very diverse—many yet undiscovered—and for many proteins their relationship to ATP in terms of number of binding sites, binding constants, and dissociation constants remain unclear.\n\nConjugating TNP to ATP renders this nucleotide triphosphate fluorescent and colored whilst allowing it to retain its biological activity. TNP-ATP is thus a fluorescent analog of ATP. This conjugation is very useful in providing information about interactions between ATP and an ATP-binding protein because TNP-ATP interacts with proteins and enzymes as a substitute for its parent nucleotide, and has a strong binding affinity for most systems that require ATP.\n\nTNP is excited at a wavelength of 408 and 470 nm, and fluoresces in the 530–560 nm range. This is a very useful range of excitation because it is far from where proteins or nucleotides absorb. When TNP-ATP is in water or other aqueous solutions, this emission is very weak. However, once TNP-ATP binds to a protein, there is a dramatic increase in fluorescent intensity. This property enables researchers to study various proteins’ binding interaction with ATP. Thus, with enhanced fluorescence, it can be seen whether or not a protein binds to ATP.\n\nWhen TNP-ATP in water is excited at 410 nm, TNP-ATP shows a single fluorescence maximum at 561 nm. This maximum shifts as the fluid's viscosity changes. For example, in N,N-dimethylformamide, instead of having its maxima at 561 nm as in water, the maxima is instead at 533 nm.\n\nBinding to a protein will also change the wavelength of maximal emission, as well as a change in fluorescent intensity. For example, binding to the chemotaxis protein CheA indicates a severalfold enhancement of fluorescence intensity and a blue-shift in wavelength of the maximal emission.\n\nUsing this TNP nucleotide analog has been shown in many instances to be superior to traditional radionucleotide-labelling based techniques. The health concerns and the cost associated with the use of radioactive isotopes makes TNP-ATP an attractive alternative.\n\nThe first fluorescent ribose-modified ATP is 2’,3’-O-(2,4,7-trinitrocyclohexadienylidene) adenosine 5’triphosphate (TNP-ATP), and was introduced in 1973 by Hiratsuka and Uchida. TNP-ATP was originally synthesized to investigate the ATP binding site of myosin ATPase. Reports of TNP-ATP’s success in the investigation of this motor protein extended TNP-ATP’s use to other proteins and enzymes. TNP-ATP has now been used as a spectroscopic probe for numerous proteins suspected to have ATP interactions. These include several protein kinases, ATPases, myosin, and other nucleotide binding proteins. Over the past twenty years, there have been hundreds of papers describing TNP-ATP’s use and applications. Many applications involving this fluorescently labeled nucleotide have helped to clarify structure-function relationships of many ATP-requiring proteins and enzymes. There have also been a growing number of papers that display TNP-ATP use as a means of assessing the ATP-binding capacity of various mutant proteins.\n\nPreparing TNP-ATP is a one-step synthesis that is relatively safe and easy. Adenosine’s ribose moiety can be trinitrophenylated by 2,4,6-trinitrobenzene-1-sulfonate (TNBS). The resulting compound assumes a bright orange color and has visible absorption characteristics, as is characteristic of a Meiseinheimer spiro complex compound linking.\n\nTo see the exact method of preparion, please refer to T. Hiratsuka's and K. Uchida's paper \"\"Preparation and Properties of 2'(r 3')-O(2,4,6-trinitrophenyl) Adenosine 5'-triphosphate, an Analog of Adenosine Triphosphate,\"\" found in the reference section.\n\nTo revert TNP-ATP back to its constituent parts, or in other words to hydrolyze TNP-ATP to give equilmolar amounts of picric acid (TNP) and ATP, TNP-ATP should be treated with 1 M HCl at 100 degrees Celsius for 1.5 hours. This is because if TNP-ATP is acidified under mild conditions, it results in the opening of the dioxolane ring attached to the 2’-oxygen, leaving a 3’O-TNP derivative as the only product.\n\nTNP-ATP should be stored at −20 degrees Celsius, in the dark, and used under minimal lighting conditions. When in solution, TNP-ATP has a shelf-life of about 30 days.\n\nWhen absorption was measured against wavelength at various pH values, the changes at wavelength 408 nm and 470 nm yielded a sigmoidal line with a midpoint at 5.1. This indicated that the absorbance at these two wavelengths depends upon the ionization of the chromophoric portion of TNP-ATP and is unaffected by ionization of ATP. Although this ionization constant of 5.1 is not in physiological range, it has been shown that the absorbance of TNP-ATP is sensitive enough to detect changes due to slight shifts in neutral pH. Spectroscopic superposition indicated TNP-ATP’s isosbestic point to be 339 nm.\n\nAt low concentrations of TNP-ATP (≤1 μM), fluorescent intensity is proportional to the concentration of TNP added. However, at concentrations exceeding 1 μM, inner filter effects cause this relationship to no longer be linear. To correct this, researchers must determine the ratio of the predicted theoretical fluorescence intensity (assuming linearity) to the observed fluorescence intensity and then apply this correction factor. However, in most cases, researchers will try to keep the concentration of TNP to lower than 1 μM.\n\nTo determine binding affinities, TNP-ATP is added to a solution and then titrated with protein. This produces a saturation curve from which the binding affinity can be determined. The number of binding sites may also be determined through this saturation curve by looking to see if there are sudden changes in slope. One can also titrate a fixed amount of protein with increasing additions of TNP-ATP to obtain a saturation curve. To do so, however, may get complicated due to the inner filter effects that will need to be corrected for.\n\nTo determine dissociation constants, TNP-ATP can be competed off of a protein with ATP. The value of the dissociation constant K for a single-site binding can then be obtained by applying the Langmuir equation for a curve fit:\n\nformula_1\n\nwhere RFU is relative fluorescent units, RFU is the fluorescence observed, RFU is the fluorescence of free TNP-ATP, and RFU is the fluorescence of TNP-ATP when completely bound to a protein.\n\nTo measure an ATP competitor, one can add competitor to pre-incubated samples of protein:TNP-ATP. The fraction of TNP-ATP bound to the protein can be calculated via:\n\nformula_2\n\nwhere θ is that fraction, and RFU is the value of fluorescence intensity at saturation, meaning when 100% of TNP-ATP is bound.\n\nThe dissociation constants for TNP and competitor can then be calculated through the equation:\n\nformula_3\n\nFor reasons not yet fully understood, TNP-ATP typically binds the ATP binding sites of proteins and enzymes anywhere from one to three times tighter than regular ATP. The dissociation constants are usually around 0.3–50 μM.\n\nIn addition to using TNP-ATP to determine whether or not a protein binds ATP, its binding affinity and dissociation constants, and number of binding sites, TNP-ATP can also be used in ligand binding studies. To do this, titrations of the protein are added to TNP-ATP. Then, ligand is added to displace the bound analog. This is measured by decreases in fluorescence. One can also do this by titrating protein with TNP-ATP in the presence and absence of varying concentrations of the ligand of interest. Using either experiment will allow the binding affinity of the ligand to protein to be measured.\n\nTNP-ATP is also valuable fluorescence acceptor. This is because, as with any good acceptor, TNP-ATP absorbs over a wide wavelength range that corresponds to the range of emission of common FRET donors. Thus, TNP-ATP can be used to look at the conformational changes that proteins undergo. For example, Na+/K+ ATPase, the distance between the active site and Cys457 was shown to change from 25 Angstroms to 28 Angstroms in changing from the Na+ conformation to the K+ conformation.\n\nIn addition to fluorescent spectroscopy, TNP-ATP is very useful in fluorescent microscopy. This is because it greatly increases the sensitivity of the observations when bound to proteins—the enhanced fluorescence greatly reduces the problem of background fluorescence. This is especially true under epifluorescent illumation (illumination and light are both on the same side of the specimen).\n\nTNP-ATP has also been used in X-ray crystallography because it can be used to determine binding constants of crystallized substrates. This technique also demonstrates the structure of proteins in the presence or absence of TNP-ATP, which may or may not correspond to the structure of proteins when they bind ATP.\n", "id": "48309405", "title": "TNP-ATP"}
{"url": "https://en.wikipedia.org/wiki?curid=6022", "text": "Cytology\n\nCytology (from Greek , \"kytos\", \"a hollow\"; and , \"-logia\") is the study of cells. Cytology is that branch of life science that deals with the study of cells in terms of structure, function and chemistry. Robert Hooke (1635 – 1703) is sometimes seen as the father of cytology.\n\nBased on usage it can refer to: \nThe International Academy of Cytology has as its official journal \"Acta Cytologica\".\n\nCells, that were once invisible to the naked eye, became visible in 17th century Europe with the invention of the compound microscope. Robert Hooke was the first person to term the building block of all living organisms as \"cells\" after looking at cork. The cell theory states that all living things are made up cells. The theory also states that both plants and animals are composed of cells which was confirmed by plant scientist, Matthias Schleiden and animal scientist, Theodor Schwann in 1839. 19 years later, Rudolf Virchow contributed to the cell theory, arguing that all cells come from the division of preexisting cells. In recent years, there have been many studies which question the cell theory. Scientists have struggled to decide whether viruses are alive or not. Viruses lack common characteristics of a living cell, such as membranes, cell organelles, and the ability to reproduce by themselves. Viruses range from 0.005 to .03 microns in size whereas Bacteria range from 1-5 microns. The late 19th century indicates the birth of cytology. Modern day cell biology research looks at different ways to culture and manipulate cells outside of a living body to further research in human anatomy and physiology, to derive treatments and other medications, etc. The techniques by which cells are studied have evolved. Advancement in microscopic techniques and technology such as fluorescence microscopy, phase-contrast microscopy, dark field microscopy, confocal microscopy, cytometry, transmission electron microscopy, etc. have allowed scientists to get a better idea of the structure of cells.\n\nThere are two fundamental classifications of cells: prokaryotes and eukaryotes. The major difference between the two is the presence and/or absence of organelles. Other factors such as size, the way in which they reproduce, and the number of cells distinguish them from one another. Eukaryotic cells include animal, plant, fungi, and protozoa cells which all have a nucleus enclosed by a membrane. Prokaryotic cells, lacking an enclosed nucleus, include bacteria and archaea. Prokaryotic cells are much smaller than eukaryotic cells, making prokaryotic cells the smallest form of life. Cytologists typically focus on eukaryotic cells whereas prokaryotic cells are the focus of microbiologists, but this is not always the case.\n\nThese are the main branches of cytology:\n\n", "id": "6022", "title": "Cytology"}
{"url": "https://en.wikipedia.org/wiki?curid=48503953", "text": "Sperm thermotaxis\n\nSperm thermotaxis is a form of sperm guidance, in which sperm cells (spermatozoa) actively change their swimming direction according to a temperature gradient, swimming up the gradient. Thus far this process has been discovered in mammals only.\n\nThe discovery of mammalian sperm chemotaxis and the realization that it can guide spermatozoa for short distances only, estimated at the order of millimeters, triggered a search for potential long-range guidance mechanisms. The findings that, at least in rabbits and pigs, a temperature difference exists within the oviduct, and that this temperature difference is established at ovulation in rabbits due to a temperature drop in the oviduct near the junction with the uterus, creating a temperature gradient between the sperm storage site and the fertilization site in the oviduct (Figure 1), led to investigation whether mammalian spermatozoa can respond to a temperature gradient by thermotaxis.\n\nMammalian sperm thermotaxis was, hitherto, demonstrated in three species: humans, rabbits, and mice. This was done by two methods. One involved a Zigmond chamber, modified to make the temperature in each well separately controllable and measurable. A linear temperature gradient was established between the wells and the swimming of spermatozoa in this gradient was analyzed. A small fraction of the spermatozoa (at the order of ~10%), shown to be the capacitated cells, biased their swimming direction according to the gradient, moving towards the warmer temperature. The other method involved two- or three-compartment separation tube placed within a thermoseparation device that maintains a linear temperature gradient. Sperm accumulation at the warmer end of the separation tube was much higher than the accumulation at the same temperature but in the absence of a temperature gradient. This gradient-dependent sperm accumulation was observed over a wide temperature range (29-41 °C).\n\nSince temperature affects almost every process, much attention has been devoted to the question of whether the measurements, mentioned just above, truly demonstrate thermotaxis or whether they reflect another temperature-dependent process. The most pronounced effect of temperature in liquid is convection, which raised the concern that the apparent thermotactic response could have been a reflection of a passive drift in the liquid current or a rheotactic response to the current (rather than to the temperature gradient per se). Another concern was that the temperature could have changed the local pH of the buffer solution in which the spermatozoa are suspended. This could generate a pH gradient along the temperature gradient, and the spermatozoa might have responded to the formed pH gradient by chemotaxis. However, careful experimental examinations of all these possibilities with proper controls demonstrated that the measured responses to temperature are true thermotactic responses and that they are not a reflection of any other temperature-sensitive process, including rheotaxis and chemotaxis.\n\nThe behavioral mechanism of sperm thermotaxis has been so far only investigated in human spermatozoa. Like the behavioral mechanisms of bacterial chemotaxis and human sperm chemotaxis, the behavioral mechanism of human sperm thermotaxis appears to be stochastic rather than deterministic. Capacitated human spermatozoa swim in rather straight lines interrupted by turns and brief episodes of hyperactivation. Each such episode results in swimming in a new direction. When the spermatozoa sense a decrease in temperature, the frequency of turns and hyperactivation events increases due to increased flagellar-wave amplitude that results in enhanced side-to-side head displacement. With time, this response undergoes partial adaptation. The opposite happens in response to an increase in temperature. This suggests that when capacitated spermatozoa swim up a temperature gradient, turns are repressed and the spermatozoa continue swimming in the gradient direction. When they happen to swim down the gradient, they turn again and again until their swimming direction is again up the gradient.\n\nThe response of spermatozoa to temporal temperature changes even when the temperature is kept constant spatially suggests that, as in the case of human sperm chemotaxis, sperm thermotaxis involves temporal gradient sensing. In other words, spermatozoa apparently compare the temperature (or a temperature-dependent function) between consecutive time points. This, however, does not exclude the occurrence of spatial temperature sensing in addition to temporal sensing.\nHuman spermatozoa can respond thermotactically within a wide temperature range (at least 29–41 °C). Within this range they preferentially accumulate in warmer temperatures rather than at a single specific, preferred temperature. Amazingly, they can sense and thermotactically respond to temperature gradients as low as <0.014 °C/mm. This means that when human spermatozoa swim a distance that equals their body length (~46 µm) they respond to a temperature difference of <0.0006 °C!\n\nThe molecular mechanism underlying thermotaxis, in general, and thermosensing with such extreme sensitivity, in particular, is obscure. It is known that, unlike other recognized thermosensors in mammals, the thermosensors for sperm thermotaxis do not seem to be temperature-sensitive ion channels. They are rather opsins, known to be G-protein-coupled receptors that act as photosensors in vision. The opsins are present in spermatozoa at specific sites, which depend on the species and the opsin type. They are involved in sperm thermotaxis via two signaling pathways—a phospholipase C signaling pathway and a cyclic-nucleotide pathway. The former was shown by pharmacological means in human spermatozoa to involve the enzyme phospholipase C, an inositol trisphosphate receptor calcium channel located on internal calcium stores, the calcium channel TRPC3, and intracellular calcium. The latter was hitherto shown to involve phosphodiesterase. Blocking both pathways fully inhibits sperm thermotaxis.\n", "id": "48503953", "title": "Sperm thermotaxis"}
{"url": "https://en.wikipedia.org/wiki?curid=17252532", "text": "Middle lamella\n\nThe middle lamella is a pectin layer which cements the cell walls of two adjoining plant cells together. It is the first formed layer which is deposited at the time of cytokinesis. The cell plate that is formed during cell division itself develops into middle lamella or lamellum. The middle lamella is made up of calcium and magnesium pectates. In a mature plant cell it is the outermost layer of cell wall.\n\nIn plants, the pectins form a unified and continuous layer between adjacent cells. Frequently, it is difficult to distinguish the middle lamella from the primary wall, especially in cells that develop thick secondary walls. In such cases, the two adjacent primary walls and the middle lamella, and perhaps the first layer of the secondary wall of each cell, may be called a compound middle lamella. When the middle lamella is degraded by enzymes, as happens during fruit ripening, the adjacent cells will separate.\n\n\n2.Telugu Akademi Hyderabad \"Intermediate first year Botany\"\n", "id": "17252532", "title": "Middle lamella"}
{"url": "https://en.wikipedia.org/wiki?curid=49024588", "text": "Deuterosome\n\nIn cell biology, a deuterosome is a protein structure within a multiciliated cell (such as an epithelial cell of respiratory tract) that produces multiple centrioles.\n\nMost cells in human body possess one primary cilium, a relatively small protrusion of the cell membrane that looks like a stick or a finger under the electron microscope. Primary cilium is typically used by the cell as a sensory organelle, or antenna. Some cells, however, have numerous cilia which they use to generate directed fluid flow. The examples include epithelial cells of the respiratory tract in which multiple cilia are used for mucus clearance, the oviduct, in which cilia help the egg migrate to the uterus, and others. \n\nEach cilium has a basal body formed from a centriole to which it is anchored and from which it starts to grow after each cell division, when a new daughter cell is formed. Centrioles typically replicate once during cell division, thus allowing for only one cilium for a daughter cell. Multiciliated cells, on the other hand, need to produce more than 100 centrioles in order to grow multiple cilia. This problem is solved by the existence of deuterosome, a structure thought to be formed from amorphous filamentous material and able to make many centrioles at once.\n\nThe evidence of the existence of deuterosome first came from electron microscopy work in various multiciliated tissues. It was found that both centriole duplication and \"de novo\" generation of centrioles occurs in such cells. The generation of new centrioles which will serve as basal bodies for multiple cilia is due to a cytoplasmic structure, which was termed the “deuterosome” by Sorokin.\n", "id": "49024588", "title": "Deuterosome"}
{"url": "https://en.wikipedia.org/wiki?curid=49296685", "text": "Biogenesis of lysosome-related organelles complex 3\n\nBLOC-3 or biogenesis of lysosome-related organelles complex 3 is a ubiquitously expressed multisubunit protein complex.\n\nbiogenesis of lysosome-related organelles complex 3 has been shown to interact with Rab9A.\n\nThe identified protein subunits of BLOC-1 include:\n\n", "id": "49296685", "title": "Biogenesis of lysosome-related organelles complex 3"}
{"url": "https://en.wikipedia.org/wiki?curid=14498136", "text": "Biogenesis of lysosome-related organelles complex 1\n\nBLOC-1 or biogenesis of lysosome-related organelles complex 1 is a ubiquitously expressed multisubunit protein complex. BLOC-1 is required for normal biogenesis of specialized organelles of the endosomal-lysosomal system, such as melanosomes and platelet dense granules. The complex was first described in 2004.\n\nThe identified protein subunits of BLOC-1 include:\n\n", "id": "14498136", "title": "Biogenesis of lysosome-related organelles complex 1"}
{"url": "https://en.wikipedia.org/wiki?curid=28643345", "text": "Viability assay\n\nA viability assay is an assay to determine the ability of organs, cells or tissues to maintain or recover viability. Viability can be distinguished from the all-or-nothing states of life and death by use of a quantifiable index between 0 and 1 (or 0% and 100%). Viability can assay mechanical activity, motility (spermatozoa or granulocytes), contraction (muscle tissue or cells), mitotic activity, etc.\n\nFor example, examining the ratio of potassium to sodium in cells can serve as an index of viability. If the cells do not have high intracellular potassium and low intracellular sodium, then (1) the cell membrane may not be intact, and/or (2) the sodium-potassium pump may not be operating well As with many kinds of viability assays, quantitative measures of physiological function do not indicate whether damage repair and recovery is possible. An assay of the ability of a cell line to adhere and divide may be more indicative of incipient damage than membrane integrity. Fluorescent-based assays do not require large sample sizes. Viability assays are used to assess the success of cryopreservation techniques, the toxicity of substances, or the effectiveness of substances in mitigating effects of toxic substances.\n\n\n\n", "id": "28643345", "title": "Viability assay"}
{"url": "https://en.wikipedia.org/wiki?curid=256162", "text": "Neutrophil\n\nNeutrophils (also known as neutrocytes) are the most abundant type of granulocytes and the most abundant (40% to 70%) type of white blood cells in most mammals. They form an essential part of the innate immune system. Their functions vary in different animals.\n\nThey are formed from stem cells in the bone marrow. They are short-lived and highly motile, or mobile, as they can enter parts of tissue where other cells/molecules cannot. Neutrophils may be subdivided into segmented neutrophils and banded neutrophils (or bands). They form part of the polymorphonuclear cells family (PMNs) together with basophils and eosinophils.\n\nThe name \"neutrophil\" derives from staining characteristics on hematoxylin and eosin (H&E) histological or cytological preparations. Whereas basophilic white blood cells stain dark blue and eosinophilic white blood cells stain bright red, neutrophils stain a neutral pink. Normally, neutrophils contain a nucleus divided into 2–5 lobes.\n\nNeutrophils are a type of phagocyte and are normally found in the bloodstream. During the beginning (acute) phase of inflammation, particularly as a result of bacterial infection, environmental exposure, and some cancers, neutrophils are one of the first-responders of inflammatory cells to migrate towards the site of inflammation. They migrate through the blood vessels, then through interstitial tissue, following chemical signals such as Interleukin-8 (IL-8), C5a, fMLP, Leukotriene B4 and HO in a process called chemotaxis. They are the predominant cells in pus, accounting for its whitish/yellowish appearance.\n\nNeutrophils are recruited to the site of injury within minutes following trauma, and are the hallmark of acute inflammation; however, due to some pathogens being indigestible, they can be unable to resolve certain infections without the assistance of other types of immune cells.\n\nWhen adhered to a surface, neutrophil granulocytes have an average diameter of 12–15 micrometers (µm) in peripheral blood smears. In suspension, human neutrophils have an average diameter of 8.85 µm.\n\nWith the eosinophil and the basophil, they form the class of \"polymorphonuclear cells\", named for the nucleus' multilobulated shape (as compared to lymphocytes and monocytes, the other types of white cells). The nucleus has a characteristic lobed appearance, the separate lobes connected by chromatin. The nucleolus disappears as the neutrophil matures, which is something that happens in only a few other types of nucleated cells. In the cytoplasm, the Golgi apparatus is small, mitochondria and ribosomes are sparse, and the rough endoplasmic reticulum is absent. The cytoplasm also contains about 200 granules, of which a third are azurophilic.\n\nNeutrophils are sexually dimorphic. Neutrophils from women exhibit a small additional X chromosome structure, known as a \"neutrophil drumstick\".\n\nNeutrophils will show increasing segmentation (many segments of nucleus) as they mature. A normal neutrophil should have 3–5 segments. Hypersegmentation is not normal, and occurs in some disorders, most notably vitamin B deficiency. This is noted on a manual review of the blood smear, and is positive when most or all of the neutrophils have 5 or more segments.\n\nNeutrophils are the most abundant white blood cells in humans (approximately 10 are produced daily); they account for approximately 50–70% of all white blood cells (leukocytes). The stated normal range for human blood counts varies between laboratories, but a neutrophil count of 2.5–7.5 x 10/L is a standard normal range. People of African and Middle Eastern descent may have lower counts, which are still normal. A report may divide neutrophils into segmented neutrophils and bands.\n\nWhen circulating in the bloodstream and inactivated, neutrophils are spherical. Once activated, they change shape and become more amorphous or amoeba-like and can extend pseudopods as they hunt for antigens.\n\nNeutrophils have a preference to engulf refined carbohydrates (from ingested glucose, fructose, sucrose, honey and orange juice) over bacteria. In 1973 Sanchez et al. found that the neutrophil phagocytic capacity to engulf bacteria is affected when simple sugars are digested, and that fasting strengthens the neutrophils' phagocytic capacity to engulf bacteria. However, the digestion of normal starches has no effect. It was concluded that the function, and not the number, of phagocytes in engulfing bacteria was altered by the ingestion of sugars. In 2007 researchers at the Whitehead Institute of Biomedical Research found that given a selection of sugars, neutrophils engulf some types of sugar preferentially.\n\nThe average lifespan of inactivated human neutrophils in the circulation has been reported by different approaches to be between 5 and 90 hours. Upon activation, they marginate (position themselves adjacent to the blood vessel endothelium) and undergo selectin-dependent capture followed by integrin-dependent adhesion in most cases, after which they migrate into tissues, where they survive for 1–2 days.\n\nNeutrophils are much more numerous than the longer-lived monocyte/macrophage phagocytes. A pathogen (disease-causing microorganism or virus) is likely to first encounter a neutrophil. Some experts hypothesize that the short lifetime of neutrophils is an evolutionary adaptation. The short lifetime of neutrophils minimizes propagation of those pathogens that parasitize phagocytes because the more time such parasites spend outside a host cell, the more likely they will be destroyed by some component of the body's defenses. Also, because neutrophil antimicrobial products can also damage host tissues, their short life limits damage to the host during inflammation.\n\nNeutrophils will be removed after phagocytosis of pathogens by macrophages. PECAM-1 and phosphatidylserine on the cell surface are involved in this process.\n\nNeutrophils undergo a process called chemotaxis via amoeboid movement, which allows them to migrate toward sites of infection or inflammation. Cell surface receptors allow neutrophils to detect chemical gradients of molecules such as interleukin-8 (IL-8), interferon gamma (IFN-γ), C3a, C5a, and Leukotriene B4, which these cells use to direct the path of their migration.\n\nNeutrophils have a variety of specific receptors, including ones for complement, cytokines like interleukins and IFN-γ, chemokines, lectins, and other proteins. They also express receptors to detect and adhere to endothelium and Fc receptors for opsonin.\n\nIn leukocytes responding to a chemoattractant, the cellular polarity is regulated by activities of small Rho guanosine triphosphatases (Rho GTPases) and the phosphoinositide 3-kinases (PI3Ks). In neutrophils, lipid products of PI3Ks regulate activation of Rho GTPases and are required for cell motility. They accumulate asymmetrically to the plasma membrane at the leading edge of polarized cells. Spatially regulating Rho GTPases and organizing the leading edge of the cell, PI3Ks and their lipid products could play pivotal roles in establishing leukocyte polarity, as compass molecules that tell the cell where to crawl.\n\nIt has been shown in mice that in certain conditions neutrophils have a specific type of migration behaviour referred to as neutrophil swarming during which they migrate in a highly coordinated manner and accumulate and cluster to sites of inflammation.\n\nBeing highly motile, neutrophils quickly congregate at a focus of infection, attracted by cytokines expressed by activated endothelium, mast cells, and macrophages. Neutrophils express and release cytokines, which in turn amplify inflammatory reactions by several other cell types.\n\nIn addition to recruiting and activating other cells of the immune system, neutrophils play a key role in the front-line defense against invading pathogens. Neutrophils have three methods for directly attacking micro-organisms: phagocytosis (ingestion), degranulation (release of soluble anti-microbials), and generation of neutrophil extracellular traps (NETs).\n\nNeutrophils are phagocytes, capable of ingesting microorganisms or particles. For targets to be recognized, they must be coated in opsonins—a process known as antibody opsonization. They can internalize and kill many microbes, each phagocytic event resulting in the formation of a phagosome into which reactive oxygen species and hydrolytic enzymes are secreted. The consumption of oxygen during the generation of reactive oxygen species has been termed the \"respiratory burst\", although unrelated to respiration or energy production.\n\nThe respiratory burst involves the activation of the enzyme NADPH oxidase, which produces large quantities of superoxide, a reactive oxygen species. Superoxide decays spontaneously or is broken down via enzymes known as superoxide dismutases (Cu/ZnSOD and MnSOD), to hydrogen peroxide, which is then converted to hypochlorous acid (HClO), by the green heme enzyme myeloperoxidase. It is thought that the bactericidal properties of HClO are enough to kill bacteria phagocytosed by the neutrophil, but this may instead be a step necessary for the activation of proteases.\n\nNeutrophils also release an assortment of proteins in three types of granules by a process called degranulation. The contents of these granules have antimicrobial properties, and help combat infection.\n\nIn 2004, Brinkmann and colleagues described a striking observation that activation of neutrophils causes the release of web-like structures of DNA; this represents a third mechanism for killing bacteria. These neutrophil extracellular traps (NETs) comprise a web of fibers composed of chromatin and serine proteases that trap and kill extracellular microbes. It is suggested that NETs provide a high local concentration of antimicrobial components and bind, disarm, and kill microbes independent of phagocytic uptake. In addition to their possible antimicrobial properties, NETs may serve as a physical barrier that prevents further spread of pathogens. Trapping of bacteria may be a particularly important role for NETs in sepsis, where NETs are formed within blood vessels. Recently, NETs have been shown to play a role in inflammatory diseases, as NETs could be detected in preeclampsia, a pregnancy-related inflammatory disorder in which neutrophils are known to be activated. In addition, NETs are known to exhibit pro-thrombotic effects both \"in vitro\" and \"in vivo\".\n\nLow neutrophil counts are termed \"neutropenia\". This can be congenital (developed at or before birth) or it can develop later, as in the case of aplastic anemia or some kinds of leukemia. It can also be a side-effect of medication, most prominently chemotherapy. Neutropenia makes an individual highly susceptible to infections. It can also be the result of colonization by intracellular neutrophilic parasites.\n\nIn alpha 1-antitrypsin deficiency, the important neutrophil enzyme elastase is not adequately inhibited by alpha 1-antitrypsin, leading to excessive tissue damage in the presence of inflammation – the most prominent one being pulmonary emphysema.\n\nIn Familial Mediterranean fever (FMF), a mutation in the \"pyrin\" (or \"marenostrin\") gene, which is expressed mainly in neutrophil granulocytes, leads to a constitutively active acute-phase response and causes attacks of fever, arthralgia, peritonitis, and – eventually – amyloidosis.\n\nDecreases in neutrophil function have been linked to hyperglycemia. Dysfunction in the neutrophil biochemical pathway myeloperoxidase as well as reduced degranulation are associated with hyperglycemia.\n\nThe Absolute neutrophil count (ANC) is also used in diagnosis and prognosis. ANC is the gold standard for determining severity of neutropenia, and thus neutropenic fever. Any ANC < 1500 cells / mm is considered neutropenia, but <500 cells / mm is considered severe. There is also new research tying ANC to myocardial infarction as an aid in early diagnosis.\n\nThere are five (HNA 1-5) sets of neutrophil antigens recognized. The three HNA-1 antigens (a-c) are located on the low affinity Fc-γ receptor IIIb (FCGR3B :CD16b) The single known HNA-2a antigen is located on CD177. The HNA-3 antigen system has two antigens (3a and 3b) which are located on the seventh exon of the CLT2 gene (SLC44A2). The HNA-4 and HNA-5 antigen systems each have two known antigens (a and b) and are located in the β2 integrin. HNA-4 is located on the αM chain (CD11b) and HNA-5 is located on the αL integrin unit (CD11a).\n\nTwo functionally unequal subpopulations of neutrophils were identified on the basis of different levels of their reactive oxygen metabolite generation, membrane permeability, activity of enzyme system, and ability to be inactivated. The cells of one subpopulation with high membrane permeability (neutrophil-killers) intensively generate reactive oxygen metabolites and are inactivated in consequence of interaction with the substrate, whereas cells of another subpopulation (neutrophil-cagers) produce reactive oxygen species less intensively, don't adhere to substrate and preserve their activity. \n\n Neutrophils display highly directional amoeboid motility in infected footpad and phalanges. Intravital imaging was performed in the footpad path of LysM-eGFP mice 20 minutes after infection with \"Listeria monocytogenes\".\n\n", "id": "256162", "title": "Neutrophil"}
{"url": "https://en.wikipedia.org/wiki?curid=858101", "text": "Inorganic ions\n\nInorganic ions in animals and plants are ions necessary for vital cellular activity. In body tissues, ions are also known as electrolytes, essential for the electrical activity needed to support muscle contractions and neuron activation. They contribute to osmotic pressure of body fluids as well as performing a number of other important functions. Below is a list of some of the most important ions for living things as well as examples of their functions:\n\n\nCalcium in biology\n\nMagnesium in biology\n\nHuman Iron Metabolism\n", "id": "858101", "title": "Inorganic ions"}
{"url": "https://en.wikipedia.org/wiki?curid=50110441", "text": "Cytochrome P450 omega hydroxylase\n\nCytochrome P450 omega hydroxylases, also termed cytochrome P450 ω-hydroxylases, CYP450 omega hydroxylases, CYP450 ω-hydroxylases, CYP omega hydroxylase, CYP ω-hydroxylases, fatty acid omega hydroxylases, cytochrome P450 monooxygenases, and fatty acid monooxygenases, are a set of cytochrome P450-containing enzymes that catalyze the addition of a hydroxyl residue to a fatty acid Substrate (chemistry). The CYP omega hydroxylases are often referred to as monoxygenases; however, the monooxygenases are CYP450 enzymes that add a hydroxyl group to a wide range of xenobiotic (e.g. drugs, industrial toxins) and naturally occurring endobiotic (e.g. cholesterol) substrates, most of which are not fatty acids. The CYP450 omega hydroxylases are accordingly better viewed as a subset of monooxygenases that have the ability to hydroxylate fatty acids. While once regarded as functioning mainly in the catabolism of dietary fatty acids, the omega oxygenases are now considered critical in the production or break-down of fatty acid-derived mediators which are made by cells and act within their cells of origin as autocrine signaling agents or on nearby cells as paracrine signaling agents to regulate various functions such as blood pressure control and inflammation.\n\nThe omega oxygenases metabolize fatty acids (RH) by adding a hydroxyl (OH) to their terminal (i.e. furthest from the fatty acids' carboxy residue) carbons; in the reaction, the two atoms of molecular oxygen(O[ are reduced to one hydroxyl group and one water (HO molecule) by the concomitant oxidation of NAD(P)H (see monooxygenase).\nRH + O + NADPH + H → ROH + HO + NADP\nCYP450 enzymes belong to a superfamily which in humans is composed of at least 57 CYPs; within this superfamily, members of six CYP4A subfamilies, (which are CYP4A, CYP4B, CYP4F, CYP4V, CYP4X, and CYP4z) possess ω-hydroxylase activity viz., CYP4A, CYP4B, and CYP4F CYP2U1 also possesses ω hydroxylase activity. These CYP ω-hydroxylases can be categorized into several groups based on their substrates and consequential function\n\n", "id": "50110441", "title": "Cytochrome P450 omega hydroxylase"}
{"url": "https://en.wikipedia.org/wiki?curid=4367754", "text": "Epoxyeicosatrienoic acid\n\nThe epoxyeicosatrienoic acids or EETs are signaling molecules formed within various types of cells by the metabolism of arachidonic acid by a specific subset of Cytochrome P450 enzymes termed cytochrome P450 epoxygenases. These nonclassic eicosanoids are generally short-lived, being rapidly converted from epoxides to less active or inactive dihydroxy-eicosatrienoic acids (diHETrEs) by a widely distributed cellular enzyme, Soluble epoxide hydrolase (sEH), also termed Epoxide hydrolase 2. The EETs consequently function as transiently acting, short-range hormones; that is, they work locally to regulate the function of the cells that produce them (i.e. they are autocrine agents) or of nearby cells (i.e. they are paracrine agents). The EETs have been most studied in animal models where they show the ability to lower blood pressure possibly by a) stimulating arterial vasorelaxation and b) inhibiting the kidney's retention of salts and water to decrease intravascular blood volume. In these models, EETs prevent arterial occlusive diseases such as heart attacks and brain strokes not only by their anti-hypertension action but possibly also by their anti-inflammatory effects on blood vessels, their inhibition of platelet activation and thereby blood clotting, and/or their promotion of pro-fibrinolytic removal of blood clots. With respect to their effects on the heart, the EETs are often termed cardio-protective. Beyond these cardiovascular actions that may prevent various cardiovascular diseases, studies have implicated the EETs in the pathological growth of certain types of cancer and in the physiological and possibly pathological perception of neuropathic pain. While studies to date imply that the EETs, EET-forming epoxygenases, and EET-inactivating sEH can be manipulated to control a wide range of human diseases, clinical studies have yet to prove this. Determination of the role of the EETS in human diseases is made particularly difficult because of the large number of EET-forming epoxygenases, large number of epoxygenase substrates other than arachidonic acid, and the large number of activities, some of which may be pathological or injurious, that the EETs possess.\n\nEETS are epoxide eicosatrienoic acid metabolites of arachidonic acid (a straight chain Eicosatetraenoic acid, omega-6 fatty acid). Arachidonic acid has 4 cis double bonds (see Cis–trans isomerism which are abbreviated with the notation \"Z\" in the IUPAC Chemical nomenclature used here. These double bonds are located between carbons 5-6, 8-9, 11-12, and 14-15; arachidonic acid is therefore 5\"Z\",8\"Z\",11\"Z\",14\"Z\"-eicosatetraenoic acid. Cytochrome P450 epoxygenases attack these double bonds to form their respective eicosatrienoic acid epoxide regioisomers (see Structural isomer, section on position isomerism (regioisomerism)) viz., 5,6-EET (i.e. 5,6-epoxy-8\"Z\",11\"Z\",14\"Z\"-eicosatrienoic acid), 8,9-EET (i.e. 5,6-epoxy-8\"Z\",11\"Z\",14\"Z\"-eicosatrienoic acid), 11,12-EET (i.e. 11,12-epoxy-5\"Z\",8\"Z\",14\"Z\"-eicosatrienoic acid), or, as drawn in the attached figure, 14,15-EET (i.e. 14,15-epoxy-5\"Z\",8\"Z\",11\"Z\"-eicosatrienoic acid). The enzymes generally form both \"R\"/\"S\" enantiomers at each former double bond position; for example, cytochrome P450 epoxidases metabolize arachidonic acid to a mixture of 14\"R\",15\"S\"-EET and 14\"S\",15\"R\"-EET.\n\nThe cytochrome P450 (CYP) superfamily of enzymes is distributed broadly throughout bacteria, archaea, fungi, plants, animals, and even viruses (see Cytochrome P450). The superfamily comprises more than 11,000 genes categorized into 1,000 families. Humans have 57 putatively active CYP genes and 58 CYP pseudogenes; only a relatively few of the active CYP genes code for EET-forming epoxygenases, i.e. protein enzymes with the capacity to attach atomic oxygen (see Allotropes of oxygen#Atomic oxygen) to the carbon-carbon double bonds of unsaturated long chain fatty acids such as arachidonic acid. The CYP epoxygenases fall into several subfamilies including CYP1A, CYP2B, CYP2C, CYP2E, CYP2J, and within the CYP3A sub family, CYP3A4; in humans, CYP2C8, CYP2C9, CYP2C19, CYP2J2, and possibly CYP2S1 isoforms are the main producers of EETs although CYP2C9, CYP2C18, CYP3A4, CYP4A11, CYP4F8, and CYP4F12 are capable of producing the EETs and may do so in certain tissues. The CYP epoxygenases can epoxidize any of the double bounds in arachidonic acid but most of them are relatively selective in that they make appreciable amounts of only one or two EETs with 11,12-EET and 14,15-EET accounting for 67%-80% of the product made by the cited CYP epoxidases as well as the main EETs made by mammalian tissues. CYP2C9, CYP2JP, and possibly the more recently characterized CYP2S1 appear to be the main produces of the EETs in humans with CYPP2C9 being the main EET producer in vascular endothelial cells and CYP2JP being highly expressed (although less catalytically active than CYP2C) in heart muscle, kidneys, pancreas, lung, and brain. CYP2S1 is expressed in macrophages, liver, lung, intestine, and spleen and is abundant in human and mouse atherosclerosis (i.e. Atheroma) plaques as well as inflamed tonsils.\nETEs are commonly produced by the stimulation of specific cell types. The stimulation causes arachidonic acid to be released from the \"sn-2\" position of cellular phospholipids through the action of Phospholipase A2-type enzymes and subsequent attack of the released arachidonic acid by a CYP epoxidase. In a typical example of this mechanism, bradykinin or acetylcholine acting through their respective Bradykinin receptor B2 and muscarinic acetylcholine receptor M1 or muscarinic acetylcholine receptor M3 stimulate vascular endothelial cells to make and release EETs.\n\nThe CYP epoxygenases, similar to essentially all CYP450 enzymes, are involved in the metabolism of diverse xenobiotics and natural compounds. Since many of these same compounds also induce increases in the levels of the epoxygenases, CYP oxygenase levels and consequently EET levels in humans vary widely and are highly dependent on their recent consumption history.\n\nIn cells, the EETs are rapidly metabolized by a cytosolic soluble epoxide hydrolase (sEH) which adds water (HO) across the epoxide to form their corresponding Vicinal (chemistry) diol dihydroxyeicosatrienoic acids (diHETrEs or DHETs), i.e. sEH converts 14,15-ETE to 14,15-dihydroxy-eicosatrienoic acid (14,15-diHETrE), 11,12-ETE to 11,12-diHETrE, 8,9-ETE to 8,9-diHETrE, and 5,6-ETE to 5,6-diHETrE. The product diHETrEs, like their epoxy precursors, are enantiomer mixtures; for instance, sEH converts 14,15-ETE to a mixture of 14(\"S\"),15(\"R\")-diHETrE and 14(\"R\"),15(\"S\")-diHETrE. However, 5,6-EET is a relatively poor substrate for sEH and in cells is more rapidly metabolized by cyclooxygenase-2 to form 5,6-epoxy-prostaglandin F1α. Since the diHETrE products are as a rule generally far less active than their epoxide precursors, the sEH pathway of EET metabolism is regarded as a critical EET-inactivating pathway. In some instances, however, the diHETrEs have been found to possess appreciable activity as indicated in the Biological activities section below.\n\nMembrane-bound Microsomal epoxide hydrolase (mEH or Epoxide hydrolase 1 [EC 3.2.2.9.]) can metabolize EETs to their dihydroxy products but is regarded as not contributing significantly to EET inactivation in vivo except perhaps in brain tissue where mEH activity levels far outstrip those of sEH. Furthermore, two other human sEH, epoxide hydrolases 3 and 4 (see epoxide hydrolase), have been defined but their role in attacking EETs (and other epoxides) in vivo has not yet been determined. Besides these four epoxide hydrolase pathways, EETs may be acylated into phospholipids in an Acylation-like reaction. This pathway may serve to limit the action of EETs or store them for future release. EETs are also inactivated by being further metabolized though three other pathways: Beta oxidation, Omega oxidation, and elongation by enzymes involved in Fatty acid synthesis. These alternate to sEH pathways of EET metabolism ensure that blockade of sEH with drugs can increase EET levels only moderately in vivo.\n\nGenerally, EETs cause:\n\nOther effects are specific to certain cells or locations; EETs:\n\nDiol metabolites of the EETs, i.e. the diHETrEs (also termed DHETs), have relatively little or no activity compared to the EETs in most systems. However:\n\nWith respect to the regulation of blood pressure as well as the kidneys' regulation of salt and water absorption (which contributes to blood pressure regulation), EETS are counterpoises to another CYP-derived arachidonic acid metabolite, 20-Hydroxyeicosatetraenoic acid (20-HETE). In humans, the major CYPs making 20-HETE are CYP4A11, CYP4F2, and CYP4F3. In animal models, 20-HETE raises blood pressure by contracting arteries and stimulating the kidney to reabsorb salt and water to increase the intravascular volume (see 20-Hydroxyeicosatetraenoic acid). EETs have the opposite effects. They are one type of Endothelium-Derived Hyperpolarizing Factor, i.e. a substance and/or electrical signal synthesized or generated in and released from the vascular endothelium that hyperpolarize nearby vascular smooth muscle cells. This causes these cells to relax and thereby lowers blood pressure. In animal (primarily rodent) models, EETs dilate smaller sized resistance arteries involved in causing hypertension as well as cardiac and renal arteries. They cause smooth muscle hyperpolarization by opening vascular smooth muscle large-conductance calcium-activated potassium channels, opening certain vascular smooth muscle transient receptor potential channels, or facilitating the movement of excitatory signals through gap junctions between endothelium and smooth muscles or between smooth muscles. The actual mechanism(s) involved in these EET-induced effects have not been fully elucidated although some studies implicate EET binding to an unidentified Cell surface receptor and/or Gs protein-linked G protein–coupled receptor to initiate the signal pathway(s) leading to the cited channel and gap junction changes. With respect to the kidney, studies in rodents find that 20-HETE increases sodium and water reabsorption while the EETs, which are made in the proximal tubules and cortical collecting ducts, reduce sodium ion and water transport at both sites by inhibiting kidney Sodium–hydrogen antiporter (i.e. Na+/H+ exchanger) and/or Epithelial sodium channels. Mice lacking either of the EET-producing Cyp2c44 or Cyp4ac44 genes (by gene knockout) develop hypertension when fed high sodium or high potassium diets. These and large number of other studies included in the cited references implicate the EETs in the control of at least certain forms of hypertension in rodents.\n\nIn humans, vascular endothelium production of EETs involves mainly CYP2C9 and numerous indirect studies have implicated CYP epoxygenase, possibly CYP2C9, in producing a product which causes vasodilation. These studies find that selective (but not entirely specific) CYP epoxygenase-inhibiting drugs reduce human vasodilation responses elicited by the vasodilators bradykinin, acetylcholine, and methacholine; this suggests that these vasodilators operate by stimulation the production of EETs. Human studies also find that Caucasian but not African American subjects who have the Lys55Arg single nucleotide polymorphism variant in the polyunsaturated fatty epoxide-inactivating enzyme, sEH, express hyperactive sEH and show reduced vasodilation responses to bradykinin. Other studies find that women with pregnancy-induced hypertension and subjects with Renovascular hypertension exhibit low plasma ETE levels. Finally, 11,12-EET has been shown to relax the internal mammary artery in women, indicating that at least this EET has direct vasodilating actions in humans. On the other hand, several studies in humans with single nucleotide polymorphism in CYP epxoygenase genes have given negative or confusing results. The most common variant of CYP2J2, rs890293, similarly contradictive or negative results are reported in studies on the rs11572082 (Arg1391Lys) variant of CYP2C8 and the rs1799853 (Arg144Cys) and rs1057910 (Ile359Leu) variants of CYP2C9, all of which code for an epoxygenase with reduced arachidonic acid-metabolizing and EET-forming activities.\n\nWhile many of the cited studies suggest that one or more of the EETs released by vascular endothelial cells are responsible for the actions of the vasodilators and that deficiencies in EET production or excessive EET inactivation by sEH underlie certain types of hypertension in humans, they are not conclusive. They do not exclude a possibility that other polyunsaturated fatty acid epoxides such as those derived from eicosatetraenoic, docosatetraenoic, or linoleic acids made by CYP2C9 or other CYP epoxygenases (see epoxygenase) contribute in small or large part to vasodilation responses and by this action promote blood flow to tissues and function in lowering high blood pressures. Furthermore, the genetic studies conducted to date on SNP variants do not give strong support for an antihypertensive role for the EETs or EET-forming epoxygenases in humans. Recently developed drugs which are metabolically stable analogs of the EETs and thereby mimic the EETs actions or, alternatively of drugs which inhibit sEH and thereby increase EET levels are in the Pre-clinical development stage for treating human hypertension. Testing for their usefulness in treating human hypertension is made difficult because of: 1) the large number of CYP epoxygenases along with their differing tissue distributions and sensitivities to drug inhibitors; 2) the diversity of EETs made by the CYP epoxygenases, some of which differ in activities; 3) the diversity of fatty acid substrates metabolized by the CYP epoxygenases some of which are converted to epoxides (e.g. the epoxide metabolites of linoleic, docosahexaenoic, eicosapentaenoic acids) with have different activities than the EETs or may even be overtly toxic to humans (see Coronaric acid); 4) the sEH-derived dihydroxy metabolites of the EETs some of which have potent vasodilating effects in the certain vascular networks in rodents and therefore potentially in humans; and 5) the non-specificity and side effects of the latter drugs.\n\nAs indicated on the ClinicalTrials.gov web site, a National Institutes of Health-sponsored clinical trial entitled \"Evaluation of Soluble Epoxide Hydrolase (s-EH) Inhibitor in Patients With Mild to Moderate Hypertension and Impaired Glucose Tolerance\" has not been completed or reported on although started in 2009.\n\nAs indicated elsewhere on this page, EETs inhibit inflammation, inhibit blood clot formation, inhibit platelet activation, dilate blood vessels including the coronary arteries, reduce certain types of hypertension, stimulate the survival of vascular endothelial and cardiac muscle cells by inhibiting apoptosis, promote blood vessel growth (i.e. angiogenesis), and stimulate smooth muscle cell migration; these activities may protect the heart. Indeed, studies on in vivo animal and in vitro animal and human cell model systems indicate that the ETEs reduce infarct (i.e. injured tissue) size, reduce cardiac arrhythmias, and improve the strength of left ventricle contraction immediately after blockade of coronary artery blood flow in animal models of ischemia-reperfusion injury; EETs also reduce the size of heart enlargement that occurs long after these experiment-induced injuries.\n\nHumans with established coronary artery disease have higher levels of plasma EETs and higher ratios of 14,15-EET to 14,15-diHETrE (14,15-diHETrE is the less active or inactive metabolite 14,15-EET). This suggests that the EETs serve a protective role in this setting and that these plasma changes were a result of a reduction in cardiac sEH activity. Furthermore, coronary artery disease patients who had lower levels of EETs/14,15-di-ETE ratios exhibited evidence of a poorer prognosis based on the presence of poor prognostic indicators, cigarette smoking, obesity, old age, and elevation in inflammation markers.\n\nIndirect studies in animal models suggest that EETs have protective effects in strokes (i.e. cerbrovasular accidents). Thus, sEH inhibitors and sEH-Gene knockout have been shown to reduce the damage to brain that occurs in several different models of ischemic stroke; this protective effect appears due to a reduction in systemic blood pressure and maintenance of blood flow to ischemic areas of the brain by arteriole dilation as a presumed consequence of inhibiting the degradation of EETs (and/or other fatty acid epoxides). sEH-gene knockout mice were also protected from that brain damage that followed induced-subarachnoid hemorrhage; this protective effect appeared due to a reduction in cerebral edema which was also presumable due to the prolongation of EET half-lives. 14,15-EET levels have been shown to be elevated in the cerebrospinal fluid of humans suffering subarachnoid hemorrhage.\n\nsEH inhibitors and gene knockout also reduce the number and severity of Epileptic seizures in several animal models; this effect is presumed due to the actions of EETs (and other epoxide fatty acids) in reducing cerebral blood flow changes, and reducing neuron production of Neuroactive steroids, reducing neuroinflammation,\n\nPortal hypertension or hypertension in the venous hepatic portal system of blood flow is defined as an increase in portal pressure above normal values of 10 Millimeter of mercury. It is a serious, sometimes life-threatening complication of various diseases such as liver cirrhosis, liver fibrosis, massive Fatty liver, portal vein thrombosis, liver schistosomiasis, massive liver involvement in miliary tuberculosis or sarcoidosis, and obstruction of the venous circuit at any level between liver and right heart (see Portal hypertension). Vascular contraction in the portal system is mediated by several agents: nitric oxide, carbon monoxide, prostacyclin I, and Endothelium-derived hyperpolarizing factors (EDHFs). EDHFs include endothelin, angiotensin II, thromboxane A2, certain leukotrienes, and the EETs. In portal hypertension, portal vein endothelium appears to be dysfunctional in that it overproduces EDHFs. The EETs, particularly 11,12-EET, have a quite different effect on the Liver sinusoidal veins than on arteries of the systemic circulation: they constrict the sinusoids. Levels of EETs in the plasma and liver of patients with cirrhosis and portal hypertension are reportedly elevated compared to normal subjects. These and other findings have led to the proposal that portal endothelium-derived EETs, perhaps acting in cooperation with another EDHF, endothelin, contribute to portal hypertension.\n\nThe forced over-expression of CYP2J2 in or the addition of an EET to cultured human Tca-8113 oral squamous cancer cells, lung cancer A549 cells and NCL-H446 cells, HepG2 liver cancer cells, LS-174 colon cancer cells, SiHa uterine cervix cancer cells, U251 glioblastoma cancer cells, ScaBER urinary bladder cancer cells, and K562 erythroleukemia and HL-60 promyelocyte leukemic blood cancer cells caused an increase in their survival and proliferation. \nPutative inhibitors of CYP2J2 inhibit the growth in culture of several human cancer cell lines that express relatively high levels of CYP2J2 viz., Tca-8113 cells, HeLa uterine cervix cell lines, A549 cells, MDA-MB-435 breast cells, and HepG2 cells but they had no significant inhibitory effects on two cell lines that expressed little or no CYP2J2. \nA putative inhibitor of CYPJ2 also inhibited the growth of human K562 erythroleukemia in a mice model as well as the growth of mouse el4 lymphoma cells in mice that were forced to overexpress CYP2J2 cells in their vascular epithelium. \nForced expression of CYP2J2 also enhanced, while forced inhibition of its expression (using Small interfering RNA) reduced, the survival, growth, and metastasis of MDA-MB-231 human breast carcinoma cells in the mouse model and likewise enhanced or reduced, respectively, the survival and growth of these cells in culture. \nFurther studies found that the expression of CYP2J2 was in increased in the malignant cells, relative to the nearby normal cells, in the following specimens taken from humans suffering squamous-cell carcinoma and adenocarcinoma types of esophageal cancer and lung cancer, small cell lung carcinoma, breast cancer, stomach cancer, liver cancer, and colon adenocarcinoma; \nthis CYP was also highly expressed in the malignant cells of patients with acute leukemia, chronic leukemia, and lymphoma. \nAs a group, patients with these cancers exhibited increased levels of EETs in their urine and blood samples.\nStudies of the CYP epoxygenases have not been restricted to the CYP2J subfamily. \nReduction in the expression of CYP3A4 or CYP2C using small interfering RNA inhibits the growth of cultured MCF7, T47D, and MDA-MB-231 human breast cancer cells; in these studies 14,15-EET stimulated the proliferation of cultured MCF7 cells, reduction in the expression of CYP3A4 by small interference RNA methods, inhibited these cells from proliferating, and 14,15-ETE reversed the effect of CYP3A4 interference; \nin other studies, the forced overexpression of CYP3A4 stimulated the growth of human liver cancer (hepatoma) cell line, Hep3 . \nIn human breast cancer, not only CYP2J2 but also CYP2C8 and CYP2C9 levels appear elevated while sEH levels appear reduced in malignant compared to nearby normal tissues; associated with this finding, the levels of 14,15-EET as well as the levels of 14,15-EET plus 14,15-dihydroxy-EET were significantly elevated in the cancerous compared to noncancerous cells and the levels of CYP2C8 and CYP2C9 proteins correlated positively and sEH levels correlated negatively with the tumor cells rate of proliferation as accessed by their Ki67 levels while CYP2J2 levels correlated positively with poorer prognosis as predicted tumor histological grade and tumor size.\n\nThe cited findings suggest that various CYP epoxygenases along with the epoxide metabolites which they make promote the growth and spread of diverse types of cancer in animals and humans. Their effects may reflect the ability of the epoxide metabolites to stimulate the proliferation and survival of the target cancer cells but perhaps also to stimulate these cells to trigger new capillary formation (see angiogenesis#Tumor angiogenesis), invade new tissues, and metastasize. \nA series of drugs derived from Terfenadine have been shown to inhibit CYP2J2 and to suppress the proliferation and cause the apoptosis of various types of human cancer cell lines in culture as well as in animal models. However, clinical studies targeting CYP epoxygenases and EETs and to successfully suppress cancer in humans have not been reported.\n\nIn vitro and animal model studies indicate that the EETs possess anti-inflammatory activity that is directed toward reducing, resolving, and limiting the damage caused by inflammation. Most of these studies have focused on circulating leukocytes, blood vessel endothelium, and the occlusion of blood vessels due to pathological blood clotting. EETs a) inhibit vascular endothelial cells from expressing Cell adhesion molecules such as VCAM-1, ICAM-1, and E-selectin thereby limiting circulating leukocytes from adhering to blood vessel endothelium and migrating across this endothelium into tissues; 2) inhibit the expression and activity of cyclooxygenase-2 in blood monocytes thereby reducing their production of pro-inflammatory metabolites of arachidonic acid such as prostaglandin E2; 3) inhibit platelet aggregation thereby reducing thrombus (i.e. blood clot) formation; 4) promote fibrinolysis thereby dissolving blood clots; and 5) inhibit vascular smooth muscle cell proliferation thereby reducing blood vessel hypertrophy and narrowing.\n\nEETs, pharmacological inhibition of sEH, and/or inhibition of sEH expression enhance insulin actions on animal tissues in vitro and have protective effects in ameliorating insulin resistance as well as many of the neurological and kidney complications of diabetes in various animal models of diabetes; the studies suggest that the EETs have beneficial effects in Type I diabetes as well as Type II diabetes. These interventions also gave beneficial results in animal models of non-alcoholic fatty liver disease and certain types inflammation-related kidney diseases including chronic kidney disease, renal ischemia-reperfusion injury, and polycystic kidney disease. The protective role of EETs in these animal model diseases may reflect, at least in part, their anti-inflammatory actions.\n\nEETs have been shown to have anti-hyperalgesic and pain-relieving activity in several animal models of pain including Nociception resulting from tissue injury, inflammation, and Peripheral neuropathy (also see Neuropathic pain) including pain secondary to experimentally induced Diabetes in mice. The epoxides of omega-3 fatty acids appear far stronger and more involved in the relief of pain than the EETs (see epoxydocosapentaenoic acid).\n", "id": "4367754", "title": "Epoxyeicosatrienoic acid"}
{"url": "https://en.wikipedia.org/wiki?curid=49599350", "text": "Epoxydocosapentaenoic acid\n\nEpoxide docosapentaenoic acids (epoxydocosapentaenoic acids, EDPs, or EpDPEs) are metabolites of the 22-carbon straight-chain omega-3 fatty acid, docosahexaenoic acid (DHA). Cell types that express certain cytochrome P450 (CYP) epoxygenases metabolize polyunsaturated fatty acid's (PUFAs) by converting one of their double bonds to an epoxide. In the best known of these metabolic pathways, cellular CYP epoxygenases metabolize the 20-carbon straight-chain omega-6 fatty acid, arachidonic acid, to epoxyeicosatrienoic acids (EETs); another CYP epoxygenase pathway metabolizes the 20-carbon omega-3 fatty acid, eicosapentaenoic acid (EPA), to epoxyeicosatetraenoic acids (EEQs). CYP epoxygenases similarly convert various other PUFAs to epoxides (see epoxygenase) These epoxide metabolites have a variety of activities. However, essentially all of them are rapidly converted to their corresponding, but in general far less active, Vicinal (chemistry) dihydroxy fatty acids by ubiquitous cellular Soluble epoxide hydrolase (sEH; also termed Epoxide hydrolase 2). Consequently, these epoxides, including EDPs, operate as short-lived signaling agents that regulate the function of their parent or nearby cells. The particular feature of EDPs (and EEQs) distinguishing them from EETs is that they derive from omega-3 fatty acids and are suggested to be responsible for some of the beneficial effects attributed to omega-3 fatty acids and omega-3-rich foods such as fish oil.\n\nEDPs are epoxide eicosapentaenoic acid metabolites of DHA. DHA has 6 cis (see Cis–trans isomerism) Double bonds each one of which is located between carbons 4-5, 7-8, 10-11, 13-14, 16-17, or 19-20. Cytochrome P450 epoxygenases attack any one of these double bounds to form a respective docosapentaenoic acid (DPA) epoxide regioisomer (see Structural isomer, section on position isomerism (regioisomerism)). A given epoxygenase may therefore convert DHA to 4,5-EDP (i.e. 4,5-epoxy-7\"Z\",10\"Z\",13\"Z\",16\"Z\",19\"Z\"-DPA), 7,8-EDP (i.e. 7,8-epoxy-4\"Z\",10\"Z\",13\"Z\",16\"Z\",19\"Z\"-DPA), 10,11-EDP (i.e. 10,11-epoxy-4\"Z\",7\"Z\",13\"Z\",16\"Z\",19\"Z\"-DPA), 13,14-EDP (i.e. 13,14-epoxy-4\"Z\",7\"Z\",10\"Z\",16\"Z\",19\"Z\"-DPA), 16,17-EDP (i.e. 16,17-epoxy-4\"Z\",7\"Z\",10\"Z\",13\"Z\",19\"Z\"-DPA, or 19,20-EDP (i.e. 19,20-epoxy-4\"Z\", 7\"Z\",10\"Z\",13\"Z\",16\"Z\"-DPA. The epoxygenase enzymes generally form both \"R\"/\"S\" enantiomers at each former double bound position; for example, cytochrome P450 epoxidases attack DHA at the 16,17-double bond position to form two epoxide enantiomers, 16\"R\",17\"S\"-EDP and 16\"S\",15\"17\"-EDP. The 4,5-EDP metabolite is unstable and generally not detected among the EDP formed by cells.\n\nEnzymes of the cytochrome P450 (CYP) superfamily that are classified as epoxygenases based on their ability to metabolize PUFA, particularly arachidonic acid, to epoxides include: CYP1A, CYP2B, CYP2C, CYP2E, CYP2J, and within the CYP3A subfamily, CYP3A4. In humans, CYP2C8, CYP2C9, CYP2C19, CYP2J2, and possibly CYP2S1 isoforms appear to be the principal epoxygenases responsible for metabolizing arachidonic acid to EETs (see Epoxyeicosatrienoic acid#Production). In general, these same CYP epoxygenases also metabolize DHA to EDP (as well as EPA to EEQ; CYP2S1 has not yet been tested for DHA-metabolizing ability), doing so at rates that are often greater than their rates in metabolizing arachidonic acid to EETs; that is, DHA (and EPA) appear to be preferred over arachidonic acid as substrates for many of the CYP epoxygenases. CYP1A1, CYP1A2, CYP2C18, CYP2E1, CYP4A11, CYP4F8, and CYP4F12 also metabolize DHA to EDPs. CYP2C8, CYP2C18, CYP2E1, CYP2J2, VYP4A11, CYP4F8, and CYP4F12 preferentially attack the terminal omega-3 double bond that distinguishes DHA from omega-6 fatty acids and therefore metabolize DHA principally to 19,20-EDP isomers while CYP2C19 metabolizes DHA to 7,8-EDP, 10,11-EDP, and 19,20-EDP isomers CYP2J2 metabolizes DHA to EPAs, principally 19,20-EPA, at twice the rate that it metabolizes arachidonic acid to EETs. In addition to the cited CYP's, CYP4A11, CYP4F8, CYP4F12, CYP1A1, CYP1A2, and CYP2E1, which are classified as CYP monooxygenase rather than CYP epoxygeanses because they metablize arachidonic acid to monohydroxy eicosatetraenoic acids (see 20-Hydroxyeicosatetraenoic acid), i.e. 19-hydroxyeicosatetraenoic acid and/or 20-hydroxyeicosatetranoic acid, take on epoxygease activity in converting DHA primarily to 19,20-EDP isomers (see epoxyeicosatrienoic acid). The CYP450 epoxygenases capable of metabolizing DHA to EDPs are wildly distributed in organs and tissues such as the liver, kidney, heart, lung, pancreas, intestine, blood vessels, blood leukocytes, and brain. These tissues are known to metabolize arachidonic acid to EETs; it has been shown or is presumed that they also metabolize DHA to EPD's.\n\nThe EDPs are commonly made by the stimulation of specific cell types by the same mechanisms which produce EETs (see Epoxyeicosatrienoic acid). That is, cell stimulation causes DHA to be released from the \"sn-2\" position of their membrane-bound cellular phospholipid pools through the action of a Phospholipase A2-type enzyme and the subsequent attack of the released DHA by CYP450 epoxidases. It is notable that the consumption of omega-3 fatty acid-rich diets dramatically raises the serum and tissue levels of EDPs and EEQs in animals as well as humans. Indeed, this rise in EDP (and EEQ) levels in humans is by far the most prominent change in the profile of PUFA metabolites caused by dietary omega-3 fatty acids and, it is suggested, may be responsible for at least some of the beneficial effects ascribed to dietary omega-3 fatty acids.\n\nSimilar to EETs (see Epoxyeicosatrienoic acid), EDPs are rapidly metabolized in cells by a cytosolic soluble epoxide hydrolase (sEH, also termed Epoxide hydrolase 2 [EC 3.2.2.10.]) to form their corresponding Vicinal (chemistry) diol dihydroxyeicosapentaenoic acids. Thus, sEH converts 19,20-EDP to 19,10-dihdroxydocosapentaenoic acid (DPA), 16,17-EDP to 16,17-dihydroxy-DPA, 13,14-EDP to 13,14-dihydroxy-DPA, 10,11-EDP to 10,11-dihydroxy-DPA, and 7,8-EDP to 7,8-dihydroxy-EDP; 4,5-EDP is unstable and therefore generally not detected in cells. The dihydroxy-EDP products, like their epoxy precursors, are enantiomer mixtures; for instance, sEH converts 16,17-EDP to a mixture of 16(\"S\"),17(\"R\")-dihydroxy-DPA and 16(\"R\"),1y(\"S\")-dihydroxy-DPA. These dihydroxy-DPAs typically are far less active than their epoxide precursors. The sEH pathway acts rapidly and is by far the predominant pathway of EDP inactivation; its operation causes EDPs to function as short-lived mediators whose actions are limited to their parent and nearby cells, i.e. they are autocrine and paracrine signaling agents, respectively.\n\nIn addition to the sEH pathway, EDPs, similar to the EETs, may be acylated into phospholipids in an Acylation-like reaction; this pathway may serve to limit the action of EETs or store them for future release. Finally, again similar to the EETs, EDPs are subject to inactivation by being further metabolized b Beta oxidation.\n\nEDPs have not be studied nearly as well as the EETs. This is particularly the case for animal studies into their potential clinical significance. In comparison to a selection of the many activities attributed to the EETs (see Epoxyeicosatrienoic acid), animal studies reported to date find that certain EDPs (16,17-EDP and 19,20-EDP have been most often examined) are: 1) more potent than EETs in decreasing hypertension and pain perception; 2) more potent than or at least equal in potency to the EETs in suppressing inflammation; and 3) act oppositely from the EETs in that EDPs inhibit angiogenesis, endothelial cell migration, endothelial cell proliferation, and the growth and metastasis of human breast and prostate cancer cell lines whereas EETs have stimulatory effects in each of these systems. As indicated in the Metabolism section, consumption of omega-3 fatty acid-rich diets dramatically raises the serum and tissue levels of EDPs and EEQs in animals as well as humans and in humans is by far the most prominent change in the profile of PUFA metabolites caused by dietary omega-3 fatty acids. Hence, the metabolism of DHA to EDPs (and EPA to EEQs) may be responsible for at least some of the beneficial effects ascribed to dietary omega-3 fatty acids.\n", "id": "49599350", "title": "Epoxydocosapentaenoic acid"}
{"url": "https://en.wikipedia.org/wiki?curid=15031355", "text": "ALOX12B\n\nArachidonate 12-lipoxygenase, 12R type, also known as ALOX12B, 12\"R\"-LOX, and arachiconate lipoygenase 3, is a lipoxygenase-type enzyme composed of 701 amino acids and encoded by the \"ALOX12B\" gene. The gene is located on chromosome 17 at position 13.1 where it forms a cluster with two other lipoxygenases, ALOXE3 and ALOX15B. Among the human lipoxygenases, ALOX12B is most closely (54% identity) related in amino acid sequence to ALOXE3\n\nALOX12B oxygenates arachidonic acid by adding molecular oxygen (O) in the form of a hydroperoxyl (HO) residue to its 12th carbon thereby forming 12(\"R\")-hydroperoxy-5\"Z\",8\"Z\",10\"E\",14\"Z\"-icosatetraenoic acid (also termed 12(\"R\")-HpETE or 12\"R\"-HpETE). When formed in cells, 12\"R\"-HpETE may be quickly reduced to its hydroxyl analog (OH), 12(\"R\")-hydroxy-5\"'Z\",8\"Z\",10\"E\",14\"Z\"-eicosatetraenoic acid (also termed 12(\"R\")-HETE or 12\"R\"-HETE), by ubiquitous peroxidase-type enzymes. These sequential metabolic reactions are:\narachidonic acid + O formula_1 12\"R\"-HpETE → 12\"R\"-HETE\n12\"R\"-HETE stimulates animal and human neutrophil chemotaxis and other responses in vitro and is able to elicit inflammatory responses when injected into the skin of an animal model However, the production of 12\"R\"-HETE for this or other purposes may not be primary function of ALOX12B.\n\nALOX12B is also capable of metabolizing free linoleic acid to 9(\"R\")-hydroperoxy-10(E),12(Z)-octadecadienoic acid (9\"R\"-HpODE) which is also rapidly converted to its hydroxyl derivative, 9-Hydroxyoctadecadienoic acid (9\"R\"-HODE).\nLinoleic acid + O formula_1 9\"R\"-HpODE → 9\"R\"-HODE\nThe \"S\" stereoisomer of 9\"R\"-HODE, 9\"S\"-HODE, has a range of biological activities related to oxidative stress and pain perception (see 9-Hydroxyoctadecadienoic acid. It is known or likely that 9\"R\"-HODE possesses at least some of these activities. For example, 9\"R\"-HODE, similar to 9\"S\"-HODE, mediates the perception of acute and chronic pain induced by heat, UV light, and inflammation in the skin of rodents (see 9-Hydroxyoctadecadienoic acid#9-HODEs as mediators of pain perception). However, production of these LA metabolites does not appear to be the primary function of ALOX12B; ALOX12B's primary function appears to be to metabolize linoleic acid that is not free but rather esterified to certain \n\nALOX12B targets Linoleic acid (LA). LA is the most abundant fatty acid in the skin epidermis, being present mainly esterified to the omega-hydroxyl residue of amide-linked omega-hydroxylated very long chain fatty acids (VLCFAs) in a unique class of ceramides termed esterified omega-hydroxyacyl-sphingosine (EOS). EOS is an intermediate component in a proposed multi-step metabolic pathway which delivers VLCFAs to the cornified lipid envelop in the skin's Stratum corneum; the presence of these wax-like, hydrophobic VLCFAs is needed to maintain the skin's integrity and functionality as a water barrier (see Lung microbiome#Role of the epithelial barrier). ALOX12B metabolizes the LA in EOS to its 9-hydroperoxy derivative; ALOXE3 then converts this derivative to three products: a) 9\"R\",10\"R\"-trans-epoxide,13\"R\"-hydroxy-10\"E\"-octadecenoic acid, b) 9-keto-10\"E\",12\"Z\"-octadecadienoic acid, and c) 9\"R\",10\"R\"-trans-epoxy-13-keto-11\"E\"-octadecenoic acid. These ALOX12B-oxidized products signal for the hydrolysis (i.e. removal) of the oxidized products from EOS; this allows the multi-step metabolic pathway to proceed in delivering the VLCFAs to the cornified lipid envelop in the skin's Stratum corneum.\n\nALOX12B protein has been detected in humans that in the same tissues the express ALOXE3 and ALOX15B viz., upper layers of the human skin and tongue and in tonsils. mRNA for it has been detected in additional tissues such as the lung, testis, adrenal gland, ovary, prostate, and skin with lower abundance levels detected in salivary and thyroid glands, pancreas, brain, and plasma blood leukocytes.\n\nDeletions of \"Alox12b\" or \"AloxE2\" genes in mice cause a congenital scaly skin disease which is characterized by a greatly reduced skin water barrier function and is similar in other ways to the autosomal recessive nonbullous Congenital ichthyosiform erythroderma (ARCI) disease of humans. Mutations in many of the genes that encode proteins, including ALOX12B and ALOXE3, which conduct the steps that bring and then bind VLCFA to the stratums corneum are associated with ARCI. ARCI refers to nonsyndromic (i.e. not associated with other signs or symptoms) congenital Ichthyosis including Harlequin-type ichthyosis, Lamellar ichthyosis, and Congenital ichthyosiform erythroderma. ARCI has an incidence of about 1/200,000 in European and North American populations; 40 different mutations in \"ALOX12B\" and 13 different mutations in \"ALOXE3\" genes account for a total of about 10% of ARCI case; these mutations uniformly cause a total loss of ALOX12B or ALOXE3 function (see mutations).\n\nIn psoriasis and other proliferative skin diseases such as the Erythrodermas underlying lung cancer, cutaneous T cell lymphoma, and drug reactions, and in Discoid lupus, Seborrheic dermatitis, Subacute Cutaneous lupus erythematosus, and Pemphigus foliaceus, cutaneous levels of ALOX12B mRNA and 12\"R\"-HETE are greatly increased. It is not clear if these increases contribute to the disease by, for example, 12\"R\"-HETE induction of inflammation, or are primarily a consequence of skin proliferation.\n\nThe expression of Alox12b and Aloxe3 mRNA in mice parallels, and is proposed to be instrumental for, skin development in mice embryogenesis; the human orthologs of these genes, i.e. ALOX12B and ALOXE3, may have a similar role in humans.\n\nSevere dietary deficiency of polyunsaturated omega 6 fatty acids leads to the essential fatty acid deficiency syndrome that is characterized by scaly skin and excessive water loss; in humans and animal models the syndrome is fully reversed by dietary omega 6 fatty acids, particularly linoleic acid. It is proposed that this deficiency disease resembles and has a similar basis to Congenital ichthyosiform erythrodema; that is, it is at least in part due to a deficiency of linoleic acid and thereby in the EOS-based delivery of VLCFA to the stratum corneum.\n\n", "id": "15031355", "title": "ALOX12B"}
{"url": "https://en.wikipedia.org/wiki?curid=49854427", "text": "Epoxyeicosatetraenoic acid\n\nEpoxyeicosatetraenoic acids (EEQs or EpETEs) are a set of biologically active epoxides that various cell types make by metabolizing the omega 3 fatty acid, eicosapentaenoic acid (EPA), with certain cytochrome P450 epoxygenases. These epoxygenases can metabolize EPA to as many as 10 epoxides that differ in the site and/or stereoisomer of the epoxide formed; however, the formed EEQs, while differing in potency, often have similar bioactivities and are commonly considered together.\n\nEPA is a straight-chain, 20 carbon omega-3 fatty acid containing cis (see Cis–trans isomerism) double bounds between carbons 5 and 6, 8 and 9, 11 and 12, 14 and 15, and 17 and 18; each of these double bonds is designated with the notation \"Z\" to indicate its cis configuration in the IUPAC Chemical nomenclature used here. EPA is therefore 5\"Z\",8\"Z\",11\"Z\",14\"Z\",17\"Z\"-eicosapentaenoic acid. Certain cytochrome P450 epoxygenases metabolize EPA by converting one of these double bounds to an epoxide thereby forming one of 5 possible eicosatetraenoic acid epoxide regioisomers (see Structural isomer, section on position isomerism (regioisomerism)). These regioisomers are: 5,6-EEQ (i.e. 5,6-epoxy-8\"Z\",11\"Z\",14\"Z\",17\"Z\"-eicosatetraenoic acid), 8,9-EEQ (i.e. 8,9-epoxy-5\"Z\",11\"Z\",14\"Z\",17\"Z\"-eicosatetraenoic acid), 11,12-EEQ (i.e. 11,12-epoxy-5\"Z\",8\"Z\",14\"Z\",17\"Z\"-eicosatetraenoic acid), 14,15-EEQ (i.e. 14,15-epoxy-5\"Z\",8\"Z\",11\"Z\",17\"Z\"-eicosatetraenoic acid, and 17,18-EEQ (i.e. 17,18-epoxy-5\"Z\",8\"Z\",11\"Z\",14\"Z\"-eicosatetraenoic acid. The epoxydases typically make both \"R\"/\"S\" enantiomers of each epoxide. For example, they metabolize EPA at its 17,18 double bond to a mixture of 17\"R\",18\"S\"-EEQ and 17\"S\",18\"R\"-EEQ. The EEQ products therefore consist of as many as 10 isomers.\n\nCellular cytochrome P450 epoxygenases metabolize various polyunsaturated fatty acids to epoxide-containng products. They metabolize the omega-6 fatty acids arachidonic acid, which possess four double bonds, to 8 different epoxide isomers which are termed epoxyeicosatrienoic acids or EETs and linoleic acid, which possess two double bonds, to 4 different epoxide isomers, i.e. two different 9,10-epoxide isomers termed vernolic acids or leukotoxins and two different 12,13-epoxides isomers termed coronaric acids or isoleukotoxins. They metabolize the omega-3 fatty acid, docosahexaenoic acid, which possesses 6 double bonds, to 12 different epoxydocosapentaenoic acid (EDPs) isomers. In general, the same epoxygenases that accomplish these metabolic conversions also metabolize the omega-6 fatty acid, EPA, to 10 epoxide isomers, the EEQs. These epoxygenases fall into several subfamilies including the cytochrome P4501A (i.e.CYP1A), CYP2B, CYP2C, CYP2E, and CYP2J subfamilies, and within the CYP3A subfamily, CYP3A4. In humans, CYP1A1, CYP1A2, CYP2C8, CYP2C9, CYP2C18, CYP2C19, CYP2E1, CYP2J2, CYP3A4, and CYP2S1 metabolize EPA to EEQs, in most cases forming principally 17,18-EEQ with smaller amounts of 5,6-EEQ, 8,9-EEQ, 11,12-EEQ, and 14,15-EEQ isomers. However, CYP2C11, CYP2C18, and CYP2S1 also form 14,15-EEQ isomers while CYP2C19 also forms 11,12-EEQ isomers. The isomers formed by these CYPs vary greatly with, for example, the 17,18-EEQs made by CYP1A2 consisting of 17\"R\",18\"S\"-EEQ but no detectable 17\"S\",18\"R\"-EEQ and those made by CYP2D6 consisting principally of 17\"R\",18\"S\"-EEQ with far smaller amounts of 17\"S\",18\"R\"-EEQ. In addition to the cited CYP's, CYP4A11, CYP4F8, CYP4F12, CYP1A1, CYP1A2, and CYP2E1, which are classified as CYP monooxygenase rather than CYP epoxygeanses because they metablize arachidonic acid to monohydroxy eicosatetraenoic acid products (see 20-Hydroxyeicosatetraenoic acid), i.e. 19-hydroxyhydroxyeicosatetraenoic acid and/or 20-hydroxyeicosatetranoic acid, take on epoxygease activity in converting EPA primarily to 17,18-EEQ isomers (see epoxyeicosatrienoic acid). 5,6-EEQ isomers are generally either not formed or formed in undetectable amounts while 8,9-EEQ isomers are formed in relatively small amounts by the cited CYPs. The EET-forming CYP epoxygenases often metabolize EPA to EEQs (as well as DHA to EDPs) at rates that exceed their rates in metabolizing arachidonic acid to EETs; that is, EPA (and DHA) appear to be preferred over arachidonic acid as substrates for many CYP epoxygenases.\n\nThe EEQ-forming cytochromes are widely distributed in the tissues of humans and other mammals, including blood vessel endothelium, blood vessel atheroma placques, heart muscle, kidneys, pancreas, intestine, lung, brain, monocytes, and macrophages. These tissues are known to metabolize arachidonic acid to EETs; it has been shown or is presumed that they also metabolize EPA to EEQs. Note, however, that the CYP epoxygenases, similar to essentially all CYP450 enzymes, are involved in the metabolism of xenobiotics as well as endogenously-formed compounds; since many of these same compounds also induce increases in the levels of the epoxygenases, CYP oxygenase levels and consequently EEQ levels in humans vary widely and are highly dependent on recent consumption history; numerous other factors, including individual genetic differences, also contribute to the variability in CYP450 epoxygenase expression.\n\nIn cells, EEQs are rapidly metabolized by the same enzyme that similarly metabolizes other epoxy fatty acids including the EETs viz., cytosolic soluble epoxide hydrolase [EC 3.2.2.10.] (also termed sEH or the EPHX2), to form their corresponding Vicinal (chemistry) diol dihydroxyeicosatetraenoic acids (diHETEs). The omega-3 fatty acid epoxides, EEQs and EPAs, appear to be preferred over EETs as substates for sEH. sEH converts 17,18-EEQ isomers to 17,18-dihydroxy-eicosatrienoic acid isomers (17,18-diHETEs), 14,15-EEQ isomers to 14,15-diHETE isomers, 11,12-EEQ isomers to 11,12-diHETE isomers, 8,9-EEQ isomers to 8,9-diHETE isomers, and 5,6-EEQ isomers to 5,6-diHETE isomers. The product diHETEs, like their epoxy precursors, are enantiomer mixtures; for instance, sEH converts 17,18-EEQ to a mixture of 17(\"S\"),19(\"R\")-diHETE and 17(\"R\"),18(\"S\")-diHETE. Since the diHETE products are as a rule generally far less active than their epoxide precursors, the sEH pathway of EET metabolism is regarded as a critical EEQ-inactivating pathway.\n\nMembrane-bound Microsomal epoxide hydrolase (mEH or Epoxide hydrolase 2 [EC 3.2.2.9.]) can metabolize EEQs to their dihydroxy products but is regarded as not contributing significantly to EEQ inactivation in vivo except possibly in rare tissues where the sEH level is exceptionally low while the mEH level is high.\n\nIn addition to the sEH pathway, EETs may be acylated into phospholipids in an Acylation-like reaction. This pathway may serve to limit the action of EETs or store them for future release. EETs are also inactivated by being further metabolized though three other pathways: Beta oxidation, Omega oxidation, and elongation by enzymes involved in Fatty acid synthesis.\n\nEEQS, similar to EDPs, have not be studied nearly as well as the EETs. In comparison to the many activities attributed to the EETs in animal model studies (see Epoxyeicosatrienoic acid), a limited set of studies indicate that EEQs (and EPAs) mimic EETS in their abilities to dilate arterioles, reduce hypertension, inhibit inflammation (the anti-inflammatory actions of EEQ are less potent than those of the EETs) and thereby reduce occlusion of arteries to protect the heart and prevent and strokes (see Epoxyeicosatrienoic acid#Clinical significance sections on a) Regulation of blood pressure, b) Heart disease, c) Strokes and seizures, and d) inflammation); they also mimic EETs in possessing analgesia properties in relieving certain types of pain (see Epoxyeicosatrienoic acid#Clinical significance#Pain). Often, the EEQs (and EPAs) exhibit greater potency and/or effectiveness than EET in these actions. In human studies potentially relevant to one or more of these activities, consumption of long chain omega-3 fatty acid (i.e. EPA- and DHA-rich) diet produced significant reductions in systolic blood pressure and increased peripheral arteriole blood flow and reactivity in patients at high to intermediate risk for cardiovascular events; an EPA/DHA-rich diet also reduced the risk while high serum levels of DHA and EPA were associated with a low risk of neovascular age-related macular degeneration. Since such diets lead to large increases in the serum and urine levels of EPAs, EEQs, and the dihydoxy metabolites of these epoxides but relatively little or no increases in EETs or lipoxygenase/cyclooxygenase-producing metabolites of arachidonic acid, DHA, and/or EEQs, it is suggested that the diet-induced increases in EPAs and/or EEQs are responsible for this beneficial effects. In direct contrast to the EETs which have stimulating effects in the following activities (see Epoxyeicosatrienoic acid#Cancer, EEQs (and EPAs) inhibit new blood vessel formation (i.e. angiogenesis), human tumor cell growth, and human tumor metastasis in animal models implanted with certain types of human cancer cells. The possible beneficial effects of omega-3 fatty acid-rich diets in pathological states involving inflammation, hypertension, blood clotting, heart attacks and other cardiac diseases, strokes, brain seizures, pain perception, acute kidney injury, and cancer are suggested to result, at least in part, from the conversion of dietary EPA and DHA to EEQs and EPAs, respectively, and the cited subsequent actions of these metabolites.\n", "id": "49854427", "title": "Epoxyeicosatetraenoic acid"}
{"url": "https://en.wikipedia.org/wiki?curid=7282499", "text": "Surface-area-to-volume ratio\n\nThe surface-area-to-volume ratio, also called the surface-to-volume ratio and variously denoted sa/vol or SA:V, is the amount of surface area per unit volume of an object or collection of objects.\nIn chemical reactions involving a solid material, the surface area to volume ratio is an important factor for the reactivity, that is, the rate at which the chemical reaction will proceed.\n\nFor a given volume, the object with the smallest surface area (and therefore with the smallest SA:V) is the sphere, a consequence of the isoperimetric inequality in 3 dimensions. By contrast, objects with tiny spikes will have very large surface area for a given volume.\n\nThe surface-area-to-volume ratio has physical dimension L (inverse length) and is therefore expressed in units of inverse distance. As an example, a cube with sides of length 1 cm will have a surface area of 6 cm and a volume of 1 cm. The surface to volume ratio for this cube is thus\n\nFor a given shape, SA:V is inversely proportional to size. A cube 2 cm on a side has a ratio of 3 cm, half that of a cube 1 cm on a side. Conversely, preserving SA:V as size increases requires changing to a less compact shape.\n\nMaterials with high surface area to volume ratio (e.g. very small diameter, very porous, or otherwise not compact) react at much faster rates than monolithic materials, because more surface is available to react. Examples include grain dust; while grain isn't typically flammable, grain dust is explosive. Finely ground salt dissolves much more quickly than coarse salt.\n\nHigh surface area to volume ratio provides a strong \"driving force\" to speed up thermodynamic processes that minimize free energy.\n\nThe ratio between the surface area and volume of cells and organisms has an enormous impact on their biology (the physiology, behavior, and other qualities of a particular organism or class of organisms). For example, many aquatic microorganisms have increased surface area to increase their drag in the water. This reduces their rate of sink and allows them to remain near the surface with less energy expenditure.\n\nAn increased surface area to volume ratio also means increased exposure to the environment. The many tentacles of jellyfish and anemones are the result of increased surface area for the acquisition of food. Greater surface area allows more of the surrounding water to be sifted for food.\n\nIndividual organs in animals are often based on the principle of greater surface area. The lung is an organ with numerous internal branchings that increase the surface area through which oxygen is passed into the blood and carbon dioxide is released from the blood. The intestine has a finely wrinkled internal surface, increasing the area through which nutrients are absorbed by the body. This is done to increase the surface area in which diffusion of oxygen and carbon dioxide in the lungs and diffusion of nutrients in villi of the small intestine can occur.\n\nCells can achieve a high surface area to volume ratio by being long and thin (nerve cells) or convoluted (microvilli)\n\nIncreased surface area can also lead to biological problems. More contact with the environment through the surface of a cell or an organ (relative to its volume) increases loss of water and dissolved substances. High surface area to volume ratios also present problems of temperature control in unfavorable environments.\n\nThe surface to volume ratios of organisms of different sizes also leads to some observations in biogeography such as Bergmann's rule.\n\nIn the context of wildfires, the ratio of the surface area of a solid fuel to its volume is an important measurement. Fire spread behavior is frequently correlated to the surface-area-to-volume ratio of the fuel (e.g. leaves and branches). The higher its value, the faster a particle responds to changes in environmental conditions, such as temperature or moisture. Higher values are also correlated to shorter fuel ignition times, and hence faster fire spread rates.\n\n\n\n\n", "id": "7282499", "title": "Surface-area-to-volume ratio"}
{"url": "https://en.wikipedia.org/wiki?curid=391141", "text": "Basophil\n\nBasophils are a type of white blood cells. Basophils are the least common of the granulocytes, representing about 0.5 to 1% of circulating white blood cells. However, they are the largest type of granulocyte. They are responsible for inflammatory reactions during immune response, as well as in the formation of acute and chronic allergic diseases, including anaphylaxis, asthma, atopic dermatitis and hay fever. They can perform phagocytosis (cell eating), produce histamine and serotonin that induce inflammation, and heparin that prevents blood clotting. It used to be thought that basophils that have migrated from blood into their resident tissues (connective tissue) are known as mast cells, but this is no longer thought to be the case.\n\nBasophils were discovered in 1879 by German physician Paul Ehrlich, who one year earlier had found a cell type present in tissues that he termed \"mastzellen\" (now mast cells). Ehrlich received the 1908 Nobel Prize in Physiology or Medicine for his discoveries.\n\nThe name comes from the fact that these leukocytes are basophilic, i.e., they are susceptible to staining by basic dyes, as shown in the picture.\n\nBasophils contain large cytoplasmic granules which obscure the cell nucleus under the microscope when stained. However, when unstained, the nucleus is visible and it usually has two lobes. The mast cell, another granulocyte, is similar in appearance and function. Both cell types store histamine, a chemical that is secreted by the cells when stimulated. However, they arise from different branches of hematopoiesis, and mast cells usually do not circulate in the blood stream, but instead are located in connective tissue. Like all circulating granulocytes, basophils can be recruited out of the blood into a tissue when needed.\n\nBasophils appear in many specific kinds of inflammatory reactions, particularly those that cause allergic symptoms. Basophils contain anticoagulant heparin, which prevents blood from clotting too quickly. They also contain the vasodilator histamine, which promotes blood flow to tissues. They can be found in unusually high numbers at sites of ectoparasite infection, e.g., ticks. Like eosinophils, basophils play a role in both parasitic infections and allergies. They are found in tissues where allergic reactions are occurring and probably contribute to the severity of these reactions. Basophils have protein receptors on their cell surface that bind IgE, an immunoglobulin involved in macroparasite defense and allergy. It is the bound IgE antibody that confers a selective response of these cells to environmental substances, for example, pollen proteins or helminth antigens. Recent studies in mice suggest that basophils may also regulate the behavior of T cells and mediate the magnitude of the secondary immune response.\n\nBasophil function is inhibited by CD200. Herpesvirus-6, herpesvirus-7, and herpesvirus-8 produce a CD200 homolog which also inhibits basophil function. This suggests that basophils may play a role in the immune response to these viruses.\n\nBasophils of mice and humans have consistent immunophenotypes, including FcεRI, CD123, CD49b(DX-5), CD69, Thy-1.2, 2B4, CD11b, CD117(c-kit), CD24, CD19, CD80, CD14, CD23, Ly49c, CD122, CD11c, Gr-1, NK1.1, B220, CD3, γδTCR, αβTCR, α and β-integrin negative.\n\nRecently, Heneberg proposed that basophils may be defined as the cellular population positive for CD13, CD44, CD54, CD63, CD69, CD107a, CD123, CD164, CD193/ CCR3, CD203c, TLR-4, and FcεRI. When activated, some additional surface markers are known to be upregulated (CD13, CD107a, CD164), or surface-exposed (CD63, and the ectoenzyme CD203c).\n\nBasophils arise and mature in bone marrow. When activated, basophils degranulate to release histamine, proteoglycans (e.g. heparin and chondroitin), and proteolytic enzymes (e.g. elastase and lysophospholipase). They also secrete lipid mediators like leukotrienes (LTD-4), and several cytokines. Histamine and proteoglycans are pre-stored in the cell's granules while the other secreted substances are newly generated. Each of these substances contributes to inflammation. Recent evidence suggests that basophils are an important source of the cytokine, interleukin-4, perhaps more important than T cells. Interleukin-4 is considered one of the critical cytokines in the development of allergies and the production of IgE antibody by the immune system. There are other substances that can activate basophils to secrete which suggests that these cells have other roles in inflammation.\n\nThe degranulation of basophils can be investigated \"in vitro\" by using flow cytometry and the so-called basophil-activation-test (BAT). Especially, in the diagnosis of allergies including of drug reactions (e.g. induced by contrast medium), the BAT is of great impact.\n\nBasopenia (a low basophil count) is difficult to demonstrate as the normal basophil count is so low; it has been reported in association with autoimmune urticaria (a chronic itching condition). Basophilia is also uncommon but may be seen in some forms of leukaemia or lymphoma.\n\nThe word \"basophil\" () uses combining forms of \"baso-\" + \"-phil\", yielding \"base-loving\".\n\n", "id": "391141", "title": "Basophil"}
{"url": "https://en.wikipedia.org/wiki?curid=50275875", "text": "Ehrlich ascites carcinoma\n\nEhrlich-Lettre ascites carcinoma (EAC) is also known as Ehrlich cell. It was originally established as an ascites tumor in mice.\n\nThe tumor was cultured \"in vivo\", which became known as the Ehrlich cell. After 1948 Ehrlich cultures spread around research institutes all over the world. The Ehrlich cell became popular because it could be expanded by \"in vivo\" passage. This made it useful for biochemical studies involving large amounts of tissues. It could also be maintained \"in vitro\" for more carefully controlled studies. Culture techniques in large-scale, mice passage is less attractive, due to the contamination of the tumor with multifarious host inflammatory cells.\n\nEAC is referred to as undifferentiated carcinoma, and is originally hyper-diploid. The permeability to water is highest at the initiation of S and progressively decreases to its lowest value just after mitosis. Activation heats for water permeability vary during the cell cycle, ranging from 9–14 kca/mole.\n\n", "id": "50275875", "title": "Ehrlich ascites carcinoma"}
{"url": "https://en.wikipedia.org/wiki?curid=50311973", "text": "Microfluidic cell culture\n\nMicrofluidics refers to a set of technologies for the manipulation for the small fluid volumes within artificially fabricated microsystems.And cell culture refers to the maintenance and growth of cells in a controlled laboratory environment. Cells are cooperatively regulated by numerous signals in their surrounding microenvironment. Microfluidic cell culture attempts to develop devices and techniques of culturing, maintaining, analyzing and experimenting in cells in micro scale volumes and facilitate simultaneous manipulation and analysis of cultured cells.The use of integrated microfluidic devices has advanced the fields of quantitative and systems in biology. Understanding the interplay between critical cell culture parameters and the micro environmental conditions created by microfluidic devices will accelerate the microfluid cell culture technology. The dimensions of the microfuidic channels are well suited to the physical scale of the biological cells.\n\nMicrofluidics provide high degree control over cell culture conditions in various aspects. Given the small geometrical dimensions in microfluidics, the movements of fluids is laminar, and placement of fluid volumes in the nL-range, pL-range and even n fL-range is possible.The ability of exactly timing fluid flow using in-chip membrane valve allows precise chemical and physical control of the microenvironment.The small dimensions of spatially separated microfluid compartments allow assembly of a multitude of individually controllable cell culture chambers on a single device.Stem cells that are difficult to culture with conventional techniques can be expanded relatively rapidly in microfluidic culture.Non-dividing or slowly dividing cells can be culture continuously in the same cell culture chamber by regular or constant replacement of media. There are some advantages of microfluidic culture over macroscopic culture.That is in culture in flasks, dishes and well plates.There is great flexibility in the design of micro fluidic devices.\n\n", "id": "50311973", "title": "Microfluidic cell culture"}
{"url": "https://en.wikipedia.org/wiki?curid=50285278", "text": "Polycomb recruitment in X chromosome inactivation\n\nRecruitment of Polycomb proteins in X chromosome Inactivation\n\nX chromosome inactivation (XCI) is the phenomenon that has been selected during the evolution to balance X-linked gene dosage between XX females and XY males. XCI is usually divided in two phases, the establishment phase when gene silencing is reversible, and maintenance phase when gene silencing becomes irreversible. During the establishment phase of X Chromosome Inactivation (XCI), Xist RNA, the master regulator of this process, spreads \"in cis\" along the future inactive X (Xi) and recruits repressive chromatin-remodelling complexes. Among these, Xist recruits proteins of the Polycomb repressive complexes. Whether Xist directly recruits Polycomb repressive complex 2 (PRC2) to the chromatin or this recruitment is the consequence of Xist-mediated changes on the chromatin has been object of intense debate. Among recent analyses of Xist interacting proteins, at least one study demonstrated that two subunits of PRC2 are interacting proteins by mass spectrometry. Biochemical studies have also shown that PRC2 binds the A-repeat of Xist RNA directly and with very high affinity (dissociation constants of 10-100 nanomolar), supporting Xist-mediated recruitment of PRC2 to the X chromosome. Failure to turn up PRC2 proteins in function screens may be due to cells not being able to survive or compete without PRC2 or incomplete screens. Two super resolution microscopy analyses have presented different views from each other. One showed that Xist and PRC2 are spatially separated, while another showed that Xist and PRC2 are tightly linked. It is possible that several mechanisms recruit PRC2 together, including Xist RNA, an adaptor protein, chromatin changes, RNA pol II exclusion, or PRC1 recruitment. More studies are needed.\n", "id": "50285278", "title": "Polycomb recruitment in X chromosome inactivation"}
{"url": "https://en.wikipedia.org/wiki?curid=50374225", "text": "Epoxide hydrolase 3\n\nEpoxide hydrolase 3 (ABHD9, EH3, EPHX3), encoded by the \"EPHX3\" gene, is the third defined isozyme in a set of epoxide hydrolase isozymes, i.e. the epoxide hydrolases. This set includes the Microsomal epoxide hydrolase (also termed epoxide hydrolase 1, EPHX1, mEH, and EH1); the epoxide hydrolase 2 (also termed soluble epoxide hydrolase, EPHX2, sEH and EH2); and the far less well defined enzymatically, epoxide hydrolase 4 (also termed ABHD7 and EH4). All four enzyme contain an Alpha/beta hydrolase fold suggesting that they have Hydrolysis activity. EH1, EH2, and EH3 have been shown to have such activity in that they add water to epoxides of unsaturated fatty acids to form vicinal cis (see cis-trans isomerism) products; the activity of EH4 has not been reported. The former three EH's differ in subcellular location, tissue expression patterns, substrate preferences, and thereby functions. These functions include limiting the biologically actions of certain fatty acid epoxides, increasing the toxicity of other fatty acid epoxides, and contributing to the metabolism of drugs and other xenobiotics.\n\nEH3 was first named ABHD9 owing to its possession of a particular Protein domain, the Alpha/beta hydrolase fold or α/β hydrolase fold domain. This domain is found in more than 30 other human hydrolytic enzymes including the four epoxide hydrolases. The gene for EH3 (\"EPHX3\") was discovered on chromosome locus 19p13.13 in sequencing the human.genome Based on its amino acid sequence, it was projected to encode a protein with an α/β hydrolase fold domain; the encoded protein was therefore dubbed ABHD9. Some 10 years later, ABHD9 was defined to possess the ability to hydrolyze certain fatty acid epoxides.\n\nSimilar to mEH but unlike sEH, EH3 is membrane-bound enzyme. Based on the expression of its mRNA in mouse tissue, EH3 has a very different distribution than mEH or sEH: EH3 expression is high in skin, lung, tongue, esophagus, and stomach; intermediate in pancreas and eye, visceral fat, lymph nodes, spleen, aortic arch, and heart; low in liver, kidney, testis, ovary intestine, and brain; and very low in skeletal muscle. Its expression in human tissues has not yet been reported.\n\nABHD9 first drew attention is studies that validated that its gene, EPHX3, was hypermethylated on CpG sites in its Promoter (genetics) in human prostate cancer tissues, particularly in the tissues of more advanced or, base on morphological criteria (i.e. Gleason score), more aggressive diseases. This allows that the gene silencing of EPHX3 due to promoter hypermethylation may contribute to the onset and/or progression of prostate cancer. Similar CpG site hypermethylations in the promoter of EPHX3 have been validated for colorectal adenocarcinomas. As similar promoter methylation pattern, although not yet validated, was also found in human malignant melanoma tissues and human gastric cancer cell lines. These studies allow but certainly do not prove that the silencing of EPHX (i.e. failure to be expressed as ABHD9 protein) is involved in the development and/or progression of certain cancers in humans.\n\nMore recently, ABHD9 was characterized as possessing epoxy hydrolase activity for metabolizing epoxyeicosatrienoic acids (EETs) and epoxides of linoleic acid (i.e. vernolic acids [also termed leukotoxins] to their corresponding diols. For example, it metabolizes one particular EET (14,15-epoxy-5Z,8Z,11Z-eicosatrienoic acid) as follows:\n14,15-epoxy-5\"Z\",8\"Z\",11\"Z\"-eicosatrienoic acid + HO → 14,15-dihydroxy-5\"Z\",8\"Z\",11\"Z\"-eicosatrienoic acid\nIn this particular reaction, the enzyme inactivates the EET and thereby may function to limit the biological activity of this as well as the other EETs upon which it acts in, for example, regulating blood pressure (see epoxyeicosatrienoic acids. In its hydrolysis one isomer of vernolic acid (12S,13R-epoxy-cis-9-octadecenoic acid)\n12\"S\",13\"R\"-epoxy-cis-9-octadecenoic acid + HO → 12\"S\",13\"R\"-dihydroxy-9\"Z\"-octadecenoic acids \nto a diol, however, the enzyme increases its toxicity in, for example, contributing to acute respiratory distress syndromes (see vernolic acid). The enzyme thereby may function to limit the cell signaling activity of the EETs yet contribute to the toxic actions of linoleic acid epoxides.\n\nWhile mEH and to a lesser extent sEH metabolize drugs, foreign toxic chemicals, and certain endogenous compounds that are not simple fatty acids (see Microsomal epoxide hydrolase and epoxide hydrolase 2), the activity of EH3 on such substrates, while likely, has not yet been reported.\n", "id": "50374225", "title": "Epoxide hydrolase 3"}
{"url": "https://en.wikipedia.org/wiki?curid=50406738", "text": "Cellular dewetting\n\nCellular dewetting refers to the process of nucleation and enlargement of transendothelial cell macroaperture (TEM) tunnels in endothelial cells (Figure 1). This phenomenon is analogous to the nucleation and growth of dry patches in viscous liquids spreading on a non-wettable substrate (Figure 2). Cellular dewetting is triggered by several protein toxins from pathogenic bacteria, notably the EDIN-like factors from \"Staphylococcus aureus\" and from \"Clostridium botulinum\", as well as edema toxin from \"Bacillus anthracis\". TEMs form in response to the rupture of cytoskeleton physical connections through the cytoplasm due to inhibition of the RhoA/ROCK pathway or to induction of the flux of cyclic-AMP (cAMP) broad signaling molecule.\n\nThe phenomenon of cellular dewetting can be interpreted by physical modeling (Figure 2). The driving force responsible for the spontaneous formation of TEM tunnels and their opening is the membrane tension that results from the spreading of cells due to actomyosin relaxation. Opposite to liquid dewetting, TEMs reach a maximum diameter, at which the driving force is balanced by a resisting force that develops along TEM edges (Figure 2). This resisting force is referred to as line tension and is uncharacterized at the molecular level.\n\nDriving forces pulling on a tunnel of radius \"R\", as depicted in Figure 2. Here, pulling is due to the tensioning of the cell membrane (σ) that is partly counteracted by a line tension around the tunnel (\"T\"). In these conditions, the net driving force (\"F\") consists of two contributions:\n\nformula_1\n\nDewetting proceeds if \"F\">0.\n\nMembrane tension (\"σ\") depends on the tunnel radius \"R\". A tunnel increase in size relaxes the membrane, inducing a decrease in membrane tension, as described by Helfrich’s law.\n\nLine tension (\"T\") corresponds to the resisting force along the edge of the tunnel that opposes membrane tension and limits dewetting. This line tension can have physical and molecular components.\n", "id": "50406738", "title": "Cellular dewetting"}
{"url": "https://en.wikipedia.org/wiki?curid=44358555", "text": "15-Hydroxyeicosatetraenoic acid\n\n15-Hydroxyeicosatetraenoic acid (also termed 15-HETE, 15(\"S\")-HETE, and 15\"S\"-HETE) is an eicosanoid, i.e. a metabolite of arachidonic acid. Various cell types metabolize arachidonic acid to 15(\"S\")-hydroperoxyeicosatetraenoic acid (15(\"S\")-HpETE). This initial hydroperoxide product is extremely short-lived in cells: if not otherwise metabolized, it is rapidly reduced to 15\"(S)\"-HETE. Both of these metabolites, depending on the cell type which forms them, can be further metabolized to 15-oxo-eicosatetraenoic acid (15-oxo-ETE), 5\"S\",15\"S\"-dihydroxy-eicosatetraenoic acid (5(\"S\"),15(\"S\")-diHETE), 5-oxo-15(\"S\")-hydroxyeicosatetraenoic acid (5-oxo-15(\"S\")-HETE, a subset of specialized pro-resolving mediators viz., the lipoxins, a class of pro-inflammatory mediators, the eoxins, and other products that have less well-defined activities and functions. Thus, 15(\"S\")-HETE and 15(\"S\")-HpETE, in addition to having intrinsic biological activities, are key precursors to numerous biologically active derivatives.\n\nSome cell types (e.g. platelets) metabolize arachidonic acid to the stereoisomer of 15(\"S\")-HpETE, 15(\"R\")-HpETE. Both stereoisomers may also be formed as result of the metabolism of arachidonic acid by cellular microsomes or as a result of arachidonic acid auto-oxidation. Similar to 15(\"S\"\")-HpETEs, 15(\"R\")-HpETE may be rapidly reduced to 15(\"R\")-HETE. These \"R,S\" stereoisomers differ only in having their hydroxy residue in opposite orientations. While the two \"R\" stereoisomers are sometimes referred to as 15-HpETE and 15-HETE, proper usage should identify them as \"R\" stereoisomers. 15(\"R\")-HpETE and 15(\"R\")-HETE lack some of the activity attributed to their \"S\" stereoisomers but can be further to metabolized to bioactive products viz., the 15(\"R\") class of lipoxins (also termed epi-lipoxins).\n\n15(\"S\")-HETE, 15(\"S\")-HpETE, and many of their derivative metabolites are thought to have physiologically important functions. They appear to act as hormone-like autocrine and paracrine signalling agents that are involved in regulating inflammatory and perhaps other responses. Clinically, drugs that are stable analogs, and therefor mimic the anti-inflammatory actions of the lipoxins and drugs that block the production or actions of the pro-inflammatory eoxins may prove useful for treating acute and chronic inflammatory disorders.\n\n15(\"S\")-HETE is unambiguously designated by a shortened version of its IUPAC name viz., 15(\"S\")-hydroxy-5\"Z\",8\"Z\",11\"Z\",13\"E\"-eicosatetraenoic acid. In this terminology \"S\" refers to the absolute configuration of the chirality of the hydroxy functional group at carbon position 15. Its 15(\"R\") enantiomer is designated 15(\"R\")-hydroxy-5\"Z\",8\"Z\",11\"Z\",13\"E\"-eicosatetraenoic acid. \"Z\" and \"E\" give the cis–trans isomerism about each double bond moiety at carbon positions 5, 8, 11, and 13 with Z indicating cis and E indicating trans isomerism. Both stereoisomers are produced from their corresponding \"S\" and \"R\" 15-HpETE stereoisomers, i.e. 15(\"S\")-hydroperoxy-5\"Z\",8\"Z\",11\"Z\",13\"E\"-eicosatetraenoic acid (15(S)-HpETE) and (15\"R\")-hydroperoxy-5\"Z\",8\"Z\",11\"Z\",13\"E\"-eicosatetraenoic acid (15(R)-HpETE).\n\nHuman cells release arachidonic acid (i.e. 5\"Z\",8\"Z\",11\"Z\",14\"Z\"-eicosatetraenoic acid) from its storage site in phospholipids by reactions that involve phospholipase C and/or lipase enzymes. This release is stimulated or enhanced by cell stimulation. The freed arachidonic acid is then converted to 15-hydroperoxy/hydroxy products by one or more of the following five pathways.\n\n15-Lipoxygenase-1: Cells metabolize arachidonic acid with 15-lipoxygenase-1 (i.e., 15-LO-1, ALOX15) to form 15(\"S\")-HpETE as a major product and 12(\"S\")-hydroperoxy-5\"Z\",8\"Z\",10\"E\",15\"Z\"-eicosatetraenoic acid (12(\"S\")-HpETE) and 14(\"S\"),15(\"S\")-\"trans\"-oxido-5\"Z\",8\"Z\",11\"Z\"-14,15-leukotriene A4 as minor products; 15(\"S\")-HpETE and 12(\"S\")-HpETE are rapidly converted to 15(\"S\")-HETE and 12(\"S\")-hydroxy-5\"Z\",8\"Z\",10\"E\",15\"Z\"-eicosatetraenoic acid (12(\"S\")-hydroxyeicosatetraenoic acid), (i.e. 12(\"S\")-HETE), respectively, or further metabolized through other enzyme pathways; 14(\"S\"),15(\"S\")-\"trans\"-oxido-5\"Z\",8\"Z\",11\"Z\"-14,15-leukotriene A is metabolized by 15-LO-1 to various isomers of 8,15(\"S\")-dihydroxy-5\"S\",8\"S\",\"11Z\",13\"S\"-eicosatetraenoic acids, e.g. 8,15(S)-LTB's.\n\n15-Lipooxygenase-2: Cells also used 15-lipoxygenase 2 (i.e. 15-LOX-2 or ALOX15B) to make 15(\"S\")-HpETE and 15(\"S\")-HETE. However this enzyme has a preference for metabolizing linoleic acid rather than arachidonic acid. It therefore forms linoleic acid metabolites (e.g. 13-hydoxyperoxy/hydroxy-octadecadienoic and 9-hydroperoxy/hydroxyl-octadecadienoic acids) in greater amounts than 15(\"S\")-HpETE and 15(\"S\")-HETE. 15-LOX-2 also differs from 15-LOX-1 in that it does not make 12(\"S\")-HpETE or the leukotriene A isomer cited above.\n\nCycloxygenase: Cells can use prostaglandin-endoperoxide synthase 1 (i.e. cyclooxygenenase-1 or COX-1) and Prostaglandin-endoperoxide synthase 2 (COX-2) to metabolize arachidonic acid primarily to prostaglandins but also to small amounts of 11(\"R\")-HETE and a racemic mixture of 15-HETEs composed of ~22% 15(\"R\")-HETE and ~78% 15(\"S\")-HETE. When pretreated with aspirin, however, COX-1 is inactive while COX-2 attacks arachidonic acid to produce almost exclusively 15(\"R\")-HETE along with its presumed precursor 15(\"R\")-HpETE.\n\nMicrosome metabolism: Human and rat microsomal cytochrome P450s, e.g. CYP2C19, metabolize arachidonic acid to a racemic mixture of 15-HETEs, i.e., 15(\"R\",\"S\")-HETEs, >90% of which is the 15(\"R\") stereoisomer.\n\nAutoxidation: The spontaneous and non-enzymatically-induced autoxidation of arachidonic acid yields 15(\"R\",\"S\")-hydroperoxy-5\"Z\",8\"Z\",11\"Z\",13\"E\"-eicosatetraenoic acids. This non-enzymatic reaction is promoted in cells undergoing oxidative stress. Cells forming this racemic mixture of 15-hydroperoxy products may convert then to 15(\"R,S\")-HETEs and other products. However, the uncontrolled overproduction of the 15-hydroperoxy products may react with other elements to produce cell injury.\n\nThe newly formed products formed by the pathways cited in the previous section are bioactive but may also flow into down-stream pathways to form other metabolites with a different sets of bioactivity. The initially formed 15(\"S\")-HpETE may be further metabolized by its parent cell or pass it to nearby cell by a process termed transcellular metabolism.\n\n15(\"S\")-HpETE may be: \n\n15(\"S\")-HETE may be:\n\n15(\"R\")-HpETE may be:\n\n15(\"R\")-HETE may be:\n\nMost studies have analyzed the action of 15(\"S\")-HETE but not that of its less stable precursor 15(\"S\")-HpETE. Since this precursor is rapidly converted to 15(\"S\")-HETE in cells, it is likely that the two metabolites share similar activities. In many studies, however, is not clear that these activities reflect their intrinsic action or reflect their conversion to the metabolites sited above.\n\n15(\"S\")-HpETE and 15(\"S\")-HETE bind to and activate the G protein-coupled receptor, Leukotriene B4 receptor 2, i.e. BLT2. This receptor activation may mediate, at least in part, certain cell-stimulating activities of the two metabolites. BLT2 may be responsible in part or whole for mediating the growth-promoting and anti-apoptosis (i.e. anti-cell death) activities of 15(S)-HETE in cultured human breast cancer cells;<ref name=\"PLoS One. 2013 May 2;8(5):e63076. doi: 10.1371/journal.pone.0063076\" ></ref> human cancer colon cells, human hepatocellular HepG2 and SMMC7721 cancer cells; mouse 3T3 cells (a fibroblast cell line); rat PA adventitia fibroblasts; Baby hamster kidney cells; and diverse types of vascular endothelial cells. These growth-stimulating effects could contribute to the progression of the cited cancer types in animal models or even humans and the excess fibrosis that causes the narrowing of pulmonary arteries in hypoxia-induced pulmonary hypertension or narrowing of portal arteries in the portal hypertension accompanying liver cirrosis. 15(\"S\")-HETE may also act through BLT2 to stimulate an immediate contractile response in rat pulmonary arteries and its angiogenic effect on human umbilical and dermal vascular endothelial cells.\n\n15(\"S\")-HpETE and 15(\"S\")-HETE also directly bind with and activate peroxisome proliferator-activated receptor gamma. This activation may contribute to the ability of 15(S)-HETE to inhibit the growth of cultured human prostate cancer PC-3, LNCaP, and DU145 cell lines and non-malignant human prostate cells; lung adenocarcinoma A549 cells; human colorectal cancer cells; corneal epithelial cells; and Jurkat T-cell leukemia cells. The decline in the level of 15(\"S\")-HpETE-forming enzymes and consequential fall in cellular 15-HETE production that occurs in human prostate cancer cells may be one mechanism by which this and perhaps other human cancer cells (e.g. those of the colon, rectum, and lung) avoid the apoptosis-inducing actions of 15(\"S\")-HpETE and/or 15(\"S\")-HETE and thereby proliferate and spread. In this scenario, 15(S)-HETE and one of its formaing enzymes, particularly 15-LOX-2, appear to act as tumor suppressors.\n\nSome of the inhibitory effects of 15(\"S\")-HpETE and 15(\"S\")-HETE, particularly when induced by high concentrations (e.g. >1-10 micromolar), may be due to a less specific mechanism: 15(\"S\")-HpETE and to a lesser extent 15(\"S\")-HETE induce the generation of Reactive oxygen species. These species trigger cells to activate their death programs, i.e. apoptosis, and/or are openly toxic to the cells. 15(\"S\")-HpETE and 15(S)-HETE inhibit angiogenesis and the growth of cultured human chronic myelogenous leukemia K-562 cells by a mechanism that is associated with the production of reactive oxygen species.\n\nSeveral bifuctional electrophilic breakdown products of 15(\"S\")-HpETE, e.g. 4-hydroxy-2(\"E\")-nonenal, 4-hydroperoxy-2(\"E\")-nonenal, 4-oxo-2(\"E\")-nonenal, and \"cis\"-4,5-epoxy-2(\"E\")-decanal, are mutagens in mammalian cells and thereby may contripute to the development and/or progression of human cancers.\n\nSimilar to 15(\"S\")-HpETE and 15(\"S\")-HETE and with similar potency, 15(\"R\")-HETE binds with and activates peroxisome proliferator-activated receptor gamma. The precursor of 15(\"R\")-HETE, 15(\"R\")-HpETE may, similar to 15(\"S\")-HpETE, break down to the mutagenic products 4-hydroxy-2(\"E\")-nonenal, 4-hydroperoxy-2(\"E\")-nonenal, 4-oxo-2(\"E\")-nonenal, and \"cis\"-4,5-epoxy-2(\"E\")-decanal and therefore be involved in cancer development and/or progression.\n\nIn cultured human monocytes of the THP1 cell line, 15-oxo-ETE inactivates IKKβ (also known as IKK2) thereby blocking this cell's NF-κB-mediated pro-inflammatory responses (e.g.. Lipopolysaccharide-induced production of TNFα, Interleukin 6, and IL1B) while concurrently activating anti-oxidant responses upregulated through the anti-oxidant response element (ARE) by forcing cytosolic KEAP1 to release NFE2L2 which then moves to the nucleus, binds ARE, and induces production of, e.g. hemoxygenase-1, NADPH-quinone oxidoreductase, and possibly glutamate-cysteine ligase modifier. By these actions, 15-oxo-ETE may dampen inflammatory and/or Oxidative stress responses. In a cell-free system, 15-oxo-ETE is a moderately potent (IC=1 μM) inhibitor of 12-lipoxygenase but not other human lipoxygenases. This effect could also have anti-inflammatory and anti-oxidative effects by blocking the formation of 12-HETE and Hepoxilins. 15-Oxo-ETE is an example of an α,β unsaturated ketone Electrophile. These ketones are highly reactive with nucleophiles, adducting to, for example, the cysteines in transcription and transcription-related regulatory factors and enzymes to form their alkylated and thereby often inactivated products. It is presumed that the preceding activities of 15-oxo-ETE reflect its adduction to the indicated elements. 15-Oxo-ETE, at 2-10 μM, also inhibits the proliferation of cultured Human umbilical vein endothelial cells and LoVo human colorectal cancer cells and at the extremely high concentration of 100 μM inhibits the proliferation of cultured MBA-MD-231 and MCF7 breast cancer cells as well as SKOV3 ovarian cancer cells. They may use a similar \"protein-adduction\" mechanism; if so the target protein(s) for these effects have not been defined or even suggested. This 15-oxo-ETE action may prove to inhibit the remodeling of blood vessels and reduce the growth of the cited cell types and cancers. At sub-micromolar concentrations, 15-oxo-ETE has weak Chemotaxis activity for human monocytes and could serve to recruit this White blood cell into inflammatory responses.\n\n5-Oxo-15(S)-hydroxy-ETE is properly a member of the 5-HETE family of agonists which binds to the Oxoeicosanoid receptor 1, a G protein-coupled receptor, to activate its various target cells. As such, it is a potent stimulator of leukocytes, particularly eosinophils, as well as other OXE1-bearing cells including MDA-MB-231, MCF7, and SKOV3 cancer cells (see 5-Hydroxyicosatetraenoic acid and 5-oxo-eicosatetraenoic acid). \nIt also binds with and activates PPARγ and thereby can stimulate or inhibit cells independently of OXE1.\n\nLXA4, LXB4, AT-LXA4, and AT-LXB4 are specialized proresolving mediators, i.e. they potently inhibit the progression and contribute to the resolution of diverse inflammatory and allergic reactions (see specialized proresolving mediators#lipoxins and Lipoxins).\n\nEoxin A4, Eoxin C4, Eoxin D4, and Eoxin E4 and analogs of leukotriene A4, C4, leukotriene D4, and E4. Formation of the leukotrienes is initiated by 5-lipoxygenase metabolism of arachidonic acid to form a 5,6-epoxide viz, leukotriene A4; the latter metabolite is then converted to C4, D4, and E4 in succession. Formation of the eoxins is initiated by a 15-lipoxyenase-mediated metabolism of arachiconic acid to a 14,15-epoxide, eoxin A4 followed by its serial conversion to epoxins C4, D4, and E4 using the same pathways and enzymes that metabolize leukotriene A4 to its down-stream products. Preliminary studies have found that the eoxins have pro-inflammatory actions, suggest that they are involved in severe asthma, aspirin-induced asthma attacks, and perhaps other allergic reactions. The production of eoxins by Reed-Sternburg cells has also led to suggestion that they are involve in the lymphoma of Hodgkins disease. Drugs blocking the 15-lipoxygenases may be useful for inhibiting inflammation by reducing the production of the eoxins.\n\n\n", "id": "44358555", "title": "15-Hydroxyeicosatetraenoic acid"}
{"url": "https://en.wikipedia.org/wiki?curid=24796896", "text": "12-Hydroxyeicosatetraenoic acid\n\n12-Hydroxyeicosatetraenoic acid (12-HETE) is a derivative of the 20 carbon polyunsaturated fatty acid, arachidonic acid, containing a Hydroxyl residue at carbon 12 and a 5\"Z\",\"8Z\",10\"E\",14\"Z\" Cis–trans isomerism configuration (Z=cis, E=trans) in its four double bonds. It was first found as a product of arachidonic acid metabolism made by human and bovine platelets through their 12\"S\"-lipoxygenase (i.e. ALOX12) enzyme(s). However, the term 12-HETE is ambiquous in that it has been used to indicate not only the initially detected \"S\" stereoisomer, 12\"S\"-hydroxy-5\"Z\",\"8Z\",10\"E\",14\"Z\"-eicosatetraenoic acid (12(\"S\")-HETE or 12\"S\"-HETE), made by platelets, but also the later detected \"R\" stereoisomer, 12(\"R\")-hydroxy-5\"Z\",\"8Z\",10\"E\",14\"Z\"-eicosatetraenoic acid (also termed 12(\"R\")-HETE or 12\"R\"-HETE) made by other tissues through their 12\"R\"-lipoxygenase enzyme, ALOX12B. The two isomers, either directly or after being further metabolized, have been suggested to be involved in a variety of human physiological and pathological reactions. Unlike hormones which are secreted by cells, travel in the circulation to alter the behavior of distant cells, and thereby act as Endocrine signalling agents, these arachidonic acid metabolites act locally as Autocrine signalling and/or Paracrine signaling agents to regulate the behavior of their cells of origin or of nearby cells, respectively. In these roles, they may amplify or dampen, expand or contract cellular and tissue responses to disturbances.\n\nIn humans, Arachidonate 12-lipoxygenase (12-LO, 12-LOX, ALO12, or platelet type 12-lipoxygenase) is encoded by the ALOX12 gene and expressed primarily in platelets and skin. ALOX12 metabolizes arachidonic acid almost exclusively to 12(\"S\")-hydroperoxy-5\"Z\",8\"Z\",10\"E\",14\"Z\"-eicosatetraenoic acid (12(\"S\")-HpETE or 12\"S\"-HpETE). Arachidonate 15-lipoxygenase-1 (15-LO-1, 15-LOX-1, ALOX15), which is expressed in far more tissues that ALOX12, metabolizes arachidonic acid primarily to 15(\"S\")-HpETE along with other metabolites of the 15-Hydroxyicosatetraenoic acid family; during this metabolism, however, ALOX15 also forms 12(\"S\")-HpETE as a minor product. Arachidonate 12-lipoxygenase, 12R type, also termed 12RLOX and encoded by the ALOX12B gene, is expressed primarily in skin and cornea; it metabolizes arachidonic acid to 12(\"R\")-HpETE. Cytochrome P450 enzymes convert arachidonic acid to a variety of hydroperoxy, epoxy, and dihydroxy derivatives including racemic mixtures of 12(\"S\")-HpETE and 12(\"R\")-HpETE or 12(\"S\")-HETE and 12(\"R\")-HETE; the \"R\" stereoisomer predominates in these mixtures. The initial 12(\"S\")-HpETE and 12(\"R\")-HpETE products, regardless of their pathway of formation, are rapidly reduced to 12(\"S\")-HETE and 12(\"R\")-HETE, respectively, by ubiquitous cellular peroxidases, including in particular Glutathione peroxidases or, alternatively, are further metabolized as described below.\n\nSub-primate mammals, such as the mouse, rat, rabbit, cow, and pig, express platelet type 12-lipoxygenase but also a leukocyte type 12-lipoxygenase (also termed 12/15-lipoxygenase, 12/15-LOX or 12/15-LO) which is an ortholog of, and metabolically equivalent to, human 15-LO-1 in that it forms predominantly 15(\"S\")-HpETE with 12(\"S\")-HpETE as a minor product. Mice also express an epidermal type 15-lipoxygenase (e-12LO) which has 50.8% amino acid sequence identity to human 15-LOX-2 and 49.3% sequence indetity to mouse Arachidonate 8-lipoxygenase. Mouse e-12LO metabolizes arachidonic acid predominantly to 12(\"S\")-HETE and to a lesser extent 15(\"S\")-HETE.\n\nSub-human primates, although not extensively examined, appear to have 12-lipoxygenase expression patterns that resemble those of sub-primate mammals or humans depending on the closeness of there genetic relateness to these species.\n\nIn human (and mouse) skin epidermis, 12(\"R\")-HpETE is metabolized by Epidermis-type lipoxygenase, i.e. eLOX3 (encoded by the ALOXE3 gene), to two products: a) a specific hepoxilin, 8\"R\"-hydroxy-11\"R\",12\"R\"-epoxy-5\"Z\",9\"E\",14\"Z\"-eicosatetraenoic acid (i.e. 8\"R\"-hydroxy,11\"R\",12\"R\"-epoxy-hepoxilin A3 or 8\"R\"-OH,11\"R\",12\"R\"-epoxy-hepoxilin A3) and b) 12-oxo-5\"Z\",\"8Z\",10\"E\",14\"Z\"-eicosatetraenoic acid (12-oxo-HETE, 12-oxoETE, 12-Keto-ETE, or 12-KETE); 8\"R\"-hydroxy,11\"R\",12\"R\"-epoxy-hepoxilin A3 is further metabolized by soluble Epoxide hydrolase 2 (sEH) to 8\"R\",11\"R\",12\"R\"-trihydroxy-5\"Z\",9\"E\",14\"Z\"-eicosatetraenoic acid. 12(\"R\")-HpETE also spontaneously decomposes to a mixture of hepoxilins and trihydroxy-eicosatetraenoic acids that possess \"R\" or \"S\" hydroxy and epoxy residues at various sites while 8\"R\"-hydroxy,11\"R\",12\"R\"-epoxy-hepoxilin A3 spontaneously decomposes to 8\"R\",11\"R\",12\"R\"-trihydroxy-5\"Z\",9\"E\",14\"Z\"-eicosatetraenoic acid. These decompositions may occur during tissue isolation procedures. Recent studies indicate that the metabolism by ALOXE3 of the \"R\" stereoisomer of 12-HpETE made by ALOX12B and therefore possibly the \"S\" stereoisomer of 12-HpETE made by ALOX12 or ALOX15 is responsible for forming various hepoxilins in the epidermis of human and mouse skin and tongue and possibly other tissues.\n\nHuman skin metabolizes 12(\"S\")-HpETE in reactions strictly analogous to those of 12(\"R\")-HpETE; it metabolized 12(\"S\")-HpETE by eLOX3 to 8\"R\"-hydroxy-11\"S\",12\"S\"-epoxy-5\"Z\",9\"E\",14\"Z\"-eicosatetraenoic acid and 12-oxo-ETE, with the former product then being metabolized by sEH to 8\"R\",11\"S\",12\"S\"-trihydroxy-5\"Z\",9\"E\",14\"Z\"-eicosatetraenoic acid. 12(\"S\")-HpETE also spontaneously decomposes to a mixture of hepoxilins and trihydroxy-eicosatetraenoic acids (trioxillins) that possess \"R\" or \"S\" hydroxy and \"R\",\"S\" or \"S\",\"R\" epoxide residues at various sites while 8\"R\"-hydroxy,11\"S\",12\"S\"-epoxy-hepoxilin A3 spontaneously decomposes to 8\"R\",11\"S\",12\"S\"-trihydroxy-5\"Z\",9\"E\",14\"Z\"-eicosatetraenoic acid.\n\nIn other tissues and animal species, numerous hepoxilins form but the hepoxilin synthase activity responsible for their formation is variable. (Hepoxilin A3 [8\"R/S\"-hydroxy-11,12-epoxy-5\"Z\",9\"E\",14\"Z\"-eicosatrienoic acid] and hepoxilin B3 [10(\"R/S\"-hydroxy-11,12-epxoy-5\"Z\",8\"Z\",14\"Z\"-eicosatrienoic acid] refer to a mixture of Diastereomers and⁄or Enantiomers derived from arachidonic acid.) Cultured RINm5F rat Insulinoma cells convert 12(\"S\")-HpETE to hepoxilin A3 in a reaction that is comletely dependent on, and co-localizes with, the cells' leukocyte type 12-LOX; furthermore, recombinant rat and porcine leukocyte type 12-LOX as well as human platelet type 12-LOX metabolize 12(\"S\")-HpETE to hepoxylin A3. However, transfection of HEK293 human embryonic kidney cells with each of the 6 rat lipoxygenases, including rat eLOX3, found that hepoxilin B3 production required eLOX3; furthermore, the development of inflammation-induced tactile pain hypersensitivity (hyperesthesia; tactile Allodynia) in rats required eLOX3-dependent production of hepoxilin B3 by spinal tissue. Thus, the production of hepoxilins from 12(S)-HpETE may result from the intrinsic activity of platelet or leukocyte type 12-LOX's, require eLOX3, or even result from 12(\"S\")-HpETE spontaneous (and perhaps artifactual) decomposition during isolation. The majority of reports on hepoxilin formation have not defined the pathways evolved.\n\nHuman and other mammalian cytochome P450 enzymes convert 12(\"S\")-HpETE to 12-oxo-ETE.\n\n12-HETE (steroisomer not determined), 12(\"S\")-HETE, 12-oxo-ETE, hepoxilin B3, and trioxilin B3 are found in the \"sn\"-2 position of phospholipids isolated from normal human epidermis and human psoriatic scales. This indicates that the metabolites are acylated into the \"sn\"-2 position after being formed and/or directly produced by the metabolism of the arachidonic acid at the \"sn\"-2 position of these phospholipids. These acylation reactions may sequester and thereby inactivate or store the metabolites for release during cell stimulation.\n\n12(\"S\")-HETE and 12(\"R\")-HETE are converted to 12-oxo-ETE by microsomal NAD+-dependent 12-hydroxyeicosanoid dehdrogenase in porcine polymophonuclear leukocytes; a similar pathway may be active in rabbit corneal epitheleum, cow corneal epitheleum, and mouse keratinocytes although this pathway has not been described in human tissues.\n\n12-oxo-ETE is metabolised by cytoslic NADH-dependent 12-oxoeicosinoid Δ10-reductase to 12-oxo-5\"Z\",8\"Z\",14\"Z\"-eicosatreienoic acid (12-oxo-ETrE); 12-ketoreductase may then reduce this 12-oxo-ETrE to 12(\"R\")-hydroxy-5\"Z\",8\"Z\",14\"Z\"-eicosatreienoic acid (12(\"R\")-HETrE) and to a lesser extent 12(\"S\")-hydroxy-5\"Z\",8\"Z\",14\"Z\"-eicosatreienoic acid (12(\"S\")-HETrE).\n\nThe G protein-coupled receptor, GPR31, cloned from PC3 human prostate cancer cell line is a high affinity (Kd=4.8 nM) receptor for 12(\"S\")-HETE; GPR31 does not bind 12(\"R\")-HETE and has relatively little affinity for 5(\"S\")-HETE or 15(\"S\")-HETE. GPR31 mRNA is expressed at low levels in several human cell lines including K562 cells (human myelogenous leukemia cell line), Jurkat cells, (T lymphocye cell line), Hut78 cells (T cell lymphoma cell line), HEK 293 cells (primary embryonic kidney cell line), MCF7 cells (mammary adenocarcinoma cell line), and EJ cells (bladder carcinoma cell line). This mRNA appears to be more highly expressed in PC3 and DU145 prostate cancer cell lines as well as in human umbilical vein endothelial cells (HUVEC), human umbilical vein endothelial cells (HUVEC), human brain microvascular endothelial cells (HBMEC), and human pulmonary aortic endothelial cells (HPAC). In PC-3 prostate cancer cells, GPR31 receptor mediates the action of 12(\"S\")-HETE in activating the Mitogen-activated protein kinase kinase/Extracellular signal-regulated kinases-1/2 pathway and NFκB pathway that lead to cell growth and other functions. Studies have not yet determined the role, if any, in GPR31 receptor in the action of 12(\"S\")-HETE in other cell types.\n\nA G protein-coupled receptor for the 5(\"S\"),12(\"R\")-dihydroxy metabolite of aracidonic acid, Leukotriene B4, vis., Leukotriene B4 receptor 2 (BLT2), but not its Leukotriene B4 receptor 1, mediates responses to 12(\"S\")-HETE, 12(\"R\")-HETE, and 12-oxo-ETE in many cell types. Based on the effects of LTB4 receptor antagonists, for example, leukotriene B4 receptor 2 mediates: the rise in cytosolic Ca2+ concentration (a key signal for cell activation) in human neutrophils and the rise in cytosolic Ca2+ concentration and chemotaxis in Chinese hamstery ovarian cells stimlated by 12(\"S\")-HETE, 12(\"R\")-HETE, and/or 12-oxo-ETE; the itch response to 12(\"S\")-HETE and PMN inflammatory infiltration response to 12(\"R\")-HETE triggered by the injection these metabolites into the skin of mice and guinea pigs, respectively; and an in vitro angiogenic response by Human umbilical vein endothelial cells (HUVEC) and in vivo angiogenic response by mice to 12(\"S\")-HETE. The BLT2 receptor, in contrast to the GPR31 receptor, appears to be expressed at a high level in a wide range of tissues including neutrophils, eosinophils, monocytes, spleen, liver, and ovary. However, 12-Hydroxyheptadecatrienoic acid (i.e. 12-(\"S\")-hydroxy-5\"Z\",8\"E\",10\"E\"-heptadecatrienoic acid or 12-HHT), a product made when prostaglandin H2 is metablized to Thromboxane A2 by Thromboxane synthase or spontaneously rearranges non-enzymatically (see 12-Hydroxyheptadecatrienoic acid) is the most potent BLT2 receptor agonist detected to date. To clarify the role of BLT2 versus GPC31 receptors in responses to 12(\"S\")-HETE, and the role(s) of LTB4, 12(\"S\")-HETE, versus 12-HHT in BLT2-mediated responses, it will be necessary to determine: a) if leukotriene B4 interacts with the GPR31 receptor; b) if BLT2 receptor antagonists interfere with the GPR31 receptor; and c) the relative concentrations and availability of LTB4, 12(\"S\")-HETE, and 12-HHT in tissues exhibiting BLT2-dependent responses. Ultimately, both receptors and all three ligands may prove to be responsible for some tissue responses in vivo.\n\n12(\"S\")-HETE and 12(\"R\")-HETE bind to and act as Competitive antagonists of the Thromboxane receptor which mediates the actions of Thromboxane A2 and Prostaglandin H2. This antagonistic activity was responsible for the ability of 12(\"S\")-HETE and 12(\"R\")-HETE to relax mouse mesenteric arteries pre-constricted with a thromboxane A2 mimetic, U46619.\n\n12(\"S\")-HETE binds with high affinity to a 50 kilodalton (Kda) subunit of a 650 kDa cytosolic and nuclear protein complex.\n\n12(\"S\")-HpETE, 12(\"R\")-HETE, racemic mixtures of these 12-HETEs, and/or 12-oxo-ETE stimulate: a) the directed migration (chemotaxis) of human, rat, and rabbit neutrophils as well as rabbit macrophages; b) human neutrophils to adhere to each other (i.e. aggregate) and in cooperation with Tumor necrosis factor alpha or Platelet-activating factor, to release their granule-bound enzymes; c) the binding of human vascular epithelial cells to human monocytes; d) DNA synthesis and mitogenesis in the immortalized human keratinocyte cell line HaCaT; and e) when injected in the skin of human volunteers, the extravasation and local accumulation of circulating blood neutrophils and mononuclear cells.\nThese results suggest these metabolites contribute to the inflammation that occurs as sites where they are formed in abnormal amounts such as in human rheumatoid arthritis, Inflammatory bowel disease, Contact dermatitis, psoriasis, various forms of Ichthyosis including Congenital ichthyosiform erythroderma, and corneal inflammatory diseases. Since BLT2 appears to mediate the responses of leukocytes to 12(\"S\")-HpETE, 12(\"S\")-HETE, 12(\"R\")-HETE, and 12-oxo-ETE but GPR31 is expressed by various other cells (e.g. vascular endothelium) involved in inflammation, the pro-inflammatory actions of 12-HETE in humans may involve both types of G protein-coupled receptors.\n\n12(\"S\")-HpETE and 12(\"S\")-HETE induce itching responses when injected into the skin of mice; this has led to the suggestion that these metabolites contribute to the itching (i.e. clinical pruritus) which accompanies such conditions as atopic dermatitis, contact dermatitis, urticaria, chronic renal failure, and cholestasis. Since it mediates 12(\"S\")-HETE-induced itching in the mouse model, BLT2 rather than GPR31 may mediate human itch in these reactions.\n\n12-HETE (stereoisomer not defined) is the dominant arachidonic acid metabolite in cultured PC3 human prostate cancer cells and its levels in human prostate cancer tissue exceed by >9-fold its levels in normal human prostate tissue. Furthermore, 12(\"S\")-HETE a) increases the expression of Alpha-v beta-5 cell surface adhesion molecule and associated with this the survival of cultured PC3 cells; b) promotes the phosphorylation of retinoblastoma protein to inhibit its tumor suppressor function while promoting the proliferation of cultured PC3 cells; c) stimulates PC3 cells to activate the Mitogen-activated protein kinase kinase/extracellular signal-regulated kinases-1/2 pathway and the NFκB pathways that lead to cell proliferation; d) reverses the apoptosis-inducing (i.e. cell-killing) effect of pharmacologically inhibiting 12-LO in cultured DU145 human prostate cancer cells; e) promotes the induction of cyclooxygenase-1 and thereby the synthesis of this enzyme's growth-promoting arachidonic acid metabolite, PGE2, in cultured PC3 and LNCaP human prostate cancer cells; and f) induces cultured PC3 cells to express Vascular endothelial growth factor (VEGF), a protein that stimulates the formation of the microvasclature which assists in the metastasis of cancer. These results suggest that the 12(\"S\")-HETE made by prostate cancer tissues serves to promote the growth and spread of this cancer. Since it mediates the action of 12(\"S\")-HETE in stimulating cultured PC3 cells to activate the Mitogen-activated protein kinase kinase/Extracellular signal-regulated kinases-1/2 pathway and NFκB pathways, the GPR31 receptor may contribute to the pro-malignant activity of 12(\"S\")-HETE. However, LNCaP and PC3 cells also express BLT2 receptors; in LNCaP cells, BLT2 receptors are positively linked (i.e. stimulate the expression of) to the growth- and metastasis-promoting androgen receptor; in PC3 cells, BLT2 receptors stimulate the NF-κB pathway to inhibit the apoptosis caused by cell detachment from surfaces (i.e. Anoikis; and, in BLT2-overexpressing PWR-1E non-malignant prostate cells, 12(\"S\")-HETE diminish anoikis-induced apoptosis. ith occurs. Thus, the role of 12(\"S\")-HETE in human prostate cancer, if any, may involve its activation of one or both of the GPR31 and BLT2 receptors.\n\nPreclinical laboratory studies analogous to those conducted on the pro-malignant effects of 12(\"S\")-HETE and growth-inhibiting effects of blocking 12-HETE production in cultured prostate cancer cell lines, have implicated 12-HETE (stereoisomer sometimes undefined) in cancer cell lines from various other human tissues including those from the liver, intestinal epithelium, lung, breast, skin (Melanoma, ovary, pancrease, and possibly bladder. These studies implicate the interaction of 12-HETE with BLT2 receptors in intestinal epithelium cancer cells, and BLT2 receptors in breast, ovary, pancreas, and bladder cancer cells. While the studies on these tissues have not been as frequent or diverse as those on prostate cancer cell lines, they are suggested to indicate that 12-HETE contributes to the growth or spread of the corresponding cancer in humans.\n\n12(S)-HETE, 12(\"S\")-HpETE, and with far less potency 12(\"R\")-HETE reduced insulin secretion and caused apoptosis in cultured human pancreatic insulin-secreting Beta cell lines and prepared Pancreatic islets. TNFα, IL-1β, and IFNγ also reduced insulin secretion in cultured human pancreatic INS-1 beta cells, apparently by inducing the expression of NOX1 (NADPH oxidase 1) and thereby to the production of cell-toxic Reactive oxygen species; these cytokine effects were completely dependent on 12-lipoxygenase and mimicked by 12(\"S\")-HETE but not 12(\"R\")-HETE. 12-lipoxygenase-knockout mice (i.e., mice genetically manipulated to remove the Alox12 [i.e. 12-lipoxygenase gene, see lipoxygenase#mouse lipoxygenases) are resistant to a) streptozotocin-induced, b) high fat diet-induced, and c) autoimmune-induced diabetes. Further studies in animal models suggest that the 12\"S\"-HETE made by pancreatic beta cells (or possibly alpha cells or other cell types indigenous to or invading the pancreatic islands) orchestrate a local immune response that results in the injury and, when extreme, death of beta cells. These results suggest that the 12-lipoxygenase-12S-HETE pathway is one factor contributing to immunity-based type I diabetes as well as low insulin output type II diabetes.\n\n12(\"S\")-HETE and 12(\"S\")-HpETE stimulate the dilation of rat mesenteric arteries; 12(\"S\")-HETE stimulates the dilation of coronary microvessels in pigs and the mesenteric arteries of mice, one or more of these three metabolites are implicated in the vasolilation of rat basilar artery, 12(\"R\")-HETE and to a slightly lesser extent 12(\"S\")-HETE constrict the renal artery of dogs and 12-HETE (stereoisomer undetermined) is implicated in the angiotensin II-induced arterial hypertension response of human placenta. The vasodilating effect on mouse mesenteric arteries appears due to 12\"S\"-HETE's ability to act as a Thromboxane receptor antagonist and thereby block the vasoconstricting actions of thromboxane A2. These results indicate that the cited metabolites have dilating or constricting effects that depend on the arterial vascular site and or species of animal examined; their role in human blood pressure regulation is unclear.\n\nExcessive 12-HETE production is implicated in psoriasis.\n\n", "id": "24796896", "title": "12-Hydroxyeicosatetraenoic acid"}
{"url": "https://en.wikipedia.org/wiki?curid=47836404", "text": "20-Hydroxyeicosatetraenoic acid\n\n20-Hydroxyeicosatetraenoic acid, also known as 20-HETE or 20-hydroxy-5\"Z\",8\"Z\",11\"Z\",14\"Z\"-eicosatetraenoic acid, is an eicosanoid metabolite of arachidonic acid that has a wide range of effects on the vascular system including the regulation of vascular tone, blood flow to specific organs, sodium and fluid transport in the kidney, and vascular pathway remodeling. These vascular and kidney effects of 20-HETE have been shown to be responsible for regulating blood pressure and blood flow to specific organs in rodents; genetic and preclinical studies suggest that 20-HETE may similarly regulate blood pressure and contribute to the development of stroke and heart attacks. Additionally the loss of its production appears to be one cause of the human neurological disease, Hereditary spastic paraplegia. Preclinical studies also suggest that the overproduction of 20-HETE may contribute to the progression of certain human cancers, particularly those of the breast.\n\nA subset of Cytochrome P450 (CYP450) microsome-bound ω-hydroxylases, the Cytochrome P450 omega hydroxylases, metabolize arachidonic acid to 20-HETE by an omega oxidation reaction. CYP450 enzymes belong to a superfamily which in humans is composed of at least 57 members and in mice at least 120 members. Among this superfamily, certain members of the CYP4A and CYP4F subfamilies in the CYP4 family are considered predominant cytochrome P450 enzymes that are responsible in most tissues for forming 20-HETE and, concurrently, smaller amounts of 19-hydroxy-5\"Z\",8\"Z\",11\"Z\",14\"Z\"-eicosatetraenoic acid (19-HETE). However, CYP2U1 may also contribute to the production of these two HETEs and CYP4F8 can metabolize arachidonic acid to 19-HETE while forming little or no 20-HETE.\n\nThe production of 19-HETE with 20-HETE may be significant since 19(\"R\")-HETE, although not its stereoisomer, 19(\"S\")-HETE, inhibits the action of 20-HETE on vascular endothelial cells. Based on studies analyzing the production of other HETEs by CYP enzymes, the production of 19-HETE by these enzymes may include both its \"R\" and \"S\" stereoisomers.\n\nIn humans, the CYP4 ω-hydroxylases include CYP4A11, CYP4F2, and CYP4F3 with the predominant 20-HETE-synthesizing enzymes being CYP4F2, which is the major 20-HETE producing enzyme in the human kidney, followed by CYP4A11. CYP4F3 is expressed as two distinct enzymes, CYP4F3A and CYP4F3B, due to alternative splicing of a single pre-mRNA precursor molecule; CYP4F3A is mostly expressed in leukocytes, CYP4F3B mostly in the liver. Human CYP4Z1, which is expressed in a limited range of tissues such as human breast and ovary, may also metabolize arachidonic acid to 20-HETE while human CYP4A22, once considered as contributing to 20-HETE production, is now regarded as being metabolically inactive. Finally, CYP2U1, the only member of the human CYP2U subfamily, is highly expressed in brain and thymus and to lesser extents in numerous other tissues such as kidney, lung and heart. CYP2U1 protein is also highly expressed, compared to several other cytochrome P450 enzymes, in malignant breast tissue; the MCF-7 human breast cancer cell line express messenger RNA for this cytochrome.\n\nIn mice, the only 20-HETE- and 19-HETE-producing enzymes of the Cyp4a subfamily are two extensively homologous ones, Cyp4a12a and Cyp4a12b; Cyp4a12a is expressed in the male kidney in an androgen hormone-dependent manner. In rats, Cyp4a1, Cyp4a2, Cyp4a3, and Cyp4a8 make 20-HETE. The tissue distribution of these enzymes differs from those of humans making extrapolations from rodent studies to humans somewhat complicated.\n\nMouse CYP2J9, rat CYP2J3, and sheep CYP2J metabolize arachidonic acid primarily to 19-HETE but also to smaller amounts of 20-HETE, and, in the case of the sheep enzyme, 18-HETE; human CYP2J2, however, is an epoxygenase, metabolizing arachidonic acid to epoxide products.\n\nMany agents stimulate cells and tissues to produce 20-HETE in vitro and in vivo. Androgens are particularly potent stimulators of this production. Other stimulators include the powerful vasoconstriction-inducing agents, angiotensin II, endothelins, and alpha adrenergic compounds (e.g. norepinephrine).\n\nNitric oxide, carbon monoxide, and superoxide inhibit 20-HETE production; these non-pharmacological agents do so by binding to the Heme binding site of the 20-HETE producing cytochrome p450 enzymes. Drugs that are substrates for the UGT enzymes which metabolize 20-HETE such as non-steroidal anti-inflammatory agents, opioids, gemfibrozil, Lasix, propanol, and various COX-2 inhibitors may act as perhaps unwanted side effects to increase the levels of 20-HETE. There are a variety of pharmacological agents which inhibit the synthesis of 20-HETE including various fatty acid analogs that compete reversibly with arachidonic acid for the substrate binding site in the CYP enzymes and benzene-based drugs.\n\nThe cytochrome ω-oxidases including those belonging to the CYP4A and CYP4F sub-families and CYPU21 hydroxylate not only arachidonic acid but also various shorter chain (e.g. lauric acid) and/or longer chain (e.g. docosahexaenoic acid) fatty acids. They can also ω-hydroxylate and thereby reduce the activity of various fatty acid metabolites (e.g. LTB4, 5-HETE, 5-oxo-eicosatetraenoic acid, 12-HETE, and several prostaglandins) that regulate inflammation, vascular responses, and other reactions. This metabolism-induced inactivation may underlie the proposed roles of the cytochromes in dampening inflammatory responses and the reported associations of certain CYP4F2 and CYP4F3 single nucleotide variants with human Krohn's disease and Coeliac disease, respectively. While many of the effects and diseases associated with the over- or under-expression, pharmacological inhibition, and single nucleotide or mutant variants of the cytochrome ω-hydroxylases have been attributed to their impact on 20-HETE production, the influence of these alternate metabolic actions have frequently not been defined.\n\nGlucuronidation of 20-HETE by UDP-glucuronosyltransferases (UGTs) is thought to be a primary pathway of 20-HETE elimination and thereby inactivation in humans.\n\nThere are several other pathways that metabolize 20-HETE. Human platelets and other tissues metabolize it via cyclooxygenase(s) to form the 20-hydroxy analogs of prostaglandin G2, thromboxane A2, thromboxane B2 and to 11(\"R\")-hydroperoxy,20-hydroxy-5\"Z\",8\"Z\",11\"Z\",14\"Z\"-eicosatetraenoic acid which is rapidly reduced to 11,20-dihydroxy-5\"Z\",8\"Z\",11\"Z\",14\"Z\"-eicosatetraenoic acid; they also metabolize it through 12-lipoxygenase to form 12(\"S\")-hydroperoxy,20-hydroxy-5\"Z\",8\"Z\",101\"E\",14\"Z\"-eicosatetraenoic acid which is also rapidly reduced to 12,20-dihydroxy-5\"Z\",8\"Z\",101\"E\",14\"Z\"-eicosatetraenoic acid. (The chirality of the hydroperoxy and hydroxyl residues at positions 11 and 12 in the eicosatetraenoic acids are predicted based on studies defining the chirality of the arachdionic metabolites made by these enzymes.) Since the prostaglandin and thromboxane metabolites of 20-HETE lack the platelet-stimulating activities to their prostaglandin and thromboxane precursors and since the 12-hydroxy and 11-hydroxy metabolites of 20-HETE may also be inactive, these metabolic pathways appear to function in inactivating 20-HETE with respect to the platelet system. However, the 20-hydroxy prostaglandin metabolites are able to contract rat aorta rings and thereby could contribute to the hypertensive actions of 20-HETE.\n\nCultured smooth muscle and endothelial cells from mouse brain microvasculature oxidize 20-HETE to its 20-carboxy analog, 20-carboxy- 5\"Z\",8\"Z\",11\"Z\",14\"Z\"-eicosatetraenoic acid, then to 18-carboxy-5\"Z\",8\"Z\",10\"Z\",14\"Z\"-octadecatetraenoic acid, and then to the further chain-shortened dicarboxylic acid, 16-carboxy-5\"Z\",8\"Z\",10\"E\"-hexadecatrrenoic acid, in a series of Beta oxidation reactions. These shortening pathways also are likely to serve in inactivating 20-HETE, although the initial product of this shortening pathway, 20-carboxy-HETE, dilates coronary microvessels in the pig heart and thereby could serve to antagonize the vasoconstrictor actions of 20-HETE, at least in this organ and species. Coronary artery endothelial cells isolated from pigs incorporate 20-HETE primarily into the sn-2 position of phospholipids through a coenzyme A-dependent process. It is likely, although not yet shown, that these mouse and pig 20-HETE metabolizing pathways also occur in humans.\n\n20-HETE-synthesizng enzymes are widely distributed to liver, kidney, brain, lung, intestine and blood vessels. In most vascular systems, 20-HETE synthesizing activity is limited to vascular smooth muscle of small blood vessels with little or no such activity in the vessel's endothelial cells or in large blood vessels. However, both the smooth muscle and endothelial cells obtained from mouse brain microvasculature, produce 20-HETE in culture.\n\n20-HETE is produced by human neutrophils and platelets and by the ascending tubule cells in the medulla as well the pre-glomerular arterioles and certain other localized areas of the rabbit kidney.\n\nIn various rodent models, 20-HETE, at low concentrations (<50 nanomolar), acts to constrict arteries by sensitizing (i.e. increasing) the contraction responses of these artery's smooth muscle cells to other contracting agents such as alpha adrenergic agonists, vasopressin, endothelin, and a product of renin angiotensin system, angiotensin II. 20-HETE has a particularly complex interaction with the renin angiotensin system: angiotensin II stimulates the preglomerular microvessels of the rat kidney to produce 20-HETE; this production is required for angiotensin II to exert its full constrictor effects; and 20-HETE induces transcription of the enzyme which converts angiotensin I to angiotensin II, i.e. angiotensin-converting enzyme. Other agents such as Androgens and alpha adrenergic compounds such as norepinephrine. likewise stimulate 20-HETE production and have vasoconstrictive actions which are enhanced by 20-HETE. These circular or positive feedback interactions may serve to perpetuate vasoconstrictor responses.\n\nAgain in rodent models, 20-HETE acts to block Calcium-activated potassium channels to promote the entry of ionic calcium into vascular smooth muscle cells through the L-type calcium channel; the attendant rise in intracellular calcium triggers these muscles to contract.\n\nStudies in rats also indicate that in vascular endothelial cells 20-HETE inhibits the association of the nitric oxide-producing enzyme, endothelial nitric oxide synthase (eNOS) with heat shock protein 90; this inhibits the ability of eNOS to become activated. The endothelial cells become dysfunctional in exhibiting decreased ability to produce the vasodilating agent, nitric oxide, and in containing elevated levels of a potentially injurious oxygen radical, superoxide anion; the blood vessels to which these dysfunctional endothelial cells belong are less able to dilate in response to the vasodilator, acetylcholine.\n\n20-HETE can also constrict rodent (and human) artery preparations by directly activating the receptor for thromboxane A2. While significantly less potent than thromboxane A2 in activating this receptor, studies on rat and human cerebral artery preparations indicate that increased blood flow through these arteries triggers production of 20-HETE which in turn binds to thromboxane receptors to constrict these vessels and thereby reduce their blood blow. Acting in the latter capacity, 20-HETE, it is proposed, functions as a mediator regulating blood flow to the brain.\n\nThese vasoconstrictor effects of 20-HETE can reduce blood flow to specific parts of the body, not only to brain (see previous paragraph) but also to kidney, liver, heart and other organs, as well as to portions of these organs; they can also contribute to systemic hypertension as well as to the physiological and pathological effects of thromboxane receptor-activation .\n\nSprague Dawley rats that underwent balloon injury of the common carotid artery exhibited elevated levels of CYP4A enzyme immunostaining in the smooth muscle of the injured arteries as well as elevated levels of 20-HETE in the injured arteries. Inhibition of 20-HETE production by two different agents greatly reduced the vascular intima hyperplasia and vascular remodeling that occurred after balloon injury. The studies suggest that the increase in expression of CYP4A and production of 20-HETE contribute to vascular intima growth, remolding, and thereby healing of injured rat carotid arteries.\n\nIn the C57BL/6 mouse laboratory model, 20-HETE pretreatment accelerates the development of thrombosis and reduces blood flow caused by the Thrombosis-inducing agent, ferric chloride, in the common carotid and femoral arteries; companion studies on human umbilical vein endothelial cells indicate that 20-HETE stimulates the activation of Extracellular signal-regulated kinases to cause ERK-dependent and L-type calcium channel-dependent release of von Willebrand factor which in turn stimulates the adhesion of platelets to the endothelial cells. The endothelial, platelet, and pro-clotting actions of 20-HETE may contribute to its ability to disrupt blood flood to tissues.\n\nIn animal models, 20-HETE stimulates the activation of protein kinase C in the epithelial cells of the proximal tubules of the kidney; the kinase then phosphorylates and thereby inhibits the Na+/K+-ATPase and concurrently also blocks the Na-K-Cl cotransporter and 70 pS K+ channel in the thick Ascending limb of loop of Henle (TALH); these effects reduce the absorption of sodium and fluids in the nephron and thereby tend to reduce blood pressure.\n\nAs indicated above, 20-HETE may raise blood pressure by constricting arterial blood vessels but also may lower blood pressure by promoting the loss of sodium and fluids in the kidneys. The effects of 20-HETE therefore are complex, as indicated in studies of the following animal models. Many of these models appear relevant to hypertension in humans in that they parallel the human disease, i.e. men have higher rates of hypertension than women, and women with increased levels of androgens (e.g. postmenopausal women and women with polycystic ovarian disease) and higher rates of hypertension.\n\nSpontaneously hypertensive rats exhibit elevated levels of CYP4A2 and 20-HETE; blockade of 20-HETE production lowers blood pressure in this model. The effect is particularly well seen in female rats: aging post-menopausal but not pre-menopausal female spontaneously hypertensive rats exhibit highly significant falls in blood pressure when treated with non-selective or selective inhibitors of CYP-induced 20-HETE production.\n\nDahl salt-sensitive rats develop hypertension that develops more quickly and exacerbated by high intake of salt (sodium chloride) and ameliorated by low salt intake. In this model, rats exhibit an up-regulated CYP4A/20-HETE pathway within their cerebral vasculature and vascular endothelial cell overproduction of reactive oxygen species that in turn stimulates the CYp4A/20-HETE pathway. Non-selective and non-selective inhibitors of CYP4A and 20-HETE production reduce hypertension in this model. The hypertension in this model is more severe in male rats and appears to be mediated at least in part by vasopressin, the renin-angiotensin system, and androgens.\n\nLewis rats (see Laboratory rat models) that had one kidney removed and then fed a high salt diet are hypertensive. Kidney medullary interstitial infusion of an inhibitor of 20-HETE production reduced the formation of 20-HETE in the outer medulla of the infused kidney, had no effect on the production of 20-HETE in the cortex of the infused kidney, and produced a mean arterial pressure rise from 115 at baseline to 142 mm of mercury; this study indicates that the hypertensive versus hypotensive effects of 20-HETE depend not only on the organ of its production but also, with respect to the kidney, the site within the organ where it is produced.\n\nAndrogen treatment causes hypertension in normal male and female rats; this hypertensive response is greatly reduced by diverse inhibitors of Cyp4a and 20-HETE production.\n\nCyp4a12-transgenic mice overexpressing Cyp4a12 develop androgen-independent hypertension that is associated with increased levels of 20-HETE; this hypertension is fully reversible by treatment with a Cyp4a selective inhibitor of 20-HETE production.\n\nMice depleted of Cyp4a14 by gene knockout (Cyp4a14(-/-) mice develop male-specific, androgen-dependent hypertension. This seemingly paradoxical result is due to the overexpression of Cyp4a12a; the knockout of Cyp4a14 (Cyp4a14 does not produce 20-HETE) leads to the overexpression of the 20-HETE-producing cytochrome, Cyp4a149(-/-), and consequent overproduction of 20-HETE. The model involves increased plasma androgens, increased vascular and urinary levels of 20-HETE, relief of hypertension by castration, and hypertension which is driven by excessive fluid reabsorption in the kidney's proximal tubule secondary to the overexpression of Sodium–hydrogen antiporter 3; these effects are presumed but not yet shown to be due to the overproduction of 20-HETE. The Cyp4a12-transgenic model (above) is referred to in support of this presumption.\n\nMice depleted of Cyp4a10 maintain normal blood pressure on a low salt diet but become hypertensive on normal or high salt diets; this paradoxical result appears due to a decrease in kidney levels of Cyp2C44 caused by the loss of Cyp4a10. Cyp2C44 metabolizes arachidonic acid a family of vasodilation-inducing and anti-hypertensive products, the Epoxyeicosatrienoic acids (EETs). The model involves normal levels of 20-HETE, reduced expression of Cyp2c44, reduced levels of EETs, and deficiencies in kidney tubule absorption of sodium regulated by EETs, and the normalization of hypertensive blood pressure by increasing expression of Cyp2c44 by treating the mice with an inducer of its expression, an activator of PPARα.\n\n20-HETE activates the mouse and human transient receptor potential cation channel subfamily V member 1 (TRPV1, also known as the capsaicin receptor and the vanilloid receptor 1), and through this receptor, cultured dorsal root ganglion cells taken from mice.\n\nHuman CYP4A11 has 72.69% amino acid identity with murine cyp4a14 and 73.02% identity with murine cyp4a10 suggesting that it plays a role in humans similar to that of cyp4a14 and/or cyp4a10 in mice. The association of hypertension with defective CYP4A11 in humans as indicated below seems to parallel the hypertension associated with Cyp4a14 gene knockout in mice (see above section on genetic models).\n\nThe gene polymorphism rs1126742 variant of CYP4A11 switches thymidine to cytosine at nucleotide 8590 [T8590C] and leads to a phenylalanine-to-serine substitution at amino acid 434); this F434S variant has significantly reduced ability to ω-oxidize arachidonic acid to 20-HETE and has been associated with essential hypertension in: 512 white males from Tennessee (Odds ratio=2.31); 1538 males and females from the Framingham Heart Study (Odds ratio=1.23); males but not females in 732 black Americans with hypertensive renal disease participating in the African American Study of Kidney Disease; males in a sample of 507 individuals in Japan and in the third MONICA (MONitoring trends and determinants In Cardiovascular disease survey of 1397 individuals the homozygous C8590C genotype to the homozygous T8590T genotype with odds ratios of 3.31 for all subjects, 4.30 for males 2.93 for women);\n\nA study of 1501 participants recruited from the Tanno-Sobetsu Study found that the variant -845G in the promoter region of CYP411 (−845A is the predominant genotype) is associated with reduced transcription of CYP411 as well as with hypertension (odds ratio of homozygous and heterozygous -845G genotype versus homozygous -845A was 1.42);\n\nA haplotype tagging single-nucleotide polymorphism (SNP) (see Tag SNP) variant of CYP4A11, C296T (cytosine to thymine at position 296), was associated with a significantly increased risk of ischemic stroke (adjusted odds ratio of 1.50 in comparing homozygous and heterozygous C296T subjects to homozygous C286C subjects) in >2000 individuals taken from the Han Chinese population. The effect of the −296C>T single base pair substitution on baseline CYP411 transcriptional activity was not significant, suggesting that this polymorphism may not be the causal variant but instead may be in linkage disequilibrium with the causal variant. Regardless, this SNP may serve as a genetic marker for large vessel disease stroke risk in this population.\n\nThe G1347A variant of CYP4F2 produces an enzyme with methionine in place of valium at position 433 (Val433Met; single nucleotide variant rs2108622); the variant enzyme has reduce capacity to metabolize arachidonic acid to 20-HETE but increased urinary excretion of 20-HETE. Studies found that: a) among 161 hypertensive and 74 normotensive subjects in Australia, the incidence of the Val433Met variant was significantly increased in the hypertensive subjects; b) among a large number of Swedish patients enrolled and monitored over 10 years in the cardiovascular cohort of the Malmö Diet and Cancer Study only males with this variant exhibited hypertension; c) among several hundred subjects in India, the variant was associated with hypertension; and d) in comparing 249 patients with hypertension to 238 age-matched controls in Japan, the variant was not associated with hypertension. The maintenance of the lower blood pressure that followed diet-induced weight loss was more difficult for carriers of the Val433Met variant and may be related to increased arterial stiffness and increased 20-HETE synthesis.\n\nThe Val433Met variant is also associated with an increased incidence of cerebral infarction (i.e. ischemic stroke) in a study of 175 subjects with infarction compared to 246 control subjects in Japan, in 507 stroke patients compared to 487 age- and sex-matched 487 controls in India, and in males but not females in a study of 558 patients compared to 557 controls in China. The variant is associated with myocardial infarction in a study of 507 patients compared to 487 age- and sex-matched controls in India, in males but not females in a study of 234 patients compared to 248 control subjects in Japan, and in male but not female patients in Sweden enrolled in the cardiovascular cohort of the Malmo Diet and Cancer Study. The incidences of cerebral and myocardial infarction in these studies appears to be independent of hypertension. (The platelets of individuals heterozygous or homozygous for the Val433Met variant exhibit increased platelet aggregation responses to epinephrine. This platelet hyper-responsiveness to epinephrine, particularly if also exhibited to other platelet-aggregating agents, could contribute to cerebral and coronary infarctions.)\n\nThe Single-nucleotide polymorphism rs1558139 guanine to cytosine variant in an intron of CYP4F2 is associated with essential hypertension in men only in a study of 249 hypertensive versus 238 age-matched controls in Japan. The impact of this variant on CYP4F2 expression is not known.\n\nThe single-nucleotide polymorphism rs2108622 located in exon 11 of CYP4F2 encodes for an enzyme with reduced ability to metabolize arachidonic acid to 20-HETE; male but not female bearers of this CYP4F2 \"G allele\" have an increased incidence of cerebral infarction base on an analysis of 175 subjects and 246 controls.\n\nA mutation (c.947A>T) in CYP2U1 has been associated with a small number of patients with Hereditary spastic paraplegia in that it segregates with the disease at the homozygous state in two afflicted families. The mutation affects an amino acid (p.Asp316Val) highly conserved among CYP2U1 orthologs as well as other cytochrome P450 proteins; the p.Asp314Val mutation is located in the enzyme's functional domain, is predicted to be damaging to the enzyme's activity, and is associated with mitochondria dysfunction. A second homozygous enzyme-disabling mutation has been identified in CYP2U1, c.1A>C/p.Met1?, that is associated with <1% of hereditary spastic paraplegia sufferers. While the role of 20-HETE in these mutations has not been established, the reduction in 20-HETE production and thereby 20-HETE's activation of the TRPV1 receptor in nerve tissues, it is hypothesized, may contribute to the disease.\n\nTwo human breast cancer cell lines, T47D and BT-474, made to overexpress CYP4Z1 by transfection overexpress messenger RNA for and overproduce vascular endothelial growth factor A while under expressing message and protein for tissue inhibitor of metalloproteinase-2. T47D cells that overexpress CYP4Z1 also overproduce 20-HETE and when ransplanted into athymic Balb/c mice show a greater increase in tumor weight and vascularity compared to control T47D cells; these increases are prevented by an inhibitor of 20-HETE production. Isoliquiritigenin, a proposed drug for treating cancer, cause cultured MDA-MB-231 and MCF-7 human breast cancer cells to die by triggering apoptosis. Among its many other effects, the drug caused these cells to decrease their levels of 20-HETE in vitro; the addition of 20-HETE to these cultures rescued the cells from apoptosis. Isoliquiritigenin also inhibits the in vivo lung metastasis of MDA-MB-231 cell transplants while concurrently decreasing the tumor's levels of 20-HETE. The growth of MDA-MB-231 cells implanted into athymic nude female mice as well as the cells' production of a large variety of agents stimulating vascularization including vascular endothelial growth factor were inhibited by treating the mice with an inhibitor of 20-HETE production.\n\nMessenger RNAs not only for CYP4Z2 but also for CYP4A11, CYP4A22, CYP4F2, and CYP4F3 are more highly expressed in samples of human breast cancer tumors compared to normal breast tissue. The Three prime untranslated regions (3'UTRs) of the CYP4Z1 gene and its Pseudogene, CYP4Z2P, share several miRNA-binding sites, including those for miR-211, miR-125a-3p, miR-197, miR-1226, and miR-204'. Since these miRNA's reduce the translation of CYP4Z1, the expression of CYP4Z2P can bind these miRNAs to reduce their interference with CYP4Z1 and thereby increase the production of CYP4Z1 protein and perhaps 20-HETE; indeed, force expression of these 3'UTRs promoted in vitro tumor angiogenesis in breast cancer cells partly via miRNA-dependent activation of the phosphoinositide 3-kinase-MAPK/ERK pathway and thereby stimulating the production of vascular endothelium growth factor and possibly other endothelium growth factors. Taken together, these pre-clinical studies suggest that 20-HETE made by one or more of the cited cytochrome P450 enzymes may contribute to the progression of breast cancer by promoting its survival, growth, and vascular endothelial growth factor-induced neovascularization.\n\n20-HETE stimulated the proliferation of cultured human brain Glioma cell line U251 and, when forced to overexpress CYP4Z1 by gene transfection, overproduced 20-HETE and exhibited a dramatically increased rate of growth that was blocked by inhibiting the cells from producing 20-HETE. A similar set of findings was found with human non-small cell lung cancer cells. A selective inhibitor of 20-HETE synthesis and a 20-HETE antagonist reduced the growth of two human kidney cancer 786-O and 769-P cell lines in culture; the 20-HETE antagonist also inhibited the growth of 786-O cells transplanted into athymic nude mice.\n\nMessenger RNAs for CYP4A11, CYP4A22, CYP4F2, and/or CYP4F3 are more highly expressed in ovary, colon, thyroid, lung, ovary, cancers compared to their normal tissue counterparts; in ovarian cancer, this higher expression is associated with an increased level of CYP4F2 protein expression and an increased ability to metabolize arachidonic acid to 20-HETE. Ovarian cancers also overexpress CYP4Z1 mRNA protein; this overexpression is associated with a poorer disease outcome.\n\nWhile these studies suggest that CYP4A11, CYP4A22, CYP4F2, and/or CYP4F3 produce 20-HETE which in turn promotes the growth of the cited cancers in model systems and therefore may do so in the human cancers, this suggestion clearly needs much further study. For example, an inhibitor of 20-HETE production blocks the growth of human brain U251 glioma cells in culture; since these cells could not be shown to produce 20-HETE, it was proposed that some other metabolite may by the inhibitor's targeted cytochrome enzymes was responsible for maintaining these cells growth. It is also possible that any such inhibitor has off-target effects that are responsible for its actions.\n\n20-HETE inhibits the aggregation of human platelets by competing with arachidonic acid for the enzymes that produce prostaglandin H2 and thromboxane A2. These products are formed in response to platelet stimulation and then act through the thromboxane receptor to mediate and/or promote the ensuing platelet aggregation response to most stimuli. The platelets metabolize 20-HETE to the 20-hydroxy analogs of prostaglandin H2 and thromboxane A2, products that are essentially inactive in platelets, while consequently form less of the arachidonic acid-derived prostaglandin and thromboxane products. In addition, 20-HETE itself blocks prostaglandin and thromboxane metabolites from interacting with the thromboxane receptor. Both effects, i.e. replacement of prostaglandin and thromboxane production with platelet-inactive products and thromboxane A2 receptor blockade, are responsible for 20-HETE's platelet aggregation-inhibiting action. However, the platelet anti-aggregating activity of 20-HETE requires micromolar levels and therefore may be more of a pharmacological than physiological activity.\n\n20-HETE constricts human artery preparations by directly activating the receptor for thromboxane A2. While significantly less potent than thromboxane A2 in activating this receptor, studies on human cerebral artery preparations indicate that increased blood flow through these arteries triggers production of 20-HETE which in turn binds to thromboxane receptors to constrict these vessels and thereby reduce their blood blow. Acting in the latter capacity, 20-HETE, it is proposed, functions as a mediator regulating blood flow to the human brain.\n\nOne study found that 30 patients with the metabolic syndrome exhibited significantly elevated levels of plasma and urinary 20-HETE compared to matched controls; women with the syndrome had particularly higher urinary 20-HETE levels.\n", "id": "47836404", "title": "20-Hydroxyeicosatetraenoic acid"}
{"url": "https://en.wikipedia.org/wiki?curid=50704695", "text": "Specialized pro-resolving mediators\n\nSpecialized pro-resolving mediators (SPM, also termed specialized proresolving mediators) are a large and growing class of cell signaling molecules formed in cells by the metabolism of polyunsaturated fatty acids (PUFA) by one or a combination of lipoxygenase, cyclooxygenase, and cytochrome P450 monooxygenase enzymes. Pre-clinical studies, primarily in animal models and human tissues, implicate SPM in orchestrating the resolution of inflammation. \n\nSPM join the long list of other physiological agents which tend to limit inflammation (see ) including glucocorticoids, interleukin 10 (an anti-inflammatory cytokine), interleukin 1 receptor antagonist (an inhibitor of the action of pro-inflammatory cytokine, interleukin 1), annexin A1 (an inhibitor of formation of pro-inflammatory metabolites of polyunsaturated fatty acids), and the gaseous resolvins, carbon monoxide (see ), nitric oxide (see ), and hydrogen sulfide (see and ).\n\nThe absolute as well as relative roles of the SPM along with other physiological anti-inflammatory agents in resolving human inflammatory responses remain to be defined precisely. However, studies suggest that synthetic SPM that are resistant to being metabolically inactivated hold promise of being clinically useful pharmacological tools for preventing and resolving a wide range of pathological inflammatory responses along with the tissue destruction and morbidity that these responses cause. Based on animal model studies, the inflammation-based diseases which may be treated by such metabolically resistant SPM analogs include not only pathological and tissue damaging responses to invading pathogens but also a wide array of pathological conditions in which inflammation is a contributing factor such as allergic inflammatory diseases (e.g. asthma, rhinitis), autoimmune diseases ( e.g. rheumatoid arthritis, systemic lupus erythematosis), psoriasis, atherosclerosis disease leading to heart attacks and strokes, type 1 and type 2 diabetes, the metabolic syndrome, and certain dementia syndromes (e.g. Alzheimer's disease, Huntingdon's disease).\n\nMany of the SPM are metabolites of omega-3 fatty acids and have been proposed to be responsible for the anti-inflammatory actions that are attributed to omega-3 fatty acid-rich diets.\n\nThrough most of its early period of study, acute inflammatory responses were regarded as self-limiting innate immune system reactions to invading foreign organisms, tissue injuries, and other insults. These reactions were orchestrated by various soluble signaling agents such as a) foreign organism-derived N-formylated oligopeptide chemotactic factors (e.g. N-formylmethionine-leucyl-phenylalanine); b) complement components C5a and C3a which are chemotactic factors formed during the activation of the host's blood complement system by invading organisms or injured tissues; and c) host cell-derived pro-inflammatory cytokines (e.g. interleukin 1s), host-derived pro-inflammatory chemokines (e.g. CXCL8, CCL2, CCL3, CCL4, CCL5, CCL11, CXCL10), platelet-activating factor, and PUFA metabolites including in particular leukotrienes (e.g. LTB4), hydroxyeicosatetraenoic acids (e.g., 5-HETE, 12-HETE), the hydroxylated heptadecatreineoic acid, 12-HHT, and oxoeicosanoids (e.g. 5-oxo-ETE). These agents functioned as pro-inflammatory signals by increasing the permeability of local blood vessels; activating tissue-bound pro-inflammatory cells such as mast cells, and macrophages; and attracting to nascent inflammatory sites and activating circulating neutrophils, monocytes, eosinophils, gamma delta T cells, and Natural killer T cells. The cited cells then proceeded to neutralize invading organisms, limit tissue injury, and initiate tissue repair. Hence, the classic inflammatory response was viewed as fully regulated by the soluble signaling agents. That is, the agents formed, orchestrated an inflammatory cell response, but then dissipated to allow resolution of the response. In 1974, however, Charles N. Serhan and his renowned colleagues, Mats Hamberg and Bengt Samuelsson, discovered that human neutrophils metabolize arachidonic acid to two novel products that contain 3 hydroxyl residues and 4 double bonds viz., 5,6,15-trihydroxy-7,9,11,13-icosatetraenoic acid and 5,14,15-trihydroxy-6,8,10,12-icosatetraenoic acid. These products are now termed lipoxin A4 and B4, respectively. While initially found to have in vitro activity suggesting that they might act as pro-inflammatory agents, Serhan and colleagues and other groups found that the lipoxins as well as a large number of newly discovered metabolites of other PUFA possess primarily if not exclusively anti-inflammatory activities and therefore may be crucial for causing the resolution of inflammation. In this view, inflammatory responses are not self-limiting but rather limited by the formation of a particular group of PUFA metabolites that counteract the actions of pro-inflammatory signals. Later, these PUFA metabolites were classified together and termed specialized pro-resolving mediators (i.e. SPM).\n\nThe production and activities of the SPM suggest a new view of inflammation wherein the initial response to foreign organisms, tissue injury, or other insults involves numerous soluble cell signaling molecules that not only recruit various cell types to promote inflammation but concurrently cause these cells to produce SPM which feed back on their parent and other cells to dampen their pro-inflammatory activity and to promote repair. Resolution of an inflammatory response is thus an active rather than self-limiting process which is set into motion at least in part by the initiating pro-inflammatory mediators (e.g. prostaglandin E2 and prostaglandin D2) which instruct relevant cells to produce SPM and to assume a more anti-inflammatory phenotype. Resolution of the normal inflammatory response, then, may involve switching production of pro-inflammatory to anti-inflammatory PUFA metabolites. Excessive inflammatory responses to insult as well as many pathological inflammatory responses that contribute to diverse diseases such as atherosclerosis, diabetes, Alzheimer's disease, Inflammatory bowel disease, etc. (see Inflammation#Inflammatory disorders) may reflect, in part, a failure in this class switching. Diseases caused or worsened by non-adaptive inflammatory responses may by amenable to treatment with SPM or synthetic SPM which, unlike natural SPM, resist in vivo metabolic inactivation. The SPM possess overlapping activities which work to resolve inflammation. SPMs (typically more than one for each listed action) have the following anti-inflammatory activities on the indicated cell types as defined in animal and human model studies:\n\nSPMs also stimulate anti-inflammatory and tissue reparative types of responses in epithelium cells, endothelium cells, fibroblasts, smooth muscle cells, osteoclasts, osteoblasts, goblet cells, and kidney podocytes as well as activate the heme oxygenase system of cells thereby increasing the production of the tissue-protective gaso-transmitter, carbon monoxide (see Carbon monoxide#Normal human physiology), in inflamed tissues.\n\nSPM are metabolites of arachidonic acid (AA), eicosapentaenoic acid (EPA), docosahexaenoic acid (DHA), or n-3 DPA (i.e. \"7\",10\"Z\",13\"Z\",19\"Z\"-docosapentaenoic acid or clupanodonic acid); these metabolites are termed lipoxins (Lx), resolvins (Rv), protectins (PD) (also termed neuroprotectins [NP]), and maresins (MaR). EPA, DHA, and n-3 DPA are n-3 fatty acids; their conversions to SPM are proposed to be one mechanism by which n-3 fatty acids may ameliorate inflammatory diseases (see Omega-3 fatty acid#Inflammation). SPM act, at least in part, by either activating or inhibiting cells through binding to and thereby activating or inhibiting the activation of specific cellular receptors.\n\nHuman cells synthesize LxA4 and LxB4 by serially metabolizing arachidonic acid (5\"Z\",8\"Z\",11\"Z\",14\"Z\"-eicosatrienoic acid) with a) ALOX15 (or possibly ALOX15B) followed by ALOX5; b) ALOX5 followed by ALOX15 (or possibly ALOX15B); or c) ALOX5 followed by ALOX12. Cells and, indeed, humans treated with aspirin form the 15\"R\"-hydroxy Epimer lipoxins of these two 15\"S\"-lipoxins viz., 15-epi-LXA4 and 15-epi-LXB4, through a pathway that involves ALOX5 followed by aspirin-treated cyclooxygenase 2 (COX2). Aspirin-treated COX-2, while inactive in metabolizing arachidonic acid to prostanoids, metabolizes this PUFA to 15\"R\"-hydroperoxy-eicosatetraenoic acid whereas the ALOX15 (or ALOX15B) pathway metabolizes arachidonic acid to 15\"S\"-hydroperoxy-eicosatetraenoic acid. The two aspirin-triggered lipoxins (AT-lipoxins) or epi-lipoxins differ structurally from LxA4 and LxB4 only in the \"S\" versus \"R\" chirality of their 15-hydroxyl residue. Numerous studies have found that these metabolites have potent anti-inflammatory activity in vitro and in animal models and in humans may stimulate cells by binding to certain Receptor (biochemistry)s in or on these cells. The following table lists the structural formulae (ETE stands for eicosatetraenoic acid), major activities, cellular receptor targets (where known), and Wikipedia pages giving further information on the activity and synthesis of the lipoxins.\n\nResolvins are metabolites of omega-3 fatty acids, EPA, DHA, and 7\"Z\",10\"Z\",13\"Z\",16\"Z\",19\"Z\"-docosapentaenoic acid (n-3 DPA). All three of these omega-3 fatty acids are abundant in salt water fish, fish oils, and other seafood. n-3 DPA (also termed clupanodonic acid) is to be distinguished from its n-6 DPA isomer, i.e. 4\"Z\",7\"Z\",10\"Z\",13\"Z\",16\"Z\"-docosapentaenoic acid, also termed osbond acid.\n\nCells metabolize EPA (5\"Z\",8\"Z\",11\"Z\",14\"Z\",17\"Z\"-eicosapentaenoic acid) by a cytochrome P450 monooxygenase(s) (in infected tissues a bacterial cytochrome P450 may supply this activity) or aspirin-treated cyclooxygenase-2 to 18\"R\"-hydroperoxy-EPA which is then reduced to 18\"R\"-hydroxy-EPA and further metabolized by ALOX5 to 5\"S\"-hydroperoxy-18\"R\"-hydroxy-EPA; the later product may be reduced to its 5,18-dihydroxy product, RvE2, or converted to its 5,6-epoxide and then acted on by an epoxide hydrolase to form a 5,12,18-trihydroxy derivative, RvE1. In vitro, ALOX5 can convert 18\"S\"-HETE to the 18\"S\" analog of RvE1 termed 18\"S\"-RvE1. 18\"R\"-HETE or 18\"S\"-HETE may also be metabolized by ALOX15 to its 17\"S\"-hydroperoxy and then reduced to its 17\"S\"-hydroxy product, Rv3. Rv3, as detected in in vitro studies, is a dihydroxy mixture of 18\"S\"-dihydroxy (i.e. 18\"S\"-RvE3) and 18\"R\"-dihydroxy (i.e. 18\"R\"-RvE3) isomers, both of which, similar to the other aforementioned metabolites possess potent SPM activity in in vitro and/or animal models. In vitro studies find that ALOX5 can convert 18\"S\"-hydroperoxy-EPA to the 18\"S\"-hydroxy analog of RvE2 termed 18\"S\"-RvE2. 18\"S\"-RvE2, however has little or no SPM activity and is therefore not considered to be a SPM here. The following table lists the structural formulae (EPA stands for eicosapentaenoic acid), major activities, cellular receptor targets (where known), and Wikipedia pages giving further information on the activity and syntheses.\n\n\nCells metabolize DHA (4\"Z\",7\"Z\",10\"Z\",13\"Z\",16\"Z\",19\"Z\"-docosahexaenoic acid) by either ALOX15 or a cytochrome P450 monooxygenase(s) (bacteria may supply the cytochrome P450 activity in infected tissues) or aspirin-treated cyclooxygenase-2 to 17\"S\"-hydroperoxy-DHA which is reduced to 17\"S\"-hydroxy-DHA. ALOX5 metabolizes this intermediate to a) 7\"S\"-hydroperoxy,17\"S\"-hydroxy-DHA which is then reduced to its 7\"S\",17\"S\"-dihydroxy analog, RvD5; b) 4\"S\"-hydroperoxy,17\"S\"-hydroxy-DHA which is reduced to its 4\"S\",17\"S\"-dihydroxy analog, RvD6; c) 7\"S\",8\"S\"-epoxy-17\"S\"-DHA which is then hydrolyzed to 7,8,17-trihydroxy and 7,16,17-trihydorxy products, RvD1 and RvD2, respectively; and d) 4\"S\",5\"S\"-epoxy-17\"S\"-DHA which is then hydrolyzed to 4,11,17-trihydroxy and 4,5,17-trihydroxy products, RvD3 and RvD4, respectively. These six RvDs possess a 17\"S\"-hydroxy residue; however, if aspirin-treated cyclooxygenase-2 is the initiating enzyme, they contain a 17\"R\"-hydroxy residue and are termed 17\"R\"-RvDs, aspirin-triggered-RvDs, or AT-RvDs 1 thru 6. In certain cases, the final structures of these AT-RvDs is assumed by analogy to the structures of their RvD counterparts. Studies have found that most (and presumably all) of these metabolites have potent anti-inflammatory activity in vitro and/or in animal models. The following table lists the structural formulae, major activities with citations, cellular receptor targets, and Wikipedia pages giving further information on the activity and synthesis of these D series resolvins.\n\n\nn-3 DPA (i.e. 7\"Z\",10\"Z\",13\"Z\",16\"Z\",19\"Z\"-docosahexaenoic acid)-derived resolvins are recently identified SPM. In the model system used to identify them, human platelets pretreated with aspirin to form acetylated COX2 or the statin, atorvastatin, to form S-ntrosylated and thereby modify this enzyme's activity metabolize n-3 DPA to form a 13\"R\"-hydroperoxy-n-3 DPA intermediate which is passed over to nearby human neutrophils; these cell then metabolize the intermediate to four poly-hydroxyl metabolites termed resolvin T1 (RvT1), RvT2, RvT3, and RvT4. (The chirality of their hydroxyl residues has not yet been determined.) These T series resolvins also form in mice undergoing experimental inflammatory responses and have potent in vitro and in vivo anti-inflammatory activity; they are particularly effective in reducing the systemic inflammation as well as increasing the survival of mice injected with lethal doses of E. coli bacteria. Another set of newly described n-3 DPA resolvins, RvD1, RvD2, and RvD5, have been named based on their presumed structural analogies to the DHS-derived resolvins RvD1, RvD2, and RvD5, respectively. These three n-3 DPA-derived resolvins have not been defined with respect to the chirality of their hydroxyl residues or the Cis–trans isomerism of their double bonds but do possess potent anti-inflammatory activity in animal models and human cells; they also have protective actions in increasing the survival of mice subjected to E. coli sepsis. The following table lists the structural formulae (DPA stands for docosapentaenoic acid), major activities, cellular receptor targets (where known), and Wikipedia pages giving further information on the activity and syntheses.\n\nCells metabolize DHA by either ALOX15, by a bacterial or mammalian cytochrome P450 monooxygenase (Cyp1a1, Cyp1a2, or Cyp1b1 in mice; see CYP450#CYP families in humans and CYP450#animals) or by aspirin-treated cyclooxygenase-2 to 17\"S\"-hydroperoxy or 17\"R\"-hydroperoxy intermediates (see previous subsection); this intermediate is then converted to a 16\"S\",17\"S\"-epoxide which is then hydrolyzed (probably by a soluble epoxide hydrolase to protectin D1 (PD1, also termed neuroprotectin D1 [NPD1] when formed in neural tissue). PDX is formed by the metabolism of DHA by two serial lipoxygenases, probably a 15-lipoxygenase and ALOX12. 22-Hydroxy-PD1 (also termed 22-hydroxy-NPD1) is formed by the Omega oxidation of PD1 probably by an unidentified cytochrome P450 enzyme. While omega-oxidation products of most bioactive PUFA metabolites are far weaker than their precursors, 22-hydroxy-PD1 is as potent as PD1 in inflammatory assays. Aspirin-triggered-PD1 (AT-PD1 or AP-NPD1) is the 17\"R\"-hydroxyl diastereomer of PD1 formed by the initial metabolism of DHA by aspirin-treated COX-2 or possibly a cytochrome P450 enzyme to 17\"R\"-hydroxy-DHA and its subsequent metabolism possibly in manner similar to that which forms PD1. 10-Epi-PD1 (ent-AT-NPD1), the 10\"S\"-hydroxy diastereomer of PD1, has been detected in small amounts in human neutrophils. While its in vivo synthetic pathway has not been defined, 10-epi-PD1 has anti-inflammatory activity. The following table lists the structural formulae (DHA stands for docosahexaenoic acid), major activities, cellular receptor targets (where known), and Wikipedia pages giving further information on the activity and syntheses.\n\n\nn-3 DPA-derived protectins with structural similarities to PD1 and PD2 have been described, determined to be formed in vitro and in animal models, and termed PD1 and PD2, respectively. These products are presumed to be formed in mammals by the metabolism of n-3 DPA by an unidentified 15-lipoxygenase activity to 16,17-epoxide intermediate and the subsequent conversion of this intermediate to the di-hydroxyl products PD1 and PD2. PD1 has anti-inflammatory activity in a mouse model of peritonitis; PD2 has anti-inflammatory activity in an in vitro model. The following table lists the structural formulae (DPA stands for docosapentaenoic acid), major activities, cellular receptor targets (where known), and Wikipedia pages giving further information on the activity and syntheses.\n\nCells metabolize DHA by ALOX12, other lipoxygenase, (12/15-lipoxygenase in mice), or an unidentified pathway to a 13\"S\",14\"S\"-epoxide-4\"Z\",7\"Z\",9\"E\",11\"E\",16\"Z\",19\"Z\"-DHA intermediate (13\"S\",14\"S\"-epoxy-marisin MaR) and then hydrolyze this intermediate by an epoxide hydrolase activity (which ALOX 12 and mouse 12/15-lipoxygenase possess) to MaR1 and MaR2. During this metabolism, cells also form 7-epi-Mar1, i.e. the 7\"S\"-12\"E\" isomer of Mar1, as well as the 14\"S\"-hydroxy and 14\"R\"-hydroxy metabolites of DHA. The latter hydroxy metabolites can be converted by an unidentified cytochrome P450 enzyme to maresin like-1 (Mar-L1) and Mar-L2 by omega oxidation; alternatively, DHA may be first metabolized to 22-hydroxy-DHA by CYP1A2, CYP2C8, CYP2C9, CYP2D6, CYP2E1, or CYP3A4 and then metabolized through the cited epoxide-forming pathways to Mar-L1 and MaR-L2. Studies have found that these metabolites have potent anti-inflammatory activity in vitro and in animal models. The following table lists the structural formulae (DHA stands for docosahexaenoic acid), major activities, cellular receptor targets (where known), and Wikipedia pages giving further information on the activity and syntheses.\n\n\nn-3 DPA-derived maresins are presumed to be formed in mammals by metabolism of n-3 DPA by an undefined 12-lipoxygenase activity to a 14-hydroperoxy-DPA intermediated and the subsequent conversion of this intermediate to di-hydroxyl products which have been termed MaR1, MaR2, and MaR3 based on their structural analogies to MaR1, MaR2, and MaR3, respectively. MaR1 and MaR have been found to possess anti-inflammatory activity in in vitro assays of human neutrophil function. These n-3 DPA-derived maresins have not been defined with respect to the chirality of their hydroxyl residues or the cis–trans isomerism of their double bonds. The following table lists the structural formulae (DPA stands for docosapentaenoic acid), major activities, cellular receptor targets (where known), and Wikipedia pages giving further information on the activity and syntheses.\n\nThe following PUFA metabolites, while not yet formally classified as SPM, have been recently described and determined to have anti-inflammatory activity.\n\n10\"R\",17\"S\"-dihydroxy-7\"Z\",11\"E\",13\"E\",15\"Z\",19\"Z\"-docosapentaenoic acid (10\"R\",17\"S\"-diHDPA) has been found in inflamed exudates of animal models and possesses in vitro and in vivo anti-inflammatory activity almost as potently as PD1.\n\nn-6 DPA (i.e. 4\"Z\",7\"Z\",10\"Z\",13\"Z\",16\"Z\"-docosapentaenoic acid or osbond acid) is an isomer of n-3 DPA (clupanodonic acid) differing form the latter fatty acid only in the location of its 5 double bonds. Cells metabolize n-6 DPA to 7-hydroxy-DPA, 10,17-dihydroxy-DPA, and 7,17-dihydroxy-DPA; the former two metabolites have been shown to possess anti-inflammatory activity in in vitro and in animal model studies.\n\nCells metabolize DHA and n-3 DPA by COX2 to 13-hydroxy-DHA and 13-hydroxy-DPA products and by aspirin-treated COX2 to 17-hydroxy-DHA and 17-hydroxy-DPA products and may then oxidize these products to there corresponding oxo (i.e. ketone) derivatives, 13-oxo-DHA (also termed electrophilic fatty acid oxo derivative or EFOX-D6), 13-oxo-DPA (EFOX-D5), 17-oxo-DHA (17-EFOX-D6), and 17-oxo-DPA (17-EFOX-D3). These oxo metabolites directly activate the nuclear receptor Peroxisome proliferator-activated receptor gamma and possess anti-inflammatory activity as assesses in in vitro systems.\n\nDHA ethanolamide ester (the DHA analog of arachindonyl ethanolamide [i.e. Anandamide]) is metabolized to 10,17-dihydroxydocosahexaenoyl ethanolamide (10,17-diHDHEA) and/or 15-hydroxy-16(17)-epoxy-docosapentaenoyl ethanolamide (15-HEDPEA) by mouse brain tissue and human neutrophils. Both compounds possess anti-inflammatory activity in vitro; 15-HEDPEA also has tissue-protective effects in mouse models of lung injury and tissue reperfusion. Like anandamide, both compounds activated the Cannabinoid receptor.\n\nPUFA derivatives containing a Cyclopentenone structure are chemically reactive and can form adducts with various tissue targets, particularly proteins. Certain of these PUFA-cyclopentenones \nbind to the sulfur residues in the KEAP1 component of the KEAP1-NFE2L2 protein complex in the cytosol of cells. This negates KEAP1's ability to bind NFE2L2; in consequence, NFE2L2 becomes free to translocate to the nuclease and stimulate the transcription of genes that encode proteins active in detoxifying reactive oxygen species; this effect tends to reduce inflammatory reactions. PUFA-cyclopentenones may likewise react with the IKK2 component of the cytosolic IKK2-NFκB protein complex thereby inhibiting NFκB from stimulating the transcription of genes that encode various pro-inflammatory proteins. One or both of these mechanisms appears to contribute to the ability of certain highly reactive PUFA-cyclopenetenones to exhibit SPM activity. The PUFA-cyclopentenones include two prostaglandins, (PG) Δ12-PGJ2 and 15-deoxy-Δ12,14-PGJ2, and two isoprostanes, 5,6-epoxyisoprostane E2 and 5,6-epoxyisoprostane A2. Both PGJ2's are arachidonic acid-derived metabolites made by cyclooxygenases, primarily COX-2, which is induced in many cell types during inflammation. Both isoprostanes form non-enzymatically as a result the attack on the arachidonic acid bond to cellular phospholipids by reactive oxygen species; they are then release from the phospholipids to become free in attacking their target proteins. All four products have been shown to form and possess SPM activity in various in vitro studies of human and animal tissue as well as in in vivo studies of animal models of inflammation; they have been termed pro-resolving mediators of inflammation\n\nMice made deficient in their 12/15-lipoxygenase gene (Alox15) exhibit a prolonged inflammatory response along with various other aspects of a pathologically enhanced inflammatory response in experimental models of cornea injury, airway inflammation, and peritonitis. These mice also show an accelerated rate of progression of atherosclerosis whereas mice made to overexpress 12/15-lipoxygenase exhibit a delayed rate of atherosclerosis development. Alox15 overexpressing rabbits exhibited reduced tissue destruction and bone loss in a model of periodontitis. Similarly, Alox5 deficient mice exhibit a worsened inflammatory component, failure to resolve, and/or decrease in survival in experimental models of respiratory syncytial virus disease, Lyme disease, Toxoplasma gondii disease, and corneal injury. These studies indicate that the suppression of inflammation is a major function of 12/15-lipoxygenase and Alox5 along with the SPMs they make in at least certain rodent experimental inflammation models; although these rodent lipoxygenases differ from human ALOX15 and ALOX5 in the profile of the PUFA metabolites that they make as well as various other parameters (e.g. tissue distribution), these genetic studies allow that human ALOX15, ALOX5, and the SPMs they make may play a similar anti-inflammatory functions in humans.\n\nConcurrent knockout of the three members of the CYP1 family of Cytochrome P450 enzymes in mice, i.e. Cyp1a1, Cyp1a2, and Cyp1b1, caused an increase in the recruitment of neutrophils to the peritoneum in mice undergoing experimental peritonitis; these triple knockout mice also exhibited an increase in the peritoneal fluid LTB4 level and decreases in the levels of peritoneal fluid NPD1 as well as the precursors to various SPMS including 5-hydroxyeicosatetraenoic acid, 15-Hydroxyeicosatetraenoic acid, 18-hydroxyeicosapentaenoic acid, 17-hydroxydocosahexaenoic acid, and 14-hydroxydocosahexaenoic. These results support the notion that Cyp1 enzymes contribute to the production of certain SPMs and inflammatory responses in mice; CYP1 enzymes may therefore play a similar role in humans.\n\nIn a randomized controlled trial, AT-LXA4 and a comparatively stable analog of LXB4, 15\"R/S\"-methyl-LXB4, reduced the severity of eczema in a study of 60 infants. A synthetic analog of ReV1 is in clinical phase III testing (see Phases of clinical research) for the treatment of the inflammation-based dry eyesyndrome; along with this study, other clinical trials (NCT01639846, NCT01675570, NCT00799552 and NCT02329743) using an RvE1 analogue to treat various ocular conditions are underway. RvE1, Mar1, and NPD1 are in clinical development studies for the treatment of neurodegenerative diseases and hearing loss. And, in a single study, inhaled LXA4 decreased LTC4-initiated bronchoprovocation in patients with asthma.\n", "id": "50704695", "title": "Specialized pro-resolving mediators"}
{"url": "https://en.wikipedia.org/wiki?curid=50871925", "text": "R bodies\n\nR bodies (from \"refractile\" bodies, also R-bodies) are polymeric protein inclusions formed inside the cytoplasm of bacteria. Initially discovered in kappa particles, bacterial endosymbionts of the ciliate \"Paramecium\", R bodies (and genes encoding them) have since been discovered in a variety of taxa.\n\nAt neutral pH, type 51 R bodies resemble a coil of ribbon approximately 500 nm in diameter and approximately 400 nm deep. Encoded by a single operon containing four open reading frames, R bodies are formed from two small structural proteins, RebA and RebB. A third protein, RebC, is required for the covalent assembly of these two structural proteins into higher-molecular weight products, visualized as a ladder on an SDS-PAGE gel.\n\nAt low pH, Type 51 R bodies undergo a dramatic structural rearrangement. Much like a paper yo-yo, the ribbon extends (from the center) to form hollow tube with pointed ends that can reach up to 20μm in length.\n\nOther types of R bodies from different bacterial species vary in their size, ribbon morphology, and triggers for extension.\n\nWhen kappa particles shed from a killer paramecium are ingested, R bodies extend within the acidic food vacuole of the predatory paramecium, distending and rupturing the membrane. This liberates the contents of the food vacuole into the cytoplasm of the paramecium. While feeding kappa particles to sensitive paramecium results in the death of paramecium, feeding purified R bodies or R bodies recombinantly expressed in \"E. coli\" is not toxic. Thus, R bodies are thought to function as a toxin delivery system.\n\nR bodies are also capable of rupturing \"E. coli\" spheroplasts, demonstrating that they can rupture membranes in a foreign context, and they can be engineered to extend at a variety of different pH levels.\n", "id": "50871925", "title": "R bodies"}
{"url": "https://en.wikipedia.org/wiki?curid=13986656", "text": "Neuroprotectin\n\nNeuroprotectin D1 (NPD1) (10\"R\",17\"S\"-dihydroxy-4\"Z\",7\"Z\",11\"E\",13\"E\",15\"Z\",19\"Z\"-docosahexaenoic acid) also known as Protectin D1 (PD1) is a docosanoid derived from the polyunsaturated fatty acid (PUFA) docosahexaenoic acid (DHA), which is a component of fish oil and the most important omega-3 PUFA. Like other members of the specialized proresolving mediators class of PUFA metabolites, NPD1 exerts potent anti-inflammatory and anti-apoptotic/neuroprotective bioactivity. Other neuroprotectins with similar activity include: PDX (10\"R\",17\"S\"-dihydroxy-4\"Z\",7\"Z\",11\"E\",13\"Z\",15\"E\",19\"Z\"-docosahexaenoic acid); 20-hydroxy-PD1 (10\"R\",17\"S\",20-trihydroxy-4\"Z\",7\"Z\",11\"E\",13\"E\",15\"Z\",19\"Z\"-docosahexaenoic acid); and 10-epi-PD1 (10\"R\",17\"S\"-Dihydroxy-4\"Z\",7\"Z\",11\"E\",13\"E\",15\"Z\",19\"Z\"-docosahexaenoic acid). The activity of neuroprotectin-like metabolite, 17-epi-PD1 (10\"R\",17\"R\"-dihydroxy-4\"Z\",7\"Z\",11\"E\",13\"E\",15\"Z\",19\"Z\"-docosahexaenoic acid), has not yet been reported.\n\nNeuroprotectins A and B, which are bicyclohexapeptides, are to be distinguished structurally and mechanistically from the neuroprotectin D's.\n\n", "id": "13986656", "title": "Neuroprotectin"}
{"url": "https://en.wikipedia.org/wiki?curid=13935428", "text": "Docosanoid\n\nIn biochemistry, docosanoids are signaling molecules made by the metabolism of twenty-two-carbon fatty acids (EFAs), especially the omega-3 fatty acid, Docosahexaenoic acid (DHA) (i.e. 4\"Z\",7\"Z\",10\"Z\",13\"Z\",16\"Z\",19\"Z\"-docosahexaenoic acid) by lipoxygenase, cyclooxygenase, and cytochrome P450 enzymes. Other docosanoids are metabolites of n-3 docosapentaenoic acid (i.e. 7\"Z\",10\"Z\",13\"Z\",16\"Z\",19\"Z\"-docosahexaenoic acid), n-6 DHA (i.e. 4\"Z\",7\"Z\",10\"Z\",13\"Z\",16\"Z\"-docosahexaenoic acid, and docosatetraenoic acid (i.e. 7\"Z\",10\"Z\",13\"Z\",16\"Z\"-docosatetraenoic acid, DTA, or adrenic acid). Prominent docosanoid metabolites of DHA and n-3 DHA are members of the specialized proresolving mediator class of polyunsaturated fatty acid metabolites that possess potent anti-inflammation, tissue healing, and other activities (see specialized proresolving mediators).\n\nPotently bioactive agents of the specialized proresolving mediator class include:\n\nThese DHA metabolites possess anti-inflammation and tissue-protection activities in animal models of inflammatory diseases; they are proposed to inhibit innate immune responses and thereby to protect from and to resolve a wide range of inflammatory responses in animals and humans. These metabolites are also proposed to contribute to the anti-inflammatory and other beneficial effects of dietary omega-3 fatty acids by being metabolized to them.\n\nDHA can be converted non-enzymatically by free radical-mediated peroxidation to 8 different neurofuran regioisomers termed neuroprostanes and neurofuranes including 4-, 7-, 10-, 11-, 13-, 14-, 17-, and 20-series neurofurans/neuroporstanes for a total of 128 different racemic compounds. The most studied DHA-derived of these products are members of the 4-series, neurofuran 4-Fneuroprostane and 4(\"RS\")-ST-Δ6-8-neurofurane. These metabolites have been used mainly as biomarkers of oxidative stress that are formed in nerve tissues of the central nervous system.\n\nCells metabolize DHA to 17\"S\"-hydroperoxy-4\"Z\",7\"Z\",10\"Z\",13\"Z\",15\"E\",19\"Z\"-docahexaenoicacid acid (17-HpDHA) and then rapidly reduce this hydroperoxide to 17\"S\"-hydroxy-4\"Z\",7\"Z\",10\"Z\",13\"Z\",15\"E\",19\"Z\"-docahexaenoicacid acid (17-HDHA) and similarly metabolize DHA to 13\"S\"-hydroperoxy-4\"Z\",7\"Z\",10\"Z\",14\"Z\",16\"Z\",19\"Z\"-docahexaenoicacid acid (13-HpDHA) and then to 13\"S\"-hydroxy-4\"Z\",7\"Z\",10\"Z\",14\"Z\",16\"Z\",19\"Z\"-docahexaenoicacid acid (13-HDHA). 17-HDHA exhibits potent in vitro as well as in vivo (animal model) anti-inflammatory activity while 17-HpDHA and to a lesser extent 17-HDHA inhibit the growth of cultured human breast cancer cells. Other SPM docosanoids, e.g. RvD1 and RvD2, have anti-growth effects against cancer cells in animal models.\n\nCells can metabolize DHA to products that possess an oxo (i.e. ketone) residue. These products include 13-oxo-DHA (termed EFOXD6) and 17-oxo-DHA (termed 18-EFOXD6). Both oxo metabolites possess anti-inflammatory activity as assesses in in vitro systems (see Specialized proresolving mediators#Oxo-DHA and oxo-DPA metabolites).\n\nCyclooxygenase and Cytochrome P450 oxidase act upon Docosatetraenoic acid to produce dihomoprostaglandins and dihomo-epoxyeicosatrienoic acids and dihomo-EETs.\n", "id": "13935428", "title": "Docosanoid"}
{"url": "https://en.wikipedia.org/wiki?curid=50986802", "text": "Dihydroxy-E,Z,E-PUFA\n\nDihydroxy-\"E\",\"Z\",\"E\"-PUFA are metabolites of polyunsaturated fatty acids (PUFA) that possess two hydroxyl residues and three in series conjugated double bonds having the \"E\",\"Z\",\"E\" cis-trans configuration. These recently classified metabolites are distinguished from the many other dihydroxy-PUFA with three conjugated double bonds that do not have this critical \"E\",\"Z\",\"E\" configuration: they inhibit the function of platelets and therefore may be involved in controlling and prove useful for inhibiting human diseases which involve the pathological activation of these blood-borne elements.\n\nDihydroxy-\"E\",\"Z\",\"E\"-PUFA are metabolites of a) docosahexaenoic acid (DHA, i.e. 4\"Z\",7\"Z\",10\"Z\",13\"Z\",16\"Z\",19\"Z\"-docosahexaenoic acid), b) α-Linolenic acid (ALA, i.e. \"9\"Z,12\"Z\",15\"Z\"-octadecatrienoic acid), an c) arachidonic acid (AA); \"E\",\"Z\",\"E\"-DHA and \"E\",\"Z\",\"E\" AA metabolites are termed poxytrins; ALA metabolites are termed linotrins. The first and perhaps most prominent member of this class of metabolites is protectin DX (PDX; i.e. 10\"R\",17\"S\"-dihydroxy-4\"Z\",7\"Z\",11\"E\",13\"Z\",15\"E\",19\"Z\"-docosahexaenoic acid). PDX is an isomer of (and sometimes confused with) neuroprotectin D1 (NPD1; i.e. 10\"R\",17\"S\"-dihydroxy-4\"Z\",7\"Z\",11\"E\",13\"E\",15\"Z\",19\"Z\"-doxahexaenoic acid; also termed protectin D1 [PD1]). NPD1 is structurally identical to PDX except that its three conjugated double bonds have the \"E\",\"E\",\"Z\" configuration as opposed to the \"E\",\"Z\",\"E\" configuration of PDX. Both compounds are members of the specialized proresolving mediators class of PUFA metabolites in that they possess potent anti-inflammatory activity; however, only PDX inhibited human platelet aggregation responses. Subsequent studies found that various other dihydroxy-\"E\",\"Z\",\"E\"-double bound-configured PUFA but not those with \"E\",\"E\",\"E\" or \"E\",\"E\",\"Z\" double bond configurations share with PDX anti-platelet activity. Cells make PDX by metabolizing DHA by double oxygenation a 15-lipoxygenase to form the 10\"R\",17\"S\"-hydroxperoxy intermediated which is reduced its 10\"R\",17\"S\"-hydroxyl product, PDX, probably by cytosolic GPX1 (i.e. glutathione peroxidase 1). Serial metabolism two different lipoxygenases or a lipoxygenase and a cytochrome P45) on PUFA possessing three double bonds in a 1\"Z\",4\"Z\",7\"Z\" configuration may also make a 1,7-dihydroxy 2\"E\",4\"Z\",6\"E\" product.\n\nOther platelet-inhibiting dihydroxy-\"E\",\"Z\",\"E\"-PUFA are: 10\"R\",17\"S\"-dihydroxy-4\"Z\",7\"Z\",11\"E\",13\"Z\",15\"E\",19\"Z\"-docosahexaenoic acid (10\"R\",17\"S\"-diHDHA); 8\"S\",15\"S\"-dihydroxy-5\"Z\",9\"E\",11\"Z\",13\"E\"-eicosatetraenoic acid (8\"S\",15\"S\"-diHETE); 9\"S\",16\"S\"-10\"E\",12\"Z\",14\"E\"-octadecatrienoic acid (linotrin-1); and 9\"R\",16\"S\"-10\"E\",12\"Z\",14\"E\"-octadecatrienoic acid (linotrin-2). 10\"R\",17\"S\"-diHDHA is the 10\"R\" diastereomer of PDX with the 10\"R\" hydroxyl residue being formed by aspirin-treated COX-2 or a cytochrome P450. Guinea pig tissues make 8\"S\",15\"S\"-diHETE probably by double oxygenation of AA by a 15-lipoxygenase (probably ALOX15) or serial metabolism by two enzymes. Linotrin-1 and linotrin-2 are among the four isomeric metabolites produced by incubating ALA with ALOX15B. The extent to which the linotrins form in cells or in vito is not clear.\n\nStimulating agents such as collagen depend to platelets to make and release thromboxane A2 (TXA2) to mediate and/or enhance their aggregating activity. 10\"R\",17\"S\"-diHDHA and to slightly lesser degrees 10\"R\",17\"S\"-diHDHA and PDX inhibit the human platelet aggregation response to collagen at ≥ 100–200 nanomolar concentrations. This inhibition appeared to reflect the ability of these metabolites to a) inhibit the activities of COX-1 and COX-2 thereby blocking the production of TXA2 and b) interfere with the activation of the TXA2 receptor (Thromboxane receptor) by TXA2. The linotrins appear to have similar or slightly lower potencies than as well as to use mechanism similar to the aforementioned metabolites. These \"E,Z,E\" PUFA are 20- to 100-fold stronger in inhibiting human platelet aggregation than two mono-hydroxyl-containing eicosanoids, 5-HETE and 12-HETE, which contain an \"E,Z\" conjugated double bond configuration.\n\nOther biologically active dihydroxy-\"E\",\"Z\",\"E\"-PUFA have not been tested for but, based on the studies cited above, are projected to possess anti-platelet activity. 10\"S\",17\"S\"-Dihydroxy-4\"Z\",7\"Z\",11\"E\",13\"Z\",15\"E\",19\"Z\"-docosahexaenoic acid. This compound is the 13\"Z\" cis-trans isomer of 10-epi-protectin D (which possesses a 13\"E\" double bond; see specialized proresolving mediators#DHA-derived protectins/neuroprotectins). Like 10-epi-protectin D1, this docosahexaenoic acid metabolite is formed by stimulated human leukocytes in vitro and possess specialized proresolving mediator (SPM) anti-inflammatory activity. A maresin termed MaR isomer or 7-epi-MaR1, i.e. 7\"S\",14\"S\"-dihydroxy-4\"Z\",8\"E\",10\"Z\",12\"E\",16\"Z\",19\"Z\"-docosahexaenoic acid (see specialized proresolving mediators#DHA-derived Maresins), likewise possesses SPM activity.\n", "id": "50986802", "title": "Dihydroxy-E,Z,E-PUFA"}
{"url": "https://en.wikipedia.org/wiki?curid=19425495", "text": "Microtrabeculae\n\nIn cell biology, microtrabeculae were a hypothesised fourth element of the cytoskeleton (the other three being microfilaments, microtubules and intermediate filaments), proposed by Keith Porter based on images obtained from high-voltage electron microscopy of whole cells in the 1970s. The images showed short, filamentous structures of unknown molecular composition associated with known cytoplasmic structures. It is now generally accepted that microtrabeculae are nothing more than an artifact of certain types of fixation treatment, although the complexity of the cell's cytoskeleton is not yet fully understood.\n", "id": "19425495", "title": "Microtrabeculae"}
{"url": "https://en.wikipedia.org/wiki?curid=2354497", "text": "Heat shock\n\nIn biochemistry, heat shock is the effect of subjecting a cell to a temperature that is greater than the optimal temperature range of function of the cell. Heat shock refers to cellular exposure to rapid stress changes such as temperature, toxins, oxidative stress, heavy metals, and pathogenic infections. Specifically temperature induced heat shock, even of a few degrees, has the potential to disrupt proper protein folding. As a result, proteins can fold incorrectly, or become entangled which can results in nonspecific aggregation. Other cellular damages induced by heat shock include cytoskeletal rearrangement, changes in organelle localization, decrease in ATP production, unsafe drop in cellular pH levels, decreased translation of proteins, and changes in RNA splicing. Introduction of heat shock to cells elicits the molecular response, the heat shock response (HSR), which repairs damages caused by stressors such as protein misfolding and protein aggregation.\n\nThe cellular response to heat shock damage, the heat shock response, includes the transcriptional up-regulation of genes encoding heat shock proteins (HSPs) as part of the cell's internal repair mechanism. The effects of stressors such as temperature changes and toxins are counteracted by these HSPs, that upon activation respond to heat, cold and oxygen deprivation by activating several cascade pathways. HSPs are also present in cells under perfectly normal conditions, but an elevation in stress levels for the cell promotes an increase in their production levels by activating heat-shock genes at levels higher than normal. Some HSPs, called chaperones, also have increased production levels when the cell faces various stress factors. Chaperones functions includes making sure that the cell’s proteins are properly folded in the correct conformation and they ensure this by facilitating protein folding using their substrate binding domain. An example of chaperons are the HSP70 (heat shock protein) chaperones. For example, HSPs help new or misfolded proteins to fold into their correct three-dimensional conformations, which is essential for their function. They also shuttle proteins from one compartment to another inside the cell, and target old or terminally misfolded proteins to proteases for degradation. Heat shock proteins are also believed to play a role in the presentation of pieces of proteins (or peptides) on the cell surface to help the immune system recognize diseased cells. 5 major families of HSPs are recognized: the Hsp70 (DnaK) family, the chaperonins (GroEL and Hsp60), the Hsp90 family, the Hsp100 (Clp) family and the small HSP (sHSP) family. Other proteins such as, protein disulfide isomerase and calnexin/calreticulin, have chaperone functions and assist protein folding in the Endoplasmic Reticulum.\n\nThe up-regulation of HSPs during heat shock is generally controlled by a single transcription factor; in eukaryotes this regulation is performed by heat shock factor (HSF), while σ is the heat shock sigma factor in \"Escherichia coli\". Under normal conditions HSF1 resides as a monomer, but when stress induces protein damage HSF1 is activated to trimerize. This trimer of HSF1 localizes to the nucleus, and here binds to the heat shock element in the promoter sequence of heat shock genes.\n\nIn fish that survive at 0 °C, heat shock can be induced with temperatures as low as 5 °C, whereas thermophilic bacteria that proliferate at 50 °C will not express heat shock proteins until temperatures reach approximately 60 °C. The process of heat shocking can be done in a CO incubator, O incubator, or a hot water bath.\n\n", "id": "2354497", "title": "Heat shock"}
{"url": "https://en.wikipedia.org/wiki?curid=4336748", "text": "George Otto Gey\n\nGeorge Otto Gey (July 6, 1899 – November 8, 1970) was the cell biologist at Johns Hopkins Hospital who is credited with propagating the HeLa cell line. He spent over 35 years developing numerous scientific breakthroughs under the Johns Hopkins Medical School and Hospital.\n\nGey (pronounced \"Guy\") was born in Pittsburgh, Pennsylvania on July 6, 1899, the son of German immigrants Frank and Emma Gey. He had an older brother Frank and younger sister Henrietta. Gey's parents immigrated from Germany, and according to the 1910 United States Census, they lived in suburban Pittsburgh.\n\nGey graduated Peabody High School, and received undergraduate degree in biology from the University of Pittsburgh in 1920. Around 1926 he married Margaret K. (1900–1989), and they later moved to Baltimore where he would earn his medical degree from Johns Hopkins University. After graduating Hopkins in 1933, Gey immediately began his 37 year teaching career at the Johns Hopkins Medical School.\n\nHeLa Cell Line\n\nGey isolated the cells taken from a cervical tumor found in a woman named Henrietta Lacks in 1951. These cells proved to be very unusual in that they could grow in culture medium that was constantly stirred using the roller drum (a technique developed by Gey), and they did not need a glass surface to grow, and therefore they had no space limit. Once Gey realized the longevity and hardiness of the HeLa cells, he began sharing them with scientists all over the world, and the use of the HeLa cell line became widespread. The cells were used in the development of the polio vaccine, lead to the first clone of a human cell, helped in the discovery that humans have 46 chromosomes, and were used to develop in vitro fertilization. By the time Gey published a short abstract claiming some credit for the development of the line (after much nagging from his wife, Margaret), the cells were already being used by scientists all over the world.\n\nControversies\n\nDue to the unusual growth capabilities of the HeLa cell line, it contaminated many cell cultures and ruined years of research, as discovered by Stanley Gartler in 1966. The cells, as it turned out, could float on dust particles and could be transferred on unwashed hands or used pipettes, and therefore end up in other cell cultures. Because the cells were so pervasive, just one could lead to the complete take-over of a culture.\n\nThere was also the controversy surrounding how the cells were retrieved, as made famous by the book, The Immortal Life of Henrietta Lacks. The cells were taken from Henrietta Lacks without her knowledge or permission, and her family remained unaware until the 1970's. He was careful in keeping her actual name secret, and it was not made public until after his death.\n\nRoller Drum Technique\n\nGey is also credited for creating the roller drum, which was essential for the development of the HeLa cell line. This machine was one of the first to help nurture cell cultures. The roller drum consisted of various holes where tissues and their appropriate growth substances were all located. The drum spun in order to mix the substances and once an hour allow the cultures to be exposed to the environment until the drum rolled again and rebathed the cells in liquid. Gey is also noted to be one of the first to document cell division and growth on film. He devised a time lapse camera that stood twelve feet, built out of spare parts from a nearby junkyard, with a temperature controlled incubator.\n\nDuring Gey's tenure at Johns Hopkins, he founded and was the first president of the Tissue Culture Association (TCA). The main object of the TCA was to introduce scientists to tissue, culture methodology, and train technical personnel. TCA is known today as the Society for In Vitro Biology, which currently embraces over 1,500 members. Through years of fundraising Gey was able to raise the millions of dollars needed to open the permanent home for the TCA, W. Alton Jones Cell Science Center at Lake Placid, New York. A few of the medical advances achieved through the TCA include the clone growth of rodent cells, the development of time lapse cinematography, and the electron microscopic examination of cell structures.\n\nGey died from pancreatic cancer on November 8, 1970 in Baltimore, Maryland, less than a year after his initial diagnosis. When undergoing an emergency procedure for his cancer, doctors found that the cancer had spread to his lymph nodes, lungs and heart, thus making his cancer inoperable. Gey traveled to New York City to enroll himself in an experimental chemotherapy trial. He wanted doctors to try to cut out a piece of the cancer in his liver to grow a new cell line for cancer research. The doctors, however, didn't listen to him during the surgery and he was \"furious\" when he woke up, although he died later.\n\nAn important legacy Gey left on the scientific world was his teaching. In his lab, the belief was that \"the way to kill your cell cultures was by using a sloppy technique\". He trained hundreds of researchers around the world in his sterile techniques and introduced the world to cautious studies. Although, Gey was not given the chance to publish papers on his research or create patents before his untimely death, he left a legacy of understanding cancer, and began the foundation from which cancer research and cell culture has grown from.\n\n\n", "id": "4336748", "title": "George Otto Gey"}
{"url": "https://en.wikipedia.org/wiki?curid=6339", "text": "Cell biology\n\nCell biology or cytology or cytobiology, (from the Greek κυτος, \"kytos\", \"vessel\") is a branch of biology that studies the different structures and functions of the cell and focuses mainly on the idea of the cell as the basic unit of life. Cell biology explains the structure, organization of the organelles they contain, their physiological properties, metabolic processes, signaling pathways, life cycle, and interactions with their environment. This is done both on a microscopic and molecular level as it encompasses prokaryotic cells and eukaryotic cells. Knowing the components of cells and how cells work is fundamental to all biological sciences; it is also essential for research in bio-medical fields such as cancer, and other diseases. Research in cell biology is closely related to genetics, biochemistry, molecular biology, immunology, and developmental biology.\n\nThe study of the cell is done on a molecular level; however, most of the processes within the cell are made up of a mixture of small organic molecules, inorganic ions, hormones, and water. Approximately 75–85% of the cell's volume is due to water making it an indispensable solvent as a result of its polarity and structure. These molecules within the cell, which operate as substrates, provide a suitable environment for the cell to carry out metabolic reactions and signalling. The cell shape varies among the different types of organisms, and are thus then classified into two categories: eukaryotes and prokaryotes. In the case of eukaryotic cells – which are made up of animal, plant, fungi, and protozoa cells – the shapes are generally round and spherical, while for prokaryotic cells – which are composed of bacteria and archaea – the shapes are: spherical (cocci), rods (bacillus), curved (vibrio), and spirals (\"spirochetes)\". \n\nCell biology focuses more on the study of eukaryotic cells, and their signalling pathways, rather than on prokaryotes which is covered under microbiology. The main constituents of the general molecular composition of the cell includes: proteins and lipids which are either free-flowing or membrane-bound, along with different internal compartments known as organelles. This environment of the cell is made up of hydrophilic and hydrophobic regions which allows for the exchange of the above-mentioned molecules and ions. The hydrophilic regions of the cell are mainly on the inside and outside of the cell, while the hydrophobic regions are within the phospholipid bilayer of the cell membrane. The cell membrane consists of lipids and proteins, which accounts for its hydrophobicity as a result of being non-polar substances. Therefore, in order for these molecules to participate in reactions, within the cell, they need to be able to cross this membrane layer to get into the cell. They accomplish this process of gaining access to the cell via: osmotic pressure, diffusion, concentration gradients, and membrane channels. Inside of the cell are extensive internal sub-cellular membrane-bounded compartments called organelles.\n\n\nThe growth process of the cell does not refer to the size of the cell, but instead the density of the number of cells present in the organism at a given time. Cell growth pertains to the increase in the number of cells present in an organism as it grows and develops; as the organism gets larger so too does the number of cells present. Cells are the foundation of all organisms, they are the fundamental unit of life. The growth and development of the cell are essential for the maintenance of the host, and survival of the organisms. For this process the cell goes through the steps of the cell cycle and development which involves cell growth, DNA replication, cell division, regeneration, specialization, and cell death. The cell cycle is divided into four distinct phases, G1, S, G2, and M. The G phases – which is the cell growth phase – makes up approximately 95% of the cycle. The proliferation of cells is instigated by progenitors, the cells then differentiate to become specialized, where specialized cells of the same type aggregate to form tissues, then organs and ultimately systems. The G phases along with the S phase – DNA replication, damage and repair – are considered to be the interphase portion of the cycle. While the M phase (mitosis and cytokinesis) is the cell division portion of the cycle. The cell cycle is regulated by a series of signalling factors and complexes such as CDK's, kinases, and p53. to name a few. When the cell has completed its growth process, and if it is found to be damaged or altered it undergoes cell death, either by apoptosis or necrosis, to eliminate the threat it causes to the organism's survival.\n\n\nCells may be observed under the microscope, using several different techniques; these include optical microscopy, transmission electron microscopy, scanning electron microscopy, fluorescence microscopy, correlative light-electron microscopy, and confocal microscopy.\n\nThere are several different methods used in the study of cells:\n\nPurification of cells and their parts\nPurification may be performed using the following methods:\n\nPractical job applications for a degree in Cell Molecular Biology includes the following.\n\n\n\n\n\n\n\n", "id": "6339", "title": "Cell biology"}
{"url": "https://en.wikipedia.org/wiki?curid=52001960", "text": "Contact guidance\n\nContact guidance refers to a phenomenon for which the orientation of cells and stress fibers is influenced by geometrical patterns such as nano/microgrooves on substrates, or collagen fibers in gels and soft tissues. This phenomenon was discovered in 1912, and the terminology was introduced in 1945, but it is with the development of tissue engineering that researchers drew increasing attention on this topic, seeing the potential of contact guidance in influencing the morphology and organization of cells. Nevertheless, the biological processes underlying contact guidance are still unclear.\n\nWhen cells are seeded onto flat substrates, they generally exhibit a random orientation. Conversely, when substrates have topographical patterns, the orientation of cells cultured on these surfaces is influenced by these geometrical cues. For example, if a substrate has nano/microgrooves running parallel to each other, cells orient along the direction of these topographical patterns. Therefore, cells seem to be able to sense the morphological characteristics of their surrounding and consequently respond by adopting the orientation of topographical stimuli. A similar effect can be obtained when cells are cultured on flat surfaces with lines of proteins printed on top (to which cells can adhere), interspersed by repellent lines; also in that case, cells align along the patterns.\nIt has been observed that the phenomenon of contact guidance on microgrooved surfaces is influenced by the groove width. For instance, osteoblast-like cells align along the nanogrooves only for grooves wider than 75 nm. A similar behavior has been observed with other cell types, such as fibroblasts, which align along these topographical patterns when the grooves are wider than 150 nm. On the other hand, too large values of groove widths can also decrease the effects of contact guidance \n\nCells can orient in response to contact guidance also when located inside three-dimensional structures, such as collagen gels, scaffolds, and soft tissues. For those conditions, it has been demonstrated that the geometrical cues provided by collagen or scaffold fibers are able to influence the orientation of cells. For example, it has been observed that endothelial colony forming cells align along the direction of the fibers present in electrospun scaffolds. Similarly, it has been demonstrated that the collagen fibers present in collagen gels and soft tissues can influence cell alignment, providing the most important stimulus in terms of cell orientation \n\nRecent research has highlighted the importance of cellular alignment for the mechanical properties and functionality of the prostheses developed using the principles of tissue engineering. Currently, scientists are investigating the mechanisms and potential of contact guidance to control cellular alignment, which would ultimately lead to the control of their cellular forces and certain aspects of collagen remodeling.\n\nMany researchers have formulated hypotheses on the biological mechanisms determining contact guidance. In general, cellular contraction, stress fibers and focal adhesions seem to play an important role. Recently, a computational model has been developed that is able to simulate the re-alignment of cells and stress fibers on top of grooved surfaces. Briefly, it has been supposed that cells, once seeded, form focal adhesions on top of the ridges and not above the grooves. Once formed, the focal adhesions produce a signal that starts to diffuse into the cell inducing stress fiber assembly. At this point, there are two different possibilities, depending on the groove size. On the one hand, when the groove size is small, the intracellular signal produced by focal adhesions on the ridges can homogenously reach all locations in the cell. In that case, the stress fiber assembly is isotropic, and these fibers can pull on their surroundings in an isotropic fashion, and consequently the resulting cell shape is isotropic (without a preferred alignment). On the other hand, when the groove size is relatively large, the intracellular signal cannot reach the locations of the cell situated on top of the grooves, as diffusion is limited. As a result, stress fibers form only close to the ridges, and these acto-myosin bundles pull on their surroundings anisotropically. Due to the anisotropic cellular contraction, stress fibers and cells align along the direction of the microgrooves. Further experiments are necessary to validate this theory.\n", "id": "52001960", "title": "Contact guidance"}
{"url": "https://en.wikipedia.org/wiki?curid=1369210", "text": "Bioenergetics\n\nBioenergetics is a field in biochemistry and cell biology that concerns energy flow through living systems. This is an active area of biological research that includes the study of the transformation of energy in living organisms and the study of thousands of different cellular processes such as cellular respiration and the many other metabolic and enzymatic processes that lead to production and utilization of energy in forms such as adenosine triphosphate (ATP) molecules. That is, the goal of bioenergetics is to describe how living organisms acquire and transform energy in order to perform biological work. The study of metabolic pathways is thus essential to bioenergetics.\n\nBioenergetics is the part of biochemistry concerned with the energy involved in making and breaking of chemical bonds in the molecules found in biological organisms. It can also be defined as the study of energy relationships and energy transformations and transductions in living organisms. The ability to harness energy from a variety of metabolic pathways is a property of all living organisms. Growth, development, anabolism and catabolism are some of the central processes in the study of biological organisms, because the role of energy is fundamental to such biological processes. Life is dependent on energy transformations; living organisms survive because of exchange of energy between living tissues/ cells and the outside environment. Some organisms, such as autotrophs, can acquire energy from sunlight (through photosynthesis) without needing to consume nutrients and break them down. Other organisms, like heterotrophs, must intake nutrients from food to be able to sustain energy by breaking down chemical bonds in nutrients during metabolic processes such as glycolysis and the citric acid cycle. Importantly, as a direct consequence of the First Law of Thermodynamics, autotrophs and heterotrophs participate in a universal metabolic network—by eating autotrophs (plants), heterotrophs harness energy that was initially transformed by the plants during photosynthesis.\n\nIn a living organism, chemical bonds are broken and made as part of the exchange and transformation of energy. Energy is available for work (such as mechanical work) or for other processes (such as chemical synthesis and anabolic processes in growth), when weak bonds are broken and stronger bonds are made. The production of stronger bonds allows release of usable energy.\n\nAdenosine triphosphate (ATP) is the main \"energy currency\" for organisms; the goal of metabolic and catabolic processes are to synthesize ATP from available starting materials (from the environment), and to break- down ATP (into adenosine diphosphate (ADP) and inorganic phosphate) by utilizing it in biological processes. In a cell, the ratio of ATP to ADP concentrations is known as the \"energy charge\" of the cell. A cell can use this energy charge to relay information about cellular needs; if there is more ATP than ADP available, the cell can use ATP to do work, but if there is more ADP than ATP available, the cell must synthesize ATP via oxidative phosphorylation.\n\nLiving organisms produce ATP from energy sources via oxidative phosphorylation. The terminal phosphate bonds of ATP are relatively weak compared with the stronger bonds formed when ATP is hydrolyzed (broken down by water) to adenosine diphosphate and inorganic phosphate. Here it is the thermodynamically favorable free energy of hydrolysis that results in energy release; the phosphoanhydride bond between the terminal phosphate group and the rest of the ATP molecule does not itself contain this energy. An organism's stockpile of ATP is used as a battery to store energy in cells. Utilization of chemical energy from such molecular bond rearrangement powers biological processes in every biological organism.\n\nLiving organisms obtain energy from organic and inorganic materials; i.e. ATP can be synthesized from a variety of biochemical precursors. For example, lithotrophs can oxidize minerals such as nitrates or forms of sulfur, such as elemental sulfur, sulfites, and hydrogen sulfide to produce ATP. In photosynthesis, autotrophs produce ATP using light energy, whereas heterotrophs must consume organic compounds, mostly including carbohydrates, fats, and proteins. The amount of energy actually obtained by the organism is lower than the amount present in the food; there are losses in digestion, metabolism, and thermogenesis.\n\nEnvironmental materials that an organism intakes are generally combined with oxygen to release energy, although some can also be oxidized anaerobically by various organisms. The bonds holding the molecules of nutrients together and in particular the bonds holding molecules of free oxygen together are relatively weak compared with the chemical bonds holding carbon dioxide and water together. The utilization of these materials is a form of slow combustion because the nutrients are reacted with oxygen (the materials are oxidized slowly enough that the organisms do not actually produce fire). The oxidation releases energy because stronger bonds (bonds within water and carbon dioxide) have been formed. This net energy may evolve as heat, which may be used by the organism for other purposes, such as breaking other bonds to do chemistry required for survival.\n\n\nThe free energy (ΔG) gained or lost in a reaction can be calculated as follows: ΔG = ΔH − TΔS\nwhere ∆G = Gibbs free energy, ∆H = enthalpy, T = temperature (in kelvins), and ∆S = entropy.\n\n\n\n\n\n\n\nIn August 1960, Robert K. Crane presented for the first time his discovery of the sodium-glucose cotransport as the mechanism for intestinal glucose absorption. Crane's discovery of cotransport was the first ever proposal of flux coupling in biology and was the most important event concerning carbohydrate absorption in the 20th century.\n\nOne of the major triumphs of bioenergetics is Peter D. Mitchell's chemiosmotic theory of how protons in aqueous solution function in the production of ATP in cell organelles such as mitochondria. This work earned Mitchell the 1978 Nobel Prize for Chemistry. Other cellular sources of ATP such as glycolysis were understood first, but such processes for direct coupling of enzyme activity to ATP production are not the major source of useful chemical energy in most cells. Chemiosmotic coupling is the major energy producing process in most cells, being utilized in chloroplasts and several single celled organisms in addition to mitochondria.\n\nEnergy homeostasis is the homeostatic control of energy balance – the difference between energy obtained through food consumption and energy expenditure – in living systems.\n\n\n\n", "id": "1369210", "title": "Bioenergetics"}
{"url": "https://en.wikipedia.org/wiki?curid=42400646", "text": "Cell biophysics\n\nCell biophysics (or cellular biophysics) is a sub-field of biophysics that focuses on physical principles underlying cell function. Sub-areas of current interest include statistical models of intracellular signaling dynamics, intracellular transport, cell mechanics (including membrane and cytoskeletal mechanics), molecular motors, biological electricity and genetic network theory. The field has benefited greatly from recent advances in live-cell molecular imaging techniques that allow spatial and temporal measurement of macromolecules and macromolecular function. Specialized imaging methods like FRET, FRAP, photoactivation and single molecule imaging have proven useful for mapping macromolecular transport, dynamic conformational changes in proteins and macromolecular interactions. Super-resolution microscopy allows imaging of cell structures below the optical resolution of light. Combining novel experimental tools with mathematical models grounded in the physical sciences has enabled significant recent breakthroughs in the field. Multiple centers across the world are advancing the research area\n", "id": "42400646", "title": "Cell biophysics"}
{"url": "https://en.wikipedia.org/wiki?curid=52737461", "text": "List of Protein subcellular localization prediction tools\n\nThis list of protein subcellular localisation prediction tools includes software, databases, and web services that are used for protein subcellular localization prediction.\n\nSome tools are included that are commonly used to infer location through predicted structural properties, such as signal peptide or transmembrane helices, and these tools output predictions of these features rather than specific locations. These software related to protein structure prediction may also appear in lists of protein structure prediction software.\n\n", "id": "52737461", "title": "List of Protein subcellular localization prediction tools"}
{"url": "https://en.wikipedia.org/wiki?curid=52790441", "text": "Groundplasm\n\nGroundplasm is the submicroscopic ground cell substance or cytoplasmatic matrix which remains after exclusion of the cell organelles and other particles. It is the \"hyaloplasm\" of light microscopy, and the high-complex, polyphasic system in which all of the resolvable cytoplasmic elements are suspended, including the larger organelles such the ribosomes, mitochondria, the plant plastids, lipid droplets, and vacuoles.\n\nGroundplasm contains most of the intermediate enzymes of cell metabolism, including those involved in preliminary or alternative pathways of ATP synthesis. It holds the metabolic cell reserves and the main cellular pool of soluble precursors. It also contains the contractile protein molecules responsible for most cell contractions and movements.\n\n", "id": "52790441", "title": "Groundplasm"}
{"url": "https://en.wikipedia.org/wiki?curid=441541", "text": "Taxis\n\nA taxis (plural taxes , ) is the movement of an organism in response to a stimulus such as light or the presence of food. Taxes are innate behavioural responses. A taxis differs from a tropism (turning response, often growth towards or away from a stimulus) in that in the case of taxis, the organism has motility and demonstrates guided movement towards or away from the stimulus source. It is sometimes distinguished from a kinesis, a non-directional change in activity in response to a stimulus.\n\nTaxes are classified based on the type of stimulus, and on whether the organism's response is to move towards or away from the stimulus. If the organism moves towards the stimulus the taxis is positive, while if it moves away the taxis is negative. For example, flagellate protozoans of the genus \"Euglena\" move towards a light source. This reaction or behaviour is called \"positive phototaxis\", since phototaxis refers to a response to light and the organism is moving towards the stimulus.\n\nMany types of taxis have been identified, including:\n\nDepending on the type of sensory organs present, a taxis can be classified as a \"klinotaxis\", where an organism continuously samples the environment to determine the direction of a stimulus; a \"tropotaxis\", where bilateral sense organs are used to determine the stimulus direction; and a \"telotaxis\", where a single organ suffices to establish the orientation of stimulus.\n\n\nThere are five types of taxis based on the movement of organisms.\n\n\n\n", "id": "441541", "title": "Taxis"}
{"url": "https://en.wikipedia.org/wiki?curid=52880878", "text": "Identification of cell death\n\nStandards for the identification of cell death have changed. Cell death used to be defined and described based on morphology. Now there is a switch in classifying it basing on molecular and genetic definitions. This description is more functional and applies to both in vitro and in vivo, so cell death subroutines are now described by a series of precise, measurable, biochemical features. A set of recommendations for describing the terminology of cell death was proposed by the Nomenclature Committee on Cell Death (NCCD) in 2009, because misusing words and concepts may slow down progress in the area of cell death research.\n\nThe classic definition of death defines it as a state characterized by the cessation of signs of life. It is when a cell has lost the integrity of its plasma membrane and/or has undergone complete disintegration, including its nucleus, and/or its fragments have been engulfed by a neighboring cell in vivo. It is caused by an irreversible functional imbalance and collapse of the internal organization of a system. The role of cell death is the maintenance of tissue and organ homeostasis , for example, the regular loss of skin cells or a more active role seen in involuting tissues like the thymus.\n\nCells die either by accident or design. In fact there are two mechanisms of cell death; necrosis and apoptosis (apoptosis in invertebrates is called cell deletion). Dying cells are engaged in a process that is reversible until a first irreversible phase or \"point-of-no-return\" is trespassed.\n\nNecrosis is an unprogrammed death of cells, which involves early plasma membrane changes leading to loss of calcium and sodium imbalance. This causes acidosis, osmotic shock, clumping of chromatin and nuclear pyknosis. These changes are accompanied by a loss of oxidative phosphorylation, a drop in ATP production, and a loss of homeostatic capability. There are also mitochondrial changes which include calcium overload and activation of phospholipases leading to membrane diffusion signals, a stage of irreversible damage. The secondary stage involves swelling of the lysosome, dilation of the endoplasmic reticulum, a leakage of enzymes and proteins and a loss of compartmentalization.\n\nApoptosis, or programmed cell death, is generally characterized by distinct morphological characteristics and energy-dependent biochemical mechanisms. It is considered a vital component of various processes of life including normal cell turnover, proper development and functioning of the immune system, hormone dependent atrophy, embryonic development and chemical-induced cell death. For example, the differentiation of fingers and toes in a developing human embryo occurs because cells between the fingers apoptose, resulting in separate digits.\n\nhe morphometric method is a way to demonstrate cell death in the laboratory. Morphomtric measurement provides the result of cell death as a volume, size, weight and length of tissue, organ and the whole organism that compares with before and after the occurrence of cell death. This method was observed by Attalah and Johnson who used electronic particle analyses to determine cell viability.\n\nAnother indicator of cell death is acid hydrolysis which is released from digestion during phagocytosis of dead cells by macrophages or neighboring cells, and the inta-vital dye isa marker of secondary phagocytosis.\n\nTo demonstrate cell death in some cases a vital dye is used to detect when cellular function is disrupted. This procedure uses living tissue that is immersed in diluted 1:0000 solution of Nile Blue Sulphate in Saline. The measurement of cell death by using this dye is observing a change of color or the formation of fluorescence. When the cell died the nucleus went through destruction stages, one of them pyknosis which lead to the release of a basic histone group and this happened when the irreversible condensation of chromatins occurred. The phagocytosis process took place in secondary lysosmes and the autophagy and heterophagy controlled the dead cell by acid hydrolysis activity.\nThe techniques used to explained this is by the detection of (6-3H)-thymidine and acid phosphates’ activity in cryostat.\n\nSpecimen was injected with (6-3H)-thymidine, and then the tissue was sacrificed, removed after 1 hour and quenched in liquid nitrogen. Then 4 µm cryostat sections were cut and mounted on clean cover slips, the cover slips were held with sections in cryostat, fixed in cold analar acetone for 10 minutes and the cover slips were rinsed in buffer-incubated in acid phosphate medium (15 minutes). Naphthol AS TR phosphate was used as the substrate and hexazonium paraosaniline as coupler. Again the sections were rinsed thoroughly in distilled water and the sections were dipped in autoradiography emulsion (I1ford L4 diluted 1:5). Preparations were exposed to be (0-4 °C) 2 to 3 weeks in dark room. The photographical slide was processed, counterstained in haematoxylin and mounted for microscopy.\n\nThe result of this experiment is the red color which is caused by azo-dye technique done above and this is an indicator that cell autolysis occurred. This was the major aim in the morphometric method. Another thing is the production of silver grains in the photographic emulsion.\n\nThis change in color is due to fine homogeneous red reaction of acid phosphatase activity. In the lysosome there’s a lot of indication of cell death like the free hydrolase. Incorporate tritiated thymidine gives silver grains in the photographic emulsion which happened in the cell nuclei. The ideal tissue for this procedure is thymus tissue. This discussion focuses on two changes that occur in the thymus of mouse as an example study. The first change is the ratio of cells that are dying (diffusing acid phosphatase) and the second is the thymidine incorporating cells (cells synthesizing DNA). The results are compared according to the age of the mouse. After measuring the ratios and numbers, the conclusion is that the level of cell death in involuting thymus doubled in comparison to the young thymus and the thymidine decreased in the older thymus compared to the young thymus. To further show these results it was observed that some thymicytes contained lysosomal sites of acid phosphatase activity. When the macrophages engulfed the dying cells the levels of acid phosphatase increased.\n\nLewis employed autoradiographic incorporation of 3H-thymidine to calculate mitotic indices and estimate pykontic indices. This technique can be use to study the tissue kinetics of tumors and has applications in the scanning electron microscope.\n\nThe scanning electron microscope was employed by Hodges & Muir(1975) to study autoradiograph. This approach was combined with the cytochemical method for demonstrating free acid phosphate and cell lysis. Dying cells which are rich in free acid phosphate will contain a brominated reaction product and will give a characteristic signal for bromine when subjected to x-ray microanalysis.\nFine structural studies \nThere are common fine-structural changes occurring in dying cells. This was concluded after some attempts from the scientists like Kerr (1972) who proposed the general concept of apoptosis in vertebrates, While Scheweichel and Merker (1973) described induced and physiological cell death in prenatal mouse tissues. Using fine structural distinctions, it is possible to recognize and differentiate between the types of cell death,\nAcid phosphate and cell deletion:\n\nAcid phosphate is an enzyme or group of iso-enzymes which can be used in demonstrating cell death and this can be easily observed by the electron microscope. P-nitrophoenyl phosphate activity can be used as a good marker for cell death. This marker has been used to localize the cell death in cells during embryological development, and the result noticed was the release of exoplasmic nonlysosomal acid phosphate. This appears as a sign of cell death. There are many experiments showing that the ecoplasmic p-nitrophoenyl phosphate which was released is related to ribosomes not to lysosmes.\n\nProgrammed cell death means genetic control of the process, thus genes specifying cell death in a developmental sequence must be present. Many authors show that there may be a premonitory increase in protein synthesis as a primer for programmed cell death.\n", "id": "52880878", "title": "Identification of cell death"}
{"url": "https://en.wikipedia.org/wiki?curid=53021322", "text": "Fusome\n\nFusomes are intercellular connective opening in various tissues with a common synchnonous development. They only consist of a single, large annular pore in the cell wall. Unlike them, other intercellular junctions, such as desmosomes and plasmodesmata, are the intercellular structures.\n\nThe examination under electronic microscope support the statement that the fusosomes enable the free passage of cytoplasmatic compounds and/or cell organelles, including the mitochondria. It is assumed that the fusosomes resulting from incomplete cell division after the annual furrow of the residual body of spindle were not divided completely during cytokinesis. The fusosomes have thick osmophylic ring around the opening.\n\n\n", "id": "53021322", "title": "Fusome"}
{"url": "https://en.wikipedia.org/wiki?curid=3065470", "text": "Inner nuclear membrane\n\nThe inner nuclear membrane of the nuclear envelope is connected to the outer nuclear envelope membrane through nuclear pores. It contains a number of proteins involved in the structural organization of the nucleus and the attachment of chromatin to the nuclear envelope.\n\nIn metazoan cells, the inner nuclear membrane contains proteins of the nuclear lamina, a protein meshwork underlying the nuclear envelope and providing structural support. Mutations in inner nuclear envelope proteins can cause nuclear envelopathies, a number of genetic disorders in humans.\n\nFor eukaryotes\n\nFor bacteria\n", "id": "3065470", "title": "Inner nuclear membrane"}
{"url": "https://en.wikipedia.org/wiki?curid=27783", "text": "Stem cell\n\nStem cells are undifferentiated biological cells that can differentiate into specialized cells and can divide (through mitosis) to produce more stem cells. They are found in multicellular organisms. In mammals, there are two broad types of stem cells: embryonic stem cells, which are isolated from the inner cell mass of blastocysts, and adult stem cells, which are found in various tissues. In adult organisms, stem cells and progenitor cells act as a repair system for the body, replenishing adult tissues. In a developing embryo, stem cells can differentiate into all the specialized cells—ectoderm, endoderm and mesoderm (see induced pluripotent stem cells)—but also maintain the normal turnover of regenerative organs, such as blood, skin, or intestinal tissues.\n\nThere are three known accessible sources of autologous adult stem cells in humans:\nStem cells can also be taken from umbilical cord blood just after birth. Of all stem cell types, autologous harvesting involves the least risk. By definition, autologous cells are obtained from one's own body, just as one may bank his or her own blood for elective surgical procedures.\n\nAdult stem cells are frequently used in various medical therapies (e.g., bone marrow transplantation). Stem cells can now be artificially grown and transformed (differentiated) into specialized cell types with characteristics consistent with cells of various tissues such as muscles or nerves. Embryonic cell lines and autologous embryonic stem cells generated through somatic cell nuclear transfer or dedifferentiation have also been proposed as promising candidates for future therapies. Research into stem cells grew out of findings by Ernest A. McCulloch and James E. Till at the University of Toronto in the 1960s.\n\nThe classical definition of a stem cell requires that it possesses two properties:\n\nTwo mechanisms exist to ensure that a stem cell population is maintained:\n\n\"Potency\" specifies the differentiation potential (the potential to differentiate into different cell types) of the stem cell.\n\n\nIn practice, stem cells are identified by whether they can regenerate tissue. For example, the defining test for bone marrow or hematopoietic stem cells (HSCs) is the ability to transplant the cells and save an individual without HSCs. This demonstrates that the cells can produce new blood cells over a long term. It should also be possible to isolate stem cells from the transplanted individual, which can themselves be transplanted into another individual without HSCs, demonstrating that the stem cell was able to self-renew.\n\nProperties of stem cells can be illustrated \"in vitro\", using methods such as clonogenic assays, in which single cells are assessed for their ability to differentiate and self-renew. Stem cells can also be isolated by their possession of a distinctive set of cell surface markers. However, \"in vitro\" culture conditions can alter the behavior of cells, making it unclear whether the cells shall behave in a similar manner \"in vivo\". There is considerable debate as to whether some proposed adult cell populations are truly stem cells.\n\nEmbryonic stem (ES) cells are the cells of the inner cell mass of a blastocyst, an early-stage embryo. Human embryos reach the blastocyst stage 4–5 days post fertilization, at which time they consist of 50–150 cells. ES cells are pluripotent and give rise during development to all derivatives of the three primary germ layers: ectoderm, endoderm and mesoderm. In other words, they can develop into each of the more than 200 cell types of the adult body when given sufficient and necessary stimulation for a specific cell type. They do not contribute to the extra-embryonic membranes or the placenta.\n\nDuring embryonic development these inner cell mass cells continuously divide and become more specialized. For example, a portion of the ectoderm in the dorsal part of the embryo specializes as 'neurectoderm', which will become the future central nervous system. Later in development, neurulation causes the neurectoderm to form the neural tube. At the neural tube stage, the anterior portion undergoes encephalization to generate or 'pattern' the basic form of the brain. At this stage of development, the principal cell type of the CNS is considered a neural stem cell. These neural stem cells are pluripotent, as they can generate a large diversity of many different neuron types, each with unique gene expression, morphological, and functional characteristics. The process of generating neurons from stem cells is called neurogenesis. One prominent example of a neural stem cell is the radial glial cell, so named because it has a distinctive bipolar morphology with highly elongated processes spanning the thickness of the neural tube wall, and because historically it shared some glial characteristics, most notably the expression of glial fibrillary acidic protein (GFAP). The radial glial cell is the primary neural stem cell of the developing vertebrate CNS, and its cell body resides in the ventricular zone, adjacent to the developing ventricular system. Neural stem cells are committed to the neuronal lineages (neurons, astrocytes, and oligodendrocytes), and thus their potency is restricted.\n\nNearly all research to date has made use of mouse embryonic stem cells (mES) or human embryonic stem cells (hES) derived from the early inner cell mass. Both have the essential stem cell characteristics, yet they require very different environments in order to maintain an undifferentiated state. Mouse ES cells are grown on a layer of gelatin as an extracellular matrix (for support) and require the presence of leukemia inhibitory factor (LIF) in serum media. A drug cocktail containing inhibitors to GSK3B and the MAPK/ERK pathway, called 2i, has also been shown to maintain pluripotency in stem cell culture. Human ES cells are grown on a feeder layer of mouse embryonic fibroblasts (MEFs) and require the presence of basic fibroblast growth factor (bFGF or FGF-2). Without optimal culture conditions or genetic manipulation, embryonic stem cells will rapidly differentiate.\n\nA human embryonic stem cell is also defined by the expression of several transcription factors and cell surface proteins. The transcription factors Oct-4, Nanog, and Sox2 form the core regulatory network that ensures the suppression of genes that lead to differentiation and the maintenance of pluripotency. The cell surface antigens most commonly used to identify hES cells are the glycolipids stage specific embryonic antigen 3 and 4 and the keratan sulfate antigens Tra-1-60 and Tra-1-81. By using human embryonic stem cells to produce specialized cells like nerve cells or heart cells in the lab, scientists can gain access to adult human cells without taking tissue from patients. They can then study these specialized adult cells in detail to try and catch complications of diseases, or to study cells reactions to potentially new drugs. The molecular definition of a stem cell includes many more proteins and continues to be a topic of research.\n\nThere are currently no approved treatments using embryonic stem cells. The first human trial was approved by the US Food and Drug Administration in January 2009. However, the human trial was not initiated until October 13, 2010 in Atlanta for spinal cord injury research. On November 14, 2011 the company conducting the trial (Geron Corporation) announced that it will discontinue further development of its stem cell programs. ES cells, being pluripotent cells, require specific signals for correct differentiation—if injected directly into another body, ES cells will differentiate into many different types of cells, causing a teratoma. Differentiating ES cells into usable cells while avoiding transplant rejection are just a few of the hurdles that embryonic stem cell researchers still face. Due to ethical considerations, many nations currently have moratoria or limitations on either human ES cell research or the production of new human ES cell lines. Because of their combined abilities of unlimited expansion and pluripotency, embryonic stem cells remain a theoretically potential source for regenerative medicine and tissue replacement after injury or disease..\n\nThe primitive stem cells located in the organs of fetuses are referred to as fetal stem cells.\nThere are two types of fetal stem cells:\n\n\nAdult stem cells, also called somatic (from Greek σωματικóς, \"of the body\") stem cells, are stem cells which maintain and repair the tissue in which they are found. They can be found in children, as well as adults.\n\nPluripotent adult stem cells are rare and generally small in number, but they can be found in umbilical cord blood and other tissues. Bone marrow is a rich source of adult stem cells, which have been used in treating several conditions including liver cirrhosis, chronic limb ischemia and endstage heart failure. The quantity of bone marrow stem cells declines with age and is greater in males than females during reproductive years. Much adult stem cell research to date has aimed to characterize their potency and self-renewal capabilities. DNA damage accumulates with age in both stem cells and the cells that comprise the stem cell environment. This accumulation is considered to be responsible, at least in part, for increasing stem cell dysfunction with aging (see DNA damage theory of aging).\n\nMost adult stem cells are lineage-restricted (multipotent) and are generally referred to by their tissue origin (mesenchymal stem cell, adipose-derived stem cell, endothelial stem cell, dental pulp stem cell, etc.). Muse cells (multi-lineage differentiating stress enduring cells) are a recently discovered pluripotent stem cell type found in multiple adult tissues, including adipose, dermal fibroblasts, and bone marrow. While rare, muse cells are identifiable by their expression of SSEA-3, a marker for undifferentiated stem cells, and general mesenchymal stem cells markers such as CD105. When subjected to single cell suspension culture, the cells will generate clusters that are similar to embryoid bodies in morphology as well as gene expression, including canonical pluripotency markers Oct4, Sox2, and Nanog.\n\nAdult stem cell treatments have been successfully used for many years to treat leukemia and related bone/blood cancers through bone marrow transplants. Adult stem cells are also used in veterinary medicine to treat tendon and ligament injuries in horses.\n\nThe use of adult stem cells in research and therapy is not as controversial as the use of embryonic stem cells, because the production of adult stem cells does not require the destruction of an embryo. Additionally, in instances where adult stem cells are obtained from the intended recipient (an autograft), the risk of rejection is essentially non-existent. Consequently, more US government funding is being provided for adult stem cell research.\n\nMultipotent stem cells are also found in amniotic fluid. These stem cells are very active, expand extensively without feeders and are not tumorigenic. Amniotic stem cells are multipotent and can differentiate in cells of adipogenic, osteogenic, myogenic, endothelial, hepatic and also neuronal lines.\nAmniotic stem cells are a topic of active research.\n\nUse of stem cells from amniotic fluid overcomes the ethical objections to using human embryos as a source of cells. Roman Catholic teaching forbids the use of embryonic stem cells in experimentation; accordingly, the Vatican newspaper \"Osservatore Romano\" called amniotic stem cells \"the future of medicine\".\n\nIt is possible to collect amniotic stem cells for donors or for autologuous use: the first US amniotic stem cells bank was opened in 2009 in Medford, MA, by Biocell Center Corporation and collaborates with various hospitals and universities all over the world.\n\nAdult stem cells have limitations with their potency; unlike ESCs, they are not able to differentiate into cells from all three germ layers. As such, they are deemed multipotent.\n\nHowever, reprogramming allows for the creation of pluripotent cells, induced pluripotent stem cells, from adult cells. It is important to note that these are not adult stem cells, but adult cells (e.g. epithelial cells) reprogrammed to give rise to cells with pluripotent capabilities. Using genetic reprogramming with protein transcription factors, pluripotent stem cells with ESC-like capabilities have been derived. The first demonstration of Induced Pluripotent Stem Cells was conducted by Shinya Yamanaka and his colleagues at Kyoto University. They used the transcription factors Oct3/4, Sox2, c-Myc, and Klf4 to reprogram mouse fibroblast cells into pluripotent cells. Subsequent work used these factors to induce pluripotency in human fibroblast cells. Junying Yu, James Thomson, and their colleagues at the University of Wisconsin–Madison used a different set of factors, Oct4, Sox2, Nanog and Lin28, and carried out their experiments using cells from human foreskin. However, they were able to replicate Yamanaka's finding that inducing pluripotency in human cells was possible.\n\nIt is important to note that iPSCs and ESCs are not equivalent. They have many similar properties, such as pluripotency and differentiation potential, the expression of pluripotency genes, epigenetic patterns, embryoid body and teratoma formation, and viable chimera formation. However, similar does not mean they are the same. In fact, there are many differences within these properties. Importantly, the chromatin of iPSCs appears to be more \"closed\" or methylated than that of ESCs. Similarly, the gene expression pattern between ESCs and iPSCs, or even iPSCs sourced from different origins. There are thus questions about the \"completeness\" of reprogramming and the somatic memory of induced pluripotent stem cells. Despite this, inducing adult cells to be pluripotent appears to be viable.\n\nAs a result of the success of these experiments, Ian Wilmut, who helped create the first cloned animal Dolly the Sheep, has announced that he will abandon somatic cell nuclear transfer as an avenue of research.\n\nFurthermore, induced pluripotent stem cells provide several therapeutic advantages. Like ESCs, they are pluripotent. They thus have great differentiation potential; theoretically, they could produce any cell within the human body (if reprogramming to pluripotency was \"complete\"). Moreover, unlike ESCs, they potentially could allow doctors to create a pluripotent stem cell line for each individual patient. In fact, frozen blood samples can be used as a source of induced pluripotent stem cells, opening a new avenue for obtaining the valued cells. Patient specific stem cells allow for the screening for side effects before drug treatment, as well as the reduced risk of transplantation rejection. Despite their current limited use therapeutically, iPSCs hold create potential for future use in medical treatment and research.\n\nTo ensure self-renewal, stem cells undergo two types of cell division (see \"Stem cell division and differentiation\" diagram). Symmetric division gives rise to two identical daughter cells both endowed with stem cell properties. Asymmetric division, on the other hand, produces only one stem cell and a progenitor cell with limited self-renewal potential. Progenitors can go through several rounds of cell division before terminally differentiating into a mature cell. It is possible that the molecular distinction between symmetric and asymmetric divisions lies in differential segregation of cell membrane proteins (such as receptors) between the daughter cells.\n\nAn alternative theory is that stem cells remain undifferentiated due to environmental cues in their particular niche. Stem cells differentiate when they leave that niche or no longer receive those signals. Studies in \"Drosophila\" germarium have identified the signals decapentaplegic and adherens junctions that prevent germarium stem cells from differentiating.\n\nStem cell therapy is the use of stem cells to treat or prevent a disease or condition. Bone marrow transplant is a form of stem cell therapy that has been used for many years without controversy. No stem cell therapies other than bone marrow transplant are widely used.\n\nStem cell treatments may require immunosuppression because of a requirement for radiation before the transplant to remove the person's previous cells, or because the patient's immune system may target the stem cells. One approach to avoid the second possibility is to use stem cells from the same patient who is being treated.\n\nPluripotency in certain stem cells could also make it difficult to obtain a specific cell type. It is also difficult to obtain the exact cell type needed, because not all cells in a population differentiate uniformly. Undifferentiated cells can create tissues other than desired types.\n\nSome stem cells form tumors after transplantation; pluripotency is linked to tumor formation especially in embryonic stem cells, fetal proper stem cells, induced pluripotent stem cells. Fetal proper stem cells form tumors despite multipotency.\n\nSome of the fundamental patents covering human embryonic stem cells are owned by the Wisconsin Alumni Research Foundation (WARF) – they are patents 5,843,780, 6,200,806, and 7,029,913 invented by James A. Thomson. WARF does not enforce these patents against academic scientists, but does enforce them against companies.\n\nIn 2006, a request for the US Patent and Trademark Office (USPTO) to re-examine the three patents was filed by the Public Patent Foundation on behalf of its client, the non-profit patent-watchdog group Consumer Watchdog (formerly the Foundation for Taxpayer and Consumer Rights). In the re-examination process, which involves several rounds of discussion between the USPTO and the parties, the USPTO initially agreed with Consumer Watchdog and rejected all the claims in all three patents, however in response, WARF amended the claims of all three patents to make them more narrow, and in 2008 the USPTO found the amended claims in all three patents to be patentable. The decision on one of the patents (7,029,913) was appealable, while the decisions on the other two were not. Consumer Watchdog appealed the granting of the '913 patent to the USPTO's Board of Patent Appeals and Interferences (BPAI) which granted the appeal, and in 2010 the BPAI decided that the amended claims of the '913 patent were not patentable. However, WARF was able to re-open prosecution of the case and did so, amending the claims of the '913 patent again to make them more narrow, and in January 2013 the amended claims were allowed.\n\nIn July 2013, Consumer Watchdog announced that it would appeal the decision to allow the claims of the '913 patent to the US Court of Appeals for the Federal Circuit (CAFC), the federal appeals court that hears patent cases. At a hearing in December 2013, the CAFC raised the question of whether Consumer Watchdog had legal standing to appeal; the case could not proceed until that issue was resolved.\n\nDiseases and conditions where stem cell treatment is being investigated include:\n\nResearch is underway to develop various sources for stem cells, and to apply stem cell treatments for neurodegenerative diseases and conditions, diabetes, heart disease, and other conditions. Research is also underway in generating organoids using stem cells, which would allow for further understanding of human development, organogenesis, and modeling of human diseases.\n\nIn more recent years, with the ability of scientists to isolate and culture embryonic stem cells, and with scientists' growing ability to create stem cells using somatic cell nuclear transfer and techniques to create induced pluripotent stem cells, controversy has crept in, both related to abortion politics and to human cloning.\n\nHepatotoxicity and drug-induced liver injury account for a substantial number of failures of new drugs in development and market withdrawal, highlighting the need for screening assays such as stem cell-derived hepatocyte-like cells, that are capable of detecting toxicity early in the drug development process.\n\n\n\n", "id": "27783", "title": "Stem cell"}
{"url": "https://en.wikipedia.org/wiki?curid=423439", "text": "Sarcoplasmic reticulum\n\nThe sarcoplasmic reticulum (SR) is a membrane-bound structure found within muscle cells that is similar to the endoplasmic reticulum in other cells. The main function of the SR is to store calcium ions (Ca). Calcium ion levels are kept relatively constant, with the concentration of calcium ions within a cell being 100,000 times smaller than the concentration of calcium ions outside the cell. This means that small increases in calcium ions within the cell are easily detected and can bring about important cellular changes (the calcium is said to be a second messenger; see calcium in biology for more details). Calcium is used to make calcium carbonate (found in chalk) and calcium phosphate, two compounds that the body uses to make teeth and bones. This means that too much calcium within the cells can lead to hardening (calcification) of certain intracellular structures, including the mitochondria, leading to cell death. Therefore, it is vital that calcium ion levels are controlled tightly, and can be released into the cell when necessary and then remove from the cell.\n\nThe sarcoplasmic reticulum is a network of tubules that extend throughout muscle cells, wrapping around (but not in direct contact with) the myofibrils (contractile units of the cell). Cardiac and skeletal muscle cells, contain structures called transverse tubules (T-tubules), which are extensions of the cell membrane that travel into the centre of the cell. T-tubules are closely associated with a specific region of the SR, known as the terminal cisternae in cardiac muscle or junctional SR in skeletal muscle, with a distance of roughly 12 nanometers, separating them. This is the primary site of calcium release. The longitudinal SR are thinner projects, that run between the terminal cisternae/junctional SR, and are the location where ion channels necessary for calcium ion absorption are most abundant. These processes are explained in more detail below and are fundamental for the process of excitation-contraction coupling in skeletal, cardiac and smooth muscle.\n\nThe SR contains ion channel pumps, within its membrane that are responsible for pumping Ca into the SR. As the calcium ion concentration within the SR is higher than in the rest of the cell, the calcium ions won't freely flow into the SR, and therefore pumps are required, that use energy, which they gain from a molecule called adenosine triphosphate (ATP). These calcium pumps are called Sarco(endo)plasmic reticulum ATPases (SERCA). There are a variety of different forms of SERCA, with SERCA 2a being found primarily in cardiac and skeletal muscle.\n\nSERCA consists of 13 subunits (labelled M1-M10, N, P and A). Calcium ions bind to the M1-M10 subunits (which are located within the membrane), whereas ATP binds to the N,P and A subunits (which are located outside the SR). When 2 calcium ions, along with a molecule of ATP, bind to the cytosolic side of the pump (i.e the region of the pump outside the SR), the pump opens. This occurs because ATP (which contains three phosphate groups) releases a single phosphate group (becoming adenosine diphosphate). The released phosphate group then binds to the pump, causing the pump to change shape. This shape change causes the cytosolic side of the pump to open, allowing the two Ca to enter. The cytosolic side of the pump then closes and the sarcoplasmic reticulum side opens, releasing the Ca into the SR.\n\nA protein found in cardiac muscle, called phospholamban (PLB) has been shown to prevent SERCA from working. It does this by binding to the SERCA and decreasing its attraction (affinity) to calcium, therefore preventing calcium uptake into the SR. Failure to remove Ca from the cytosol, prevents muscle relaxation and therefore means that there is a decrease in muscle contraction too. However, molecules such as adrenaline and noradrenaline, can prevent PLB from inhibiting SERCA. When these hormones bind to a receptor, called a beta 1 adrenoceptor, located on the cell membrane, they produce a series of reactions (known as a cyclic AMP pathway) that produces an enzyme called protein kinase A (PKA). PKA can add a phosphate to PLB (this is known as phosphorylation), preventing it from inhibiting SERCA and allowing for muscle relaxation.\n\nLocated within the SR is a protein called calsequestrin. This protein can bind to around 50 Ca, which decreases the amount of free Ca within the SR (as more is bound to calsequestrin). Therefore, more calcium can be stored (the calsequestrin is said to be a buffer). It is primarily located within the junctional SR/terminal cisternae , in close association with the calcium release channel (described below)\n\nCalcium ion release from the SR, occurs in the junctional SR/terminal cisternae through a ryanodine receptor (RyR) and is known as a calcium spark. There are three types of ryanodine receptor, RyR1 (in skeletal muscle), RyR2 (in cardiac muscle) and RyR3 (in the brain). Calcium release through ryanodine receptors in the SR is triggered differently in different muscles. In cardiac and smooth muscle an electrical impulse (action potential) triggers calcium ions to enter the cell through an L-type calcium channel located in the cell membrane (smooth muscle) or T-tubule membrane (cardiac muscle). These calcium ions bind to and activate the RyR, producing a larger increase in intracellular calcium. In skeletal muscle, however, the L-type calcium channel is bound to the RyR. Therefore activation of the L-type calcium channel, via an action potential, activates the RyR directly, causing calcium release (see calcium sparks for more details). Also, caffeine (found in coffee) can bind to and stimulate RyR. Caffeine works by making the RyR more sensitive to either the action potential (skeletal muscle) or calcium (cardiac or smooth muscle) therefore producing calcium sparks more often (this can result in increased heart rate, which is why we feel more awake after coffee).\n\nTriadin and Junctin are proteins found within the SR membrane, that are bound to the RyR. The main role of these proteins is to anchor calsequestrin (see above) to the ryanodine receptor. At ‘normal’ (physiological) SR calcium levels, calsequestrin binds to the RyR, Triadin and Junctin, which prevents the RyR from opening. If calcium concentration within the SR falls too low, there will be less calcium bound to the calsequestrin. This means that there is more room on the calsequestrin, to bind to the junctin, triadin and ryanodine receptor, therefore it binds tighter. However, if calcium within the SR rises too high, more calcium binds to the calsequestrin and therefore it binds to the junctin-triadin-RyR complex less tightly. The RyR can therefore open and release calcium into the cell.\nIn addition to the effects that PKA had on phospholamban (see above) that resulted in increased relaxation of the cardiac muscle, PKA (as well as another enzyme called calmodulin kinase II) can also phosphorylate ryanodine receptors. When phosphorylated, RyRs are more sensitive to calcium, therefore they open more often and for longer periods of time. This increases calcium release from the SR, increasing the rate of contraction. Therefore, in cardiac muscle, activation of PKA, through the cyclic AMP pathway, results in increased muscle contraction (via RyR2 phosphorylation) and increased relaxation (via phospholamban phosphorylation), which increases heart rate.\n\nThe mechanism behind the termination of calcium release through the RyR is still not fully understood. Some researchers believe it is due to the random closing of ryanodine receptors (known as stochastic attrition), or the ryanodine receptors becoming inactive after a calcium spark, while others believe that a decrease in SR calcium, triggers the receptors to close (see calcium sparks for more details).\n", "id": "423439", "title": "Sarcoplasmic reticulum"}
{"url": "https://en.wikipedia.org/wiki?curid=21819103", "text": "Megakaryocyte–erythroid progenitor cell\n\nThe megakaryocyte–erythroid progenitor cell (or MEP, or hMEP to specify human) is a cell that gives rise to megakaryocytes and erythrocytes.\n\nIt is derived from the common myeloid progenitor.\n", "id": "21819103", "title": "Megakaryocyte–erythroid progenitor cell"}
{"url": "https://en.wikipedia.org/wiki?curid=21440386", "text": "Enucleation (microbiology)\n\nIn the context of microbiology, enucleation refers to removing the nuclear body of a cell.\n\nEnucleation is the removal of a nucleus from its cell. This process is used in the cloning of organisms.\n\n", "id": "21440386", "title": "Enucleation (microbiology)"}
{"url": "https://en.wikipedia.org/wiki?curid=53441689", "text": "Annulate lamella\n\nAnnulate lamella is one of cell membrane classes, occurring as set of parallel elemernts with duble same dimensional membranes, as the nuclear envelope. These lamella have pore complexes which are identical to those of the nuclear cover. It is arranged in highly ordered structure with a regular specing between themselves.\n\nThese lamella are characteristic for the oocytes, spermatocytes, some somatic and cancer cels. They are characteristic of actively growing cells, including many functions in genetic information transfer and storage. They are probably formed from the nuclear envelope.\n\nSimilar membranes are found in both the cytoplasm and nucleoplasm. In the nucleoplasm, they are small, irrrgular, as well as short-living. It have been established that, in some condition, ribosomes being directly connected to the annulate lamellar membrane, supposing a role in the process of protein synthesis.\n\n", "id": "53441689", "title": "Annulate lamella"}
{"url": "https://en.wikipedia.org/wiki?curid=53451790", "text": "Cytosolic ciliogenesis\n\nCytosolic ciliogenesis, otherwise cytoplasmic ciliogenesis, is a type of ciliogenesis where the cilium axoneme is formed in the cytoplasm or becomes exposed to the cytoplasm.\n\nCytosolic ciliogenesis is divided into three types: Primary cytosolic cilia are formed by exposing the axoneme of compartmentalized cilium (formed initially by compartmentalized ciliogenesis) to the cytoplasm. This type of cilia is found in the sperm of human and other mammals. Secondary cytosolic cilia are formed in parallels to the formation of the typical compartmentalized cilium. One end of the axoneme is exposed to the cytoplasm as the other end of the axoneme is formed as compartmentalized cilia. This type of cilia is found in insects. Tertiary cytosolic cilia are axonemes that form directly in the cytoplasm. This type of cilia is found in Plasmodium (the malaria parasite).\n\nThe term Cytosolic Ciliogenesis was coined in 2004 as part of a study that identified a large set of ciliogenesis genes.\nIt was found that a subset of genes that are thought to be essential for compartmentalized cilia are not essential to form the sperm flagellum. Since the axoneme of this flagellum was exposed to the cytoplasm it was named Cytosolic Ciliogenesis.\n", "id": "53451790", "title": "Cytosolic ciliogenesis"}
{"url": "https://en.wikipedia.org/wiki?curid=1351369", "text": "Ligand-gated ion channel\n\nLigand-gated ion channels (LICs, LGIC), also commonly referred as ionotropic receptors, are a group of transmembrane ion-channel proteins which open to allow ions such as Na, K, Ca, and/or Cl to pass through the membrane in response to the binding of a chemical messenger (i.e. a ligand), such as a neurotransmitter.\n\nWhen a presynaptic neuron is excited, it releases a neurotransmitter from vesicles into the synaptic cleft. The neurotransmitter then binds to receptors located on the postsynaptic neuron. If these receptors are ligand-gated ion channels, a resulting conformational change opens the ion channels, which leads to a flow of ions across the cell membrane. This, in turn, results in either a depolarization, for an excitatory receptor response, or a hyperpolarization, for an inhibitory response.\n\nThese proteins are typically composed of at least two different domains: a transmembrane domain which includes the ion pore, and an extracellular domain which includes the ligand binding location (an allosteric binding site). This modularity has enabled a 'divide and conquer' approach to finding the structure of the proteins (crystallising each domain separately). The function of such receptors located at synapses is to convert the chemical signal of presynaptically released neurotransmitter directly and very quickly into a postsynaptic electrical signal. Many LICs are additionally modulated by allosteric ligands, by channel blockers, ions, or the membrane potential. LICs are classified into three superfamilies which lack evolutionary relationship: cys-loop receptors, ionotropic glutamate receptors and ATP-gated channels.\n\nThe cys-loop receptors are named after a characteristic loop formed by a disulfide bond between two cysteine residues in the N terminal extracellular domain. \nThey are part of a larger family of pentameric ligand-gated ion channels that usually lack this disulfide bond, hence the tentative name \"Pro-loop receptors\".\nA binding site in the extracellular N-terminal ligand-binding domain gives them receptor specificity for (1) acetylcholine (AcCh), (2) serotonin, (3) glycine, (4) glutamate and (5) γ-aminobutyric acid (GABA) in vertebrates. The receptors are subdivided with respect to the type of ion that they conduct (anionic or cationic) and further into families defined by the endogenous ligand. They are usually pentameric with each subunit containing 4 transmembrane helices constituting the transmembrane domain, and a beta sheet sandwich type, extracellular, N terminal, ligand binding domain. Some also contain an intracellular domain like shown in the image.\n\nThe prototypic ligand-gated ion channel is the nicotinic acetylcholine receptor. It consists of a pentamer of protein subunits (typically ααβγδ), with two binding sites for acetylcholine (one at the interface of each alpha subunit). When the acetylcholine binds it alters the receptor's configuration (twists the T2 helices which moves the leucine residues, which block the pore, out of the channel pathway) and causes the constriction in the pore of approximately 3 angstroms to widen to approximately 8 angstroms so that ions can pass through. This pore allows Na ions to flow down their electrochemical gradient into the cell. With a sufficient number of channels opening at once, the inward flow of positive charges carried by Na ions depolarizes the postsynaptic membrane sufficiently to initiate an action potential.\n\nWhile single-cell organisms like bacteria would have little apparent need for the transmission of an action potential, a bacterial homologue to an LIC has been identified, hypothesized to act nonetheless as a chemoreceptor. This prokaryotic nAChR variant is known as the GLIC receptor, after the species in which it was identified; Gloeobacter Ligand-gated Ion C channel.\n\nCys-loop receptors have structural elements that are well conserved, with a large extracellular domain (ECD) harboring an alpha-helix and 10 beta-strands. Following the ECD, four transmembrane segments (TMSs) are connected by intracellular and extracellular loop structures. Except the TMS 3-4 loop, their lengths are only 7-14 residues. The TMS 3-4 loop forms the largest part of the intracellular domain (ICD) and exhibits the most variable region between all of these homologous receptors. The ICD is defined by the TMS 3-4 loop together with the TMS 1-2 loop preceding the ion channel pore. Crystallization has revealed structures for some members of the family, but to allow crystallization, the intracellular loop was usually replaced by a short linker present in prokaryotic cys-loop receptors, so their structures as not known. Nevertheless, this intracellular loop appears to function in desensitization, modulation of channel physiology by pharmacological substances, and posttranslational modifications. Motifs important for trafficking are therein, and the ICD interacts with scaffold proteins enabling inhibitory synapse formation.\n\nThe ionotropic glutamate receptors bind the neurotransmitter glutamate. They form tetramers with each subunit consisting of an extracellular amino terminal domain (ATD, which is involved tetramer assembly), an extracellular ligand binding domain (LBD, which binds glutamate), and a transmembrane domain (TMD, which forms the ion channel). The transmembrane domain of each subunit contains three transmembrane helices as well as a half membrane helix with a reentrant loop. The structure of the protein starts with the ATD at the N terminus followed by the first half of the LBD which is interrupted by helices 1,2 and 3 of the TMD before continuing with the final half of the LBD and then finishing with helix 4 of the TMD at the C terminus. This means there are three links between the TMD and the extracellular domains. Each subunit of the tetramer has a binding site for glutamate formed by the two LBD sections forming a clamshell like shape. Only two of these sites in the tetramer need to be occupied to open the ion channel. The pore is mainly formed by the half helix 2 in a way which resembles an inverted potassium channel.\n\nThe α-amino-3-hydroxy-5-methyl-4-isoxazolepropionic acid receptor (also known as AMPA receptor, or quisqualate receptor) is a non-NMDA-type ionotropic transmembrane receptor for glutamate that mediates fast synaptic transmission in the central nervous system (CNS). \nIts name is derived from its ability to be activated by the artificial glutamate analog AMPA. The receptor was first named the \"quisqualate receptor\" by Watkins and colleagues after a naturally occurring agonist quisqualate and was only later given the label \"AMPA receptor\" after the selective agonist developed by Tage Honore and colleagues at the Royal Danish School of Pharmacy in Copenhagen. AMPARs are found in many parts of the brain and are the most commonly found receptor in the nervous system. The AMPA receptor GluA2 (GluR2) tetramer was the first glutamate receptor ion channel to be crystallized.\nLigands:\n\nThe N-methyl-D-aspartate receptor (NMDA receptor) – a type of ionotropic glutamate receptor – is a voltage-dependent ligand-gated ion channel that is gated by the simultaneous binding of glutamate and a co-agonist (i.e., either D-serine or glycine). Studies show that the NMDA receptor is involved in regulating synaptic plasticity and memory.\n\nThe name \"NMDA receptor\" is derived from the ligand N-methyl-D-aspartate (NMDA), which acts as a selective agonist at these receptors. When the NMDA receptor is activated by the binding of two co-agonists, the cation channel opens, allowing Na and Ca to flow into the cell, in turn raising the cell's electric potential. Thus, the NMDA receptor is an excitatory receptor. At resting potentials, the binding of Mg or Zn at their extracellular binding sites on the receptor blocks ion flux through the NMDA receptor channel. \"However, when neurons are depolarized, for example, by intense activation of colocalized postsynaptic AMPA receptors, the voltage-dependent block by Mg is partially relieved, allowing ion influx through activated NMDA receptors. The resulting Ca influx can trigger a variety of intracellular signaling cascades, which can ultimately change neuronal function through activation of various kinases and phosphatases\".\n\nLigands:\n\nGABA receptors are major inhibitory neurotransmitter expressed in the major interneurons in animal cortex.\n\nGABA receptors are ligand-gated ion channels. GABA (\"gamma\"-aminobutyric acid), the endogenous ligand for these receptors, is the major inhibitory neurotransmitter in the central nervous system. When activated, it mediates Cl flow into the neuron, hyperpolarizing the neuron. GABA receptors occur in all organisms that have a nervous system. Due to their wide distribution within the nervous system of mammals, they play a role in virtually all brain functions.\n\nVarious ligands can bind specifically to GABA receptors, either activating or inhibiting the Cl channel.\n\n\"Ligands\":\n\n5-HT receptors, also known as the serotonin receptors, or 5-hydroxytryptamine receptors, are ligand-gated ion channels. They activate an intracellular second messenger cascade to produce an excitatory/inhibitory response. They are found in mammals, both central nervous system (CNS) and peripheral nervous system (PNS), as well as other animals. Its natural ligand is Serotonin, and it modulates the release of multiple neurotransmitters, such as dopamine, epinephrine/norepinephrine, glutamate, and GABA. \nResearch confirm that the 5-HT receptors are involved in many neurological processes, such as anxiety, depression, sleep, cognition, memory, and so on. Thus there are several drugs targeting the 5-HT system, including some antidepressants, antipsychotics, anxiolytics, antiemetics, and antimigraine drugs, as well as the psychedelic drugs and empathogens.\n\nATP-gated channels open in response to binding the nucleotide ATP. They form trimers with two transmembrane helices per subunit and both the C and N termini on the intracellular side.\nPhosphatidylinositol 4,5-bisphosphate (PIP) binds to and directly activates inwardly rectifying potassium channels (K). PIP is a cell membrane lipid, and its role in gating ion channels represents a novel role for the molecule.\nIn contrast to ligand-gated ion channels, there are also receptor systems in which the receptor and the ion channel are separate proteins in the cell membrane, instead of a single molecule. In this case, ion channels are indirectly modulated by activation of the receptor, instead of being gated directly.\n\nAlso called G protein-coupled receptor, seven-transmembrane domain receptor, 7 TM receptor, constitute a large protein family of receptors that sense molecules outside the cell and activate inside signal transduction pathways and, ultimately, cellular responses. They pass through the cell membrane 7 times. \nG-protein-Linked receptors are a huge family that have hundreds of members identified. Ion-channel-linked receptors (e.g. GABAB, NMDA, etc.) are only a part of them.\n\n\"Table 1. Three major families of Trimeric G Proteins\"\nGABAB receptors are metabotropic transmembrane receptors for gamma-aminobutyric acid. They are linked via G-proteins to K+ channels, when active, they create hyperpolarized effect and lower the potential inside the cell.\n\n\"Ligands\":\n\nThe cyclic-adenosine monophosphate (cAMP)-generating enzyme adenylate cyclase is the effector of both the G and G pathways. Ten different AC gene products in mammals, each with subtle differences in tissue distribution and/or function, all catalyze the conversion of cytosolic adenosine triphosphate (ATP) to cAMP, and all are directly stimulated by G-proteins of the G class. Interaction with Gα subunits of the G type, on the contrary, inhibits AC from generating cAMP. Thus, a GPCR coupled to G counteracts the actions of a GPCR coupled to G, and vice versa. The level of cytosolic cAMP may then determine the activity of various ion channels as well as members of the ser/thr-specific protein kinase A (PKA) family. As a result, cAMP is considered a second messenger and PKA a secondary effector.\n\nThe effector of the G pathway is phospholipase C-β (PLCβ), which catalyzes the cleavage of membrane-bound phosphatidylinositol 4,5-biphosphate (PIP2) into the second messengers inositol (1,4,5) trisphosphate (IP3) and diacylglycerol (DAG). IP3 acts on IP3 receptors found in the membrane of the endoplasmic reticulum (ER) to elicit Ca release from the ER, DAG diffuses along the plasma membrane where it may activate any membrane localized forms of a second ser/thr kinase called protein kinase C (PKC). Since many isoforms of PKC are also activated by increases in intracellular Ca, both these pathways can also converge on each other to signal through the same secondary effector. Elevated intracellular Ca also binds and allosterically activates proteins called calmodulins, which in turn go on to bind and allosterically activate enzymes such as Ca/calmodulin-dependent kinases (CAMKs).\n\nThe effectors of the G pathway are three RhoGEFs (p115-RhoGEF, PDZ-RhoGEF, and LARG), which, when bound to G allosterically activate the cytosolic small GTPase, Rho. Once bound to GTP, Rho can then go on to activate various proteins responsible for cytoskeleton regulation such as Rho-kinase (ROCK). Most GPCRs that couple to G also couple to other sub-classes, often G.\n\nThe above descriptions ignore the effects of Gβγ–signalling, which can also be important, in particular in the case of activated G-coupled GPCRs. The primary effectors of Gβγ are various ion channels, such as G-protein-regulated inwardly rectifying K channels (GIRKs), P/Q- and N-type voltage-gated Ca channels, as well as some isoforms of AC and PLC, along with some phosphoinositide-3-kinase (PI3K) isoforms.\n\n\"Ligand-gated ion channels\" are likely to be the major site at which anaesthetic agents and ethanol have their effects, although unequivocal evidence of this is yet to be established. In particular, the GABA and NMDA receptors are affected by anaesthetic agents at concentrations similar to those used in clinical anaesthesia.\n\nBy understanding the mechanism and exploring the chemical/biological/physical component that could function on those receptors, more and more clinical applications are proven by preliminary experiments or FDA.\nA series recent study shows that GABA receptors are involved with addiction-related behaviors, such as cocaine, heroin, alcohol, etc. Understanding the mechanism of receptors helped scientist develop pharmaceutical tools to treat addictions by modifying the receptors' activity.\nMemantine is approved by the U.S. F.D.A and the European Medicines Agency for the treatment of moderate-to-severe Alzheimer's disease, and has now received a limited recommendation by the UK's National Institute for Health and Care Excellence for patients who fail other treatment options.\nAgomelatine, is a type of drug that acts on a dual melatonergic-serotonergic pathway, which have shown its efficacy in the treatment of anxious depression during clinical trails, study also suggests the efficacy in the treatment of atypical and melancholic depression.\n\n\n", "id": "1351369", "title": "Ligand-gated ion channel"}
{"url": "https://en.wikipedia.org/wiki?curid=53645232", "text": "Zellballen\n\nZellballen is a term used to describe a group of chief cells with pale eosinophilic staining. Zellballen are separated into groups by segmenting bands of fibrovascular stroma, and are surrounded by sustentacular cells. Zellbalen are typically seen in Paraganglioma and Pheochromocytoma. \n", "id": "53645232", "title": "Zellballen"}
{"url": "https://en.wikipedia.org/wiki?curid=5884194", "text": "Vesicular transport adaptor protein\n\nVesicular transport adaptor proteins are proteins involved in forming complexes that function in the trafficking of molecules from one subcellular location to another. These complexes concentrate the correct cargo molecules in vesicles that bud or extrude off of one organelle and travel to another location, where the cargo is delivered. While some of the details of how these adaptor proteins achieve their trafficking specificity has been worked out, there is still much to be learned.\n\nThere are several human disorders associated with defects in components of these complexes including Alzheimer's and Parkinson's diseases.\n\nMost of the adaptor proteins are heterotetramers. In the AP complexes, there are two large proteins (∼100 kD) and two smaller proteins. One of the large proteins is termed β (beta), with β1 in the AP-1 complex, β2 in the AP-2 complex, and so on. The other large protein has different designations in the different complexes. In AP-1 it is named γ (gamma), AP-2 has α (alpha), AP-3 has δ (delta), AP-4 has ε (epsilon) and AP-5 has ζ (zeta). The two smaller proteins are a medium subunit named μ (mu ∼50 kD) and a small subunit σ (sigma ∼20 kD), and named 1 through 5 corresponding to the 5 AP complexes. Components of COPI (cop one) a coatomer, and TSET (T-set) a membrane trafficking complex have similar heterotetramers of the AP complexes.\n\nRetromer is not closely related, has been reviewed, and its proteins will not be described here. GGAs (Golgi-localising, Gamma-adaptin ear domain homology, ARF-binding proteins) are a group of related proteins (three in humans) that act as monomeric clathrin adaptor proteins in various important membrane vesicle traffickings, but are not similar to any of the AP complexes and will not be discussed in detail in this article. Stonins (not shown in the lead figure) are also monomers similar in some regards to GGA and will also not be discussed in detail in this article.\n\nPTBs are protein domains that include NUMB, DAB1 and DAB2. Epsin and AP180 in the ANTH domain are other adaptor proteins that have been reviewed.\n\nAn important transport complex, COPII, was not shown in the lead figure. The COPII complex is a heterohexamer, but not closely related to the AP/TSET complexes. The individual proteins of the COPII complex are called SEC proteins, because they are encoded by genes identified in secretory mutants of yeast. One especially interesting aspect of COPII is that it can form typical spherical vesicles \"and\" tubules to transport large molecules like collagen precursors, which cannot fit inside typical spherical vesicles. COPII structure has been discussed in an open article and will not be a focus of this article. These are examples of the much larger set of cargo adaptors.\n\nThe most recent common ancestor (MRCA) of the eukaryotes must have had a mechanism for trafficking molecules between its endomembranes and organelles, and the likely identity of the adaptor complex involved has been reported. It is believed that the MRCA had 3 proteins involved in trafficking and that they formed a heterotrimer. That heterotrimer next \"dimerized\" to form a 6 membered-complex. The individual components further changed into the current complexes, in the order shown, with AP1 and AP2 being the last to diverge.\n\nIn addition, one component of TSET, a muniscin also known as the TCUP protein, appears to have evolved into part of the proteins of opisthokonts (animals and fungi). Parts of the AP complexes have evolved into parts of the GGA and stonin proteins. There is evidence indicating that parts of the nuclear pore complex and COPII may be evolutionarily related.\n\nThe best characterized type of vesicle is the clathrin coated vesicle (CCV). The formation of a COPII vesicle at the endoplasmic reticulum and its transport to the Golgi body. The involvement of the heterotetramer of COPI is similar to that of the AP/clathrin situation, but the coat of COPI is not closely related to the coats of either CCVs or COPII vesicles. AP-5 is associated with 2 proteins, SPG11 and SPG15, which have some structural similarity to clathrin, and may form the coat around the AP-5 complex, but the ultrastructure of that coat is not known. The coat of AP-4 is unknown.\n\nAn almost universal feature of coat assembly is the recruitment of the various adaptor complexes to the \"donor\" membrane by the protein Arf1. The one known exception is AP-2, which is recruited by a particular plasma membrane lipid.\n\nAnother almost universal feature of coat assembly is that the adaptors are recruited first, and they then recruit the coats. The exception is COPI, in which the 7 proteins are recruited to the membrane as a heptamer.\n\nAs illustrated in the accompanying image, the production of a coated vesicle is not instantaneous, and a considerable fraction of the maturation time is used by making \"abortive\" or \"futile\" interactions until enough interactions occur simultaneously to allow the structure to continue to develop.\n\nThe last step in the formation of a transport vesicle is \"pinching off\" from the donor membrane. This requires energy, but even in the well studied case of CCVs, not all require dynamin. The accompanying illustration shows the case for AP-2 CCVs, however AP-1 and AP-3 CCVs do not use dynamin.\n\nWhich cargo molecules are incorporated into a particular type of vesicle relies on specific interactions. Some of these interactions are directly with AP complexes and some are indirectly with \"alternative adaptors\", as shown in this diagram. As examples, membrane proteins can have direct interactions, while proteins that are soluble in the lumen of the donor organelle bind indirectly to AP complexes by binding to membrane proteins that traverse the membrane and bind at their lumenal end to the desired cargo molecule. Molecules that should not be included in the vesicle appear to be excluded by \"molecular crowding\".\n\nThe \"signals\" or amino acid \"motifs\" in the cargo proteins that interact with the adaptor proteins can be very short. For example, one well-know example is the dileucine motif, in which a leucine amino acid (aa) residue is followed immediately by another leucine or isoleucine residue. An even simpler example is the tyrosine based signal, which is YxxØ (a tyrosine residue separated by 2 aa residues from another bulky, hydrophobic aa residue). The accompanying figure shows how a small part of a protein can interact specifically with another protein, so these short signalling motifs should not be surprising. The sort of sequence comparisons used, in part, to define these motifs.\n\nIn some cases, post-translational modifications, such as phosphorylations (shown in the figure) are important for cargo recognition.\n\nAdaptor diseases have been reviewed.\n\nAP-2/CCVs are involved in autosomal recessive hypercholesterolemia through the associated low-density lipoprotein receptor adapter protein 1.\n\nRetromer is involved in recycling components of the plasma membrane. The importance of that recycling at a synapse is hinted at in one of the figures in the gallery. There are at least 3 ways in which retromer dysfunction can contribute to brain disorders, including Alzheimer and Parkinson diseases.\n\nAP-5 is the most recently described complex, and one reason supporting the idea that it is an authentic adaptor complex is that it is associated with hereditary spastic paraplegia, as is AP-4. AP-1 is linked to MEDNIK syndrome. AP-3 is linked to Hermansky–Pudlak syndrome. COPI is linked to an autoimmune disease. COPII is linked to cranio–lenticulo–sutural dysplasia.\nOne of the GGA proteins may be involved in Alzheimer's disease.\n\n", "id": "5884194", "title": "Vesicular transport adaptor protein"}
{"url": "https://en.wikipedia.org/wiki?curid=54151525", "text": "Muniscins\n\nThe muniscin protein family was initially defined in 2009 as proteins having 2 homologous domains that are involved in clathrin mediated endocytosis (CME) and have been reviewed. In addition to FCHO1, FCHO2 and Syp1, SGIP1 is also included in the family because it contains the μ (mu) homology domain and is involved in CME, even though it does not contain the F-BAR domain\n\nMuniscins are known as alternate cargo adaptors. That is, they participate in selecting which cargo molecules are internalized via CME. Additionally, the structure of the dimer, with its concave face oriented toward the plasma membrane, is thought to help curve the membrane as the clathrin coated pit forms. The muniscins are early arriving proteins involved in CME. FCHO proteins are required for CME, but do not appear to be required to \"initiate\" CME.\n\nThe μ homology domain of muniscins has been reported to have evolved from part of an ancient cargo adaptor protein complex named TSET.\n\n", "id": "54151525", "title": "Muniscins"}
{"url": "https://en.wikipedia.org/wiki?curid=54445465", "text": "Neutrophil swarming\n\nNeutrophil swarming is a specific type of neutrophil migration behaviour characterised by a high coordination between neutrophils, clustering of neutrophils to the inflammation site and signalling to other neutrophils further away. This specific type of migration rely on the production and secretion of LTB4 and on the use of integrins for neutrophil to stop at the cluster site.\n", "id": "54445465", "title": "Neutrophil swarming"}
{"url": "https://en.wikipedia.org/wiki?curid=54629293", "text": "Single cell epigenomics\n\nSingle cell epigenomics is the study of epigenomics (the complete set of epigenetic modifications on the genetic material of a cell) in individual cells by single cell sequencing. Since 2013, methods have been created including whole-genome single-cell bisulfite sequencing to measure DNA methylation, whole-genome ChIP-sequencing to measure histone modifications, whole-genome ATAC-seq to measure chromatin accessibility and chromosome conformation capture.\n\nSingle cell DNA genome sequencing quantifies DNA methylation. This is similar to single cell genome sequencing, but with the addition of a bisulfite treatment before sequencing. Forms include whole genome bisulfite sequencing, and reduced representation bisulfite sequencing \n\nATAC-seq stands for Assay for Transposase-Accessible Chromatin with high throughput sequencing. It is a technique used in molecular biology to identify accessible DNA regions, equivalent to DNase I hypersensitive sites. Single cell ATAC-seq has been performed since 2015, using methods ranging from FACS sorting, microfluidic isolation of single cells, to combinatorial indexing. In initial studies, the method was able to reliably separate cells based on their cell types, uncover sources of cell-to-cell variability, and show a link between chromatin organization and cell-to-cell variation.\n\nChIP-sequencing, also known as ChIP-seq, is a method used to analyze protein interactions with DNA. ChIP-seq combines chromatin immunoprecipitation (ChIP) with massively parallel DNA sequencing to identify the binding sites of DNA-associated proteins. In epigenomics, this is often used to assess histone modifications (such as methylation). ChIP-seq is also often used to determine transcription factor binding sites.\n\nSingle-cell ChIP-seq is extremely challenging due to background noise caused by nonspecific antibody pull-down, and only one study so far has performed it successfully. This study used a droplet-based microfluidics approach, and the low coverage required thousands of cells to be sequenced in order to assess cellular heterogeneity.\n\nChromosome conformation capture techniques (often abbreviated to 3C technologies or 3C-based methods) are a set of molecular biology methods used to analyze the spatial organization of chromatin in a cell. These methods quantify the number of interactions between genomic loci that are nearby in three dimensional space, but may be separated by many nucleotides in the linear genome.\n\nAll 3C methods start with a similar set of steps, performed on a sample of cells. First, the cell genomes are cross-linked, which introduces bonds that \"freeze\" interactions between genomic loci. The genome is then cut into fragments. Next, random ligation is performed. Lastly, the fragments are sequenced to determine their proximity to each other (fragments are more likely to be ligated to nearby fragments.) \n\nIn single-cell 3C, this last step has typically been done using high-throughput sequencing (Hi-C). Although the recovery rate is as low as 2.5% of potential interactions, it has been possible to generate three dimensional maps of entire genomes using this method.\n\n", "id": "54629293", "title": "Single cell epigenomics"}
{"url": "https://en.wikipedia.org/wiki?curid=54466482", "text": "Fluorochromasia\n\nFluorochromasia (Greek flōr χρῶμα- Pronunciation: flｕ̇r·ō·krə′mā·zhə), is a universal cellular phenomenon characterized by immediate appearance of bright green fluorescence inside viable cells upon exposure to certain membrane permeable fluorogenic substrates such as fluorescein diacetate, fluorescein dibutyrate and fluorescein dipropionate.\nThe phenomenon is widely used to measure cellular viability of many different species including animals, plants, and microorganisms. Moreover, fluorochromasia has been observed within organs, embryos,and Zebra fish.\nFluorochromasia has many applications including histocompatibility testing, measurement of cytotoxic antibodies, in vitro chemo sensitivity testing of tumors, and fluorochrome intercellular translocation.\nThe number of scientific articles reporting use of FDA for monitoring cellular viability precludes citation here. From Google Scholar, there are about 29,000 papers reporting use of FDA for measuring cell viability. Furthermore, several companies offer dead/live kits containing FDA. In this regard, fluorochromasia suffered the fate of Obliteration by incorporation.\nTherefore, this article shows only a few selected references to assess viability of diverse organisms such as \nplants, bacteria, mammalian oocytes, mouse embryos, and human tumor cells,\n\nIn 1966, Rotman and Papermaster accidentally discovered fluorochromasia while studying intracellular enzymes using fluorogenic substrates. They studied its mode of action of and presented a molecular model in which intracellular retention of fluorescein depends on the integrity of the cell membrane. Non- polar molecules of fluorescein-esters, such as fluorescein diacetate, readily enter the cell and are hydrolyzed\nby non-specific esterases producing fluorescein, as the polar compound. In viable cells, the intracellular fluorescein is unable to readily pass through the intact membrane (i.e., it leaks slowly),accumulating in the cytoplasm of the cell. Their model is illustrated in Figure 1.\n", "id": "54466482", "title": "Fluorochromasia"}
{"url": "https://en.wikipedia.org/wiki?curid=54953948", "text": "Type 1 regulatory T cells (Tr1 cells)\n\nType 1 regulatory cells (Tr 1 cells) are a class of regulatory T cells participating in peripheral immunity as a subsets of CD4+ T cells . Tr1 cells regulate tolerance towards antigens of any origin. Tr1 cells are self or non-self antigen specific and their key role is to induce and maintain peripheral tolerance and suppress tissue inflammation in autoimmunity and graft vs. host disease.\n\nThe specific cell-surface markers for Tr1 cells in humans and mice are CD4 CD49bLAG-3 CD226 from which LAG-3 and CD49b are indispensable. LAG-3 is a membrane protein on Tr1 cells that negatively regulates TCR-mediated signal transduction in cells. LAG-3 activates dendritic cells (DCs) and enhances the antigen-specific T-cell response which is necessary for Tr1 cells antigen specifity. CD49b belongs to the integrin family and is a receptor for many (extracellular) matrix and non-matrix molecules. CD49b provides only little contribution to the differentiation and function of Tr1 cells.\n\nThey characteristically produce high levels of IL-10, IFNy, IL-5 and also TGF- β but no IL-4 nor IL-2 Production of IL-10 is also much more rapid then its production of other T-helper cell types.\n\nTr1 cells do not constitutively express FOXP3 but only transiently, upon their activation and in smaller amounts then CD25 FOXP3 regulatory cells. FOXP3 is not required for Tr1 induction nor for its function\".\" They also express repressor of GATA-3 (ROG), while CD25 FOXP3 regulatory cells do not. ROG then dowregulates GATA-3, a characteristic transcription factor for Th2 cells.\n\nTr1 cells express high levels of regulatory factors, such as glucocorticoid-induced tumor necrosis factor receptor (GITR), OX40 (CD134), and tumor-necrosis factor receptor (TNFRSF9). Resting human Tr1 cells express Th1 assosiated chemokine receptors CXCR3 and CCR5, and Th2-associated CCR3, CCR4 and CCR8. Upon activation, Tr1 cells migrate preferentially in response to I-309, a ligand for CCR8.\n\nThe suppressing and tolerance-inducing effect of Tr1 cells is mediated mainly by cytokines. The other mechanism as cell to cell contact, modulation of dendritic cells, metabolic disruption and cytolysis is however also available to them. In vivo Tr1 cells need to be activated, to be able to exert their regulatory effects.\n\nTr1 cells secrete large amount of suppressing cytokines IL-10 and TGF-β. IL-10 directly inhibits T cells by blocking its production of IL-2, IFNy and GM-CSF and have tolerogenic effect on B cells and support differentiation of other regulatory T cells. IL-10 indirectly downregulates MHC II molecules and co-stimulatory molecules on antigen-presenting cells (APC) and force them to upregulate tolerogenic molecules such as ILT-3, ILT-4 and HLA-G. \nType 1 regulatory T cells poses inhibitory receptor CTLA-4 through which they exert suppressor function.\nTr1 cells can express ectoenzymes CD39 and CD73 and are suspected of generating adenosine which suppresses effector T cell proliferation and their cytokine production in vitro.\nTr1 cells can both express Granzyme A and granzyme B. It was shown recently, that Tr1 cells, in vitro and also ex vivo, specifically lyse cells of myeloid origin, but not other APC or T or B lymphocytes. Cytolysis indirectly suppresses immune response by reducing numbers of myeloid-origin antigen presenting cells.\n\nTr 1 cells are inducible, arising from precursors naive T cells. They can be differentiated ex vivo and in vivo. The ways of Tr1 cells induction in vivo, ex vivo and in vitro differ and also envelope many different approaches but the molecular mechanism, till this day, appears to be conserved.\n\nIL-27, together with TGF-β induces IL-10–producing regulatory T cells with Tr1-like properties cells. IL-27 alone can induce IL-10-producing Tr1 cells, but in the absence of TGF-β, the cells produce large quantities of both IFN-γ and IL-10. IL-6 and IL-21 also plays a role in differentiation as they regulate expression of transcription factors necessary for IL-10 production, which is believed to start up the differentiation itself later on.\n\nProposed transcription biomarkers for type 1 regulatory cells differentiation are:\nExpression of these transcriptional factors are driven by IL-6 in IL-21 and IL-2 dependant manner.\n\nTr1 cells possess huge clinical potential in means to prevent, block and even cure several T cells mediated diseases, including GvHD, allograft rejection, autoimmunity and chronic inflammatory diseases. The first successful tests were performed on mouse models and on humans as well.\n\nTransplantation research has shown, that donor Tr1 in response to recipient alloantigens, was found to correlate with the absence of GvHD after bone marrow transplantation, while decreased numbers of Tr1 markedly associated with severe GvHD. Decreased levels of IL-10 CD4+ producing cells were also observed in inflamed synovium and peripheral blood of patients with rheumatoid arthritis.\n\nPhase I/II of clinical trials of Tr1 cell treatment concerning Crohn's disease have been successful and appear to be safe and do not lead to a general immune suppression.\n", "id": "54953948", "title": "Type 1 regulatory T cells (Tr1 cells)"}
{"url": "https://en.wikipedia.org/wiki?curid=55008850", "text": "Th 9 cells\n\nT9 cells (T helper type 9 cells, CD4+IL-9+IL-13−IFNγ − ) are a sub-population of CD4+T cells that produce interleukin-9 (IL-9). They play a role in defense against helminth infections, in allergic responses and in autoimmunity.\n\nT9 cells lack any specific biomarker and thus they are defined by their high secretion of interleukin‑9. Besides of IL-9, T9 cells also produce IL-10 and IL-21. However, their functions in T9 cells are still unclear.\n\nTh9 cells can differentiate either from naive T lymphocytes or by a shift from T2 cells. There are numbers of cytokines, transcription factors and other molecules, that have a role in T9 differentiation.\n\nCytokines play a major role in development of T9 cells. There are many cytokines impacting differentiation of T9 cells and their production of IL-9 but IL-4 and TGF-β are indispensable for their development and polarization.\n\nIL-4 and TGF-β are necessary for naive T lymphocytes to differentiate into T9 cells. while TGF-β alone can switch T2 cells into T9 cells.\n\nIL-2 is critical for interleukin-9 production by T9 cells.\n\nIL-1 may induce IL-9 in some cases, and IL-33 is able to induce IL-9 in T cells generally. Generally IL-1 family members enhance expression of \"Il9\" gene.\n\nIL-25 also induces IL-9 production \"in vivo.\"\n\nDevelopment of T9 cells requires a balanced cytokines signaling for its establishment. All mentioned cytokines then signal through specific transcription factors, which are later on required for a T9 polarization.\n\nSTAT6, IRF4, GATA3 are absolutely required for T9 cell development and other such as PU.1, BATF, NF-κB, NFAT1, STAT5, AP-1 contribute to T9 sub-population commitment and to IL-9 production.\n\nSTAT6 is activated by signaling through IL-4 receptor. Once activated, phosphorylated STAT6 mediate the transcription of Gata3 and Irf4, which are both necessary for polarization of T9 cells. STAT6 repress the expression of transcription factors T-bet and Foxp3 in T9 cells, that normally block IL-9 production.\n\nGATA-3 in T9 cells development represses transcriptional factor FOXP3, which would other wise let to other T helper cell subpopulation.\n\nIRF4 binds to the promoter of \"Il-9 gene\" in T9 cells and it is dependent on STAT6.\n\nBATF has been also shown to bind to the \"Il-9 gene\" promoter and to activate \"Il-9gene\" transcription.\n\nPU.1 works by directly binding to the promoter of \"Il-9 gene\" and attract chromatin-modifying enzymes which reinforce \"Il9-gene\" transcription.\n\nNF-κB and NFAT1, are needed for a TCR-induced interleukin-9 production by T9 cells.\n\nSTAT5, downstream factor of IL-2, induce T9 cells IL-9. STAT5 directly bind to \"Il-9 gene\" promoter, although it has not yet been determined how important this pathway is for T9 development \"in vitro\" and \"in vivo\".\n\nNumbers of molecules enhance or dampen IL-9 production and contribute to T9 development such as:\n\nActivin A that can fully substitute the role of TGF-β in T9 cells, then Jagged2, programmed cell death ligand (PD-L2), cyclooxy- genase (COX)-2, 1,25-dihydroxyvitamin D3, calcitonin gene-related peptide (CGRP), tumor necrosis factor receptor superfamily member 4 (TNFRSF4 or OX40), and thymic stromal lymphopoietin (TSLP).\n\nThe role of T9 cells is not absolutely clear yet but so far it seems that they main physiological role is defense against helminthis infections and it was also shown that T9 cells are able to inhibit melanoma cells growth. Interleukin-9 produced by T9 cells promotes survival of leukocytes such as CD4+, mast cells and others as well as promote growth of mast cells.\n\nT9 cells appear to be linked to many pathophysiological processes. Their exact role is being examined, as they appear to have a pleiotropic effect and they seem to be heavily dependent on cytokine environment.\n\nT9 cells are present in the peripheral blood of allergic patients while such a population is rare in non-allergic persons. Few studies have reported distinct correlations of \"in vivo\" IL-9 with serum IgE concentration. The percentages of IL-9-secreting T cells of atopic patients also correlated with serum IgE in adults with asthma.\n\nTwo studies showed that transferred T9 cells result in allergic inflammation in the lung. It was also observed that T9 cells can promote intestinal and central nervous system inflammation.\n\nBased on these findings it seems to be apparent that T9 cells have a role in autoimmunity and allergic responses.\n", "id": "55008850", "title": "Th 9 cells"}
{"url": "https://en.wikipedia.org/wiki?curid=43815710", "text": "Amoeba\n\nAn amoeba (; rarely spelled \"amœba\", US English spelled \"ameba\"; plural \"am(o)ebas\" or \"am(o)ebae\" ), often called amoeboid, is a type of cell or organism which has the ability to alter its shape, primarily by extending and retracting pseudopods. Amoebas do not form a single taxonomic group; instead, they are found in every major lineage of eukaryotic organisms. Amoeboid cells occur not only among the protozoa, but also in fungi, algae, and animals.\n\nMicrobiologists often use the terms \"amoeboid\" and \"amoeba\" interchangeably for any organism that exhibits amoeboid movement.\n\nIn older classification systems, most amoebas were placed in the class or subphylum Sarcodina, a grouping of single-celled organisms that possess pseudopods or move by protoplasmic flow. However, molecular phylogenetic studies have shown that Sarcodina is not a monophyletic group whose members share common descent. Consequently, amoeboid organisms are no longer classified together in one group.\n\nThe best known amoeboid protists are the \"giant amoebae\" \"Chaos carolinense\" and \"Amoeba proteus\", both of which have been widely cultivated and studied in classrooms and laboratories.Other well known species include the so-called \"brain-eating amoeba\" \"Naegleria fowleri\", the intestinal parasite \"Entamoeba histolytica\", which causes amoebic dysentery, and the multicellular \"social amoeba\" or slime mould \"Dictyostelium discoideum\".\n\nAmoebae move and feed by using pseudopods, which are bulges of cytoplasm formed by the coordinated action of actin microfilaments pushing out the plasma membrane that surrounds the cell. Typically, an amoeba moves by extending a pseudopod, attaching it to the substrate and filling it with cytosol, then releasing its rear portion from attachment to the substrate, which results in the organism being propelled forward.\n\nThe appearance and internal structure of pseudopods are used to distinguish groups of amoebae from one another. Amoebozoan species, such as those in the genus Amoeba, typically have bulbous (lobose) pseudopods, rounded at the ends and roughly tubular in cross-section. Cercozoan amoeboids, such as \"Euglypha\" and \"Gromia\", have slender, thread-like (filose) pseudopods. Foraminifera emit fine, branching pseudopods that merge with one another to form net-like (reticulose) structures. Some groups, such as the Radiolaria and Heliozoa, have stiff, needle-like, radiating axopodia (actinopoda) supported from within by bundles of microtubules.\nFree-living amoebae may be \"testate\" (enclosed within a hard shell), or \"naked\" (a.k.a. , lacking any hard covering). The shells of testate amoebae may be composed of various substances, including calcium, silica, chitin, or agglutinations of found materials like small grains of sand and the frustules of diatoms.\nTo regulate osmotic pressure, most freshwater amoebae have a contractile vacuole which expels excess water from the cell. This organelle is necessary because freshwater has a lower concentration of solutes (such as salt) than the amoeba's own internal fluids (cytosol). Because the surrounding water is hypotonic with respect to the contents of the cell, water is transferred across the amoeba's cell membrane by osmosis. Without a contractile vacuole, the cell would fill with excess water and, eventually, burst.\n\nMarine amoebae do not usually possess a contractile vacuole because the concentration of solutes within the cell are in balance with the tonicity of the surrounding water.\nThe food sources of amoebae vary. Some amoebae are predatory and live by consuming bacteria and other protists. Some are detritivores and eat dead organic material.\n\nAmoebae typically ingest their food by phagocytosis, extending pseudopods to encircle and engulf live prey or particles of scavenged material. Amoeboid cells do not have a mouth or cytostome, and there is no fixed place on the cell at which phagocytosis normally occurs.\n\nSome amoebae also feed by pinocytosis, imbibing dissolved nutrients through vesicles formed within the cell membrane .\nThe size of amoeboid cells and species is extremely variable. The marine amoeboid \"Massisteria voersi\" is just 2.3 to 3 micrometres in diameter, within the size range of many bacteria. At the other extreme, the shells of deep-sea xenophyophores can attain 20 cm in diameter. Most of the free-living freshwater amoebae commonly found in pond water, ditches and lakes are microscopic, but some species, such as the so-called \"giant amoebae\" Pelomyxa palustris and Chaos carolinense, can be large enough to see with the naked eye.\n\nSome multicellular organisms have amoeboid cells only in certain phases of life, or use amoeboid movements for specialized functions. In the immune system of humans and other animals, amoeboid white blood cells pursue invading organisms, such as bacteria and pathogenic protists, and engulf them by phagocytosis.\n\nAmoeboid stages also occur in the multicellular fungus-like protists, the so-called slime moulds. Both the plasmodial slime moulds, currently classified in the class Myxogastria, and the cellular slime moulds of the groups Acrasida and Dictyosteliida, live as amoebae during their feeding stage. The amoeboid cells of the former combine to form a giant multinucleate organism, while the cells of the latter live separately until food runs out, at which time the amoebae aggregate to form a multicellular migrating \"slug\" which functions as a single organism.\n\nOther organisms may also present amoeboid cells during certain life-cycle stages, e.g., the gametes of some green algae (Zygnematophyceae) and pennate diatoms, the spores (or dispersal phases) of some Mesomycetozoea, and the sporoplasm stage of Myxozoa and of Ascetosporea.\n\nThe earliest record of an amoeboid organism was produced in 1755 by August Johann Rösel von Rosenhof, who named his discovery \"Der Kleine Proteus\" (\"the Little Proteus\"). Rösel's illustrations show an unidentifiable freshwater amoeba, similar in appearance to the common species now known as Amoeba proteus. The term \"Proteus animalcule\" remained in use throughout the 18th and 19th centuries, as an informal name for any large, free-living amoeboid.\n\nIn 1822, the genus \"Amiba (\"from the Greek \"amoibè\", meaning \"change\") was erected by the French naturalist Bory de Saint-Vincent. Bory's contemporary, C. G. Ehrenberg, adopted the genus in his own classification of microscopic creatures, but changed the spelling to \"Amoeba\".\n\nIn 1841, Félix Dujardin\" \"coined the term \"\"sarcode\"\" (from Greek \"sarx\", flesh, and \"eido\"s, form) for the \"thick, glutinous, homogenous substance\" which fills protozoan cell bodies. Although the term originally referred to the protoplasm of any protozoan, it soon came to be used in a restricted sense to designate the gelatinous contents of amoeboid cells. Thirty years later, the Austrian zoologist Ludwig Karl Schmarda used \"sarcode\" as the conceptual basis for his Division Sarcodea, a phylum-level group made up of \"unstable, changeable\" organisms with bodies largely composed of 'sarcode.' Later workers, including the influential taxonomist Otto Bütschli, emended this group to create the class Sarcodina, a taxon that remained in wide use throughout most of the 20th century.\n\nWithin the traditional Sarcodina, amoebae were generally divided into morphological categories, on the basis of the form and structure of their pseudopods. Amoebae with pseudopods supported by regular arrays of microtubules (such as the freshwater Heliozoa and marine Radiolaria) were classified as ; whereas those with unsupported pseudopods were classified as . The Rhizopods were further subdivided into lobose, filose, and reticulose amoebae, according to the morphology of their pseudopods.\n\nIn the final decade of the 20th century, a series of molecular phylogenetic analyses confirmed that Sarcodina was not a monophyletic group. In view of these findings, the old scheme was abandoned and the amoebae of Sarcodina were dispersed among many other high-level taxonomic groups. Today, the majority of traditional \"Sarcodines\" are placed in two eukaryote supergroups: Amoebozoa and Rhizaria. The rest have been distributed among the excavates, opisthokonts, and stramenopiles. Some, like the Centrohelida, have yet to be placed in any supergroup.\n\nRecent classification places the various amoeboid genera in the following groups:\n\nSome of the amoeboid groups cited (e.g., part of chrysophytes, part of xanthophytes, chlorarachniophytes) were not traditionally included in Sarcodina, being classified as algae or flagellated protozoa.\n\nSome amoebae can infect other organisms pathogenically, causing disease:\n\n\nRecent evidence indicates that several Amoebozoa lineages undergo meiosis.\n\nOrthologs of genes employed in meiosis of sexual eukaryotes have recently been identified in the \"Acanthamoeba\" genome. These genes included \"Spo11, Mre11, Rad50, Rad51, Rad52, Mnd1, Dmc1, Msh\" and \"Mlh\". This finding suggests that the ‘’Acanthamoeba‘’ are capable of some form of meiosis and may be able to undergo sexual reproduction.\n\nThe meiosis-specific recombinase, Dmc1, is required for efficient meiotic homologous recombination, and \"Dmc1\" is expressed in \"Entamoeba histolytica\". The purified Dmc1 from \"E. histolytica\" forms presynaptic filaments and catalyses ATP-dependent homologous DNA pairing and DNA strand exchange over at least several thousand base pairs. The DNA pairing and strand exchange reactions are enhanced by the eukaryotic meiosis-specific recombination accessory factor (heterodimer) Hop2-Mnd1. These processes are central to meiotic recombination, suggesting that \"E. histolytica\" undergoes meiosis.\n\nStudies of \"Entamoeba invadens\" found that, during the conversion from the tetraploid uninucleate trophozoite to the tetranucleate cyst, homologous recombination is enhanced. Expression of genes with functions related to the major steps of meiotic recombination also increase during encystations. These findings in \"E. invadens\", combined with evidence from studies of \"E. histolytica\" indicate the presence of meiosis in the \"Entamoeba\".\n\n\"Dictyostelium discoideum\" in the supergroup Amoebozoa can undergo mating and sexual reproduction including meiosis when food is scarce.\n\nSince the Amoebozoa diverged early from the eukaryotic family tree, these results suggest that meiosis was present early in eukaryotic evolution. Furthermore, these findings are consistent with the proposal of Lahr et al. that the majority of amoeboid lineages are anciently sexual.\n\nThe crew of the \"Enterprise\" went up against a giant amoeba in the 1968 \"\" episode, .\n\n\"A Very Cellular Song,\" a song from British psychedelic folk band the Incredible String Band's 1968 album \"The Hangman's Beautiful Daughter,\" is told partially from the point of view of an amoeba.\n\n\"Amoeba,\" a song from American punk rock band The Adolescents's 1981 debut album \"The Adolescents\".\n\n", "id": "43815710", "title": "Amoeba"}
{"url": "https://en.wikipedia.org/wiki?curid=102858", "text": "Cell theory\n\nIn biology, cell theory is the historic scientific theory, now universally accepted, that living organisms are made up of cells. Cells are the basic unit of structure in all organisms and also the basic unit of reproduction. With continual improvements made to microscopes over time, magnification technology advanced enough to discover cells in the 17th century. This discovery is largely attributed to Robert Hooke, and began the scientific study of cells, also known as cell biology. Over a century later, many debates about cells began amongst scientists. Most of these debates involved the nature of cellular regeneration, and the idea of cells as a fundamental unit of life. Cell theory was eventually formulated in 1839. This is usually credited to Matthias Schleiden and Theodor Schwann. However, many other scientists like Rudolf Virchow contributed to the theory.\n\nThe three tenets to the cell theory are as described below:\n\nThe first of these tenets is disputed, as non-cellular entities such as viruses are sometimes considered life-forms.\n\nThe discovery of the cell was made possible through the invention of the microscope. In the first century BC, Romans were able to make glass, discovering that objects appeared to be larger under the glass. In Italy during the 12th century, Salvino D’Armate made a piece of glass fit over one eye, allowing for a magnification effect to that eye. The expanded use of lenses in eyeglasses in the 13th century probably led to wider spread use of simple microscopes (magnifying glasses) with limited magnification. Compound microscope, which combine an objective lens with an eyepiece to view a real image achieving much higher magnification, first appeared in Europe around 1620 In 1665, Robert Hooke used a microscope about six inches long with two convex lenses inside and examined specimens under reflected light for the observations in his book \"Micrographia\". Hooke also used a simpler microscope with a single lens for examining specimens with directly transmitted light, because this allowed for a clearer image.\n\nExtensive microscopic study was done by Anton van Leeuwenhoek, a draper who took the interest in microscopes after seeing one while on an apprenticeship in Amsterdam in 1648. At some point in his life before 1668, he was able to learn how to grind lenses. This eventually led to Leeuwenhoek making his own unique microscope. His were a single lens simple microscope, rather than a compound microscope. This was because he was able to use a single lens that was a small glass sphere but allowed for a magnification of 270x. This was a large progression since the magnification before was only a maximum of 50x. After Leeuwenhoek, there was not much progress for the microscopes until the 1850s, two hundred years later. Carl Zeiss, a German engineer who manufactured microscopes, began to make changes to the lenses used. But the optical quality did not improve until the 1880s when he hired Otto Schott and eventually Ernst Abbe.\n\nOptical microscopes can focus on objects the size of a wavelength or larger, giving restrictions still to advancement in discoveries with objects smaller than the wavelengths of visible light. Later in the 1920s, the electron microscope was developed, making it possible to view objects that are smaller than optical wavelengths, once again, changing the possibilities in science.\n\nThe cell was first discovered by Robert Hooke in 1665, which can be found to be described in his book Micrographia. In this book, he gave 60 ‘observations’ in detail of various objects under a coarse, compound microscope. One observation was from very thin slices of bottle cork. Hooke discovered a multitude of tiny pores that he named \"cells\". This came from the Latin word Cella, meaning ‘a small room’ like monks lived in and also Cellulae, which meant the six sided cell of a honeycomb. However, Hooke did not know their real structure or function. \nWhat Hooke had thought were cells, were actually empty cell walls of plant tissues. With microscopes during this time having a low magnification, Hooke was unable to see that there were other internal components to the cells he was observing. Therefore, he did not think the \"cellulae\" were alive. His cell observations gave no indication of the nucleus and other organelles found in most living cells. In Micrographia, Hooke also observed mould, bluish in color, found on leather. After studying it under his microscope, he was unable to observe “seeds” that would have indicated how the mould was multiplying in quantity. This led to Hooke suggesting that spontaneous generation, from either natural or artificial heat, was the cause. Since this was an old Aristotelian theory still accepted at the time, others did not reject it and was not disproved until Leeuwenhoek later discovers generation is achieved otherwise.\n\nAnton van Leeuwenhoek is another scientist who saw these cells soon after Hooke did. He made use of a microscope containing improved lenses that could magnify objects almost 300-fold, or 270x. Under these microscopes, Leeuwenhoek found motile objects. In a letter to The Royal Society on October 9, 1676, he states that motility is a quality of life therefore these were living organisms. Over time, he wrote many more papers in which described many specific forms of microorganisms. Leeuwenhoek named these “animalcules,” which included protozoa and other unicellular organisms, like bacteria. Though he did not have much formal education, he was able to identify the first accurate description of red blood cells and discovered bacteria after gaining interest in the sense of taste that resulted in Leeuwenhoek to observe the tongue of an ox, then leading him to study \"pepper water\" in 1676. He also found for the first time the sperm cells of animals and humans. Once discovering these types of cells, Leeuwenhoek saw that the fertilization process requires the sperm cell to enter the egg cell. This put an end to the previous theory of spontaneous generation. After reading letters by Leeuwenhoek, Hooke was the first to confirm his observations that were thought to be unlikely by other contemporaries.\n\nThe cells in animal tissues were observed after plants were because the tissues were so fragile and susceptible to tearing, it was difficult for such thin slices to be prepared for studying. Biologists believed that there was a fundamental unit to life, but were unsure what this was. It would not be until over a hundred years later that this fundamental unit was connected to cellular structure and existence of cells in animals or plants. This conclusion was not made until Henri Dutrochet. Besides stating “the cell is the fundamental element of organization”, Dutrochet also claimed that cells were not just a structural unit, but also a physiological unit.\n\nIn 1804, Karl Rudolphi and J.H.F. Link were awarded the prize for \"solving the problem of the nature of cells\", meaning they were the first to prove that cells had independent cell walls by the Königliche Societät der Wissenschaft (Royal Society of Science), Göttingen. Before, it had been thought that cells shared walls and the fluid passed between them this way.\n\nCredit for developing cell theory is usually given to two scientists: Theodor Schwann and Matthias Jakob Schleiden. While Rudolf Virchow contributed to the theory, he is not as credited for his attributions toward it. In 1839, Schleiden suggested that every structural part of a plant was made up of cells or the result of cells. He also suggested that cells were made by a crystallization process either within other cells or from the outside. However, this was not an original idea of Schleiden. He claimed this theory as his own, though Barthelemy Dumortier had stated it years before him. This crystallization process is no longer accepted with modern cell theory. In 1839, Theodor Schwann states that along with plants, animals are composed of cells or the product of cells in their structures. This was a major advancement in the field of biology since little was known about animal structure up to this point compared to plants. From these conclusions about plants and animals, two of the three tenets of cell theory were postulated.\n\n1. All living organisms are composed of one or more cells\n\n2. The cell is the most basic unit of life\n\nSchleiden's theory of free cell formation through crystallization was refuted in the 1850s by Robert Remak, Rudolf Virchow, and Albert Kolliker. In 1855, Rudolf Virchow added the third tenet to cell theory. In Latin, this tenet states \"Omnis cellula e cellula\". This translated to:\n\n3. All cells arise only from pre-existing cells\n\nHowever, the idea that all cells come from pre-existing cells had in fact already been proposed by Robert Remak; it has been suggested that Virchow plagiarized Remak and did not give him credit. Remak published observations in 1852 on cell division, claiming Schleiden and Schawnn were incorrect about generation schemes. He instead said that binary fission, which was first introduced by Dumortier, was how reproduction of new animal cells were made. Once this tenet was added, the classical cell theory was complete.\n\nThe generally accepted parts of modern cell theory include:\n\n\nThe modern version of the cell theory includes the ideas that:\n\nThe cell was first discovered by Robert Hooke in 1665 using a microscope. The first cell theory is credited to the work of Theodor Schwann and Matthias Jakob Schleiden in the 1830s. In this theory the internal contents of cells were called protoplasm and described as a jelly-like substance, sometimes called living jelly. At about the same time, colloidal chemistry began its development, and the concepts of bound water emerged. A colloid being something between a solution and a suspension, where Brownian motion is sufficient to prevent sedimentation.\nThe idea of a semipermeable membrane, a barrier that is permeable to solvent but impermeable to solute molecules was developed at about the same time. The term osmosis originated in 1827 and its importance to physiological phenomena realized, but it wasn’t until 1877, when the botanist Pfeffer proposed the membrane theory of cell physiology. In this view, the cell was seen to be enclosed by a thin surface, the plasma membrane, and cell water and solutes such as a potassium ion existed in a physical state like that of a dilute solution. In 1889 Hamburger used hemolysis of erythrocytes to determine the permeability of various solutes. By measuring the time required for the cells to swell past their elastic limit, the rate at which solutes entered the cells could be estimated by the accompanying change in cell volume. He also found that there was an apparent nonsolvent volume of about 50% in red blood cells and later showed that this includes water of hydration in addition to the protein and other nonsolvent components of the cells.\n\nTwo opposing concepts developed within the context of studies on osmosis, permeability, and electrical properties of cells. The first held that these properties all belonged to the plasma membrane whereas the other predominant view was that the protoplasm was responsible for these properties.\nThe membrane theory developed as a succession of ad-hoc additions and changes to the theory to overcome experimental hurdles. Overton (a distant cousin of Charles Darwin) first proposed the concept of a lipid (oil) plasma membrane in 1899. The major weakness of the lipid membrane was the lack of an explanation of the high permeability to water, so Nathansohn (1904) proposed the mosaic theory. In this view, the membrane is not a pure lipid layer, but a mosaic of areas with lipid and areas with semipermeable gel. Ruhland refined the mosaic theory to include pores to allow additional passage of small molecules. Since membranes are generally less permeable to anions, Leonor Michaelis concluded that ions are adsorbed to the walls of the pores, changing the permeability of the pores to ions by electrostatic repulsion. Michaelis demonstrated the membrane potential (1926) and proposed that it was related to the distribution of ions across the membrane. Harvey and Danielli (1939) proposed a lipid bilayer membrane covered on each side with a layer of protein to account for measurements of surface tension. In 1941 Boyle & Conway showed that the membrane of frog muscle was permeable to both K+ and Cl-, but apparently not to Na+, so the idea of electrical charges in the pores was unnecessary since a single critical pore size would explain the permeability to K+, H+, and Cl- as well as the impermeability to Na+, Ca+, and Mg++.\nOver the same time period, it was shown (Procter & Wilson, 1916) that gels, which do not have a semipermeable membrane, would swell in dilute solutions. Loeb (1920) also studied gelatin extensively, with and without a membrane, showing that more of the properties attributed to the plasma membrane could be duplicated in gels without a membrane. In particular, he found that an electrical potential difference between the gelatin and the outside medium could be developed, based on the H+ concentration. Some criticisms of the membrane theory developed in the 1930s, based on observations such as the ability of some cells to swell and increase their surface area by a factor of 1000. A lipid layer cannot stretch to that extent without becoming a patchwork (thereby losing its barrier properties. Such criticisms stimulated continued studies on protoplasm as the principal agent determining cell permeability properties. In 1938, Fischer and Suer proposed that water in the protoplasm is not free but in a chemically combined form—the protoplasm represents a combination of protein, salt and water—and demonstrated the basic similarity between swelling in living tissues and the swelling of gelatin and fibrin gels. Dimitri Nasonov (1944) viewed proteins as the central components responsible for many properties of the cell, including electrical properties.\nBy the 1940s, the bulk phase theories were not as well developed as the membrane theories. In 1941, Brooks & Brooks published a monograph The Permeability of Living Cells, which rejects the bulk phase theories.\n\nWith the development of radioactive tracers, it was shown that cells are not impermeable to Na. This was difficult to explain with the membrane barrier theory, so the sodium pump was proposed to continually remove Na+ as it permeates cells. This drove the concept that cells are in a state of dynamic equilibrium, constantly using energy to maintain ion gradients. In 1935, Karl Lohmann discovered ATP and its role as a source of energy for cells, so the concept of a metabolically-driven sodium pump was proposed.\nThe tremendous success of Hodgkin, Huxley, and Katz in the development of the membrane theory of cellular membrane potentials, with differential equations that modeled the phenomena correctly, provided even more support for the membrane pump hypothesis.\nThe modern view of the plasma membrane is of a fluid lipid bilayer that has protein components embedded within it. The structure of the membrane is now known in great detail, including 3D models of many of the hundreds of different proteins that are bound to the membrane.\nThese major developments in cell physiology placed the membrane theory in a position of dominance and stimulated the imagination of most physiologists, who now apparently accept the theory as fact—there are, however, a few dissenters.[citation needed]\n\nIn 1956, Afanasy S. Troshin published a book, \"The Problems of Cell Permeability\", in Russian (1958 in German, 1961 in Chinese, 1966 in English) in which he found that permeability was of secondary importance in determination of the patterns of equilibrium between the cell and its environment. Troshin showed that cell water decreased in solutions of galactose or urea although these compounds did slowly permeate cells. Since the membrane theory requires an impermanent solute to sustain cell shrinkage, these experiments cast doubt on the theory. Others questioned whether the cell has enough energy to sustain the sodium/potassium pump. Such questions became even more urgent as dozens of new metabolic pumps were added as new chemical gradients were discovered.\n\nIn 1962, Gilbert Ling became the champion of the bulk phase theories and proposed his association-induction hypothesis of living cells.\n\nCells can be subdivided into the following subcategories:\n\n\nAnimals have evolved a greater diversity of cell types in a multicellular body (100–150 different cell types), compared\nwith 10–20 in plants, fungi, and protoctista.\n\n\n", "id": "102858", "title": "Cell theory"}
{"url": "https://en.wikipedia.org/wiki?curid=55289434", "text": "Echinobase\n\nEchinobase, is a web information system that catalogs diverse genomic and biological data for the echinoderm clade. The system provides a gene search engine, genomics browser and other bioinformatics tools to explore genomic and transcriptomic data. The Echinobase information system focuses on information from eight echinoderm research models: \"Strongylocentrotus purpuratus\", \"Strongylocentrotus fransciscanus, Allocentrotus fragilis\", \"Lytechinus variegatus\", \"Patiria miniata\", \"Parastichopus parvimensis\" and \"Ophiothrix spiculata\", \"Eucidaris tribuloides\". The goal of Echinobase is to support molecular biological science including developmental processes and gene regulatory networks.\n\nEchinobase provides a comparative genomics platform for the echinoderm clade which includes genomes and transcriptomes for Strongylocentrotus purpuratus, Lytechinus variegatus, Patiria miniata, Parastichopus parvamensis and Ophiothrix spiculata.\nEchinobase was created with software Maker 2, GLEAN, SNAP gene, AUGUSTUS, Web Apollo tool, RepeatModeler pipeline, genbank , IPR scan, NCBI, BLAST, PubMed. Echinobase works in a cloud environment that employs Drupal, PHP, CSS, JavaScript and PostgreSQL.\n\n\"Echinoderm genome sequences are a corpus of useful information about a clade of animals that serve as research models in fields ranging from marine ecology to cell and developmental biology. Genomic information from echinoids has contributed to insights into the gene interactions that drive the developmental process at the molecular level.\" ...\"A wide variety of development occurs in echinoderms; this includes direct or indirect (through a feeding larval stage) development, and a variety of larval structures such as the pluteus, auricularia, doliolaria, etc., and some species even go through a combination of these stages .\" \n\n\nSir Richard Timothy Hunt, FRS FMedSci FRSE (born 19 February 1943) is a British biochemist and molecular physiologist. He was awarded the 2001 Nobel Prize in Physiology or Medicine with Paul Nurse and Leland H. Hartwell for their discoveries of protein molecules that control the division of cells. It was at Woods Hole in the Summer of 1982 using the sea urchin (Arbacia punctulata) egg as his model organism, he discovered the cyclin protein molecule which plays a key role in regulating the cell-division cycle.\n\n\n", "id": "55289434", "title": "Echinobase"}
{"url": "https://en.wikipedia.org/wiki?curid=238729", "text": "Eosinophil\n\nEosinophils, sometimes called eosinophiles or, less commonly, acidophils, are a variety of white blood cells and one of the immune system components responsible for combating multicellular parasites and certain infections in vertebrates. Along with mast cells and basophils, they also control mechanisms associated with allergy and asthma. They are granulocytes that develop during hematopoiesis in the bone marrow before migrating into blood, after which they are terminally differentiated and do not multiply. \n\nThese cells are eosinophilic or \"acid-loving\" due to their large acidophilic cytoplasmic granules, which show their affinity for acids by their affinity to coal tar dyes: Normally transparent, it is this affinity that causes them to appear brick-red after staining with eosin, a red dye, using the Romanowsky method. The staining is concentrated in small granules within the cellular cytoplasm, which contain many chemical mediators, such as eosinophil peroxidase, ribonuclease (RNase), deoxyribonucleases (DNase), lipase, plasminogen, and major basic protein. These mediators are released by a process called degranulation following activation of the eosinophil, and are toxic to both parasite and host tissues.\n\nIn normal individuals, eosinophils make up about 1–3% of white blood cells, and are about 12–17 micrometres in size with bilobed nuclei. While they are released into the bloodstream as neutrophils are, eosinophils reside in tissue They are found in the medulla and the junction between the cortex and medulla of the thymus, and, in the lower gastrointestinal tract, ovary, uterus, spleen, and lymph nodes, but not in the lung, skin, esophagus, or some other internal organs under normal conditions. The presence of eosinophils in these latter organs is associated with disease. For instance, patients with eosinophilic asthma have high levels of eosinophils that lead to inflammation and tissue damage, making it more difficult for patients to breathe. Eosinophils persist in the circulation for 8–12 hours, and can survive in tissue for an additional 8–12 days in the absence of stimulation. Pioneering work in the 1980s elucidated that eosinophils were unique granulocytes, having the capacity to survive for extended periods of time after their maturation as demonstrated by ex-vivo culture experiments.\n\nTH2 and ILC2 cells both express the transcription factor GATA-3 which promotes the production of TH2 cytokines, including the interleukins (ILs). IL-5 controls the development of eosinophils in the bone marrow, as they differentiate from myeloid precursor cells. Their lineage fate is determined by transcription factors, including GATA and C/EBP. Eosinophils produce and store many secondary granule proteins prior to their exit from the bone marrow. After maturation, eosinophils circulate in blood and migrate to inflammatory sites in tissues, or to sites of helminth infection in response to chemokines like CCL11 (eotaxin-1), CCL24 (eotaxin-2), CCL5 (RANTES), 5-hydroxyicosatetraenoic acid and 5-oxo-eicosatetraenoic acid, and certain leukotrienes like leukotriene B4 (LTB4) and MCP1/4. Interleukin-13, another TH2 cytokine, primes eosinophilic exit from the bone marrow by lining vessel walls with adhesion molecules such as VCAM-1 and ICAM-1. \nWhen eosinophils are activated, they undergo cytolysis, where the breaking of the cell releases eosinophilic granules found in extracellular DNA traps. High concentrations of these DNA traps are known to cause cellular damage, as the granules they contain are responsible for the ligand-induced secretion of eosinophilic toxins which cause structural damage. There is evidence to suggest that eosinophil granule protein expression is regulated by the non-coding RNA EGOT.\n\nFollowing activation, eosinophils effector functions include production of:\n\nThere are also eosinophils that play a role in fighting viral infections, which is evident from the abundance of RNases they contain within their granules, and in fibrin removal during inflammation. Eosinophils, along with basophils and mast cells, are important mediators of allergic responses and asthma pathogenesis and are associated with disease severity. They also fight helminth (worm) colonization and may be slightly elevated in the presence of certain parasites. Eosinophils are also involved in many other biological processes, including postpubertal mammary gland development, oestrus cycling, allograft rejection and neoplasia. They have also been implicated in antigen presentation to T cells.\n\nEosinophils are responsible for tissue damage and inflammation in many diseases, including asthma. High levels of interleukin-5 has been observed to up regulate the expression of adhesion molecules, which then facilitate the adhesion of eosinophils to endothelial cells, thereby causing inflammation and tissue damage. \n\nAn accumulation of eosinophils in the nasal mucosa is considered a major diagnostic criterion for allergic rhinitis (nasal allergies).\n\nFollowing activation by an immune stimulus, eosinophils degranulate to release an array of cytotoxic granule cationic proteins that are capable of inducing tissue damage and dysfunction. These include:\n\nMajor basic protein, eosinophil peroxidase, and eosinophil cationic protein are toxic to many tissues. Eosinophil cationic protein and eosinophil-derived neurotoxin are ribonucleases with antiviral activity. Major basic protein induces mast cell and basophil degranulation, and is implicated in peripheral nerve remodelling. Eosinophil cationic protein creates toxic pores in the membranes of target cells allowing potential entry of other cytotoxic molecules to the cell, can inhibit proliferation of T cells, suppress antibody production by B cells, induce degranulation by mast cells, and stimulate fibroblast cells to secrete mucus and glycosaminoglycan. Eosinophil peroxidase forms reactive oxygen species and reactive nitrogen intermediates that promote oxidative stress in the target, causing cell death by apoptosis and necrosis.\n\nAn increase in eosinophils, i.e., the presence of more than 500 eosinophils/microlitre of blood is called an eosinophilia, and is typically seen in people with a parasitic infestation of the intestines; autoimmune and collagen vascular disease (such as rheumatoid arthritis) and Systemic lupus erythematosus; malignant diseases such as eosinophilic leukemia, clonal hypereosinophilia, and Hodgkin's disease; lymphocyte-variant hypereosinophilia; extensive skin diseases (such as exfoliative dermatitis); Addison's disease and other causes of low corticosteroid production (corticosteroids suppress blood eosinophil levels); reflux esophagitis (in which eosinophils will be found in the squamous epithelium of the esophagus) and eosinophilic esophagitis; and with the use of certain drugs such as penicillin. But, perhaps the most common cause for eosinophilia is an allergic condition such as asthma. In 1989, contaminated L-tryptophan supplements caused a deadly form of eosinophilia known as eosinophilia-myalgia syndrome, which was reminiscent of the Toxic Oil Syndrome in Spain in 1981.\n\nEosinophils play an important role in asthma as the number of accumulated eosinophils corresponds to the severity of asthmatic reaction. Eosinophilia in mice models are shown to be associated with high interleukin-5 levels. Furthermore, mucosal bronchial biopsies conducted on patients with diseases such as asthma have been found to have higher levels of interleukin-5 leading to higher levels of eosinophils. The infiltration of eosinophils at these high concentrations causes an inflammatory reaction. This ultimately leads to airway remodelling and difficulty of breathing. \n\nEosinophils can also cause tissue damage in the lungs of asthmatic patients. High concentrations of eosinophil major basic protein and eosinophil-derived neurotoxin that approach cytotoxic levels are observed at degranulation sites in the lungs as well as in the asthmatic sputum. \n\nTreatments used to combat autoimmune diseases and conditions caused by eosinophils include:\n\nMonoclonal antibodies such as dupilumab and lebrikizumab target IL-13 and its receptor, which reduces eosinophilic inflammation in pateints with asthma due to lowering the number of adhesion molecules present for eosinophils to bind to, thereby decreasing inflammation. Mepolizumab and benralizumab are other treatment options that target the alpha subunit of the IL-5 receptor, thereby inhibiting its function and reducing the number of developing eosinophils as well as the number of eosinophils leading to inflammation through antibody-dependent cell-mediated cytotoxicity and eosinophilic apoptosis.\n\nWithin the fat (adipose) tissue of CCR2 deficient mice, there is an increased number of eosinophils, greater alternative macrophage activation, and a propensity towards type 2 cytokine expression. Furthermore, this effect was exaggerated when the mice became obese from a high fat diet.\nMouse models of eosinophilia from mice infected with T canis showed an increase in IL-5 mRNA in mice spleen. Mouse models of asthma from OVA show a higher TH2 response. When mice are administered IL-12 to induce the TH1 response, the TH2 repsonse becomes suppressed, showing that mice that do not have TH2 cytokines are significantly less likely to express asthma symptoms. \n\n\n", "id": "238729", "title": "Eosinophil"}
{"url": "https://en.wikipedia.org/wiki?curid=569480", "text": "Receptor (biochemistry)\n\nIn biochemistry and pharmacology, a receptor is a protein molecule that receives chemical signals from outside a cell. When such chemical signals bind to a receptor, they cause some form of cellular/tissue response, e.g. a change in the electrical activity of a cell. In this sense, a receptor is a protein-molecule that recognizes and responds to endogenous chemical signals, e.g. an acetylcholine receptor recognizes and responds to its endogenous ligand, acetylcholine. However, sometimes in pharmacology, the term is also used to include other proteins that are drug targets, such as enzymes, transporters, and ion channels.\n\nReceptor proteins can be classified by their location. Transmembrane receptors include ion channel-linked (ionotropic) receptors, G protein-linked (metabotropic) hormone receptors, and enzyme-linked hormone receptors. Intracellular receptors are those found inside the cell, and include cytoplasmic receptors and nuclear receptors. A molecule that binds to a receptor is called a ligand, and can be a protein or peptide (short protein), or another small molecule such as a neurotransmitter, hormone, pharmaceutical drug, toxin, or parts of the outside of a virus or microbe. The endogenously designated -molecule for a particular receptor is referred to as its endogenous ligand. E.g. the endogenous ligand for the nicotinic acetylcholine receptor is acetylcholine but the receptor can also be activated by nicotine and blocked by curare.\n\nEach receptor is linked to a specific cellular biochemical pathway. While numerous receptors are found in most cells, each receptor will only bind with ligands of a particular structure, much like how locks will only accept specifically shaped keys. When a ligand binds to its corresponding receptor, it activates or inhibits the receptor's associated biochemical pathway.\n\nThe structures of receptors are very diverse and can broadly be classified into the following categories: \n\nMembrane receptors may be isolated from cell membranes by complex extraction procedures using solvents, detergents, and/or affinity purification.\n\nThe structures and actions of receptors may be studied by using biophysical methods such as X-ray crystallography, NMR, circular dichroism, and dual polarisation interferometry. Computer simulations of the dynamic behavior of receptors have been used to gain understanding of their mechanisms of action.\n\nLigand binding is an equilibrium process. Ligands bind to receptors and dissociate from them according to the law of mass action.\n\nOne measure of how well a molecule fits a receptor is its binding affinity, which is inversely related to the dissociation constant \"K\". A good fit corresponds with high affinity and low \"K\". The final biological response (e.g. second messenger cascade, muscle-contraction), is only achieved after a significant number of receptors are activated.\n\nAffinity is a measure of the tendency of a ligand to bind to its receptor. Efficacy is the measure of the bound ligand to activate its receptor.\n\nNot every ligand that binds to a receptor also activates that receptor. The following classes of ligands exist:\n\n\nNote that the idea of receptor agonism and antagonism only refers to the interaction between receptors and ligands and not to their biological effects.\n\nA receptor which is capable of producing a biological response in the absence of a bound ligand is said to display \"constitutive activity\". The constitutive activity of a receptor may be blocked by an inverse agonist. The anti-obesity drugs rimonabant and taranabant are inverse agonists at the cannabinoid CB1 receptor and though they produced significant weight loss, both were withdrawn owing to a high incidence of depression and anxiety, which are believed to relate to the inhibition of the constitutive activity of the cannabinoid receptor.\n\nMutations in receptors that result in increased constitutive activity underlie some inherited diseases, such as precocious puberty (due to mutations in luteinizing hormone receptors) and hyperthyroidism (due to mutations in thyroid-stimulating hormone receptors).\n\nThe central dogma of receptor pharmacology is that a drug effect is directly proportional to the number of receptors that are occupied. Furthermore, a drug effect ceases as a drug-receptor complex dissociates.\n\nAriëns & Stephenson introduced the terms \"affinity\" & \"efficacy\" to describe the action of ligands bound to receptors.\n\n\nIn contrast to the accepted \"Occupation Theory\", Rate Theory proposes that the activation of receptors is directly proportional to the total number of encounters of a drug with its receptors per unit time. Pharmacological activity is directly proportional to the rates of dissociation and association, not the number of receptors occupied:\n\n\nAs a drug approaches a receptor, the receptor alters the conformation of its binding site to produce drug—receptor complex.\n\nIn some receptor systems (e.g. acetylcholine at the neuromuscular junction in smooth muscle), agonists are able to elicit maximal response at very low levels of receptor occupancy (<1%). Thus, that system has spare receptors or a receptor reserve. This arrangement produces an economy of neurotransmitter production and release.\n\nCells can increase (upregulate) or decrease (downregulate) the number of receptors to a given hormone or neurotransmitter to alter their sensitivity to different molecule. This is a locally acting feedback mechanism.\n\n\nThe ligands for receptors are as diverse as their receptors. Examples include:\n\nMany genetic disorders involve hereditary defects in receptor genes. Often, it is hard to determine whether the receptor is nonfunctional or the hormone is produced at decreased level; this gives rise to the \"pseudo-hypo-\" group of endocrine disorders, where there appears to be a decreased hormonal level while in fact it is the receptor that is not responding sufficiently to the hormone.\n\nThe main receptors in the immune system are pattern recognition receptors (PRRs), toll-like receptors (TLRs), killer activated and killer inhibitor receptors (KARs and KIRs), complement receptors, Fc receptors, B cell receptors and T cell receptors.\n\n\n", "id": "569480", "title": "Receptor (biochemistry)"}
{"url": "https://en.wikipedia.org/wiki?curid=56233788", "text": "NCI-60\n\nThe NCI-60 cancer cell line panel is a group of 60 human cancer cell lines used by the National Cancer Institute (NCI) for the screening of compounds to detect potential anticancer activity.\n\nThe screening procedure is called the NCI-60 Human Tumor Cell Lines Screen, and it is one of the Discovery & Development Services of NCI's Developmental Therapeutics Program (DTP).\nThe screening rates for each cell line the cytostatic and cytotoxic impact of tested substances.\n\nDue to the diversity of the cell lines, it is possible to compare tested compounds by their effect patterns, high correlation potentially corresponding to similar effect mechanisms.\nAn automated comparison against a database of more than 88,000 pure compounds and more than 34,000 crude extracts () is provided by the COMPARE tool, which shows a list of substances ranked by the Pearson correlation coefficients for a given test substance.\n\nThe same panel is used in the Molecular Target Program for the characterization of molecular targets. Measurements include protein levels, RNA measurements, mutation status and enzyme activity levels.\n\nThe panel holds cell lines representing leukemia, melanoma, non-small-cell lung carcinoma, and cancers of the brain, ovary, breast, colon, kidney, and prostate.\n\n13 additional cell lines are evaluated for use in the screening program,\namong them two lines deriving from so far not represented small-cell lung carcinoma.\n\nAll cell lines but one () are available to other laboratories, including the additional cell lines.\n\nStarting around the turn of the millennium, several cell lines were found to be misidentified or misclassified at the time of investigation or earlier:\n\nMDA-MB-435, originally classified as breast cancer cell line, was identified as being a melanoma cell line.\nWhen investigated further, current MDA-MB-435 appeared to be derived from the same individual as cell line M14.\nAn examination of clones made clear that the mixup with M14 happened very early in the history of MDA-MB-435, before establishment in the Developmental Therapeutics Program.\n\nNCI/ADR-RES, originally classified as breast cancer cell line, was identified as being an ovarian tumor cell line.\nNCI/ADR-RES appears to have been derived at some point in time from cell line OVCAR-8.\nOriginally the cell line was named MCF-7/ADR-RES; it was renamed together with the change in classification.\n\nTwo brain cancer cell lines, SNB-19 and U251, were discovered to come from the same person.\nThis makes a mixup likely.\n\nA 61th cell line, MDA-N, has been confirmed to being derived from the misclassified MDA-MB-435 cell line.\nSo it is also misclassified, really being a melanoma cell line, but the official website still lists it as breast cancer cell line.\nThis cell line is not available .\n\nThe International Cell Line Authentication Committee maintaines a list of contaminated cell lines.\nIt includes the cell lines reported above, although usually with reporting dates and articles considerably later than the first dates and articles rising specific concern regarding the respective cell line.\n\n Hundreds of research studies still use MDA-MB-435 as model of breast cancer, even after it was officially declared to be a melanoma cell line in 2007, and even in highest-rated international peer-reviewed journals.\nSimilar is true for other misidentified cell lines.\n", "id": "56233788", "title": "NCI-60"}
{"url": "https://en.wikipedia.org/wiki?curid=254439", "text": "Protoplasm\n\nProtoplasm is the living content of a cell that is surrounded by a plasma membrane.\n\nIn some definitions, it is a general term for the cytoplasm (e.g., Mohl, 1846), but for others, it also includes the nucleoplasm (e.g., Strasburger, 1882). For Sharp (1921), \"According to the older usage the extra-nuclear portion of the protoplast [\"the entire cell, excluding the cell wall\"] was called \"protoplasm,\" but the nucleus also is composed of protoplasm, or living substance in its broader sense. The current consensus is to avoid this ambiguity by employing Strasburger's [\"(1882)\"] terms cytoplasm [\"coined by Kölliker (1863), originally as synonym for protoplasm\"] and nucleoplasm ([\"term coined by van Beneden (1875), or\"] karyoplasm, [\"used by\"] Flemming [\"(1878)\"])\". The cytoplasm definition of Strasburger excluded the plastids (\"Chromatoplasm\").\n\nAs for the nucleus, the inclusion or not of the vacuole in the protoplasm concept is also controversial.\n\nThe word \"protoplasm\" comes from the Greek \"protos\" for \"first\", and \"plasma\" for \"thing formed\", and was originally used in religious contexts. It was used in 1839 by J. E. Purkinje for the material of the animal embryo. Later, in 1846 Hugo von Mohl redefined the term (also named as \"Primordialschlauch\", \"primordial utricle\") to refer to the \"tough, slimy, granular, semi-fluid\" substance within plant cells, to distinguish this from the cell wall and the cell sap (\"Zellsaft\") within the vacuole. Thomas Huxley (1869) later referred to it as the \"physical basis of life\" and considered that the property of life resulted from the distribution of molecules within this substance. The protoplasm became an \"epistemic thing\". Its composition, however, was mysterious and there was much controversy over what sort of substance it was.\n\nIn 1872, Beale created the vitalist term \"bioplasm\", to contrast with the materialism of Huxley. In 1880, term protoplast was proposed by Hanstein (1880) for the entire cell, excluding the cell wall, and some authors like Julius von Sachs (1882) preferred that name instead of cell.\n\nIn 1965, Hardy introduced the term \"cytosol\", later redefined to refer to the liquid inside cell.\n\nOther related terms are: \"Urschleim\" (Oken, 1802, 1809), \"sarcode\" (Dujardin, 1835, 1841), \"Grundsubstanz\" (ground substance, Cienkowski, 1863), enchylema/hyaloplasma (Hanstein, 1880), paramitome (Flemming, 1882), inter-filar substance (Velten, 1876) and inter-alveolar substance (Bütschli, 1892).\n\nBy the time Huxley wrote, a long-standing debate was largely settled over the fundamental unit of life: was it the cell or was it protoplasm? By the late 1860s, the debate was largely settled in favor of protoplasm. The cell was a container for protoplasm, the fundamental and universal material substance of life. Huxley's principal contribution was to establish protoplasm as incompatible with a vitalistic theory of life. Attempts to investigate the origin of life through the creation of synthetic \"protoplasm\" in the laboratory were not successful.\n\nThe idea that protoplasm of eukaryotes is simply divisible into a ground substance called \"cytoplasm\" and a structural body called the cell nucleus reflects the more primitive knowledge of cell structure that preceded the development of electron microscopy, when it seemed that cytoplasm was a homogeneous fluid and the existence of most sub-cellular compartments, or how cells maintain their shape, was unknown. Today, it is known that the cell contents are structurally very complex and contain multiple organelles.\n\nProtoplasm is composed of a mixture of small molecules such as ions, amino acids, monosaccharides and water, and macromolecules such as nucleic acids, proteins, lipids and polysaccharides. In eukaryotes the protoplasm surrounding the cell nucleus is known as the cytoplasm and that inside the nucleus as the nucleoplasm. In prokaryotes the material inside the plasma membrane is the bacterial cytoplasm, while in Gram-negative bacteria the region outside the plasma membrane but inside the outer membrane is the periplasm.\n\nProtoplasm was said to exist in two forms: a liquid-like sol state or a jelly-like gel state.\n\n", "id": "254439", "title": "Protoplasm"}
{"url": "https://en.wikipedia.org/wiki?curid=4407137", "text": "Cross-fostering\n\nCross-fostering is a technique used in animal husbandry, animal science, genetic and nature versus nurture studies, and conservation, whereby offspring are removed from their biological parents at birth and raised by surrogates. This can also occasionally occur in nature.\n\nCross-fostering young animals is usually done to equalize litter size. Individual animals born in large litters are faced with much more competition for resources, such as breast milk, food and space, than individuals born in smaller litters. Herd managers will typically move some individuals from a large litter to a smaller litter where they will be raised by a non-biological parent. This is typically done in pig farming because litters with up to 15 piglets are common. A sow with a large litter may have difficulty producing enough milk for all piglets, or the sow may not have enough functional teats to feed all piglets simultaneously. When this occurs, smaller or weaker piglets are at risk of starving to death. Herd managers will often transfer some piglets from a large litter to another lactating sow which either has a smaller litter or has had her own biological piglets recently weaned. Herd managers will typically try to equalize litters by number and also weight of individuals. When done successfully, cross-fostering reduces piglet mortality.\n\nCross-fostering can be used to study the impact of postnatal environment on genetic-linked diseases as well as on behavioural pattern. In behavioral studies, if cross-fostered offspring show a behavioral trait similar to their biological parents and dissimilar from their foster parents, a behavior can be shown to have a genetic basis. Similarly if the offspring develops traits dissimilar to their biological parents and similar to their foster parents environmental factors are shown to be dominant. In many cases there is a blend of the two, which shows both genes and environment play a part.\n\nIn animal studies, genetically hypertensive offspring reared by normotensive dams have been shown to have lower blood pressure compared to the controls. This shows that hypertensive genotype could be modified by the changes of the postnatal environment. Besides this, hyperkinetic animals reared by a normal dam have been shown to have lower locomotor activity compared to its controls.\n\nIn one experiment, siblicide was shown to be somehow related to parental care. When non-obligate siblicidal blue-footed boobies were swapped with obligate siblicidal masked booby chicks, it was found that the blue-footed chicks exhibited more siblicidal behavior.\n\nIn selective livestock breeding cross-fostering can be used to combine desirable genetic qualities such as weight, fat distribution or appearance with environmentally influenced ones such as temperament.\n\nIn humans, studies of children in foster care have shown that alcoholism is both genetic and environmental: early onset alcoholism can be linked to biological parentage, whereas adult onset alcoholism is often influenced by the alcohol abuse by foster parents.\n\nCross fostering has been used in conservation biology such as the rearing of black robin chicks by other species. In this instance the species was so close to extinction, with literally a handful of surviving individuals and a single mother, there was little chance of raising many offspring. In this case a related species were used to raise the eggs, with their own eggs being replaced by conservation workers with those of the robin. In this case imprinting is one of the concerns, as species raised in a different environment may not be able to recognize their own species. In a world first, the Adelaide Zoo successfully cross-fostered a baby tree kangaroo, whose mother was killed when it was five weeks old, with a surrogate rock-wallaby mother. The Zoo has had a successful cross-fostering program between wallaby species, but this is the first time it was tried with a tree kangaroo and wallaby.\n\nCross fostering may occasionally occur in natural situations. In Australia, the closely related species from the cockatoo family, \"Eolophus roseicapilla\" (the galah) and \"Cacatua leadbeateri\" (the pink cockatoo), have overlapping ranges, and compete for nesting holes. However, two pairs of birds may share the same nest for a time, as they do not become aggressive until several eggs have been laid and incubation begins. When they do, the pink cockatoos are always the victors, evicting the galahs in what is termed interference competition. They are not consciously aware that some of the eggs in the nest were laid by the other bird however, and thus raise offspring of both species. These natural experiments have been used by Australian ornithologists Graeme Chapman and Ian Rowley to investigate the relative importance of genes and environment. For example, they discovered that the galah chicks gave normal begging calls and alarm calls, but their contact calls (used to maintain social cohesion) were more like those of the pink cockatoos with which they lived.\n\nSuch natural instances of cross fostering can also lead to hybridization between species that would not normally breed. A case of this is offered by the Galapagos finches. Two species of the genus \"Geospiza\", the medium ground-finch (\"Geospiza fortis\") and the common cactus-finch (\"Geospiza scandens\") occasionally hybridize. The birds' songs are a barrier to interbreeding, but sometimes young birds will not learn their own species song, e.g. if their father dies and they are nesting near another species. Another situation where birds can imprint on the wrong song is when one species takes over the nest of another, but fails to remove all of its eggs. Cross fostered young can then hybridize with their foster parents' species, allowing gene flow between the two populations. Hybrids experience reduced fitness, however, so the two species can remain separate.\n\n\n", "id": "4407137", "title": "Cross-fostering"}
{"url": "https://en.wikipedia.org/wiki?curid=11406931", "text": "Umbrella species\n\nUmbrella species are species selected for making conservation-related decisions, typically because protecting these species indirectly protects the many other species that make up the ecological community of its habitat. Species conservation can be subjective because it is hard to determine the status of many species. With millions of species of concern, the identification of selected \"keystone species\", \"flagship species\" or \"umbrella species\" makes conservation decisions easier. Umbrella species can be used to help select the locations of potential reserves, find the minimum size of these conservation areas or reserves, and to determine the composition, structure and processes of ecosystems.\n\nTwo commonly used definitions:\n\n\nOther descriptions include:\n\nThe use of umbrella species as a conservation tool is highly debated. The term was first used by Wilcox (1984) who defined an umbrella species as one whose minimum area requirements are at least as comprehensive of the rest of the community for which protection is sought though the establishment and management of a protected area.\n\nSome scientists have found that the umbrella effect provides a simpler way to manage ecological communities. Others feel that a combination of other tools establish better land management reserves to help protect more species than just using umbrella species alone. Individual invertebrate species can be good umbrella species because they can protect older, unique ecosystems. There have been cases where umbrella species have protected a large amount of area which has been beneficial to surrounding species such as the northern spotted owl.\n\nCurrently research is being done on land management decisions based on using umbrella species to protect habitat of specific species as well as other organisms in the area. Dunk, Zielinski and Welsh (2006) reported that the reserves in Northern California (Klamath-Siskiyou forests), set aside for the northern spotted owl, also protect mollusks and salamanders within that habitat. According to their conclusions, the reserves set aside for the northern spotted owl \"serve as a reasonable coarse-filter umbrella species for the taxa [they] evaluated\", which were the mollusks and salamanders.\n\nThe Bay checkerspot butterfly has been on the Endangered Species List since 1987 and is still currently listed. Launer and Murphy (1994) tried to determine whether this butterfly could be considered an umbrella species in protecting the native grassland it inhabits. They discovered that the Endangered Species Act (ESA) has a loophole to eliminate federally protected plants that reside on private property. However, the California Environmental Quality Act (CEQA) reinforces state conservation regulations. Using the ESA to protect termed umbrella species and their habitats can be controversial because they are not as reinforced in some states as others (such as California) to protect overall biodiversity.\n\n\n", "id": "11406931", "title": "Umbrella species"}
{"url": "https://en.wikipedia.org/wiki?curid=18966509", "text": "Camera trap\n\nA camera trap is a remotely activated camera that is equipped with a motion sensor or an infrared sensor, or uses a light beam as a trigger. Camera trapping is a method for capturing wild animals on film when researchers are not present, and has been used in ecological research for decades. In addition to applications in hunting and wildlife viewing, research applications include studies of nest ecology, detection of rare species, estimation of population size and species richness, as well as research on habitat use and occupation of human-built structures.\n\nCamera traps, also known as trail cameras, are used to capture images of wildlife with as little human interference as possible. Since the introduction of commercial infrared-triggered cameras in the early 1990s their use has increased. With advancements in the quality of camera equipment this method of field observation has become more popular among researchers. Hunting has played an important role in development of camera traps, since hunters like to use them to scout for game. These hunters have opened a commercial market for the devices which have led to many improvements over time.\n\nThe great advantage of camera traps is that they can record very accurate data without disturbing the photographed animal. These data are superior to human observations, because they can be reviewed by other researchers. \nThey minimally disturb wildlife and can replace the use of more invasive survey and monitoring techniques such as live trap and release. They operate continually and silently, provide proof of species presence in an area, can reveal what prints and scats belong to which species, provide evidence for management and policy decisions, and are a cost effective monitoring tool. Infrared flash cameras have low disturbance and visibility. Besides olfactory and acoustic cues, camera flash may scare animals so that they avoid or destroy camera traps. The major alternative light source is infrared, which is usually not detectable by mammals or birds.\n\nCamera traps are also helpful in quantifying the number of different species in an area; this is a more effective method than attempting to count by hand every individual organism in a field. It can also be useful in identifying new or rare species that have yet to be well documented. By using camera traps, the well-being and survival rate of animals can be observed over time. \nCamera traps are helpful in determining behavioral and activity patterns of animals, such as which time of day they visit mineral licks. \nCamera traps are also useful to record animal migrations.\n\nCamera traps have revolutionized wildlife research and conservation, enabling collection of photographic evidence of rarely seen and often globally endangered species, with little expense, relative ease, and minimal disturbance to wildlife. Camera traps can document wildlife presence, abundance, and population changes, particularly in the face of deforestation and habitat destruction. Camera traps enable collection of baseline population data on elusive mammals and birds where only estimates — and often just guesses — were possible before. Camera traps are increasingly being used to raise conservation awareness worldwide, with Non-governmental organizations (NGO)s embracing the tool as a powerful way of reaching out to the public through electronic media. Wildlife conservation groups such as Panthera, Wildlife Conservation Society (WCS), World Wildlife Fund (WWF) have found camera trap videos and photos to be an important part of campaigns to save threatened or endangered species.\n\nThe earliest models used traditional film and a one-shot trigger function. These cameras contained film that needed to be collected and developed like any other standard camera. Today, more advanced cameras utilize digital photography, sending photos directly to a computer. Even though this method is uncommon it is highly useful and could be the future of this research method. Some cameras are even programmed to take multiple pictures after a triggering event.\n\nThere are non-triggered cameras that either run continuously or take pictures at specific time intervals. The more common ones are the advanced cameras that are triggered only after sensing movement and/or a heat signature to increase the chances of capturing a useful image. Infrared beams can also be used to trigger the camera. Video is also an emerging option in camera traps, allowing researchers to record running streams of video and to document animal behavior.\n\nThe battery life of some of these cameras is another important factor in which cameras are used; large batteries offer a longer running time for the camera but can be cumbersome in set up or when lugging the equipment to the field site .\n\nWeather proof and waterproof housing for camera traps protect the equipment from damage and disguise the equipment from animals.\n\nNoise-reduction housing limits the possibility of disturbing and scaring away animals. Sound recording is another feature that can be added to the camera to record animal calls and times when specific animals are the most vocal.\n\nHumidity has a highly negative effect on camera traps and can result in camera malfunction.\nThis can be problematic since the malfunction is often not immediately discovered, so a large portion of research time can be lost. Often a researcher expecting the experiment to be complete will trek back to the site, only to discover far less data than expected – or even none at all.\n\nThe best type of weather for it to work in is any place with low humidity and stable moderate temperatures.\nThere is also the possibility, if it is a motion activated camera, that any movement within the sensitivity range of the camera’s sensor will trigger a picture, so the camera might end up with numerous pictures of anything the wind moves, such as plants.\n\nAs far as problems with camera traps, it cannot be overlooked that sometimes the subjects themselves negatively affect the research. One of the most common things is that animals unknowingly topple a camera or splatter it with mud or water ruining the film or lens. One other method of animal tampering involves the animals themselves taking the cameras for their own uses. There are examples of some animals actually taking the cameras and snapping pictures of themselves.\n\nLocal people sometimes use the same game trails as wildlife, and hence are also photographed by camera traps placed along these trails. This can make camera traps a useful tool for anti-poaching or other law enforcement effort.\n\nOne of the most important things to consider when setting up camera traps is choosing the location in order to get the best results. Camera traps near mineral licks or along game trails, where it is more likely that animals will visit frequently, are normally seen. Animals congregate around mineral licks to consume water and soil, which can be useful in reducing toxin levels or supplement mineral intake in their diet. These locations for camera traps also allow for variety of animals who show up at different times and use the licks in different ways allowing for the study of animal behavior.\n\nAnother major factor in whether this is the best technique to use in the specific research is which type of species one is attempting to observe with the camera. Species such as small-bodied birds and insects may be too small to trigger the camera. Reptiles and amphibians will not be able to trip the infrared or heat differential-based sensors, however, methods have been developed to detect these species by utilizing a reflector based sensor system. However, for most medium and large-bodied terrestrial species camera traps have proven to be a successful tool for study.\n\n\n\n", "id": "18966509", "title": "Camera trap"}
{"url": "https://en.wikipedia.org/wiki?curid=19789633", "text": "Trick tank\n\nA trick tank is a watering device for livestock or wildlife. It collects precipitation, holds the water in a covered tank to minimize evaporation and maintain adequate water quality, and dispenses water on demand into a basin from which animals can drink. Dispensing may be regulated by a mechanical float device similar to a ballcock in the tank of a flush toilet.\n\nTrick tanks are manufactured in several styles, including inverted umbrella and apron. They are heavy and often are used in remote wilderness locations, to which they may require delivery via helicopter.\n\nTo provide water to wild animals, not livestock, fencing may be built to surround a trick tank. Fences serve to exclude cattle and sheep. Trick tanks are widely used in the southwest United States, where periodic droughts may cause population crashes in game animals unless water supplies are provided.\n\n", "id": "19789633", "title": "Trick tank"}
{"url": "https://en.wikipedia.org/wiki?curid=21548666", "text": "Felidae Conservation Fund\n\nFelidae Conservation Fund (FCF) is a California-based non-profit organization dedicated to preserving wild cats and their habitats. The organization supports and promotes international wild cat research and conservation by collaborating on field research projects, partnering with other environmental organizations, and developing community outreach and education programs.\n\nFCF was founded in 2006 by conservationist and entrepreneur Zara McDonald. As a competitive marathon runner, McDonald twice encountered mountain lions during solitary runs in the Marin Headlands in Northern California. These encounters led her to become involved in California mountain lion research in 2002, and she soon expanded her research work to include other wild cat species. In the fall of 2004, after returning from extended capture work with mountain lions, she began developing a conservation model that combined scientific research with education and outreach programs. This led her to found the Felidae Conservation Fund (501(c)(3)) in April 2006.\n\nToday Felidae supports and collaborates in scientific research projects in nine countries, promotes community-level education and outreach programs, and fosters international cooperation among scientists, conservationists, governments, and environmental NGOs. Felidae is based in Sausalito, California, and raises money through donations, grants, fundraising events and online social networks.\n\nFCF's mission is to advance the conservation of the planet's wild cat species and their habitats through partnerships in research, education and technology. Its model is to collaborate on research studies that examine human impact on wild cats and their habitats, then disseminate the results in outreach and education programs designed to convince people of the importance of preserving the natural environment. Felidae collaborates with scientists, educators, communities and lawmakers with the goal of protecting ecosystems, staving off further extinctions, and promoting healthy ways for humans to coexist with wild cats and their habitats.\n\nFelidae's focus on wild cat conservation is motivated by the belief that the study of wild cats can serve as a leverage point for addressing the broader environmental issues of habitat loss, human-nature interactions, and wildlife sustainability. This belief is based on the idea that because cats are often the top predators in the ecosystems they inhabit, understanding and solving the problems they face can inform and guide the conservation and preservation of wild animals and wild habitats of all kinds.\n\nFelidae currently collaborates on research projects in field locations around the globe, including the United States, Malaysia, Mongolia, Chile, Peru, Iran, Namibia and Pakistan. Felidae provides strategic guidance, funding, field support, supplies and equipment to its project partners to help them achieve their research goals.\n\nTo link this scientific research to conservation efforts, Felidae incorporates the results of field studies into its outreach and education programs. These include talks and presentations throughout the US, collaborations with artists and video producers to convey the conservation message through visual media, and online projects aimed at educating young people through an interactive portal, an online and mobile phone game, and social network activities.\n\nIn its field work and conservation efforts FCF collaborates with the following organizations: National Park Service, California State Parks, California Department of Fish and Game, UC Santa Cruz, UC Davis, Wildlife Conservation Society, Wildlife Conservation Research Unit, Snow Leopard Trust, Snow Leopard Conservancy, International Wildlife Film Festival, Craighead Beringa South, Cheetah Conservation Fund and the International League of Conservation Photographers, among many other organizations.\n\nFelidae's scientific research projects are based in field locations around the globe.\n\nThe Bay Area Puma Project in Northern California is the first comprehensive study of mountain lions in the San Francisco Bay Area. A primary goal of this study is to determine priority locations for wildlife overpasses and underpasses to maintain connectivity for the region's wildlife populations. In addition, the study uses GPS collars equipped with accelerometers to record detailed information on mountain lion movements that will reveal new insights into their behavior and physiology. Felidae is working with Dr. Chris Wilmers of UC Santa Cruz, along with the California Department of Fish and Game and California State Parks.\n\nThe Patagonia Puma Project in Chile is a long-term ecological study by Dr. Heiko Wittmer of UC Davis which examines the dynamics relating to the puma’s role in the decline of the huemul deer. The researchers hope to exonerate the puma from major blame in the huemul's decline.\n\nThe Bornean Wild Cat and Clouded Leopard Project in Malaysia investigates the conservation needs of five species of Bornean wild cats (Bornean clouded leopard, bay cat, flat-headed cat, marbled cat, and leopard cat). The study will use GPS collars and radio tracking to document spatial patterns, ranging behavior, activity patterns, and habitat use. Felidae is working in partnership with the Global Canopy Programme (UK), the Institute for Tropical Biology and Conservation at the University of Malaysia, and Oxford graduate students Andrew Hearn and Joanna Ross.\n\nThe Study on Endangered Snow Leopards in Mongolia is a long-term research project that will answer basic ecological and behavioral questions about the mysterious and elusive snow leopard. The study will be conducted using GPS collars, non-invasive genetics, and camera trapping with advanced mark-recapture modeling. It will attempt to answer basic questions about snow leopards (birth and mortality rates, cub survival, dispersal rates, habitat use, and home range size) that are currently unknown due to their cryptic nature and inaccessible habitat. Felidae's partners in the project are the Snow Leopard Trust and the Wildlife Conservation Society.\n\nThe Teton Cougar Project in Wyoming studies the population dynamics of mountain lions in the Greater Yellowstone ecosystem by examining predation, behavior associated with human development, and interactions with wolves, grizzly bears and black bears. The project is operated by Craighead Beringia South with support from Felidae.\n\nThe Southern California Puma Project examines the progress and implications of habitat fragmentation as puma populations in Southern California become more isolated. Felidae is collaborating with UC Davis Wildlife Health Center on this study, which has radio-collared more than 50 pumas over 7 years.\n\nThe Asiatic Cheetah Project in Iran is the first detailed ecological study of the critically endangered Asiatic cheetah. Researchers in Northern Iran work to gain insight into the cheetahs’ movements within and between reserves, information that can help scientists to protect the cats' habitat and stave off extinction.\n\nThe Snow Leopard Conservation Project in Pakistan is a high-profile study in the North Western Frontier Province of Pakistan in which the first ever GPS collar was placed on a snow leopard, as seen in the BBC documentary \"Snow Leopard: Beyond the Myth\". The study is a partnership between Snow Leopard Trust, WWF-Pakistan, NWFP Wildlife Department, and Felidae Conservation Fund.\n\nThe African Cheetah Project in Namibia is an ongoing study of the African cheetah that includes camera-trapping, spoor tracking, and DNA research. The study is led by the Cheetah Conservation Fund and Dr. Laurie Marker with support from Felidae.\n\n\n", "id": "21548666", "title": "Felidae Conservation Fund"}
{"url": "https://en.wikipedia.org/wiki?curid=13191721", "text": "Vulnerability and susceptibility in conservation biology\n\nIn conservation biology, susceptibility is the extent to which an organism or ecological community would suffer from a threatening process or factor if exposed, without regard to the likelihood of exposure. It should not be confused with vulnerability, which takes into account both the effect of exposure \"and\" the likelihood of exposure.\n\nFor example, a plant species may be highly susceptible to a particular plant disease, meaning that exposed populations invariably become extinct or decline heavily. However, that species may not be vulnerable if it occurs only in areas where exposure to the disease is unlikely, or if it occurs over such a wide distribution that exposure of all populations is unlikely. Conversely, a plant species may show low susceptibility to a disease, yet may be considered vulnerable if the disease is present in every population.\n", "id": "13191721", "title": "Vulnerability and susceptibility in conservation biology"}
{"url": "https://en.wikipedia.org/wiki?curid=23266530", "text": "Forest genetic resources\n\nForest genetic resources or tree genetic resources are genetic material of shrub and tree species of actual or future value. Forest genetic resources are essential for forest-depending communities who rely for a substantial part of their livelihoods on timber and non-timber forest products (for example fruits, gums and resins) for food security, domestic use and income generation. These resources are also the basis for large-scale wood production in planted forests to satisfy the worldwide need for timber and paper. Genetic resources of several important timber, fruit and other non-timber tree species are conserved ex situ in genebanks or maintained in field collections. Nevertheless, in situ conservation in forests and on farms is in the case of most tree species the most important measure to protect their genetic resources.\n\nA better understanding of the diversity of these species is crucial for their sustainable use and conservation. Monitoring ol patterns of distribution and genetic diversity of these species allows the prioritization of populations for in situ conservation, identification of populations and species most at risk and existing gaps in genebank collections. Also available in French and Spanish. This is vital information which helps tackle global challenges such as food security and climate change.\n\nIn 2014, the Food and Agriculture Organization of the United Nations published the first State of the World's Forest Genetic Resources. The publication addressed the conservation, management and sustainable use of forest tree and other woody plant genetic resources of actual and potential value for human well-being in the broad range of management systems. It was prepared based on information provided by 86 countries, outcomes from regional and subregional consultations, and commissioned thematic studies. Amongst the ten key findings, half of the forest species reported as regularly utilized by countries are threatened by the conversion of forests to pastures and farmland, overexploitation, and the impacts of climate change.\n\nOn the basis of the information and knowledge compiled by FAO for The State of World’s Forest Genetic Resources, the Commission on Genetic Resources for Food and Agriculture developed the Global Plan of Action for the Conservation, Sustainable Use and Development of Forest Genetic Resources. This Global Plan of Action identifies 27 strategic priorities grouped into 4 areas: 1) improving the availability of, and access to, information on forest genetic resources; 2) conservation of forest genetic resources (in situ and ex situ); 3) sustainable use, development and management of forest genetic resources; 4) policies, institutions and capacity-building.\n\nEven though this is a field with many uncertainties, it is evident that during the next 50–100 years climate changes will have an effect on the distribution of forest tree species and the composition of forests. Diversity of forest genetic resources enables the potential for a species (or a population) to adapt to climatic changes and related future challenges such as temperature changes, drought, pests, diseases and forest fires. Though forest trees are known for showing great plasticity in their response to climate changes, not all species are naturally capable to adapt at the pace necessary. For that reason human interventions, such as transfer of forest reproductive material, may be needed. This is particular important for rare and scattered distributed species and species found on the edge of its distribution range.\n\n\n", "id": "23266530", "title": "Forest genetic resources"}
{"url": "https://en.wikipedia.org/wiki?curid=412702", "text": "Monotypic taxon\n\nIn biology, a monotypic taxon is a taxonomic group (taxon) that contains only one immediately subordinate taxon.\n\nA monotypic species is one that does not include subspecies or smaller, infraspecific taxa. In the case of genera, the term \"unispecific\" or \"monospecific\" is sometimes preferred.\n\nIn botanical nomenclature, a monotypic genus is a genus in the special case where a genus and a single species are simultaneously described.\n\nIn contrast an oligotypic taxon contains more than one but only a very few subordinate taxa.\n\nJust as the term \"monotypic\" is used to describe a taxon including only one subdivision, one can also refer to the contained taxon as monotypic within the higher-level taxon, e.g. a genus monotypic within a family. Some examples of monotypic groups are:\n\n", "id": "412702", "title": "Monotypic taxon"}
{"url": "https://en.wikipedia.org/wiki?curid=1790574", "text": "Restoration ecology\n\nRestoration ecology emerged as a separate field in ecology in the 1980s. It is the scientific study supporting the practice of ecological restoration, which is the practice of renewing and restoring degraded, damaged, or destroyed ecosystems and habitats in the environment by active human intervention and action. Restoration ecology is the academic study of the process, whereas ecological restoration is the actual project or process by restoration practitioners.\n\nThe Society for Ecological Restoration defines \"\"ecological restoration\"\" as an \"intentional activity that initiates or accelerates the recovery of an ecosystem with respect to its health, integrity and sustainability\". The practice of ecological restoration includes a wide scope of projects such as erosion control, reforestation, usage of genetically local native species, removal of non-native species and weeds, revegetation of disturbed areas, daylighting streams, reintroduction of native species, as well as habitat and range improvement for targeted species.\n\nE. O. Wilson, a biologist states that: \"Here is the means to end the great extinction spasm. The next century will, I believe, be the era of restoration in ecology.\"\n\nLand managers, laypeople, and stewards have been practicing ecological restoration or ecological management for many hundreds, if not thousands, of years, yet the scientific field of \"restoration ecology\" was not first formally identified and coined until the late 1980s, by John Aber and William Jordan when they were at the University of Wisconsin-Madison. Around this time environmental disasters caused by industry were taking place motivating people toward restoration. They held the first international meetings on this topic in Madison during which attendees visited the University of Wisconsin's Arboretum—the oldest restoration ecology project made famous by Professor Aldo Leopold. The study of restoration ecology has only become a robust and independent scientific discipline over the last two decades, and the commercial applications of ecological restoration have tremendously increased in recent years.\n\nThere is consensus in the scientific community that the current environmental degradation and destruction of many of the Earth's biota is considerable and is taking place on a \"catastrophically short timescale\". Estimates of the current extinction rate is 1,000 to 10,000 times more than the normal rate. For many people biological diversity (biodiversity) has an intrinsic value that humans have a responsibility towards other living things and an obligation to future generations.\n\nOn a more anthropocentric level, natural ecosystems provide human society with food, fuel, and timber. Fundamentally, ecosystem services involve the purification of air and water, detoxification and decomposition of wastes, regulation of climate, regeneration of soil fertility and pollination of crops. Such processes have been estimated to be worth trillions of dollars annually.\n\nHabitat loss is the leading cause of both species extinctions and ecosystem service decline. The two ways to reverse this trend of habitat loss are conservation of currently viable habitat and restoration of degraded habitats.\n\nRestoration ecology may be viewed as a sub-discipline of conservation biology, the scientific study of how to protect and restore biodiversity, and restoration a part of the resulting conservation movement.\n\nThough restoration ecologists and other conservation biologists generally agree that habitat is the most important locus of biodiversity protection, the disciplines themselves have different focuses. Conservation biology as an academic discipline is rooted in population biology. Because of that, it is generally organized at the genetic level, looking at specific species populations (i.e. endangered species). Restoration ecology is organized at the community level, looking at specific ecosystems.\n\nBecause it is organized by species, conservation biology often emphasizes vertebrate animals because of their salience and popularity, whereas restoration ecology emphasizes plants because restorations begin by establishing plant communities. Ecosystem restoration is botanically based but does have \"poster species\" for individual ecosystems to get the public involved. Since soils define the foundation of any functional terrestrial system, restoration ecology's ecosystem-level focus also results in greater emphasis on the role of soil's physical and microbial processes.\n\nRestoration ecology draws on a wide range of ecological concepts.\n\nDisturbance is a change of environmental conditions which interferes with the functioning of a biological system. Disturbance, at a variety of spatial and temporal scales, is a natural component of many communities.\n\nHumans have had limited natural impacts on ecosystems for as long as humans have existed, however, the severity and scope of our influences has accelerated in the last few centuries. Understanding and minimizing the differences between modern anthropogenic and \"natural\" disturbances is crucial to restoration ecology. For example, new forestry techniques that better imitate historical disturbances are now being implemented.\n\nIn addition, restoring a fully sustainable ecosystem often involves studying and attempting to restore a natural disturbance regime (e.g., fire ecology).\n\nEcological succession is the process by which the component species of a community changes over time. Following a disturbance, an ecosystem generally progresses from a simple level of organization (i.e. few dominant pioneer species) to a more complex community (i.e. many interdependent species) over time. Depending on the severity of the disturbance, restoration often consists of initiating, assisting, or accelerating ecological successional processes.\n\nIn many ecosystems, communities tend to recover following mild to moderate natural and anthropogenic disturbances. Restoration in these systems involves hastening natural successional trajectories. However, a system that has experienced a more severe disturbance (i.e. physical or chemical alteration of the environment) may require intensive restorative efforts to recreate environmental conditions that favor natural successional processes. This ability to recover is called resilience.\n\nHabitat fragmentation is the emergence of spatial discontinuities in a biological system. Through land use changes (e.g. agriculture) and \"natural\" disturbance, ecosystems are broken up into smaller parts. Small fragments of habitat can support only small populations and small populations are more vulnerable to extinction. Furthermore, fragmenting ecosystems decreases interior habitat. Habitat along the edge of a fragment has a different range of environmental conditions and therefore supports different species than the interior. Fragmentation effectively reduces interior habitat and may lead to the extinction of those species which require interior habitat. Restorative projects can increase the effective size of a habitat by simply adding area or by planting habitat corridors that link and fill in the gap between two isolated fragments. Reversing the effects of fragmentation and increasing habitat connectivity can be an important effect of restoration ecology.\n\nEcosystem function describes the foundational processes of natural systems, including nutrient cycles and energy fluxes. These processes are the most basic and essential components of ecosystems. An understanding of the full complexity and intricacies of these cycles is necessary to address any ecological processes that may be degraded. A functional ecosystem, that is completely self-perpetuating (no management required), is the ultimate goal of restorative efforts. Since, these ecosystem functions are emergent properties of the system as a whole, monitoring and management are crucial for the long-term stability of an ecosystem.\n\nCommunity assembly \"is a framework that can unify virtually all of (community) ecology under a single conceptual umbrella\". Community assembly theory attempts to explain the existence of environmentally similar sites with differing assemblages of species. It assumes that species have similar niche requirements, so that community formation is a product of random fluctuations from a common species pool. Essentially, if all species are fairly ecologically equivalent then random variation in colonization, migration and extinction rates between species, drive differences in species composition between sites with comparable environmental conditions.\n\nSpatial heterogeneity of resources can influence plant community composition, diversity and assembly trajectory. Baer et al. (2005) manipulated soil resource heterogeneity in a tallgrass prairie restoration project. They found increasing resource heterogeneity, which on its own was insufficient to insure species diversity in situations where one species may dominate across the range of resource levels. Their findings were consistent with the theory regarding the role of ecological filters on community assembly. The establishment of a single species, best adapted to the physical and biological conditions can play an inordinately important role in determining the community structure.\n\nRestoration is used as a tool for reducing the spread of invasive plant species in a number of ways. The first method views restoration primarily as a means to reduce the presence of invasive species and limit their spread. As this approach emphasizes control of invaders, the restoration techniques can differ from typical restoration projects. The goal of such projects is not necessarily to restore an entire ecosystem or habitat. These projects frequently use lower diversity mixes of aggressive native species seeded at high density. These projects frequently use lower diversity mixes of aggressive native species seeded at high density. They are not always actively managed following seeding. The target areas for this type of restoration are those which are heavily dominated by invasive species. The goals are to first remove the species and then in so doing, reduce the number of invasive seeds being spread to surrounding areas. This approach has been shown to be effective in reducing weeds, although it is not always a sustainable solution long term without additional weed control, such as mowing, or re-seeding.\n\nRestoration projects are also used as a way to better understand what makes an ecological community resistant to invasion. As restoration projects have a broad range of implementation strategies and methods used to control invasive, they can be used by ecologists to test theories about invasion. Restoration projects have been used to understand how the diversity of the species introduced in the restoration affects invasion. We know that generally higher diversity prairies have lower levels of invasion. Incorporation of functional ecology has shown that more functionally diverse restorations have lower levels of invasion. Furthermore, studies have shown that using native species functionally similar to invasive species are better able to compete with invasive species. Restoration ecologists have also used the variety of strategies employed at different restoration sites to better understand the most successful management techniques to control invasion.\n\nProgress along a desired successional pathway may be difficult if multiple stable states exist. Looking over 40 years of wetland restoration data Klotzi and Gootjans (2001) argue that unexpected and undesired vegetation assemblies \"may indicate that environmental conditions are not suitable for target communities\". Succession may move in unpredicted directions, but constricting environmental conditions within a narrow range may rein in the possible successional trajectories and increase the likelihood of a desired outcome.\n\nThe UK Natural Capital Committee (NCC) made a recommendation in its second State of Natural Capital report published in March 2014 that in order to meet the Government's goal of being the first generation to leave the environment in a better state than it was inherited, a long-term 25-year plan was needed to maintain and improve England's natural capital. The UK Government has not yet responded to this recommendation.\n\nThe Secretary of State for the UK's Department for Environment, Food and Rural Affairs, Owen Paterson, described his ambition for the natural environment and how the work of the Committee fits into this at an NCC event in November 2012: \"I do not, however, just want to maintain our natural assets; I want to improve them. I want us to derive the greatest possible benefit from them, while ensuring that they are available for generations to come. This is what the NCC's innovative work is geared towards\".\n\nAccording to the Society for Ecological Restoration, ecosystem restoration is the return of a damaged ecological system to a stable, healthy, and sustainable state that have been degraded, damaged, or destroyed, often together with associated ecosystem services. The scientific study of these practices is restoration ecology, while the physical act of managing ecosystems is referred to as ecosystem restoration.\n\nDuring seed based restoration projects, it is generally recommended to source from local populations, to minimize the effects of maladaptation. One of the many challenges of restoration is that every species is different and requires different sourcing guidelines. Rather than putting strict distance recommendations, other guidelines recommend sourcing seeds to match similar environmental conditions. For example, sourcing for \"Castilleja levisecta\" found that farther source populations that matched similar environmental variables were better suited for the restoration project than closer source populations. Restoration guidelines vary drastically between states and agency. For example, Minnesota is broken up into 9 seed sourcing zones, where its neighbor Iowa, is broken into three latitudinal zones. US Forest Service recently developed provisional seed zones based on a combination of minimum winter temperature zones, aridity, and the Level III ecoregions.\n\nThere are many reasons to restore ecosystems. Some include:\n\nThere exists considerable differences of opinion in how to set restoration goals and how to define their success among conservation groups. Some urge active restoration (e.g. eradicating invasive animals to allow the native ones to survive) and others who believe that protected areas should have the bare minimum of human interference, such as rewilding. Ecosystem restoration has generated controversy. Skeptics doubt that the benefits justify the economic investment or who point to failed restoration projects and question the feasibility of restoration altogether. It can be difficult to set restoration goals, in part because, as Anthony Bradshaw claims, \"ecosystems are not static, but in a state of dynamic equilibrium…. [with restoration] we aim [for a] moving target.\"\n\nSome conservations argue, that though an ecosystem may not be returned to its original state, the functions of the ecosystem (especially ones that provide services to us) may be more valuable than its current configuration (Bradshaw 1987). One reason to consider ecosystem restoration is to mitigate climate change through activities such as afforestation. Afforestation involves replanting forests, which remove carbon dioxide from the air. Carbon dioxide is a leading cause of global warming (Speth, 2005) and capturing it would help alleviate climate change. Another example of a common driver of restoration projects in the United States is the legal framework of the Clean Water Act, which often requires mitigation for damage inflicted on aquatic systems by development or other activities.\n\nSome view ecosystem restoration as impractical, partially because restorations often fall short of their goals. Hilderbrand et al. point out that many times uncertainty (about ecosystem functions, species relationships, and such) is not addressed, and that the time-scales set out for 'complete' restoration are unreasonably short, while other critical markers for full scale restoration are either ignored or abridged due to feasibility concerns. In other instances an ecosystem may be so degraded that abandonment (allowing an injured ecosystem to recover on its own) may be the wisest option (Holl, 2006). Local communities sometimes object to restorations that include the introduction of large predators or plants that require disturbance regimes such as regular fires, citing threat to human habitation in the area (MacDonald et al. 2002). High economic costs can also be perceived as a negative impact of the restoration process.\n\nPublic opinion is very important in the feasibility of a restoration; if the public believes that the costs of restoration outweigh the benefits they will not support it (MacDonald et al. 2002).\n\nMany failures have occurred in past restoration projects, many times because clear goals were not set out as the aim of the restoration, or an incomplete understanding of the underlying ecological framework lead to insufficient measures. This may be because, as Peter Alpert says, \"people may not [always] know how to manage natural systems effectively\". Furthermore, many assumptions are made about myths of restoration such as carbon copy, where a restoration plan, which worked in one area, is applied to another with the same results expected, but not realized (Hilderbrand et al. 2005).\n\nOne of the struggles for both fields is a divide between restoration ecology and ecological restoration in practice. Currently, many restoration practitioners as well as scientists feel that science is not being adequately incorporated into ecological restoration projects. In a 2009 survey of practitioners and scientists, the \"science-practice gap\" was listed as the second most commonly cited reason limiting the growth of both science and practice of restoration.\n\nThere are a variety of theories about the cause of this gap. However, it has been well established that one of the main issues is that the questions studied by restoration ecologists are frequently not found useful or easily applicable by land managers. For instance, many publications in restoration ecology characterize the scope of a problem in depth, without providing concrete solutions. Additionally many restoration ecology studies are carried out under controlled conditions and frequently at scales much smaller than actual restorations. Whether or not these patterns hold true in an applied context is often unknown. There is evidence that these small scale experiments inflate type II error rates and differ from ecological patterns in actual restorations.\n\nThere is further complication in that restoration ecologists who want to collect large scale data on restoration projects can face enormous hurdles in obtaining the data. Managers vary in how much data they collect, and how many records they keep. Some agencies keep only a handful of physical copies of data that make it difficult for the researcher to access. Many restoration projects are limited by time and money, so data collection and record keeping are not always feasible. However, this limits the ability of scientists to analyze restoration projects and give recommendations based on empirical data.\n\n\n", "id": "1790574", "title": "Restoration ecology"}
{"url": "https://en.wikipedia.org/wiki?curid=13977513", "text": "Buffer strip\n\nA buffer strip is an area of land maintained in permanent vegetation that helps to control air, soil, and water quality, along with other environmental problems, dealing primarily on land that is used in agriculture. Buffer strips trap sediment, and enhance filtration of nutrients and pesticides by slowing down runoff that could enter the local surface waters. The root systems of the planted vegetation in these buffers hold soil particles together which alleviate the soil of wind erosion and stabilize stream banks providing protection against substantial erosion and landslides. Farmers can also use buffer strips to square up existing crop fields to provide safety for equipment while also farming more efficiently.\n\nBuffer strips can have several different configurations of vegetation found on them varying from simply grass to combinations of grass, trees, and shrubs. Areas with diverse vegetation provide more protection from nutrient and pesticide flow and at the same time provide better biodiversity amongst plants and animals.\n\nMany country, state, and local governments provide financial incentives for conservation programs such as buffer strips because they help stabilize the environment even when the land is being used. Buffer strips not only stabilize the land but can also provide a visual demonstration that land is under stewardship.\n\nA grassed waterway reduces soil erosion and captures most nutrients and pesticides that would normally wash out of crop fields and into major waters. These waterways help to carry surface water at a non-erosive velocity to an area where it will have a stable outlet. Outlets must be adequate enough to allow water to drain without ponding or flooding the area being protected, while also preventing erosion of the water into the outlet which can be accomplished through the use of riprap. A limitation is during large runoff events, when soil is saturated, grassed waterways will have a very concentrated flow of water making them not as effective during high rainfalls. Grassed waterways require very little maintenance once they are introduced with major upkeep being mowing of the grass and reseeding. Farm machinery and cattle can cross these waterways but it may be hazardous during wet periods. One of the major disadvantages of waterways are actually getting them established. A late summer or early fall seeding when rainfall is minimal is recommended to allow the seed to have the best chance at establishing a root system.\n\nContour buffer strips are strips of perennial vegetation alternated with wider cultivated strips of cropland. This type of buffer strip is most effective when runoff water enters uniformly as sheetflow. They are very adapted to trapping pesticides and reducing rill erosion. These buffers need to be at least wide and make up for 20 to 30 percent of slope of an area. A lot of the time contour buffers can be used as a very inexpensive substitute for terraces. Most of the time a grass is selected that can be harvested during mid-summer. These buffers are not permanent and can be moved up and down hillsides from season to season in order to re-establish vegetation.\n\nVegetative barriers are narrower buffer strips of hardy, native, perennial grasses or shrubs planted in parallel rows to crops. They are very effective in reducing wind and water erosion which results in sediment trapping and water infiltration. They function in similar fashion to a contour buffer strip, just much narrower.\n\nField borders are bands or strips of perennial vegetation that is found on the edge of a cropland field. Field borders help with runoff only when it flows over the strip. They’re very effective in benefiting spraying operations because they allow for extra room between adjacent fields. They also provide room for farming equipment to turn around. Field borders are effective in reducing wind and water erosion and provide great wildlife habitat.\n\nFilter strips are areas of grass or other permanent vegetation that protect riparian areas from sediment runoff, pesticides, pathogens, organics and nutrients. These strips are very important in protecting stream banks and water quality. Filter strips work best when other conservation practices are used in order to drain water in their direction. Filter strips were originally used mostly in agriculture, but now are a common practice in urban areas where water quality has become an increasingly important issue.\n\nRiparian forest buffers are diverse communities of trees, shrubs and native perennial grasses. They are great for providing habitat for wildlife on land and in the water. Taller trees next to the streams help to lower water temperatures with shade which improves aquatic communities. The shrubs and grasses help to slow flooding and the larger trees can sometimes intercept nitrates before they reach the water with their deep roots.\n\nThe main purpose of a windbreak or a shelterbelt is to protect areas from wind causing erosion on the bare soil of croplands. Windbreaks can also serve as an area that separates fields and protects them from spray drift of pesticides.\n\nBuffer strips are very important in helping to provide habitat for many species of wildlife in the open farm lands by causing an edge effect. With much of the land open on farms having an edge allows a safe-haven for animals to move between different ecosystems. Buffers are also helpful in conserving biodiversity especially to that of rare or endangered species through the incorporation of native grasses into their seeding by the landowner. are especially important to pheasants, quail, chukar and songbirds because they provide the foods they need as well as the shelter from predators. Since most buffer strip areas have limited disturbance from farming it allows for a shelter to hide year round for many of the species including insects, birds, and mammals. When buffers run into and follow riparian areas along stream beds it is important to have larger vegetation like trees and shrubs that shade the water from the open sun. The water is then able to be cooler allowing for greater fish production and other aquatic plants and other biota to thrive in a less disturbed environment.\n\nThis area of vegetation following a body of water is noted as a riparian zone. These buffer areas often incorporate large trees that protect stream banks from excessive erosion and shade aquatic areas. The shade provided by the larger trees reduces water temperatures and light intensity from ultraviolet light. Debris including leaves and branches that fell from trees, often contain aquatic invertebrates important to the structure of the water following the \"River Continuum\" concept. Since the riparian zones contain a larger variety of plants the overall diversity is much greater as well. With more photosynthesis and higher amounts of available water plant primary production can increase in turn creating more potential food for the wildlife \n\nThe USDA shows that grassed waterways of less than 5% slopes for a chosen waterway will greatly reduce velocity of draining water within the land. The Natural Resources Conservation Service (NRCS) offers the use of an online Soil survey to view the area of land to be planted and examine slope and soil drainage. As viewed by the Natural Resources Conservation Service, soil drainage is the number one priority for location of certain grasses. Poorer drainage causes less infiltration of water into the soil as groundwater recharge causing ponding and flooding of surrounding crops. Higher drainage becomes more droughty which hinders the establishment of certain grasses good for waterways. Medium soil drainage becomes the most suitable for planting. Determining exact grasses and seed amounts to plant follows specifications of a local NRCS Field Office Technical Guide and the Contour Buffer practice standard while taking practice on land and regional environmental conditions into consideration.\n\nThe NRCS has shown contour strip cropping provides the greatest effectiveness when slopes of the area are within 4-8%. For greater success in lowering the erosion, contour strips on the slopes need to follow the contours of the landscape. Row crops like corn, legumes, or soybeans should alternate strips of small grains or forages to successfully limit erosion and slowing or capturing the runoff of fertilizers and pesticides. Tests from the NRCS have shown that the smaller tighter rooted grasses and hays provide more surface cover to prevent rain and wind erosion while slowing runoff, increasing infiltration, and trapping sediment from the high erosive row crops. Proper planting of the contour crops is important for higher success of erosion control to protect highly fertile topsoil.\n\n\n", "id": "13977513", "title": "Buffer strip"}
{"url": "https://en.wikipedia.org/wiki?curid=13224331", "text": "Ecological resilience\n\nIn ecology, resilience is the capacity of an ecosystem to respond to a perturbation or disturbance by resisting damage and recovering quickly. Such perturbations and disturbances can include stochastic events such as fires, flooding, windstorms, insect population explosions, and human activities such as deforestation, fracking of the ground for oil extraction, pesticide sprayed in soil, and the introduction of exotic plant or animal species. Disturbances of sufficient magnitude or duration can profoundly affect an ecosystem and may force an ecosystem to reach a threshold beyond which a different regime of processes and structures predominates. Human activities that adversely affect ecosystem resilience such as reduction of biodiversity, exploitation of natural resources, pollution, land use, and anthropogenic climate change are increasingly causing regime shifts in ecosystems, often to less desirable and degraded conditions. Interdisciplinary discourse on resilience now includes consideration of the interactions of humans and ecosystems via socio-ecological systems, and the need for shift from the maximum sustainable yield paradigm to environmental resource management which aims to build ecological resilience through \"resilience analysis, adaptive resource management, and adaptive governance\".\n\nThe concept of resilience in ecological systems was first introduced by the Canadian ecologist C.S. Holling in order to describe the persistence of natural systems in the face of changes in ecosystem variables due to natural or anthropogenic causes. Resilience has been defined in two ways in ecological literature:\n\nThe second definition has been termed ‘ecological resilience’, and it presumes the existence of multiple stable states or regimes.\n\nSome shallow temperate lakes can exist within either clear water regime, which provides many ecosystem services, or a turbid water regime, which provides reduced ecosystem services and can produce toxic algae blooms. The regime or state is dependent upon lake phosphorus cycles, and either regime can be resilient dependent upon the lake's ecology and management.\n\nMulga woodlands of Australia can exist in a grass-rich regime that supports sheep herding, or a shrub-dominated regime of no value for sheep grazing. Regime shifts are driven by the interaction of fire, herbivory, and variable rainfall. Either state can be resilient dependent upon management.\n\nEcologists Brian Walker, C S Holling and others describe four critical aspects of resilience: \"latitude\", \"resistance\", \"precariousness\", and \"panarchy\".\n\nThe first three can apply both to a whole system or the sub-systems that make it up.\n\n\nClosely linked to resilience is \"adaptive capacity\", which is the property of an ecosystem that describes change in stability landscapes and resilience. Adaptive capacity in socio-ecological systems refers to the ability of humans to deal with change in their environment by observation, learning and altering their interactions.\n\nResilience refers to ecosystem's stability and capability of tolerating disturbance and restoring itself.  If the disturbance is of sufficient magnitude or duration, a threshold may be reached where the ecosystem undergoes a regime shift, possibly permanently. Sustainable use of environmental goods and services requires understanding and consideration of the resilience of the ecosystem and its limits. However, the elements which influence ecosystem resilience are complicated. For example, various elements such as the water cycle, fertility, biodiversity, plant diversity and climate, interact fiercely and affect different systems.\n\nThere are many areas where human activity impacts upon and is also dependent upon the resilience of terrestrial, aquatic and marine ecosystems. These include agriculture, deforestation, pollution, mining, recreation, overfishing, dumping of waste into the sea and climate change.\n\nAgriculture can be seen as a significant example which the resilience of terrestrial ecosystems should be considered. The organic matter (elements carbon and nitrogen) in soil, which is supposed to be recharged by multiple plants, is the main source of nutrients for crop growth. At the same time, intensive agriculture practices in response to global food demand and shortages involves the removal of weeds and the application of fertilisers to increase food production. However, as a result of agricultural intensification and the application of herbicides to control weeds, fertilisers to accelerate and increase crop growth and pesticides to control insects, plant biodiversity is reduced as is the supply of organic matter to replenish soil nutrients and prevent run-off. This leads to a reduction in soil fertility and productivity. More sustainable agricultural practices would take into account and estimate the resilience of the land and monitor and balance the input and output of organic matter.\n\nThe term deforestation has a meaning that covers crossing the threshold of forest's resilience and losing its ability to return its originally stable state. To recover itself, a forest ecosystem needs suitable interactions among climate conditions and bio-actions, and enough area. In addition, generally, the resilience of a forest system allows recovery from a relatively small scale of damage (such as lightning or landslide) of up to 10 per cent of its area. The larger the scale of damage, the more difficult it is for the forest ecosystem to restore and maintain its balance.\n\nDeforestation also decreases biodiversity of both plant and animal life and can lead to an alteration of the climatic conditions of an entire area. Deforestation can also lead to species extinction, which can have a domino effect particularly when keystone species are removed or when a significant number of species is removed and their ecological function is lost.\n\nClimate resilience is generally defined as the capacity for a socio-ecological system to: (1) absorb stresses and maintain function in the face of external stresses imposed upon it by climate change and (2) adapt, reorganize, and evolve into more desirable configurations that improve the sustainability of the system, leaving it better prepared for future climate change impacts. Increasingly, climate change is threatening human communities around the world in a variety of ways such as rising sea levels, increasingly frequent large storms, tidal surges and flooding damage. One of the main results of climate change is rising sea water temperature which has a serious effect on coral reefs, through thermal-stress related coral bleaching. Between 1997-1998 the most significant worldwide coral bleaching event was recorded which corresponded with the El Nino Southern Oscillation, with significant damage to the coral reefs of the Western Indian Ocean.\n\nIt has been estimated by the United Nations Food and Agriculture Organisation that over 70% of the world’s fish stocks are either fully exploited or depleted which means overfishing threatens marine ecosystem resilience and this is mostly by rapid growth of fishing technology. One of the negative effects on marine ecosystems is that over the last half-century the stocks of coastal fish have had a huge reduction as a result of overfishing for its economic benefits. Blue fin tuna is at particular risk of extinction. Depletion of fish stocks results in lowered biodiversity and consequently imbalance in the food chain, and increased vulnerability to disease.\n\nIn addition to overfishing, coastal communities are suffering the impacts of growing numbers of large commercial fishing vessels in causing reductions of small local fishing fleets. Many local lowland rivers which are sources of fresh water have become degraded because of the inflows of pollutants and sediments.\n\nDumping both depends upon ecosystem resilience whilst threatening it. Dumping of sewage and other contaminants into the ocean is often undertaken for the dispersive nature of the oceans and adaptive nature and ability for marine life to process the marine debris and contaminants. However, waste dumping threatens marine ecosystems by poisoning marine life and eutrophication.\n\nAccording to the International Maritime Organisation oil spills can have serious effects on marine life. The OILPOL Convention recognized that most oil pollution resulted from routine shipboard operations such as the cleaning of cargo tanks.  In the 1950s, the normal practice was simply to wash the tanks out with water and then pump the resulting mixture of oil and water into the sea. OILPOL 54   prohibited the dumping of oily wastes within a certain distance from land and in 'special areas' where the danger to the environment was especially acute. In 1962 the limits were extended by means of an amendment adopted at a conference organized by IMO. Meanwhile, IMO in 1965 set up a Subcommittee on Oil Pollution, under the auspices of its Maritime Safety committee, to address oil pollution issues.\n\nThe threat of oil spills to marine life is recognised by those likely to be responsible for the pollution, such as the International Tanker Owners Pollution Federation:\n\nThe marine ecosystem is highly complex and natural fluctuations in species composition, abundance and distribution are a basic feature of its normal function. The extent of damage can therefore be difficult to detect against this background variability. Nevertheless, the key to understanding damage and its importance is whether spill effects result in a downturn in breeding success, productivity, diversity and the overall functioning of the system. Spills are not the only pressure on marine habitats; chronic urban and industrial contamination or the exploitation of the resources they provide are also serious threats.\n\nThe Woods Hole Oceanographic Institution calls nutrient pollution the most widespread, chronic environmental problem in the coastal ocean. The discharges of nitrogen, phosphorus, and other nutrients come from agriculture, waste disposal, coastal development, and fossil fuel use. Once nutrient pollution reaches the coastal zone, it stimulates harmful overgrowths of algae, which can have direct toxic effects and ultimately result in low-oxygen conditions. Certain types of algae are toxic. Overgrowths of these algae result in harmful algal blooms, which are more colloquially referred to as \"red tides\" or \"brown tides\". Zooplankton eat the toxic algae and begin passing the toxins up the food chain, affecting edibles like clams, and ultimately working their way up to seabirds, marine mammals, and humans. The result can be illness and sometimes death.\n\nThere is increasing awareness that a greater understanding and emphasis of ecosystem resilience is required to reach the goal of sustainable development. A similar conclusion is drawn by Perman et al. who use resilience to describe one of 6 concepts of sustainability; \"A sustainable state is one which satisfies minimum conditions for ecosystem resilience through time\". Resilience science has been evolving over the past decade, expanding beyond ecology to reflect systems of thinking in fields such as economics and political science. And, as more and more people move into densely populated cities, using massive amounts of water, energy, and other resources, the need to combine these disciplines to consider the resilience of urban ecosystems and cities is of paramount importance.\n\nThe interdependence of ecological and social systems has gained renewed recognition since the late 1990s by academics including Berkes and Folke and developed further in 2002 by Folke et al. as the concept of sustainable development has evolved beyond the 3 pillars of sustainable development to place greater political emphasis on economic development. This is a movement which causes wide concern in environmental and social forums and which Clive Hamilton describes as \"the growth fetish\".\n\nThe purpose of ecological resilience that is proposed is ultimately about averting our extinction as Walker cites Holling in his paper: \"[..] \"resilience is concerned with [measuring] the probabilities of extinction” (1973, p. 20)\". Becoming more apparent in academic writing is the significance of the environment and resilience in sustainable development. Folke et al state that the likelihood of sustaining development is raised by \"Managing for resilience\" whilst Perman et al. propose that safeguarding the environment to \"deliver a set of services\" should be a \"necessary condition for an economy to be sustainable\".\n\nThe challenge of applying the concept of ecological resilience to the context of sustainable development is that it sits at odds with conventional economic ideology and policy making. Resilience questions the free market model within which global markets operate. Inherent to the successful operation of a free market is specialisation which is required to achieve efficiency and increase productivity. This very act of specialisation weakens resilience by permitting systems to become accustomed to and dependent upon their prevailing conditions. In the event of unanticipated shocks; this dependency reduces the ability of the system to adapt to these changes. Correspondingly; Perman et al. note that; \"Some economic activities appear to reduce resilience, so that the level of disturbance to which the ecosystem can be subjected to without parametric change taking place is reduced\".\n\nBerkes and Folke table a set of principles to assist with \"building resilience and sustainability\" which consolidate approaches of adaptive management, local knowledge-based management practices and conditions for institutional learning and self-organisation.\n\nMore recently, it has been suggested by Andrea Ross that the concept of sustainable development is no longer adequate in assisting policy development fit for today’s global challenges and objectives. This is because the concept of sustainable development is \"based on weak sustainability\" which doesn’t take account of the reality of \"limits to earth's resilience\". Ross draws on the impact of climate change on the global agenda as a fundamental factor in the \"shift towards ecological sustainability\" as an alternative approach to that of sustainable development.\n\nScientific research associated with resilience is beginning to play a role in influencing policy-making and subsequent environmental decision making.\n\nThis occurs in a number of ways:\n\nEcological resilience and the thresholds by which resilience is defined are closely interrelated in the way that they influence environmental policy-making, legislation and subsequently environmental management. The ability of ecosystems to recover from certain levels of environmental impact is not explicitly noted in legislation, however, because of ecosystem resilience, some levels of environmental impact associated with development are made permissible by environmental policy-making and ensuing legislation.\n\nSome examples of the consideration of ecosystem resilience within legislation include:\n\n\n", "id": "13224331", "title": "Ecological resilience"}
{"url": "https://en.wikipedia.org/wiki?curid=10777001", "text": "Conservation Biology (journal)\n\nConservation Biology is a bimonthly peer-reviewed scientific journal of the Society for Conservation Biology, published by Wiley-Blackwell. It covers the science and practice of conserving Earth's biological diversity, including issues concerning any of the Earth's ecosystems or regions. According to the \"Journal Citation Reports\", the journal has a 2013 impact factor of 4.320.\n", "id": "10777001", "title": "Conservation Biology (journal)"}
{"url": "https://en.wikipedia.org/wiki?curid=25030863", "text": "Threshold host density\n\nThreshold host density (N), in the context of wildlife disease ecology, refers to the concentration of a population of a particular organism as it relates to disease. Specifically, the threshold host density (N) of a species refers to the minimum concentration of individuals necessary to sustain a given disease within a population.\n\nThreshold host density (N) only applies to density dependent diseases, where there is an \"aggregation of risk\" to the host in either high host density or low host density patches. When low host density causes an increase in incidence of parasitism or disease, this is known as inverse host density dependence, whereas when incidence of parasitism or disease is elevated in high host density conditions, it is known as direct host density dependence.\n\nHost density independent diseases show no correlation between the concentration of a given host population and the incidence of a particular disease. Some examples of host density independent diseases are sexually transmitted diseases in both humans and other animals. This is due to the constant incidence of interaction observed in sexually transmitted diseases—even if there are only 20 individuals left of a given population, survival of the species requires sexual contact, and continued spread of the disease.\n\nDensity dependent diseases are significantly less likely to cause extinction of a population, as the natural course of disease will bring down the density, and thus the propinquity of individuals in the population. In other words, less individuals—as caused by disease—means lower infection rates and a population equilibrium.\n\n\n\nThis graph shows the direct relationship between disease spread through contact and population density. As the population density increases, so do transmission events between individuals.\n\nThere is a rapid initial increase in disease transmission as the population increases from zero, and then the plateau of transmission throughout most of the graph. As sexual contact is required in nearly all sexually reproducing species, transmission is not very host density dependent. It is only in cases of near-extinction where sexually transmitted diseases show any dependence on host density. It is for this reason that sexually transmitted diseases are more likely than density dependent diseases to cause extinction.\n\nThis graph shows the relationship between population density and the transmission of vector-borne disease. Initially, the number of contacts between individuals and vectors increases as population density increases. Eventually, however, the advantage of host density diminishes as the density becomes too great for the vector to maintain its natural ecological relationship with the host, and transmission decreases.\n\n\n", "id": "25030863", "title": "Threshold host density"}
{"url": "https://en.wikipedia.org/wiki?curid=10536491", "text": "Nuisance wildlife management\n\nNuisance wildlife management is the term given to the process of selective removal of problem individuals or populations of specific species of wildlife. Other terms for the field, include wildlife damage management, wildlife control, and animal damage control to name a few. Some species of wildlife may become habituated to man's presence, causing property damage or risking transfer of disease to humans or pets (zoonosis). Many wildlife species coexist with humans very successfully, such as commensal rodents which have become more or less dependent on humans.\n\nTypically, species that are most likely to be considered a nuisance by humans have the following characteristics. First, they are adaptable to fragmented habitat. Animals such as Canada geese (\"Branta canadensis\") love ponds with low sloping banks leading to lush green grass. Humans love this sort of landscaping too, so it is not surprising that Canada geese have thrived (not to mention the decline in hunting).\n\nSecond, these animals are not tied to eating a specific type of food. For example, lynx do not thrive in human impacted environments because they rely so heavily on snowshoe hares. In contrast, raccoons have been very successful in urban landscapes because they can live in attics, chimneys, and even sewers, and can sustain themselves with food gained from trashcans and discarded litter. \n\nThird, successful animals must not pose an obvious significant risk to human health and safety. Animals perceived as grave threats will incur the extreme ire of humans and be under constant threat of humans seeking to eliminate them.\n\nFinally, successful animals in humanized landscapes are often perceived as \"cute\", at least until they become so numerous that their preferential status becomes diminished. Many wildlife species have the potential of becoming a \"nuisance\" species, and whether or not a species is regarded as a pest can be directly correlated with the degree to which that animal can be tolerated by humans. For many people, tree squirrels feeding in their yards or gardens are not a problem; a neighbor may feel that these same squirrels nesting in the attic of their house are a nuisance and a fire hazard, due to their habit of gnawing on electrical cables.\n\nCommon wildlife pests include armadillos, skunks, boars, foxes, squirrels, snakes, rats, groundhogs, beavers, opossums, raccoons, bats, moles, deer, mice, coyotes, bears, ravens, seagulls, woodpeckers and pigeons. Some of these species are protected by state or federal regulations, such as bears, ravens, bats, deer, woodpeckers, and coyotes, and a permit may be required to control some species.\n\nWildlife are usually only pests in certain situations, such as when their numbers become \"excessive\" in a particular area. Human-induced changes in the environment will often result in increased numbers of a species. For example, piles of scrap building material make excellent sites where rodents can nest. Food left out for household pets is often equally attractive to some wildlife species. In these situations, the wildlife have suitable food and habitat and may become a nuisance.\n\nThe primary objective of any control program should be to reduce damage in a practical, humane and environmentally acceptable manner. Wildlife managers and wildlife control operators (WCOs) use control methods based on the habits and biology of the animals causing damage. By using methods matched to the nuisance species, control efforts will be more effective and will serve to maximize safety to the environment, humans and other animals.\n\nA key to controlling wildlife damage is prompt and accurate determination of which animal is causing the damage. Even someone with no training or experience can sometimes identify the pest by thoroughly examining the damaged area. Because feeding indications of many wildlife species are similar, other signs – such as droppings, tracks, burrows, nests or food caches – are usually needed to make a positive species identification.\n\nAfter the wildlife pest is identified, control methods can be chosen appropriate to the animal species involved. Improper control methods may harm but not kill the animal, causing it to become leery of those and other methods in the future. For example, using traps and poison baits improperly or in the wrong situation may teach the animal that the control method is harmful. This may make the animal difficult to control later, even with the correct method.\n\n\nThe most commonly used methods for controlling nuisance wildlife around homes and gardens include exclusion, habitat modification, repellents, toxic baits, glue boards, traps and frightening. Wildlife control involves human risks both from possible injury to person and property, but also from zoonotic disease.\n\nPhysically excluding an offending animal from the area being damaged or disturbed is often the best and most permanent way to control the problem. Depending upon size of the area to be protected, this control method can range from inexpensive to prohibitively costly.\n\nFor example, damage by birds or rabbits to ornamental shrubs or garden plants can be reduced inexpensively by placing bird netting over the plants to keep the pests away. On the other hand, fencing out deer from a lawn or garden can be more costly. Materials needed for exclusion will depend upon the species causing the problem. Large mammals can be excluded with woven wire fences, poly-tape fences, and electric fences; but many communities forbid the use of electric fencing in their jurisdictions. Small mammals and some birds can be excluded with netting, tarp, hardware cloth or any other suitable material; nets come in different weave sizes suitable for different animals to be excluded.\n\nHowever, exclusion can interfere with the natural movement of wildlife, particularly when exclusion covers large areas of land.\n\nModifying an animal’s habitat often provides lasting and cost-effective relief from damage caused by nuisance wildlife. Habitat modification is effective because it limits access to one or more of the requirements for life – food, water or shelter. However, habitat modification, while limiting nuisance wildlife, may also limit desirable species such as songbirds as well.\n\nRodent- or bat-proofing buildings by sealing cracks and holes prevents these animals from gaining access to suitable habitats where they are not welcome. Storing seed and pet food in tightly closed containers, controlling weeds and garden debris around homes and buildings, and storing firewood and building supplies on racks or pallets above ground level are also practices that can limit or remove the animals’ sources of food, water or shelter.\n\nUsing a repellent that changes the behavior of an animal may lead to a reduction or elimination of damage. Several available repellents, such as objectionable-tasting coatings or odor repellents, may deter wildlife from feeding on plants. Other repellents such as sticky, tacky substances placed on or near windows, trees or buildings may deter many birds and small mammals. Unfortunately, most wildlife soon discover that repellents are not actually harmful, and the animals may quickly become accustomed to the smell, taste or feel of these deterrents.\n\nChemical repellents applied outdoors will have to be reapplied due to rain or heavy dew, or applied often to new plant growth to be effective. Failure to carefully follow the directions included with repellents can drastically diminish the effectiveness of the product. Some repellents contain toxic chemicals, such as paradichlorobenzene, and are ineffective unless used at hazardous concentrations. Other more natural repellents contain chili pepper or capsaicin extracted from hot peppers.\n\nHowever, even under the best of conditions, repellents frequently fail to live up to user expectations. The reason for this is twofold. First, many repellents simply don't work. For example, peer-reviewed publications have consistently shown that ultrasonic devices do not drive unwanted animals away. Second, even when the repellent has been shown to work, animals in dire need of food will \"hold their nose\" and eat anyway because the alternative is essentially death by starvation. Repellents are most successful (referring to products actually demonstrated by peer-reviewed research to be effective) when animals have access to alternative food sources in a different location.\n\nGlue traps and boards can be either a lethal or non-lethal method of control. Glue boards can be used to trap small mammals and snakes. Applying vegetable oil will dissolve the glue, allowing for release, but caution must be taken to avoid scratches and bites from the trapped animal.\n\nUsing traps can be very effective in reducing actual population numbers of certain species. However, many species cannot be trapped without a permit. In most cases, homeowners may trap an offending animal within 100 yards of their residence without a permit, however relocation is often illegal.\n\nTraditional live traps such as cage or box traps are easily purchased at most garden centers or hardware stores. These traps allow for safe release of the trapped animal. The release of the animal to another area may be prohibited by state law, or may be regulated by the local Department of Fish and Game. Leghold traps may allow for either release or euthanasia of the trapped animal. Traps such as body-gripping traps, scissor and harpoon traps, as well as rat/mouse snap traps, are nearly always lethal. Knowledge of animal behavior, trapping techniques, and baits is essential for a successful trapping program.(Bornheimer, Shane P. \"PreferredWildlifeservices.com\" July 2013)\n\nFrightening devices such as bells, whistles, horns, clappers, sonic emitters, audio tapes and other sound devices may be quite successful in the short term for repelling an animal from an area. Other objects such as effigies, lights, reflectors and windmills rely on visual stimulation to scare a problem animal away. Often nuisance animals become accustomed to these tactics, and will return later if exposed to these devices daily.\n\nIn 2013, Dr. John Swaddle and Dr. Mark Hinders at the College of William and Mary created a new method of deterring birds and other animals using benign sounds projected by conventional and directional (parametric) speakers. The initial objectives of the technology were to displace problematic birds from airfields to reduce bird strike risks, minimize agricultural losses due to pest bird foraging, displace nuisance birds that cause extensive repair and chronic clean-up costs, and reduce bird mortality from flying into man-made structures. The sounds, referred to as a “Sonic Net,” do not have to be loud and are a combination of wave forms - collectively called \"colored\" noise - forming non-constructive and constructive interference with how birds and other animals such as deer talk to each other. Technically, the Sonic Nets technology is not a bird or wildlife scarer, but discourages birds and animals from going into or spending time in the target area. The impact to the animals is similar to talking in a crowded room, and since they cannot understand each other they go somewhere else. Early tests at an aviary and initial field trials at a landfill and airfield indicate that the technology is effective and that birds do not habituate to the sound. The provisional and full patents were filed in 2013 and 2014 respectively, and further research and commercialization of the technology are ongoing.\n\nBefore initiating any wildlife control activities, a person must become familiar with applicable federal, state, and local laws. One way to learn these rules is to contact the state's wildlife agency, which is usually responsible for selling hunting and fishing licenses. In general, property owners are permitted to prevent wildlife damage through exclusion and habitat modification, though they may be prohibited from disturbing an occupied nest or den, or directly harming an animal.\n\nMany regulations exist in the United States concerning animal trapping including trap check intervals, usually requiring all traps be checked at least once during a 24-hour period. Some governments permit relocation of wildlife, however humane considerations must be taken into account before relocating wildlife, including population and habitat.\n\nThere are many ethical considerations in nuisance wildlife management. Some species of wildlife cannot be ethically relocated due to overabundance of competing species, or lack of availability of proper food and habitat. Control during the spring months does run the risk of killing the young by starvation. Proper euthanasia of animals when necessary is also a controversial and sensitive consideration to be taken prior to engaging in nuisance wildlife management, and requires training and certification in some areas of the United States. \n\n\n\n", "id": "10536491", "title": "Nuisance wildlife management"}
{"url": "https://en.wikipedia.org/wiki?curid=25408281", "text": "Conservation biology of parasites\n\nA large proportion of living species on Earth live a parasitic way of life. Parasites have traditionally been seen as targets of eradication efforts, and they have often been overlooked in conservation efforts. In the case of parasites living in the wild – and thus harmless to humans and domesticated animals – this view is changing.\n\nA note published in 1990 pointed out that the captive breeding and reintroduction program to save the black-footed ferret would cause the loss of its specific parasites and demanded \"\"equal rights for parasites!\"\". Then a paper in 1992 has warned that not only the loss of certain host species from the wild, but even host population bottlenecks or the fragmentation of host populations would predictably lead to the extinction of several host specific parasite species. It also noted that parasites are not only components of biodiversity by definition, but they also exert selective pressures upon their host populations that increase host genetic diversity. Firstly, this view met with open scepticism. Soon after, it became clear that the co-extinction of hosts and their specific parasites is likely to increase the current estimates of extinction rates significantly. A decade later, a study focusing on some highly host-specific groups (such as fig wasps, parasites, butterflies, and myrmecophil butterflies) estimated the number of co-endangered species (i.e. endangered by the endangered status of the host) at about 6300. Other authors argued that host specific parasite faunae have an unexpected advantage for conservation scientists. Their genealogies and population genetic patterns may help to illuminate their hosts' evolutionary and demographic history. Recently, scientists suggested that rich parasite faunae are inevitably needed for healthy ecosystem functioning and also that parasites and mutualists are the most endangered species on Earth. Even vets have started to argue about the conservational values of parasite species.\n\nA recent study on parasites of coral reef fish suggested that extinction of a coral reef fish species would eventually result in the coextinction of at least ten species of parasites. Although this number might seem high, the study included only large parasites such as parasitic worms and crustaceans, but not microparasites such as Myxosporea and Microsporidia.\n\nThe list below follows that of Mey (2005)\n\n\nAdditionally, \"Columbicola extinctus\" is a parasite of the extinct passenger pigeon (\"Ectopistes migratorius\"). However, recent taxonomic studies show that it is conspecific with the lice living on band-tailed pigeon (\"Columba fasciata\"), thus it is not extinct.\n\nNaturally, medical (and veterinary) science and practice aim to exterminate parasites and pathogens living in humans (and in domesticated animals). In case of the few highly host-specific pathogens, this equals the extinction of the pathogen species. Throughout human history, however, one species, the smallpox virus, was eradicated from the Globe. The last cases of smallpox occurred 1978. However, secured stocks still exist in the United States and Russia for defensive purposes such as developing new vaccines, antiviral drugs, and diagnostic tests.\n\nA second candidate for purposeful extermination is the \"Dracunculus medinensis\" (guinea worm). Once widespread across some 20 nations of Africa and Asia, the parasite nowadays is much withdrawn occurring only in four countries in Sub-Saharan Africa with only a few hundred known cases of infection in 2011. Prevalent civil wars in the region, such as the War in Darfur have ensured the survival of this species up to the present.\n", "id": "25408281", "title": "Conservation biology of parasites"}
{"url": "https://en.wikipedia.org/wiki?curid=22237707", "text": "Genetic monitoring\n\nGenetic monitoring is the use of molecular markers to (i) identify individuals, species or populations, or (ii) to quantify changes in population genetic metrics (such as effective population size, genetic diversity and population size) over time. Genetic monitoring can thus be used to detect changes in species abundance and/or diversity, and has become an important tool in both conservation and livestock management. The types of molecular markers used to monitor populations are most commonly mitochondrial, microsatellites or single-nucleotide polymorphisms (SNPs), while earlier studies also used allozyme data. Species gene diversity is also recognized as an important biodiversity metric for implementation of the Convention on Biological Diversity.\n\nTypes of population changes that can be detected by genetic monitoring include population growth and decline, spread of pathogens, adaptation to environmental change, hybridization, introgression and habitat fragmentation events. Most of these changes are monitored using ‘neutral’ genetic markers (markers for which mutational changes do not change their adaptive fitness within a population). However markers showing adaptive responses to environmental change can be ‘non-neutral’ (e.g. mutational changes affect their relative fitness within a population). \n\nTwo broad categories of genetic monitoring have been defined: Category I encompasses the use of genetic markers as identifiers of individuals (Category Ia), populations and species (Category Ib) for traditional population monitoring. Category II represents the use of genetic markers to monitor changes of population genetic parameters, which include estimators of effective population size (Ne), genetic variation, population inter-mixing, structure and migration.\n\nAt the individual level, genetic identification can enable estimation of population abundance and population increase rates within the framework of mark-recapture models. The abundance of cryptic or elusive species that are difficult to monitor can be estimated by collecting non-invasive biological samples in the field (e.g. feathers, scat or fur) and using these to identify individuals through microsatellite or single-nucleotide polymorphism (SNP) genotyping. This census of individuals can then be used to estimate population abundance via mark-recapture analysis. For example, this technique has been used to monitor populations of grizzly bear, brush-tailed rock-wallaby, Bengal tiger and snow leopard. Population growth rates are a product of rates of population recruitment and survival, and can be estimated through open mark-recapture models. For example, DNA from feathers shed by the eastern imperial eagle shows lower cumulative survival over time than seen for other long-lived raptors.\n\nUse of molecular genetic techniques to identify species can be useful for a number of reasons. Species identification in the wild can be used to detect changes in population ranges or site occupancy, rates of hybridization and the emergence and spread of pathogens and invasive species. Changes in population ranges have been investigated for Iberian lynx and wolverine, while monitoring of westslope cutthroat trout shows widespread ongoing hybridization with introduced rainbow trout (see cutbow) and Canada lynx-bobcat hybrids have been detected at the southern periphery of the current population range for lynx. The emergence and spread of pathogens can be tracked using diagnostic molecular assays – for example, identifying the spread of West Nile virus among mosquitoes in the eastern US to identify likely geographical origins of infection and identifying gene loci associated with parasite susceptibility in bighorn sheep. Genetic monitoring of invasive species is of conservation and economic interest, as invasions often affect the ecology and range of native species and may also bring risks of hybridization (e.g. for copepods, ducks, barred owl and spotted owl, and Lessepsian rabbitfish).\n\nSpecies identification is also of considerable utility in monitoring fisheries and wildlife trade, where conventional visual identification of butchered or flensed products is difficult or impossible. Monitoring of trade and consumption of species of conservation interest can be carried out using molecular amplification and identification of meat or fish obtained from markets. For example, genetic market surveys have been used to identify protected species and populations of whale (e.g., North Pacific minke whale) and dolphin species appearing in the marketplace. Other surveys of market trade have focused on pinnipeds, sea horses and sharks. Such surveys are used to provide ongoing monitoring of the quantity and movement of fisheries and wildlife products through markets and for detecting poaching or other illegal, unreported or unregulated (IUU) exploitation (e.g. IUU fishing).\n\nAlthough initial applications focused on species identification and population assessments, market surveys also provide the opportunity for a range of molecular ecology investigations including capture-recapture, assignment tests and population modeling. These developments are potentially relevant to genetic monitoring Category II.\n\nMonitoring of population changes through genetic means can be done retrospectively, through analysis of 'historical' DNA recovered from museum-archived species and comparison with contemporary DNA of that species. It can also be used as a tool for evaluating ongoing changes in the status and persistence of current populations. Genetic measures of relative population change include changes in diversity (e.g. heterozygosity and allelic richness). Monitoring of relative population changes through these metrics has been performed retrospectively for Beringian bison, Galapagos tortoise, houting, Atlantic salmon, northern pike, New Zealand snapper, steelhead trout, greater prairie chicken, Mauritius kestrel and Hector's dolphin and is the subject of many ongoing studies, including Danish and Swedish brown trout populations. Measuring absolute population changes (e.g. effective population size (Ne)) can be carried out by measuring changes in population allele frequencies (‘Ftemporal’) or levels of linkage disequilibrium over time (‘LDNe’), while changing patterns of gene flow between populations can also be monitored by estimating differences in allele frequencies between populations over time. Subjects of such studies include grizzly bears, cod, red deer, Leopard frogs and Barrel Medic.\n\nGenetic monitoring has also been increasingly used in studies that monitor environmental changes through changes in the frequency of adaptively selected markers. For example, the genetically controlled photo-periodic response (hibernating time) of pitcher-plant mosquitos (\"Wyeomyia smithii\") has shifted in response to longer growing seasons for pitcher plants brought on by warmer weather. Experimental wheat populations grown in contrasting environments over a period of 12 generations found that changes in flowering time were closely correlated with regulatory changes in one gene, suggesting a pathway for genetic adaptation to changing climate in plants.\n\nGenetic monitoring is also useful in monitoring the ongoing health of small, relocated populations. Good examples of this are found for New Zealand birds, many species of which were greatly impacted by habitat destruction and the appearance of numerous mammalian predators in the last century and have recently become part of relocation programs that transfer a few ‘founder’ individuals to predator-free offshore “ecological” islands. E.g. black robin, and kakapo.\n\nIn February 2007 an international summit was held at the Institute of the Environment at UCLA, concerning ‘Evolutionary Change in Human Altered Environments: An International Summit to translate Science into Policy’. This led to a special issue of the journal of Molecular Ecology organized around our understanding of genetic effects in three main categories: (i) habitat disturbance and climate change (ii) exploitation and captive breeding (iii) invasive species and pathogens.\n\nIn 2007 a Working Group on Genetic Monitoring was launched with joint support from NCEAS and NESCent to further develop the techniques involved and provide general monitoring guidance for policy makers and managers.\n\nCurrently the topic is covered in several well known text books, including McComb et al. (2010) and Allendorf et al. (2013)\n\nMany natural resource agencies see genetic monitoring as a cost-effective and defensible way to monitor fish and wildlife populations. As such scientists in the U.S. Geological Survey, U.S. Forest Service, National Park Service, and National Marine Fisheries Service have been developing new methods and tools to use genetic monitoring, and applying such tools across broad geographic scales. Currently the USFWS hosts a website that informs managers as to the best way to use genetic tools for monitoring (see below).\n\n\n", "id": "22237707", "title": "Genetic monitoring"}
{"url": "https://en.wikipedia.org/wiki?curid=30142956", "text": "Mutualisms and conservation\n\nConservation is the maintenance of biological diversity. Conservation can focus on preserving diversity at genetic, species, community or whole ecosystem levels. This article will examine conservation at the species level, because mutualisms involve interactions between species. The ultimate goal of conservation at this level is to prevent the extinction of species. However, species conservation has the broader aim of maintaining the abundance and distribution of all species, not only those threatened with extinction (van Dyke 2008). Determining the value of conserving particular species can be done through the use of evolutionary significant units, which essentially attempt to prioritise the conservation of the species which are rarest, fastest declining, and most distinct genotypically and phenotypically (Moritz 1994, Fraser and Bernatchez 2001).\n\nMutualisms can be defined as \"interspecific interactions in which each of two partner species receives a net benefit\" (Bronstein et al. 2004). Here net benefit is defined as, a short-term increase in inclusive fitness (IF). Incorporating the concept of genetic relatedness (through IF) is essential because many mutualisms involve the eusocial insects, where the majority of individuals are not reproductively active. The short-term component is chosen because it is operationally useful, even though the role of long-term adaptation is not considered (de Mazancourt et al. 2005). This definition of mutualism should be suffice for this article, although it neglects discussion of the many subtitles of IF theory applied to mutualisms, and the difficulties of examining short-term compared to long-term benefits, which are discussed in Foster and Wenselneers (2006) and de Mazancourt et al. (2005) respectively. Mutualisms can be broadly divided into two categories. Firstly, obligate mutualism, where two mutualistic partners are completely interdependent for survival and reproduction. Secondly, facultative mutualism, where two mutualistic partners both benefit from the mutualism, but can theoretically survive in each other's absence.\n\nMutualisms are remarkably common, in fact all organisms are believed to be involved in a mutualism at some point during their lives (Bronstein et al. 2004). This is particularly likely to be true for the definition of mutualism adopted here, where herbivory can paradoxically be mutualistic, for example in a situation where a plant overcompensates by producing more biomass when grazed on. Therefore, any species identified as particularly important to conserve will probably have mutualistic partners. It is beyond the purview of this article to discuss all these mutualisms, so the focus will be on specifically animal-plant mutualisms.\n\nA mutualism coextinction event is where a species goes extinct upon the loss of its mutualist (Koh et al. 2004). Models have attempted to predict when the breakdown of a mutualism leads to coextinction, because in this situation protecting the mutualism will be particularly important for conservation. These models are multi-dimensional, so examine complex networks of interactions, rather than just pairs of interacting species. This means that these models incorporate modelling the breakdown of obligate mutualisms (which lead directly to coextinction), but also the breakdown of facultative mutualisms (which can lead indirectly to coextinction). Koh et al. (2004) use a \"nomographic model of affiliate extinctions\", which estimates the probability that the extinction of a species leads to the extinction of its mutualist, for a given estimate of the specificity of the mutualism. By applying the model to actual species, Koh et al. (2004) estimate that 200 coextinctions have occurred since records of species extinction began in the past few centuries, and 6300 coextinctions are at risk of occurring in the near future. However, these estimates are not exclusively for mutualism coextinctions (e.g. parasitic coextinctions are incorporated), but mutualism coextinctions make up a significant proportion of the number quoted. Additionally the model predicts that these coextinctions can start extinction cascades, where many other species in the surrounding ecosystem go extinct. Other recent models largely agree with this one, predicting that mutualism coextinction is a very significant cause of species loss, and that it can lead to extinction cascades (Dunn et al. 2009).\n\nSurprisingly, given the model predictions, there are very few recorded examples of global mutualism coextinctions actually occurring (Bronstein et al. 2004, Dunn et al. 2009), and many examples often quoted are unconvincing on examination. For example, a well documented case of animal-plant coextinction and an extinction cascade involves a butterfly (\"Maculinea arion\") to ant (\"Myrmica sableti\") interaction. \"M. arion\" larvae provide honeydew for the \"M. sableti\" workers, which raise the caterpillars in their nest. When the Myxoma virus was introduced to control rabbit populations in the UK, the subsequent increase in grassland caused a decrease in soil temperatures at ground level. This caused reductions in the \"M. sableti\" populations, which led to the extinction of the M. arion populations (Dunn 2005). However, this is actually a relatively weak example, because it was a local (rather than a global) extinction, and the nature of the interaction is often not viewed as mutualistic, because it has been long known that the \"M. sableti\" caterpillars eat \"M. sableti\" larvae (Elmes and Thomas 1992).\n\nSo, why are there very few documented examples of mutualism coextinctions? There are various possible reasons. Perhaps global mutualism coextinctions are genuinely uncommon, and the model predictions are inaccurate. The models may overestimate the specificity of the mutualisms, because species may only associate with alternative species when their 'normal' mutualist is rare or absent. For example, oligolectic bees visit a small number of flowers for pollen. However, these bees do not generally have strongly specialised anatomy, morphology or physiology. Therefore, in the absence of these usual flowers, many oligolectic bee species are able switch to collecting pollen from flower species they would never normally associate with (Wcislo and Cane 1996). Even some fig wasps, often considered to be in completely obligate relationships, have maintained low population densities when introduced to new areas without their natural mutualist fig tree species (McKey 1989). The models may also underestimate the robustness of the mutualisms. For example, fig trees and fig wasps are coadapted so that the wasps can find the trees from a long distances away (Bronstein et al. 1994).\n\nAlternatively, there may simply be many global mutualism coextinctions that have occurred which we are not yet aware of. This explanation is not unlikely, because mutualisms have generally been understudied as interactions (Bronstein 1994, Richardson et al. 2000). There is additionally the difficulty of defining when a species becomes globally extinct, compared to just extremely rare or maintained exclusively through captive breeding programs. Of course, these stated explanations are not mutually exclusive. However, more research is required to rectify the model predictions of many mutualism coextinctions, with the lack of empirical evidence for such events. Only then can we discover if conserving mutualisms is likely to prevent many global species extinction.\n\nEven if global mutualism coextinctions are genuinely rare, conserving mutualisms may still be important for conservation. As mentioned previously, conservation is not just about preventing extinctions, but also about preventing species decline. Unlike with coextinctions, there are numerous recorded examples of where the decline or extinction of a species has led to the decline of its mutualist (\"codeclines\"). A documented example of a pollination mutualism breakdown leading to population declines is the Indian rubber tree (\"Ficus elastica\") to its pollinator wasp (\"Pleistodontes clavigar\") interaction. Habitat fragmentation has led to the \"F. elastica\" declining to very low population levels. However, F. Elastic can propagate clonally, so has remained extant. Meanwhile, \"P. clavigar\" is virtually extinct globally, because the mutualist relationship is probably obligate for P. clavigar (Mawsdley et al. 1998). An example of a seed dispersal mutualism breakdown causing population declines comes from two endemic species on Menorca Island. A frugivorous lizard (\"Podarcis lilfordi\") is a seed disperser of a shrub (\"Daphne rodriguezii\"). When \"P. lilfordi\" became extinct on Menorca, due to the introduction of carnivorous mammals, \"D. rodriguezii\" numbers declined significantly to endangered levels. This \"D. rodriguezii\" decline could be attributed to the local extinction of \"P. lilfordi\", due the lack of seedling recruitment on Menorca compared to other nearby islands, where \"P. lilfordi\" remained extant and \"D. rodriguezii\" populations larger (Traveset and Riera 2005).\n\nHowever, in some cases it has been shown that declines of one partner in a mutualism do not lead to significant declines in the other. For example, a Hawaiian vine (\"Freycinetia arborea\") was pollinated in the nineteenth century by four species of birds. These bird species are all now either locally endangered or extinct. Despite this, \"F. arborea\" continues to survive in reasonable abundance, but is now mainly pollinated by the recently introduced white-eye (\"Zosterops japonica\") (Cox and Elmqvist 2000). In this case, conservation of the mutualism was not required to maintain the \"F. arborea\" population. There are probably no published estimates of how frequently declines of one species do not result in declines of that species' mutualist, due to a 'replacement' mutualist. However, judging by the few examples in the literature where this replacement has been reported to have happened, it seems to be a relatively rare occurrence.\n\nThe Hawaiian vine example also illustrates that alien species can be involved in animal-plant mutualisms. In fact, alien species are often dependent on mutualisms to establish themselves in new habitats (particularly on islands), and especially those alien species requiring animal mediated pollination (Richardson et al. 2000). These alien species will, by definition, be beneficial to the short-term inclusive fitness of the species they form a mutualism with. However, the alien species will negatively impact other species in the ecosystem. For example, through competition for resources (including competition for mutualist partners) (Kaiser-Bunbury et al. 2009). In fact, these negative impacts could theoretically cascade through the ecosystem, and lead to the alien species having an indirect long-term negative impact on its mutualist. This means that mutualisms involving alien species is important in conservation. However, the action taken by a conservation organization could be either to conserve or disrupt the mutualism.\n\nIn some situations, a conservation organization will want to conserve the mutualistic relationship. For example, many of the Hawaiian Islands have lost the vast majority of their native seed dispersers, and introduced bird species now act as very major seed dispersers of native species. In fact, these exotic species appear to actually facilitate the re-growth of native forests in some areas (Foster and Robinson 2007). In these situations, conserving the native mutualism may become less important than conserving the new one. Alien species involved in mutualisms may actually be desirable for conservationists to protect in a more general way. Alien species are particularly likely to generate highly generalised and asymmetric mutualisms, which help stabilise communities, making them less vulnerable to decline and extinctions (Aizen et al. 2008).\n\nIn other situations, conservation will be facilitated by disrupting mutualisms involving alien species. For example alien bumblebees (Bombus terrestris) have displaced many native pollinators, and pollinated some unwanted weed species, across the globe (Hingston et al. 2002). These mutualisms could lead to a decline in both animal and plant species of particular value to conservation. The empirical evidence would suggest that in the majority of cases a conservation organisation should try and disrupt the mutualisms involving the alien species (Kaiser-Bunbury et al. 2009).\n\n\n", "id": "30142956", "title": "Mutualisms and conservation"}
{"url": "https://en.wikipedia.org/wiki?curid=27258244", "text": "Organization for Bat Conservation\n\nOrganization for Bat Conservation (OBC) is a national environmental education nonprofit based in Bloomfield Hills, Michigan established to educate and inspire people to save bats. \n\nFounded in 1992 by Rob Mies (current Executive Director), OBC is the leading environmental educator focused on bats. At its home base at Cranbrook Institute of Science in Bloomfield Hills, Michigan, OBC operates the Bat Zone, a live animal center with nearly 200 animals including bats from around the world and other nocturnal animals. Each year, thousands of visitors of all ages come to the Bat Zone to attend tours and participate in live animal educational programs. In addition, OBC educators travel throughout the country presenting to nearly 250,000 students, children and adults at schools, festivals, museums, science and nature centers each year. \n\nOBC also organizes and participates in many special “batty” events. The Annual Great Lakes Bat Festival, started in 2002, celebrates the unique role of bats in the Great Lakes ecosystem as insect eaters, while dispelling myths and misinformation that generate needless fears and threaten bats and their habitats around the world. The goal of the festival is to help people understand the impact to natural ecosystems and human economies should bat populations continue to decline. The festival features activities for children, families, educators and conservation professionals. Presentations, speakers, live animals, hands-on activities, games for kids, and interactive exhibits provide fun and environmental education. \n\nOBC also shares the importance and uniqueness of bats nationally through print and television appearances including The Tonight Show, The Ellen Degeneres Show, The Today Show, Live with Regis and Kelly, Late Night with Conan O’Brien, Fox & Friends, The Doctors, National Geographic TV, and Martha Stewart Living. \n\nIn September 2014, OBC launched a new public action campaign called Save the Bats. Save the Bats is aimed at preventing the decline of this important and beloved animal in our ecosystem. Save the Bats grew out of public demand for specific ways for people to protect bats and the recognition that Americans need to be mobilized to prevent the extinction of these important animals. \n\nSave the Bats encourages people to take action in their own backyards and neighborhoods, including installing bat houses, planting wildlife gardens, and teaching others about the importance of bats. Using multiple social media platforms, public relations and in-person educational events, Save the Bats is expected to have tremendous reach across the U.S. The campaign has many celebrity, government agency and corporate supporters.\n\nIn addition, OBC and Warner Brothers Entertainment worked together on the set of Batman v Superman Dawn of Justice to re-purpose parts of the movie set into bat houses. Director Zack Snyder contacted OBC when he heard about bats dying off from White-nose Syndrome and enlisted Rob Mies, OBC Executive Director, to assist in the bat house design and construction. More than 150 bat houses were made on the movie set in Pontiac, some of which were painted and signed by Zack, Amy Adams, and Ben Affleck. The bat houses will be auctioned off to support the Save the Bats campaign. Warner Brothers released a short PSA documenting the bat house build featuring Ben Affleck encouraging people to join the campaign. To date, more than 1,000,000 people have viewed the video.\n\nIn August 2017, Organization for Bat Conservation purchased the mineral rights for Magazine Mine, a silica mine in southern Illinois. Magazine Mine is one of the largest Indiana bat hibernacula in the world.\n\n\n\n\n", "id": "27258244", "title": "Organization for Bat Conservation"}
{"url": "https://en.wikipedia.org/wiki?curid=186351", "text": "In Situ Conservation in India\n\n\"In-situ\" conservation is the on-site conservation or the conservation of genetic resources in natural populations of plant or animal species, such as forest genetic resources in natural populations of tree species. It is the process of protecting an endangered plant or animal species in its natural habitat, either by protecting or restoring the habitat itself, or by defending the species from predators. It is applied to conservation of agricultural biodiversity in agro ecosystems by farmers, especially those using unconventional farming practices.\ne.g., Nilgiri biosphere in India.\n\nAbout 4% of the total geographical area of the country is used for \"in situ\" conservation. The following methods are presently used for \"in situ\" conservation.\n\nBiosphere reserves cover very large areas, often more than 5000 km. They are used to protect species for a long time. Currently, there are 18 Biosphere Reserves in India.\nA national park is an area dedicated for the conservation of wildlife along with its environment. It is usually a small reserve covering an area of about 100 to 500 square kilometers. Within biosphere reserves, one or more national parks may also exist. Currently, there are 103 national parks in India.\nA wildlife sanctuary is an area which is reserved for the conservation of animals only. Currently, there are 543 wild sanctuaries in India.\n\nA gene sanctuary is an area where plants are conserved.\nIt includes both biosphere reserves as well as national parks.\nIndia has set up its first gene sanctuary in the Garo Hills of Meghalaya for wild relatives of citrus. Efforts are also being made to set up gene sanctuaries for banana, sugarcane, rice and mango.\n\nIt is the type of protected area introduced in Wildlife Protection Amendment Act 2002 to provide legal support to community or privately owned reserves which cannot be designated as national park or wildlife sanctuary.\n\nThey are tracts of forest set aside where all the trees and wildlife within are venerated and given total protection.\n\nOne benefit of \"in situ\" conservation is that it maintains recovering populations in the environment where they have developed their distinctive properties. Another benefit is that this strategy helps ensure the ongoing processes of evolution and adaptation within their environments. As a last resort, ex-situ conservation may be used on some or all of the population, when \"in situ\" conservation is too difficult, or impossible. The species gets adjusted to the natural disasters like drought, floods, forest fires and this method is very cheap and convenient.\n\nWildlife and livestock conservation is mostly based on \"in situ\" conservation. This involves the protection of wildlife habitats. Also, sufficiently large reserves are maintained to enable the target species to exist in large numbers. The population size must be sufficient to enable the necessary genetic diversity to survive within the population, so that it has a good chance of continuing to adapt and evolve over time. This reserve size can be calculated for target species by examining the population density in naturally occurring situations. The reserves must then be protected from intrusion or destruction by man, and against other catastrophes.\n\nIn agriculture, \"in situ conservation\" techniques are an effective way to improve, maintain, and use traditional or native varieties of agricultural crops. Such methodologies link the positive output of scientific research with farmers' experience and field work.\n\nFirst, the accessions of a variety stored at a germplasm bank and those of the same variety multiplied by farmers are jointly tested in the producers field and in the laboratory, under different situations and stresses. Thus, the scientific knowledge about the production characteristics of the native varieties is enhanced. Later, the best tested accessions are crossed, mixed, and multiplied under replicable situations. At last, these improved accessions are supplied to the producers. Thus, farmers are enabled to crop improved selections of their own varieties, instead of being lured to substitute their own varieties with commercial ones or to abandon their crop. This technique of conservation of agricultural biodiversity is more successful in marginal areas, where commercial varieties are not expedient, due to climate and soil fertility constraints. Or where the taste and cooking characteristics of traditional varieties compensate for their lower yields.\n\n\n", "id": "186351", "title": "In Situ Conservation in India"}
{"url": "https://en.wikipedia.org/wiki?curid=31093490", "text": "Koedoe\n\nKoedoe, subtitled \"African Protected Area Conservation and Science\", is a peer-reviewed open access scientific journal covering biology, ecology, and biodiversity conservation in Africa. It was established in 1958. Koedoe is Afrikaans for Kudu.\n\nFor full information visit the journal website link http://koedoe.co.za/index.php/koedoe/pages/view/about#7\n", "id": "31093490", "title": "Koedoe"}
{"url": "https://en.wikipedia.org/wiki?curid=31624114", "text": "Wild Salmon Center\n\nThe Wild Salmon Center (WSC) is an international conservation organization that works to protect wild salmon, steelhead, char, trout and the ecosystems on which these species depend. Headquartered in Portland, Oregon, United States, the WSC works with communities, businesses, governments, and other non-profits to protect and preserve healthy salmon ecosystems in the North Pacific. WSC programs range in location from Russia, Japan, Alaska, British Columbia, Washington State, Oregon, and California.\n\nThe WSC was founded as a non-profit by Pete Soverel and Tom Pero in 1992, and was run entirely by volunteers during its first five years. Originally the WSC received funding for research and conservation through organizing angling trips to the Kamchatka Peninsula in the Russian Far East. These expeditions were a joint venture between the WSC and Moscow State University. In 1998, WSC hired Guido Rahr as Executive Director, formerly with the conservation organization Oregon Trout, where he developed an approach to salmon conservation that focused on proactive protection of the strongest remaining populations (stronghold strategy). The organization expanded rapidly between 1999 and 2010. A new organization called The Conservation Angler was created in 2003 to take over the ecotourism programs, allowing the WSC to focus solely on science and conservation. One of the WSC programs, State of the Salmon, a science-based program created in 2003 in collaboration with Ecotrust, used data to track the health and trends of wild salmon populations. This data was then analyzed, and used to inform salmon management and conservation throughout the Pacific Rim. While State of the Salmon has concluded, sustainable fisheries work continues with a new organization, Ocean Outcomes, which was incubated and launched by Wild Salmon Center in 2015. Ocean Outcomes is a global fishery improvement organization targeting high risk fisheries - the fisheries that face the biggest conservation challenges and have the most to gain from improvements. O2 works hand-in-hand with commercial fisheries and local communities to improve the sustainability of global fisheries.\n\nAdopted in 1999, the WSC has been focused on a proactive \"salmon stronghold\" conservation strategy as a regional and international approach to salmon conservation. Salmon strongholds refer to river ecosystems that contain the most abundant and biologically diverse populations of wild salmon. Select areas on the Kamchatka Peninsula, Sakhalin Island, and the Russian Far East mainland, as well as key watersheds in the lower 48 US States, British Columbia, Bristol Bay and much of Alaska are considered salmon strongholds . As part of its efforts to protect habitat in Oregon, the Wild Salmon Center is a member of the North Coast State Forest Coalition. In identifying and then protecting salmon strongholds, the WSC aims to conserve healthy salmon stocks before they decline and ensure sustainable fish populations survive for the long term.\n\n", "id": "31624114", "title": "Wild Salmon Center"}
{"url": "https://en.wikipedia.org/wiki?curid=32488261", "text": "Catch per unit effort\n\nIn fisheries and conservation biology, the catch per unit effort (CPUE) is an indirect measure of the abundance of a target species. Changes in the catch per unit effort are inferred to signify changes to the target species' true abundance. A decreasing CPUE indicates overexploitation, while an unchanging CPUE indicates sustainable harvesting.\n\nCPUE has a number of advantages over other methods of measuring abundance. It does not interfere with routine harvesting operations, and data are easily collected. The data are also easy to analyse, even for non-specialists, in contrast to methods based on transects. This means that decisions about stock management can also be made by the people doing the harvesting. The best practice is to standardise the effort employed (\"e.g.\" number of traps or duration of searching), which controls for the reduction in catch size that often results from subsequent efforts.\n\nAlthough CPUE is a relative measure of abundance, it can be used to estimate absolute abundances. The main difficulty when using measures of CPUE is to define the unit of effort.\n\n", "id": "32488261", "title": "Catch per unit effort"}
{"url": "https://en.wikipedia.org/wiki?curid=36309813", "text": "Mangrove restoration\n\nMangrove restoration is the regeneration of mangrove forest ecosystems in areas where they have previously existed. The practice of mangrove restoration is grounded in the discipline of restoration ecology, which aims to “[assist] the recovery of resilience and adaptive capacity of ecosystems that have been degraded, damaged, or destroyed”. Since environmental impacts are an ongoing threat, to successfully restore an ecosystem implies not merely to recreate its former condition, but to strengthen its capacity to adapt to change over time.\n\nMangrove forests, along with the animal species they shelter, represent globally significant sources of biodiversity and provide humanity with valuable ecosystem services. They are used by mammals, reptiles and migratory birds as feeding and breeding grounds, and provide crucial habitats for fish and crustacean species of commercial importance. The roots of the mangrove physically buffer shorelines from the erosive impacts of ocean waves and storms. Additionally, they protect riparian zones by absorbing floodwaters and slowing down the flow of sediment-loaded river water. This allows sediments to drop to the bottom where they are held in place, thus containing potentially toxic waste products and improving the quality of water and sanitation in coastal communities. \n\nTo the human communities who rely on them, mangrove forests represent local sources of sustainable income from the harvest of fish and timber, as well as non-timber forest products such as medicinal plants, palm leaves and honey. On a global scale, they have been shown to sequester carbon in quantities comparable to higher-canopy terrestrial rainforests, which means that they may play a role in climate change mitigation, in addition to physically protecting coastlines from the projected sea-level rise associated with climate change. However, there are limits to the capacity of mangroves to adapt to climate change. It is projected that a 1-meter rise in sea level could inundate and destroy mangrove forests in many regions around the globe, which would leave coastal communities vulnerable to the risks of flooding, shoreline erosion, saline intrusion and increased storm activity.\n\nThe issue of restoration is critical today since mangrove forests are being lost very quickly – at an even faster rate than tropical rainforests inland. A recent estimate puts the total mangrove area worldwide in 2005 at 152,000 km – down from 188,000 km in 1980. In other words some 36,000 km, or nearly 20% of the world’s mangroves, were lost over a period of twenty-five years. Other estimates of loss may differ due to having been drawn from a smaller pool of data. The Millennium Ecosystem Assessment estimates the total loss worldwide at 35% between 1980 and 2000, but this result was drawn from data on only slightly more than half of the total mangrove area. Much of this lost mangrove area was destroyed to make room for industry, housing and tourism development; for aquaculture, primarily shrimp farms; and for agriculture, such as rice paddies, livestock pasture and salt production. Other drivers of mangrove forest destruction include activities that divert their sources of freshwater, such as groundwater withdrawals, the building of dams, and the building of roads and drainage canals across tidal flats.\n\nMangroves are sensitive ecosystems, changing dynamically in response to storms, sediment blockage, and fluctuations in sea level and present a “moving target” for restoration efforts. Different restoration approaches face this challenge in different ways. The most common method simply consists in planting single-species stands of mangroves in areas thought to be suitable, without consideration of whether or not they supported mangroves in the past. This approach usually fails over the long term because the underlying soil and hydrological requirements of the mangroves are not being met. More informed methods aim to bring a damaged mangrove area back into its preexisting condition, taking into account not only ecosystem factors but also social, cultural and political perspectives. These approaches begin with the understanding that a damaged mangrove area may be able to repair itself through the natural processes of secondary succession, without being physically planted, provided that its tidal and freshwater hydrology is functioning normally and there is an adequate supply of seedlings.\nTaking this into account, it becomes crucial to the success of a restoration project to evaluate what the hydrology of a disturbed mangrove site should look like under normal conditions, and the ways in which it has been modified.\nOne example of this approach is the Ecological Mangrove Restoration method which recommends the following steps, to be undertaken using healthy mangroves of the surrounding area as a reference: \nThe actual planting of seedlings is a last resort, since it fails in many cases; it should be considered only if natural recruitment of seedlings fails to reach the restoration objective.\n\nAn important but often overlooked aspect of mangrove restoration efforts is the role that the local communities play as stakeholders in the process and the outcome. Since they may directly feel the effects of restoration projects, they should be involved in the process as much as feasibly possible, from decision-making to maintenance over the long term. Their involvement and local knowledge, as well as collaboration with other stakeholders such as sponsors and governing agencies, is crucial to the success of restoration projects.\n\nIn some areas, restoration may be prohibitively difficult due to the degradation of the soil that regularly follows the clear-cutting of mangrove forests. Common effects include advanced erosion of the soil, loss of nutrients, high levels of salinity, and/or buildup of toxins. However, even without this extent of degradation, the soil may become unable to host plant life at all due to the loss of the live mangrove roots, which exuded oxygen and carbohydrate into the soil and maintained its quality. Using foresight early in the restoration process to carefully select sites that are likely to succeed as self-maintaining ecosystems, as well as ensuring that proper management is built into the conservation effort, can prevent the waste of time and energy that often accompanies restoration projects. The long-lasting aftereffects of mangrove degradation underscore the importance of eliminating its causes, since once sites are cleared, it is difficult for them to recover without a scientific intervention.\n\n", "id": "36309813", "title": "Mangrove restoration"}
{"url": "https://en.wikipedia.org/wiki?curid=25682936", "text": "Resistance (ecology)\n\nIn the context of ecological stability, resistance is the property of communities or populations to remain \"essentially unchanged\" when subject to disturbance. The inverse of resistance is sensitivity.\n\nResistance is one of the major aspects of ecological stability. Volker Grimm and Christian Wissel identified 70 terms and 163 distinct definitions of the various aspects of ecological stability, but found that they could be reduced to three fundamental properties: \"staying essentially unchanged\", \"returning to the reference state...after a temporary disturbance\" and \"persistence through time of an ecological system\". Resistant communities are able to remain \"essentially unchanged\" despite disturbance. Although commonly seen as distinct from resilience, Brian Walker and colleagues considered resistance to be a component of resilience in their expanded definition of resilience, while Fridolin Brand used a definition of resilience that he described as \"close to the stability concept 'resistance', as identified by Grimm and Wissel (1997)\". The inverse of resistance is sensitivity - sensitive species or communities show large changes when subject to environmental stress or disturbance.\n\nIn 1988, Hurricane Joan hit the rainforests along Nicaragua's Caribbean coast. Douglas Boucher and colleagues contrasted the resistant response of \"Qualea paraensis\" with the resilient response of \"Vochysia ferruginea\"; the mortality rate was low for \"Q. paraensis\" (despite extensive damage to the trees), but the growth rates of surviving trees were also low and few seedlings established. Despite the disturbance, populations were essentially unchanged. In contrast, \"V. ferruginea\" experienced very high rates of mortality in the hurricane but showed very high rates of seedling recruitment. As a result, population densities of the species increased. In their study of Jamaican montane forests affected by Hurricane Hugo in 1988, Peter Bellingham and colleagues used the degree of hurricane damage and the magnitude of the post-hurricane response to categorise tree species into four groups – resistant species (those with limited storm damage and low response), susceptible species (greater damage but low response), usurpers (limited damage but high response) and resilient species (greater damage and high response).\n\nEnglish ecologist Charles Elton applied the term resistance to the ecosystem properties which limit the ability of introduced species to successfully invade communities. These properties include both abiotic factors like temperature and drought, and biotic factors including competition, predation and the lack of necessary mutualists. Higher species diversity and lower resource availability can also contribute to resistance.\n", "id": "25682936", "title": "Resistance (ecology)"}
{"url": "https://en.wikipedia.org/wiki?curid=320033", "text": "Habitat conservation\n\nHabitat conservation is a management practice that seeks to conserve, protect and restore habitat areas for wild plants and animals, especially conservation reliant species, and prevent their extinction, fragmentation or reduction in range. It is a priority of many groups that cannot be easily characterized in terms of any one ideology.\n\nFor much of human history, \"nature\" had been seen as a resource, one that could be controlled by the government and used for personal and economic gain. The idea was that plants only existed to feed animals and animals only existed to feed humans. The land itself had limited value only extending to the resources it could provide such as minerals and oil.\n\nThroughout the 18th and 19th centuries social views started to change and scientific conservation principles were first practically applied to the forests of British India. The conservation ethic that began to evolve included three core principles: that human activity damaged the environment, that there was a civic duty to maintain the environment for future generations, and that scientific, empirically based methods should be applied to ensure this duty was carried out. Sir James Ranald Martin was prominent in promoting Pbnjbthis ideology, publishing many medico-topographical reports that demonstrated the scale of damage wrought through large-scale deforestation and desiccation, and lobbying extensively for the institutionalization of forest conservation activities in British India through the establishment of Forest Departments.\n\nThe Madras Board of Revenue started local conservation efforts in 1842, headed by Alexander Gibson, a professional botanist who systematically adopted a forest conservation program based on scientific principles. This was the first case of state conservation management of forests in the world. Governor-General Lord Dalhousie introduced the first permanent and large-scale forest conservation program in the world in 1855, a model that soon spread to other colonies, as well the United States, where Yellowstone National Park was opened in 1872 as the world’s first national park.\n\nRather than focusing on the economic or material benefits associated with nature, humans began to appreciate the value of nature itself and the need to protect pristine wilderness. By the middle of the 20th century countries such as the United States, Canada, and Britain understood this appreciation and instigated laws and legislation in order to ensure that the most fragile and beautiful environments would be protected for generations to come. \nToday with the help of NGO’s, not-for profit organizations and governments worldwide there is a stronger movement taking place, with a deeper understanding of habitat conservation with the aim of protecting delicate habitats and preserving biodiversity on a global scale. The commitment and actions of small volunteering association in villages and towns, that endeavour to emulate the work done by well known Conservation Organisations, is paramount in ensuring generations that follow understand the importance of conserving natural resources. A village conservation group with the mission statement \"We are committed to protecting and enhancing the natural environment in and around the adjoining villages of Ouston and Urpeth.\" may one day inspire a child who becomes the employee of a worldwide conservation organisation.\n\nThe natural environment is a source for a wide range of resources that can be exploited for economic profit, for example timber is harvested from forests and clean water is obtained from natural streams. However, land development from anthropogenic economic growth often causes a decline in the ecological integrity of nearby natural habitat. For instance, this was an issue in the northern rocky mountains of the USA.\n\nHowever, there is also economic value in conserving natural habitats. Financial profit can be made from tourist revenue, for example in the tropics where species diversity is high, or in recreational sports which take place in natural environments such as hiking and mountain biking. The cost of repairing damaged ecosystems is considered to be much higher than the cost of conserving natural ecosystems.\n\nMeasuring the worth of conserving different habitat areas is often criticized as being too utilitarian from a philosophical point of view.\n\nHabitat conservation is important in maintaining biodiversity, an essential part of global food security. There is evidence to support a trend of accelerating erosion of the genetic resources of agricultural plants and animals. An increase in genetic similarity of agricultural plants and animals means an increased risk of food loss from major epidemics. Wild species of agricultural plants have been found to be more resistant to disease, for example the wild corn species Teosinte is resistant to 4 corn diseases that affect human grown crops. A combination of seed banking and habitat conservation has been proposed to maintain plant diversity for food security purposes.\n\nPearce and Moran outlined the following method for classifying environmental uses:\n\nHabitat loss and destruction can occur both naturally and through anthropogenic causes. Events leading to natural habitat loss include climate change, catastrophic events such as volcanic explosions and through the interactions of invasive and non-invasive species. Natural climate change, events have previously been the cause of many widespread and large scale losses in habitat. For example, some of the mass extinction events generally referred to as the \"Big Five\" have coincided with large scale such as the Earth entering an ice age, or alternate warming events. Other events in the big five also have their roots in natural causes, such as volcanic explosions and meteor collisions. The Chicxulub impact is one such example, which has previously caused widespread losses in habitat as the Earth either received less sunlight or grew colder, causing certain fauna and flora to flourish whilst others perished. Previously known warm areas in the tropics, the most sensitive habitats on Earth, grew colder, and areas such as Australia developed radically different flora and fauna to those seen today. The big five mass extinction events have also been linked to sea level changes, indicating that large scale marine species loss was strongly influenced by loss in marine habitats, particularly shelf habitats. Methane-driven oceanic eruptions have also been shown to have caused smaller mass extinction events.\n\nHumans have been the cause of many species’ extinction. Due to humans’ changing and modifying their environment, the habitat of other species often become altered or destroyed as a result of human actions. Even before the modern industrial era, humans were having widespread, and major effects on the environment. A good example of this is found in Aboriginal Australians and Australian megafauna. Aboriginal hunting practices, which included burning large sections of forest at a time, eventually altered and changed Australia’s vegetation so much that many herbivorous megafauna species were left with no habitat and were driven into extinction. Once herbivorous megafauna species became extinct, carnivorous megafauna species soon followed.\nIn the recent past, humans have been responsible for causing more extinctions within a given period of time than ever before. Deforestation, pollution, anthropogenic climate change and human settlements have all been driving forces in altering or destroying habitats. The destruction of ecosystems such as rainforests has resulted in countless habitats being destroyed. These biodiversity hotspots are home to millions of habitat specialists, which do not exist beyond a tiny area. Once their habitat is destroyed, they cease to exist.This destruction has a follow-on effect, as species which coexist or depend upon the existence of other species also become extinct, eventually resulting in the collapse of an entire ecosystem. These time-delayed extinctions are referred to as the extinction debt, which is the result of destroying and fragmenting habitats.\nAs a result of anthropogenic modification of the environment, the extinction rate has climbed to the point where the Earth is now within a sixth mass extinction event, as commonly agreed by biologists. This has been particularly evident, for example, in the rapid decline in the number of amphibian species worldwide.\n\nDetermining the size, type and location of habitat to conserve is a complex area of conservation biology. Although difficult to measure and predict, the conservation value of a habitat is often a reflection of the quality (e.g. species abundance and diversity), endangerment of encompassing ecosystems, and spatial distribution of that habitat.\n\nHabitat conservation is vital for protecting species and ecological processes. It is important to conserve and protect the space/ area in which that species occupies. Therefore, areas classified as ‘biodiversity hotspots’, or those in which a flagship, umbrella, or endangered species inhabits are often the habitats that are given precedence over others. Species that possess an elevated risk of extinction are given the highest priority and as a result of conserving their habitat, other species in that community are protected thus serving as an element of gap analysis. In the United States of America, a Habitat Conservation Plan (HCP) is often developed to conserve the environment in which a specific species inhabits. Under the U.S. Endangered Species Act (ESA) the habitat that requires protection in an HCP is referred to as the ‘critical habitat’. Multiple-species HCPs are becoming more favourable than single-species HCPs as they can potentially protect an array of species before they warrant listing under the ESA, as well as being able to conserve broad ecosystem components and processes . As of January 2007, 484 HCPs were permitted across the United States, 40 of which covered 10 or more species.The San Diego Multiple Species Conservation Plan (MSCP) encompasses 85 species in a total area of 26,000-km2. Its aim is to protect the habitats of multiple species and overall biodiversity by minimizing development in sensitive areas. Hi\n\nHCPs require clearly defined goals and objectives, efficient monitoring programs, as well as successful communication and collaboration with stakeholders and land owners in the area. Reserve design is also important and requires a high level of planning and management in order to achieve the goals of the HCP. Successful reserve design often takes the form of a hierarchical system with the most valued habitats requiring high protection being surrounded by buffer habitats that have a lower protection status. Like HCPs, hierarchical reserve design is a method most often used to protect a single species, and as a result habitat corridors are maintained, edge effects are reduced and a broader suite of species are protected.\n\nA range of methods and models currently exist that can be used to determine how much habitat is to be conserved in order to sustain a viable population, including Resource Selection Function and Step Selection models. Modelling tools often rely on the spatial scale of the area as an indicator of conservation value. There has been an increase in emphasis on conserving few large areas of habitat as opposed to many small areas. This idea is often referred to as the \"single large or several small\", SLOSS debate, and is a highly controversial area among conservation biologists and ecologists. The reasons behind the argument that \"larger is better\" include the reduction in the negative impacts of patch edge effects, the general idea that species richness increases with habitat area and the ability of larger habitats to support greater populations with lower extinction probabilities. Noss & Cooperrider support the \"larger is better\" claim and developed a model that implies areas of habitat less than 1000ha are \"tiny\" and of low conservation value. However, Shwartz suggests that although \"larger is better\", this does not imply that \"small is bad\". Shwartz argues that human induced habitat loss leaves no alternative to conserving small areas. Furthermore, he suggests many endangered species which are of high conservation value, may only be restricted to small isolated patches of habitat, and thus would be overlooked if larger areas were given a higher priority. The shift to conserving larger areas is somewhat justified in society by placing more value on larger vertebrate species, which naturally have larger habitat requirements.\n\nSince its formation in 1951 The Nature Conservancy has slowly developed into one of the world’s largest conservation organizations. Currently operating in over 30 countries, across 5 continents worldwide, The Nature Conservancy aims to protect nature and its assets for future generations. The organization purchases land or accepts land donations with the intension of conserving its natural resources. In 1955 The Nature Conservancy purchased its first 60-acre plot near the New York/Connecticut border in the United States of America. Today the Conservancy has expanded to protect over 119 million acres of land, 5,000 river miles as well as participating in over 1000 marine protection programs across the globe .\nSince its beginnings The Nature Conservancy has understood the benefit in taking a scientific approach towards habitat conservation. For the last decade the organization has been using a collaborative, scientific method known as ‘Conservation by Design’. By collecting and analyzing scientific data The Conservancy is able to holistically approach the protection of various ecosystems. This process determines the habitats that need protection, specific elements that should be conserved as well as monitoring progress so more efficient practices can be developed for the future.\n\nThe Nature Conservancy currently has a large number of diverse projects in operation. They work with countries around the world to protect forests, river systems, oceans, deserts and grasslands. In all cases the aim is to provide a sustainable environment for both the plant and animal life forms that depend on them as well as all future generations to come. turtles\n\nThe World Wildlife Fund (WWF) was first formed in after a group of passionate conservationists signed what is now referred to as the Morges Manifesto. WWF is currently operating in over 100 countries across 5 continents with a current listing of over 5 million supporters. \nOne of the first projects of WWF was assisting in the creation of the Charles Darwin Research Foundation which aided in the protection of diverse range of unique species existing on the Galápagos’ Islands, Ecuador. It was also a WWF grant that helped with the formation of the College of African Wildlife Management in Tanzania which today focuses on teaching a wide range of protected area management skills in areas such as ecology, range management and law enforcement.\nThe WWF has since gone on to aid in the protection of land in Spain, creating the Coto Doñana National Park in order to conserve migratory birds and The Democratic Republic of Congo, home to the world’s largest protected wetlands. The WWF also initiated a debt-for-nature concept which allows the country to put funds normally allocated to paying off national debt, into conservation programs that protect its natural landscapes. Countries currently participating include Madagascar, the first country to participate which since 1989 has generated over $US50 million towards preservation, Bolivia, Costa Rica, Ecuador, Gabon, the Philippines and Zambia.\n\nRare has been in operation since 1973 with current global partners in over 50 countries and offices in the United States of America, Mexico, the Philippines, China and Indonesia. Rare focuses on the human activity that threatens biodiversity and habitats such as overfishing and unsustainable agriculture. By engaging local communities and changing behaviour Rare has been able to launch campaigns to protect areas in most need of conservation.\nThe key aspect of Rare’s methodology is their \"Pride Campaign’s\". For example, in the Andes in South America, Rare has incentives to develop watershed protection practices. In the Southeast Asia’s \"coral triangle\" Rare is training fishers in local communities to better manage the areas around the coral reefs in order to lessen human impact. Such programs last for three years with the aim of changing community attitudes so as to conserve fragile habitats and provide ecological protection for years to come.\n\nWWF Netherlands, along with ARK Nature, Wild Wonders of Europe and Conservation Capital have started the Rewilding Europe project. This project intents to rewild several areas in Europe.\n\n", "id": "320033", "title": "Habitat conservation"}
{"url": "https://en.wikipedia.org/wiki?curid=40159918", "text": "Ecosystem health\n\nEcosystem health is a metaphor used to describe the condition of an ecosystem. Ecosystem condition can vary as a result of fire, flooding, drought, extinctions, invasive species, climate change, mining, overexploitation in fishing, farming or logging, chemical spills, and a host of other reasons. There is no universally accepted benchmark for a healthy ecosystem, rather the apparent health status of an ecosystem can vary depending upon which health metrics are employed in judging it and which societal aspirations are driving the assessment. Advocates of the health metaphor argue for its simplicity as a communication tool. “Policy-makers and the public need simple, understandable concepts like health.” Critics worry that ecosystem health, a “value-laden construct,” is often “passed off as science to unsuspecting policy makers and the public.”\n\nThe health metaphor applied to the environment has been in use at least since the early 1800s and the great American conservationist Aldo Leopold (1887 – 1948) spoke metaphorically of land health, land sickness, mutilation, and violence when describing land use practices. The term “ecosystem management” has been in use at least since the 1950s. The term “ecosystem health” has become widespread in the ecological literature, as a general metaphor meaning something good, and as an environmental quality goal in field assessments of rivers, lakes, seas, and forests.\n\nThe term ecosystem health has been employed to embrace some suite of environmental goals deemed desirable. Edward Grumbine’s highly cited paper “What is ecosystem management?” surveyed ecosystem management and ecosystem health literature and summarized frequently encountered goal statements:\n\n\nGrumbine describes each of these goals as a “value statement” and stresses the role of human values in setting ecosystem management goals.\n\nIt is the last goal mentioned in the survey, accommodating humans, that is most contentious. “We have observed that when groups of stakeholders work to define … visions, this leads to debate over whether to emphasize ecosystem health or human well-being … Whether the priority is ecosystems or people greatly influences stakeholders’ assessment of desirable ecological and social states.” and, for example, “For some, wolves are critical to ecosystem health and an essential part of nature, for others they are a symbol of government overreach threatening their livelihoods and cultural values.”\n\nMeasuring ecosystem health requires extensive goal-driven environmental sampling. For example, a vision for ecosystem health of Lake Superior was developed by a public forum and a series of objectives were prepared for protection of habitat and maintenance of populations of some 70 indigenous fish species. A suite of 80 lake health indicators was developed for the Great Lakes Basin including monitoring native fish species, exotic species, water levels, phosphorus levels, toxic chemicals, phytoplankton, zooplankton, fish tissue contaminants, etc.\nSome authors have attempted broad definitions of ecosystem health, such as benchmarking as healthy the historical ecosystem state “prior to the onset of anthropogenic stress.” A difficulty is that the historical composition of many human-altered ecosystems is unknown or unknowable. Also, fossil and pollen records indicate that the species that occupy an ecosystem reshuffle through time, so it is difficult to identify one snapshot in time as optimum or “healthy.”.\n\nA commonly cited broad definition states that a healthy ecosystem has three attributes:\n\nWhile this captures significant ecosystem properties, a generalization is elusive as those properties do not necessarily co-vary in nature. For example, there is not necessarily a clear or consistent relationship between productivity and species richness. Similarly, the relationship between resilience and diversity is complex, and ecosystem stability may depend upon one or a few species rather than overall diversity. And some undesirable ecosystems are highly productive.\n\n“Resilience is not desirable per se. There can be highly resilient states of ecosystems which are very undesirable from some human perspectives , such as algal-dominated coral reefs.” Ecological resilience is a “capacity” that varies depending upon which properties of the ecosystem are to be studied and depending upon what kinds of disturbances are considered and how they are to be quantified. Approaches to assessing it “face high uncertainties and still require a considerable amount of empirical and theoretical research.”\nOther authors have sought a numerical index of ecosystem health that would permit quantitative comparisons among ecosystems and within ecosystems over time. One such system employs ratings of the three properties mentioned above: Health = system vigor x system organization x system resilience. Ecologist Glenn Suter argues that such indices employ “nonsense units,” the indices have “no meaning; they cannot be predicted, so they are not applicable to most regulatory problems; they have no diagnostic power; effects of one component are eclipsed by responses of other components, and the reason for a high or low index value is unknown.”\n\nHealth metrics are determined by stakeholder goals, which drive ecosystem definition. An ecosystem is an abstraction. “Ecosystems cannot be identified or found in nature. Instead, they must be delimited by an observer. This can be done in many different ways for the same chunk of nature, depending on the specific perspectives of interest.” \n\nEcosystem definition determines the acceptable range of variability (reference conditions) and determines measurement variables. The latter are used as indicators of ecosystem structure and function, and can be used as indicators of “health.”\n\nAn indicator is a variable, such as a chemical or biological property, that when measured, is used to infer trends in another (unmeasured) environmental variable or cluster of unmeasured variables (the indicandum). For example, rising mortality rate of canaries in a coal mine is an indicator of rising carbon monoxide levels. Rising chlorophyll-a levels in a lake may signal eutrophication.\n\nEcosystem assessments employ two kinds of indicators, descriptive indicators and normative indicators. “Indicators can be used descriptively for a scientific purpose or normatively for a political purpose.”\n\nUsed descriptively, high chlorophyll-a is an indicator of eutrophication, but it may also be used as an ecosystem health indicator. When used as a normative (health) indicator, it indicates a rank on a health scale, a rank that can vary widely depending on societal preferences as to what is desirable. A high chlorophyll-a level in a natural successional wetland might be viewed as healthy whereas a human-impacted wetland with the \"same\" indicator value may be judged unhealthy.\n\nEstimation of ecosystem health has been criticized for intermingling the two types of environmental indicators. A health indicator is a normative indicator, and if conflated with descriptive indicators “implies that normative values can be measured objectively, which is certainly not true. Thus, implicit values are insinuated to the reader, a situation which has to be avoided.”\n\nIt can be argued that the very act of selecting indicators of any kind is biased by the observer’s perspective but separation of goals from descriptions has been advocated as a step toward transparency: “A separation of descriptive and normative indicators is essential from the perspective of the philosophy of science … Goals and values cannot be deduced directly from descriptions … a fact that is emphasized repeatedly in the literature of environmental ethics … Hence, we advise always specifying the definition of indicators and propose clearly distinguishing ecological indicators in science from policy indicators used for decision-making processes.”\n\nAnd integration of multiple, possibly conflicting, normative indicators into a single measure of “ecosystem health” is problematic. Using 56 indicators, “determining environmental status and assessing marine ecosystems health in an integrative way is still one of the grand challenges in marine ecosystems ecology, research and management”\n\nAnother issue with indicators is validity. Good indicators must have an independently validated high predictive value, that is high sensitivity (high probability of indicating a significant change in the indicandum) and high specificity (low probability of wrongly indicating a change). The reliability of various health metrics has been questioned and “what combination of measurements should be used to evaluate ecosystems is a matter of current scientific debate.” Most attempts to identify ecological indicators have been correlative rather than derived from prospective testing of their predictive value and the selection process for many indicators has been based upon weak evidence or has been lacking in evidence.\n\nIn some cases no reliable indicators are known: “We found no examples of invertebrates successfully used in [forest] monitoring programs. Their richness and abundance ensure that they play significant roles in ecosystem function but thwart focus on a few key species.” And, “Reviews of species-based monitoring approaches reveal that no single species, nor even a group of species, accurately reflects entire communities. Understanding the response of a single species may not provide reliable predictions about a group of species even when the group is a few very similar species.”\n\nA trade-off between human health and the “health” of nature has been termed the “health paradox” and it illuminates how human values drive perceptions of ecosystem health.\n\nHuman health has benefited by sacrificing the “health” of wild ecosystems, such as dismantling and damming of wild valleys, destruction of mosquito-bearing wetlands, diversion of water for irrigation, conversion of wilderness to farmland, timber removal, and extirpation of tigers, whales, ferrets, and wolves.\n\nThere has been an acrimonious schism among conservationists and resource managers over the question of whether to “ratchet back human domination of the biosphere” or whether to embrace it. These two perspectives have been characterized as utilitarian vs protectionist.\n\nThe utilitarian view treats human health and well-being as criteria of ecosystem health. For example, destruction of wetlands to control malaria mosquitoes “resulted in an improvement in ecosystem health.”\nThe protectionist view treats humans as an invasive species: “If there was ever a species that qualified as an invasive pest, it is \"Homo sapiens\",”\n\nProponents of the utilitarian view argue that “healthy ecosystems are characterized by their capability to sustain healthy human populations,” and “healthy ecosystems must be economically viable,” as it is “unhealthy” ecosystems that are likely to result in increases in contamination, infectious diseases, fires, floods, crop failures and fishery collapse.\n\nProtectionists argue that privileging of human health is a conflict of interest as humans have demolished massive numbers of ecosystems to maintain their welfare, also disease and parasitism are historically normal in pre-industrial nature. Diseases and parasites promote ecosystem functioning, driving biodiversity and productivity, and parasites may constitute a significant fraction of ecosystem biomass.\nThe very choice of the word “health” applied to ecology has been questioned as lacking in neutrality in a BioScience article on responsible use of scientific language: “Some conservationists fear that these terms could endorse human domination of the planet … and could exacerbate the shifting cognitive baseline whereby humans tend to become accustomed to new and often degraded ecosystems and thus forget the nature of the past.”\n\nCriticism of ecosystem health largely targets the failure of proponents to explicitly distinguish the normative dimension from the descriptive dimension, and has included the following:\n\nAlternatives have been proposed for the term ecosystem health, including more neutral language such as ecosystem status, ecosystem prognosis, and ecosystem sustainability. Another alternative to the use of a health metaphor is to “express exactly and clearly the public policy and the management objective,” to employ habitat descriptors and real properties of ecosystems. An example of a policy statement is “The maintenance of viable natural populations of wildlife and ecological functions always takes precedence over any human use of wildlife.” An example of a goal is “Maintain viable populations of all native species in situ.” An example of a management objective is \"Maintain self-sustaining populations of lake whitefish within the range of abundance observed during 1990-99.\"\n\nKurt Jax presented an ecosystem assessment format that avoids imposing a preconceived notion of normality, that avoids the muddling of normative and descriptive, and that gives serious attention to ecosystem definition. (1) Societal purposes for the ecosystem are negotiated by stakeholders, (2) a functioning ecosystem is defined with emphasis on phenomena relevant to stakeholder goals, (3) benchmark reference conditions and permissible variation of the system are established, (4) measurement variables are chosen for use as indicators, and (5) the time scale and spatial scale of assessment are decided.\n\nEcological health has been used as a medical term in reference to human allergy and multiple chemical sensitivity and as a public health term for programs to modify health risks (diabetes, obesity, smoking, etc.). Human health itself, when viewed in its broadest sense, is viewed as having ecological foundations. It is also an urban planning term in reference to “green” cities (composting, recycling), and has been used loosely with regard to various environmental issues, and as the condition of human-disturbed environmental sites. Ecosystem integrity implies a condition of an ecosystem exposed to a minimum of human influence. Ecohealth is the relationship of human health to the environment, including the effect of climate change, wars, food production, urbanization, and ecosystem structure and function. Ecosystem management and ecosystem-based management refer to the sustainable management of ecosystems and in some cases may employ the terms ecosystem health or ecosystem integrity as a goal.\n", "id": "40159918", "title": "Ecosystem health"}
{"url": "https://en.wikipedia.org/wiki?curid=41251693", "text": "Cobthorn Trust\n\nThe Cobthorn Trust works on the conservation of commensal and food species, their related farm and wild species and their environments. Formed in 1986, the trust has been involved in the conservation of several rare breeds, initiation of the National Poultry Collection, genetic research on Dexter cattle, and the development of conservation grazing.\n\nThe Cobthorn Trust was formed in 1986, originally to support and promote the conservation activities at Cobthorn Farm in Congresbury, North Somerset. Cobthorn Farm has been involved in rare breed farming since 1959 and is now the base for the trust’s conservation activities. It has been farmed by the present (2013) Director’s family since at least the 1820s.\n\nMajor conservation breeding of the Cobthorn Trust has involved many breeds of domestic cattle, pigs, sheep and particularly poultry, plus related wild species such as pheasants. From 1969, there has been close involvement with the Rare Poultry Society and subsequently the Rare Breeds Survival Trust (RBST). While the RBST is solely involved with native British breeds, the Cobthorn Trust holds stocks of internationally endangered rarities and related wild species.\n\nThe National Poultry Collection (NPC) began with breeding stocks established at Cobthorn Farm and the trust; it is now maintained on numerous farms in co-operation with the trust. All the birds in the collection have an individually recorded pedigree. The collection includes all the main domesticated poultry species of fowls, ducks, geese and turkeys. All the traditional British breeds have been bred in the collection, and numerous other rare or endangered poultry from around the world. Several of the breeding stocks held in the National Poultry Collection are the only ones known to remain for those breeds.\n\nThe Cobthorn Trust has undertaken many field conservation projects, working with a number of other conservation organisations such as wildlife trusts and local authorities. The trust has produced surveys of biodiversity and species records for several sites, both in the UK and overseas.\n\nConservation grazing is actively promoted by the Cobthorn Trust with the publication of observations on grazing patterns for the various rare breeds on the farm. Conservation grazing is now accepted as an environmental conservation technique of fundamental importance. Using both cattle and sheep, schemes have been prepared for a number of conservation sites, including the restoration of Cadbury Hill at Congresbury and the site of special scientific interest at Uphill Cliffs near Weston-super-Mare.\n\nSeven rare breeds of sheep have been bred by Cobthorn Trust including the most endangered bloodline of Norfolk Horn sheep which was kept for 20 years. Research has included the determination of the colour genetics in Hebrideans. Rare breeds of sheep are used by the trust in the development of conservation grazing.\n\nConservation breeding groups of some of the rarest cattle have been maintained by the Cobthorn Trust since 1976, including Irish Moiled and Gloucester. Longhorn and Highland cattle have also been bred at the farm. The trust has been a centre of research into the breeding and genetics of Dexter cattle worldwide. The genetic nature of a major defect in the breed was established in a breeding programme at Cobthorn and has been instrumental in isolating the gene concerned. Studies have shown there to be very few purebred Dexters and a small group of these purebreds is kept by the trust. The trust's database on Dexters is highly detailed and a project to examine the genetic history of the breed is being undertaken in collaboration with Cardiff University.\n\nThe trust has contributed to the conservation of rare breed pigs with a herd of Oxford Sandy and Blacks. As a result of work at the trust, a breed society was established in 1985, ensuring the continuance of the breed. Several of the boars bred at Cobthorn have become the principal sires used to perpetuate this critically endangered breed.\n\nBreeding groups of wild species of pheasants have been kept at Cobthorn for many years. These include the jungle fowl and gallopheasants, with breeding successes in Swinhoe's pheasants (\"Lophura swinhoii\") in the 1960s leading to the establishment of a number of breeding populations, including at Bristol Zoo. Cobthorn Trust is engaged on a breeding programme to study the biology of the kalij pheasant (\"Lophura leucomelanos\") and silver pheasant (\"Lophura nycthemera\"). The trust has also undertaken field studies of several pheasant species in their native habitats in Asia.\n", "id": "41251693", "title": "Cobthorn Trust"}
{"url": "https://en.wikipedia.org/wiki?curid=30497807", "text": "UCbase\n\nUCbase is a database of ultraconserved sequences (UCRs or UCEs) that were first described by Bejerano, G. et al. in 2004. They are highly conserved genome regions that share 100% identity among human, mouse and rat. UCRs are 481 sequences longer than 200 bases. They are frequently located at genomic regions involved in cancer, differentially expressed in human leukemias and carcinomas and in some instances regulated by microRNAs. The first release of UCbase was published by Taccioli, C. et al. in 2009. Recent updates include new annotation based on hg19 Human genome, information about disorders related to the chromosome coordinates using the SNOMED CT classification, a query tool to search for SNPs, and a new text box to directly interrogate the database using a MySQL interface. Moreover, a sequence comparison tool allows the researchers to match selected sequences against ultraconserved elements located in genomic regions involved in specific disorders. To facilitate the interactive, visual interpretation of UCR chromosomal coordinates, the authors have implemented the graph visualization feature of UCbase creating a link to UCSC genome browser. UCbase 2.0 does not provide microRNAs (miRNAs) information anymore focusing only on UCRs. The official release of UCbase 2.0 was published in 2014 and is accessible at http://ucbase.unimore.it\n\n\n", "id": "30497807", "title": "UCbase"}
{"url": "https://en.wikipedia.org/wiki?curid=1557574", "text": "Conservation genetics\n\nConservation genetics is an interdisciplinary subfield of Population Genetics that aims to understand the dynamics of genes in populations principally to avoid extinction. Therefore, it applies genetic methods to the conservation and restoration of biodiversity. Researchers involved in conservation genetics come from a variety of fields including population genetics, molecular ecology, biology, evolutionary biology, and systematics. Genetic diversity is one of the three fundamental levels of biodiversity, so it is directly important in conservation. Genetic variability influences both the health and long-term survival of populations because decreased genetic diversity has been associated with reduced fitness, such as high juvenile mortality, diminished population growth, reduced immunity, and ultimately, higher extinction risk.\n\nGenetic diversity is the variability of genes in a species. A number of means can express the level of genetic diversity: observed heterozygosity, expected heterozygosity, the mean number of alleles per locus, or the percentage of polymorphic loci.\n\nGenetic diversity determines the potential fitness of a population and ultimately its long-term persistence, because genes encode phenotypic information. Extinction risk has been associated with low genetic diversity because several researchers have documented reduced fitness in populations with low genetic diversity. For example, low genetic diversity as low heterozigosity has been associated with low juvenile survival, reduced population growth, low body size, diminished adult lifespan.\n\nThe importance of genetic diversity has many reasons. For example, one can consider the probability of within any given population that at least one individual or a potential reproductive pair have the genetic composition encoding a phenotype capable of survival an environment event. If l the individuals are nearly identical, if new pressures (such as environmental disasters) occur, a population with high genetic diversity has a greater chance of having at least some individuals with a genetic makeup that allows them to survive, or if genetic diversity is very low, none of the individuals in a population may have the characteristics needed to cope with the new environmental conditions. Such a population could be suddenly wiped out.\n\nThe genetic diversity of a species is always open to change. No matter how many variants of a gene are present in a population today, only the variants that survive in the next generation can contribute to species diversity in the future. Once gene variants are lost, they cannot be recovered.\n\n\nSpecific genetic techniques are used to assess the genomes of a species regarding specific conservation issues as well as general population structure. This analysis can be done in two ways, with current DNA of individuals or historic DNA.\n\nTechniques for analysing the differences between individuals and populations include\n\n\nThese different techniques focus on different variable areas of the genomes within animals and plants. The specific information that is required determines which techniques are used and which parts of the genome are analysed. For example, mitochondrial DNA in animals has a high substitution rate, which makes it useful for identifying differences between individuals. However, it is only inherited in the female line, and the mitochondrial genome is relatively small. In plants, the mitochondrial DNA has very high rates of structural mutations, so is rarely used for genetic markers, as the chloroplast genome can be used instead. Other sites in the genome that are subject to high mutation rates such as the major histocompatibility complex, and the microsatellites and minisatellites are also frequently used.\n\nThese techniques can provide information on long-term conservation of genetic diversity and expound demographic and ecological matters such as taxonomy.\n\nAnother technique is using historic DNA for genetic analysis. Historic DNA is important because it allows geneticists to understand how species reacted to changes to conditions in the past. This is a key to understanding the reactions of similar species in the future.\n\nTechniques using historic DNA include looking at preserved remains found in museums and caves. Museums are used because there is a wide range of species that are available to scientists all over the world. The problem with museums is that, historical perspectives are important because understanding how species reacted to changes in conditions in the past is a key to understanding reactions of similar species in the future. Evidence found in caves provides a longer perspective and does not disturb the animals.\n\nAnother technique that relies on specific genetics of an individual is noninvasive monitoring, which uses extracted DNA from organic material that an individual leaves behind, such as a feather. This too avoids disrupting the animals and can provide information about the sex, movement, kinship and diet of an individual.\n\nOther more general techniques can be used to correct genetic factors that lead to extinction and risk of extinction. For example, when minimizing inbreeding and increasing genetic variation multiple steps can be taken. Increasing heterozygosity through immigration, increasing the generational interval through cryopreservation or breeding from older animals, and increasing the effective population size through equalization of family size all helps minimize inbreeding and its effects. Deleterious alleles arise through mutation, however certain recessive ones can become more prevalent due to inbreeding. Deleterious mutations that arise from inbreeding can be removed by purging, or natural selection. Populations raised in captivity with the intent of being reintroduced in the wild suffer from adaptations to captivity.\n\nInbreeding depression, loss of genetic diversity, and genetic adaptation to captivity are disadvantageous in the wild, and many of these issues can be dealt with through the aforementioned techniques aimed at increasing heterozygosity. In addition creating a captive environment that closely resembles the wild and fragmenting the populations so there is less response to selection also help reduce adaptation to captivity.\n\nSolutions to minimize the factors that lead to extinction and risk of extinction often overlap because the factors themselves overlap. For example, deleterious mutations are added to populations through mutation, however the deleterious mutations conservation biologists are concerned with are ones that are brought about by inbreeding, because those are the ones that can be taken care of by reducing inbreeding. Here the techniques to reduce inbreeding also help decrease the accumulation of deleterious mutations.\n\nThese techniques have wide ranging applications. One application of these specific molecular techniques is in defining species and sub-species of salmonids. Hybridization is an especially important issue in salmonids and this has wide ranging conservation, political, social and economic implications. In Cutthroat Trout mtDNA and alloenzyme analysis, hybridization between native and non-native species was shown to be one of the major factors contributing to the decline in their populations. This led to efforts to remove some hybridized populations so native populations could breed more readily. Cases like these impact everything from the economy of local fishermen to larger companies, such as timber. Specific molecular techniques led to a closer analysis of taxonomic relationships, which is one factor that can lead to extinctions if unclear.\n\nNew technology in conservation genetics has many implications for the future of conservation biology. At the molecular level, new technologies are advancing. Some of these techniques include the analysis of minisatellites and MHC. These molecular techniques have wider effects from clarifying taxonomic relationships, as in the previous example, to determining the best individuals to reintroduce to a population for recovery by determining kinship. These effects then have consequences that reach even further. Conservation of species has implications for humans in the economic, social, and political realms. In the biological realm increased genotypic diversity has been shown to help ecosystem recovery, as seen in a community of grasses which was able to resist disturbance to grazing geese through greater genotypic diversity. Because species diversity increases ecosystem function, increasing biodiversity through new conservation genetic techniques has wider reaching effects than before.\n\nA short list of studies a conservation geneticist may research include:\n\n\n\n\n", "id": "1557574", "title": "Conservation genetics"}
{"url": "https://en.wikipedia.org/wiki?curid=6260894", "text": "Biological integrity\n\nBiological integrity is associated with how \"pristine\" an environment is and its function relative to the potential or original state of an ecosystem before human alterations were imposed. Biological integrity is built on the assumption that a decline in the values of an ecosystem's functions are primarily caused by human activity or alterations. The more an environment and its original processes are altered, the less biological integrity it holds for the community as a whole. If these processes were to change over time naturally, without human influence, the integrity of the ecosystem would remain intact. The integrity of the ecosystem relies heavily on the processes that occur within it because those determine what organisms can inhabit an area and the complexities of their interactions.\n\nThe concept of biological integrity first appeared in the 1972 amendments to the U.S. Federal Water Pollution Control Act, also known as the Clean Water Act. The United States Environmental Protection Agency (EPA) had used the term as a way to gauge the standards to which water should be maintained, but the vocabulary instigated years of debate about the implications of not only the meaning of biological integrity, but also how it can be measured. The first conference about the term occurred in March 1975 called \"The Integrity of Water\" and provided the first accepted definition of biological integrity (see below). In 1981, EPA assembled a field of experts from the U.S. Fish and Wildlife Service, academia, and its own staff to further refine the definition and identify key indicators to quantitatively measure biological integrity. The conference not only identified a definition, but also methods to evaluate the community, and they established that multiple sites should be used to determine the condition of the environment\n\nToday, the accepted definition is “the capability of supporting and maintaining a balanced, integrated, adaptive community of organisms having a species composition, diversity, and functional organization comparable to that of the natural habitat of the region.” This definition was adapted from Frey (1977). The implications of this definition are that living systems have a variety of scales relative to which they exist, that one can quantify the parts that sustain or contribute to a system's functioning and that all systems must be seen in the context of their environments and evolutionary history. This term primarily refers to aquatic environments because the vocabulary is derived from the Clean Water Act, but the concepts can be applied to other ecosystems.\n\nIn order to quantify and evaluate the biological integrity of a system, the Index of Biological Integrity (IBI) was created. In this index the baseline biological integrity (its function before human influence) and the current functions of an ecosystem are measured against one another to evaluate how much of ecosystem’s function has been preserved. The IBI evaluates the ecosystem by utilizing biosurveys and comparing species richness, indicator taxa, hybrids, and invasive species. IBIs are used primarily to evaulate aquatic ecosystems even though one could technically apply any measurement of biological integrity to any natural ecosystem.\n\n", "id": "6260894", "title": "Biological integrity"}
{"url": "https://en.wikipedia.org/wiki?curid=1478035", "text": "Flagship species\n\nThe concept of flagship species has its genesis in the field of conservation biology. The flagship species concept holds that by raising the profile of a particular species, it can successfully leverage more support for biodiversity conservation at large in a particular context.\n\nSeveral definitions have been advanced for the flagship species concept and for some time there has been confusion even in the academic literature. Most of the latest definitions focus on the strategic and socio-economical character of the concept, with a recent publication establishing a clear link with the marketing field.\n\n\nThe term flagship is linked to the metaphor of representation. In its popular usage, flagships are viewed as ambassadors or icons for a conservation project or movement.\n\nHowever, more recently, work in the field of microbiology has started to use the concept of flagship species in a distinct way. This work relates to the biogeography of micro-organisms and uses particular species because \"eyecatching \"flagships\" with conspicuous size and/or morphology are the best distribution indicators\".\n\nExamples of flagship species include the Bengal tiger (\"Panthera tigris\"), the giant panda (\"Ailuropoda melanoleuca\"), the Golden lion tamarin (\"Leontopithecus rosalia\"), the African elephant (\"Loxodonta sp.\") and Asian elephant (\"Elephas maximus\"). Jaguar is a key stone species.\n\nFlagship species can represent an environmental feature (e.g. a species or ecosystem), cause (e.g. climate change or ocean acidification), organization (e.g. NGO or government department) or geographic region (e.g. state or protected area).\n\nThe flagship species concept appears to have become popular around the mid 1980s within the debate on how to prioritise species for conservation. The first widely available references to use the flagship concept applied it to both neotropical primates and African elephants and rhinos, in the typical mammal centric approach that still dominates how the concept is used today\n\nThe use of the concept has been largely dominated by large bodied species, especially mammals, although species from other taxonomic groups have occasionally been used\n\nFlagship species can be selected according to many different characteristics depending on what is valued by the audience they try to target. This is best illustrated by the differences in recommendations made for flagship species selection targeting different target audiences such as local communities. and tourists.\n\nSeveral limitations have been recognized concerning the use of flagship species:\n\nA major challenge for the deployment of several flagship species in non-Western contexts is that they may come into conflict with local communities, thereby jeopardizing well-intended conservation actions. This has been termed 'flagship mutiny' and is exemplified by the Asian elephant in countries where there is human-elephant conflict.\n\nConservation flagships can also appear at broader levels, for example as ecosystems (such as coral reefs or rainforests or protected areas (Serengeti or Yellowstone). A number of recent initiatives has developed new conservation flagships based on conservation values of particular areas or species. Examples of these are the EDGE project run by the Zoological Society of London and the Hotspots run by Conservation International.\n\n\n", "id": "1478035", "title": "Flagship species"}
{"url": "https://en.wikipedia.org/wiki?curid=3612067", "text": "Invader potential\n\nIn conservation biology, invader potential is the qualitative and quantitative measure of a given invasive species probability to invade a given ecosystem. Exotic species with high invader potential are ones with high tolerance of different climates, dissolved oxygen content (for aquatic organisms), high propagule pressure and species with a large number of individuals introduced. The last factor is called a transport vector, for instance, sea lampreys and zebra mussels were transported into the Great Lakes through the vector of ballast water in ships. Transport vector is one of the most important factors, because if a large enough number of individuals are transported to an area that they cannot thrive in, a mutation within that population to thrive in the new ecosystem is more likely.\n\nMost invaders are adapted to disturbed areas, so ecosystems that have been disrupted or roadside ditches are susceptible to invasion.\n\nClimate matching is one of the most common measures of invader potential. Mostly exotic species that have already exhibited invasive traits are studied. \n\nBiotic resistance is a controversial concept in invader potential. Small scale studies have borne the concept of diversity resistance, that diverse ecosystems resist invasions better than less diverse ecosystems. However, evidence on regional scales finds a positive correlation between diversity and number of invasions. The exact interpretation of these studies is unclear.\n", "id": "3612067", "title": "Invader potential"}
{"url": "https://en.wikipedia.org/wiki?curid=11451063", "text": "Wildlife corridor\n\nA wildlife corridor, habitat corridor, or green corridor is an area of habitat connecting wildlife populations separated by human activities or structures (such as roads, development, or logging). This allows an exchange of individuals between populations, which may help prevent the negative effects of inbreeding and reduced genetic diversity (via genetic drift) that often occur within isolated populations. Corridors may also help facilitate the re-establishment of populations that have been reduced or eliminated due to random events (such as fires or disease).\n\nThis may potentially moderate some of the worst effects of habitat fragmentation, wherein urbanization can split up habitat areas, causing animals to lose both their natural habitat and the ability to move between regions to use all of the resources they need to survive. Habitat fragmentation due to human development is an ever-increasing threat to biodiversity, and habitat corridors are a possible mitigation.\n\nThe main goal of implementing habitat corridors is to increase biodiversity. When areas of land are broken up by human interference, population numbers become unstable and many animal and plant species become endangered. By re-connecting the fragments, the population fluctuations can decrease dramatically. Corridors can contribute to three factors that stabilize a population: \n\nAlthough corridors have been implemented with the assumption that they will increase biodiversity, not enough research has been done to come to a solid conclusion. The case for corridors has been built more on intuition and much less on empirical evidence (Tewksbury et al. 2002). Another factor that needs to be taken into account is what species the corridor is intended for. Some species have reacted more positively to corridors than others.\nA habitat corridor could be considered as a possible solution in an area where the destruction of a natural area has greatly affected its native species. Development such as roads, buildings, and farms can interrupt plants and animals in the region being destroyed. Furthermore, natural disasters such as wildfires and floods can leave animals with no choice but to evacuate. If the habitat is not connected to a safer one, it will ultimately lead to death. A remaining portion of natural habitat is called a remnant, and such portions need to be connected because when migration decreases, extinction increases (Fleury 1997).\n\nCorridors can be made in two distinct areas—either water or land. Water corridors are called riparian ribbons and usually come in the form of rivers and streams. Land corridors come on a scale as large as wooded strips connecting larger woodland areas. However, they can also be as simple as a line of shrubs along a sidewalk (Fleury 1997). Such areas can facilitate the movement of small animals, especially birds, from tree to tree, until they find a safe habitat to nest in. Not only do minimal corridors aid in the movement of animals, they are also aesthetically pleasing, which can sometimes encourage the community to accept and support them.\n\nSpecies can be categorized in one of two groups; passage users and corridor dwellers.\n\nPassage users occupy corridors for brief periods of time. These animals use corridors for such events as seasonal migration, dispersal of a juvenile, or moving between parts of a large home range. Usually large herbivores, medium to large carnivores, and migratory species are passage users (Beier & Loe 1992). One common misconception is that the corridor only needs to be wide enough for the passage users to get through. However, the corridor still must be wide enough to be safe and also encourage the animals to use it, even though they do not live out their entire lives in it.\n\nCorridor dwellers can occupy the passage anywhere from several days to several years. Species such as plants, reptiles, amphibians, birds, insects, and small mammals can spend their entire lives in linear habitats. In this case, the corridor must include everything that a species needs to live and breed, such as soil for germination, burrowing areas, and multiple other breeding adults (Beier & Loe 1992).\n\nHabitat corridors can be categorized according to their width. Typically the wider the corridor, the more use it will get from species. However, the width-length ratio, as well as design and quality play just as important of a role in creating the perfect corridor (Fleury 1997). The strip of land will suffer less from edge effects such as weeds, predators, and chemicals if it is constructed properly. The following are three divisions in corridor widths: \n\nHabitat corridors can also be divided according to their continuity. Continuous corridors are strips that are not broken up, while “stepping stone” corridors are small patches of suitable habitat. When stepping stones are arranged in a line, they form a strip of land connecting two areas, just like a continuous corridor would. Both kinds provide linkages between protected core areas and stimulate or allow species to migrate.\n\nFinally, corridors can come in the form of underpasses or overpasses, which can be very safe for both animals and humans. Many busy highways cross through natural habitats that native species occupy, as well. Large animals such as deer become a hazard when they cross in front of traffic and get hit. An overpass or an underpass serves as a bridge to facilitate the movement of animals across a busy road. Observations have shown that underpasses are actually more successful than overpasses because many times animals are too timid to cross over a bridge in front of traffic and would prefer to be more hidden (Dole et al. 2003).\nCorridors can be expensive to plan out and put into action. For example, Daniel Simberloff et al. states that “a bridge that would maintain a riparian corridor costs about 13 times as much per lane-mile as would a road that would sever the corridor.” He also states that maintenance of a corridor would be much more costly than refuges for endangered species. It would simply be easier to move animals between refuges than to buy land, install a corridor, and maintain it. However, where the goal is not just to preserve a few large animal species but to protect biodiversity among all plants and animals, then habitat corridors may be the only option. Corridors are going to be expensive to implement no matter what, but it does depend on the type, location, and size, which can all vary to a great degree. With the lack of field data on the effectiveness, many agencies are not willing to consider putting in corridors.\n\nIt is extremely important for researchers to pay attention to the population changes in animals after a corridor has been implemented to ensure that there are no harmful effects. Researchers can use both mark-recapture techniques and evaluate genetic flow in order to observe how much a corridor is being used. Marking and recapturing animals is more useful when keeping a close eye on individual movement (Mech & Hallet 2001). The only problem is that tagging animals and watching them does not tell anyone whether the migrating individuals are successfully mating with other populations in connected areas of land. On the other hand, genetic techniques can be more effective in evaluating migration and mating patterns.\n\nOne of the most important goals of developing a corridor is to increase migration in certain animal species. By looking at a population’s gene flow, researchers can understand the genetic consequences of corridors (Mech & Hallett 2001). The migration patterns of an entire population are much more important than the movements of a few individuals. From these techniques, researchers will better understand whether or not habitat corridors are increasing biodiversity.\n\nStephen Mech and James Hallett introduce an additional reason genetic techniques are more useful; they “measure average migration rates over time, which reveals the effects of fragmentation of several generations and is not as sensitive to current population sizes as mark-recapture studies are.” For example, when a population is extremely small, mark-recapture is almost impossible. Clearly, genetic analysis of a species is the best way to determine if animals are actually using corridors to move and reproduce.\n\nAccording to new research, wildlife corridors are best built with a certain degree of randomness or asymmetry, rather than built symmetrically. The research was conducted at UC Davis.\n\nWildlife corridors are susceptible to edge effects; habitat quality along the edge of a habitat fragment is often much lower than in core habitat areas. Wildlife corridors are important for large species requiring significant sized ranges; however, they are also vital as connection corridors for smaller animals and plants as well as ecological connectors to provide a \"rescue effect\".\n\nBoth the safety of animals and humans can be achieved through the creation of corridors. For example, deer commonly cross roads in order to get to other grazing land. When they are faced with a car coming at them, they freeze; this puts both the deer and the human’s life in danger. In Alberta, Canada, an overpass was constructed to keep animals off of the busy highway; the area is part of a national park, so many different creatures roam the area. The top of the bridge is covered in the native grass of the area so that it blends in better and animals will not know the difference. Gates were also put of on either side of the overpass to help guide animals in the right direction (Semrad 2007).\n\nIn Southern California, 15 underpasses and drainage culverts were observed to see how many animals used them as corridors. They proved to be especially effective on wide-ranging species such as carnivores, mule deer, small mammals, and reptiles, even though the corridors were not intended specifically for animals. Researchers also learned that factors such as surrounding habitat, underpass dimensions, and human activity also played a role in how much use they got. From this experiment, much was learned about what would constitute a successful habitat corridor (Dole et al. 2003).\n\nIn South Carolina, five remnant areas of land were monitored; one was put in the center and four were surrounding it. Then, a corridor was put between one of the remnants and the center. Butterflies that were placed in the center habitat were two to four times more likely to move to the connected remnant rather than the disconnected ones. Furthermore, male holly plants were placed in the center region, and female holly plants in the connected region increased by 70 percent in seed production compared to those plants in the disconnected region. The most impressive dispersal into the connected region, though, was through bird droppings. Far more plant seeds were dispersed through bird droppings in the corridor-connected patch of land (M. 2002).\n\nThere have also been positive effects on the rates of transfer and interbreeding in vole populations. A control population in which voles were confined to their core habitat with no corridor was compared to a treatment population in their core habitat with passages that they could use to move to other regions. Females typically stayed and mated within their founder population, but the rate of transfer through corridors in the males was very high. Researchers are not sure why the females did not move about as much, but it is apparent that the corridor effectively transferred at least some of the species to another location for breeding (Aars 1999).\n\nIn 2001, a wolf corridor was restored through a golf course in Jasper National Park, Alberta, which enabled wolves to pass through the course. After this restoration, wolves passed through the corridor frequently. This is one of the first demonstrations that corridors are used by wildlife, and can be effective in decreasing fragmentation. Earlier studies had been criticised for failing to demonstrate that corridor restoration leads to a change in wildlife behaviour.\n\nElephant corridors are narrow strips of land that allow elephants to move from one habitat patch to another. There are 88 identified elephant corridors in India.\n\nIn Africa, Botswana houses the largest number of free-roaming elephant herds. Elephants Without Borders (EWB) studies the movement of elephants is working to gain community support of local community corridors, so that elephants and humans can co-exist.\n\nSeveral artificial wildlife corridors have been created, these include:\n\nSome animal species are much more apt to use habitat corridors than others depending on what their migration and mating patterns are like. For example, many cases of birds and butterflies successfully using corridors have been observed. Less successful stories have come out of mammals such as deer. How effective a corridor is may simply rely on what species it is directed towards (Tewskbury 2002). Corridors created with birds in mind may be more successful because they are highly migratory to begin with.\n\nHuman interference is almost inevitable with the quickly increasing population. The goal behind habitat corridors shows the most hope for solving habitat fragmentation and restoring biodiversity as much as possible. Although there are many positives and negatives, there may be enough positives to continue studying and improving corridors. It is truly difficult to say whether corridors are the solution to increasing biodiversity, because each one must be judged on its own. Each corridor has its own set of standards and goals that may set it apart from another one.\n\nA major downfall to habitat corridors is that not much information has been gathered about their success. Due to the lack of positive data, many agencies will not allow corridors to be established because they are unsure of their effectiveness. Another problem with corridors is that they are not as useful as simply preserving land so that it cannot be fragmented. However, it is becoming very difficult to set aside land for nature reserves when road-building, industry, and urban sprawl are all competing for space.\n\nEven if corridors are sought as a solution, it does not necessarily mean that animals will use them. Especially in the case of overpasses, research shows that animals do not like to use them to get to another remnant area of land. Usually overpasses are built over busy highways, and many species are too timid to expose themselves in front of all of the traffic. As more roads and buildings arise, there becomes less space to try to preserve.\n\nHabitat corridors need to be species-specific (not every kind of animal will use every kind of corridor) and corridors can be barriers to some species. For instance plants may use road verges as corridors however some mammals will not cross roads to reach a suitable habitat.\n\nWhen a corridor is implemented, many times development is so close by, that it becomes difficult to build a wide enough passage. There is usually a very limited amount of space available for corridors, so buffers are not usually added in (Rosenberg 1997). Without a buffer zone, corridors become susceptible to harmful outside factors from city streets, suburb development, rural homes, forestry, cropland, and feedlots.\n\nUnfortunately, another limiting factor to the implementation of corridors is money. With such inconclusive data about the effectiveness of connecting land, it is difficult to get the proper funding. Those who would be in charge of the corridor design and construction would ask such questions as, “What if the corridors affect species negatively?” and “What if they actually aid in the spread of disease and catastrophic events?” Furthermore, there is a possibility that corridors could not only aid in the dispersal of native organisms, but invasive ones, as well (Beier & Loe 1998). If invasive species take over an area they could potentially threaten another species, even to the point of extinction.\n\nAlthough wildlife corridors have been proposed as solutions to habitat and wildlife population fragmentation, there is little evidence that they are broadly useful as a conservation strategy for all biodiversity in non-developed or less-developed areas, compared to protecting connectivity as the relevant ecological attribute. In other words, corridors may be a useful meme for conservation planning/ers, but the concept has less meaning to wildlife species themselves. Very few wildlife follow easily identified \"corridors\" or \"linkages\" (e.g., using computer modeling), instead most species meander and opportunistically move through landscapes during daily, seasonal, and dispersal movement behavior. Wildlife corridors may be useful in highly developed landscapes where they are easily identified as the last remaining and available habitat.\n\nHabitat corridors may be defenseless against a number of outside influences, but they are still an efficient way of increasing biodiversity. Strips of land aid in the movement of various animal species and pollen and seed dispersal, which is an added benefit to the intended one (M. 2002). For example, when insects carrying pollen or birds carrying seeds travel to another area, plant species effectively get transported, as well.\n\nAnother positive aspect of corridors is that they allow both animals and humans to occupy virtually the same areas of land, and thus co-exist where without the corridor this would not be possible. Large animals such as bears can be attracted to residential areas in search of food due to lack of natural resources because of habitat fragmentation. A corridor would provide a passage for the bears to forage in other locations, so that they would not pose as much of a threat to humans.\n\n\n\n", "id": "11451063", "title": "Wildlife corridor"}
{"url": "https://en.wikipedia.org/wiki?curid=21650435", "text": "Conservation-reliant species\n\nConservation-reliant species are animal or plant species that require continuing species-specific wildlife management intervention such as predator control, habitat management and parasite control to survive, even when a self-sustainable recovery in population is achieved.\n\nThe term \"conservation-reliant species\" grew out of the conservation biology undertaken by \"The Endangered Species Act at Thirty Project\" (launched 2001) and its popularization by project leader J. Michael Scott. Its first use in a formal publication was in \"Frontiers in Ecology and the Environment\" in 2005. Worldwide use of the term has not yet developed and it has not yet appeared in a publication compiled outside North America.\n\nPassages of the 1973 Endangered Species Act (ESA) carried with it the assumption that endangered species would be delisted as their populations recovered. It assumed they would then thrive under existing regulations and the protections afforded under the ESA would no longer be needed. However, eighty percent of species currently listed under the ESA fail to meet that assumption. To survive, they require species-specific conservation interventions (e.g. control of predators, competitors, nest parasites, prescribed burns, altered hydrological processes, etc.) and thus they are conservation-reliant.\n\nThe criteria for assessing whether a species is conservation-reliant are:\n\nThere are five major areas of management action for conservation of vulnerable species:\n\nA prominent example is in India, where tigers, an apex predator and the national animal, are considered a conservation-reliant species. This keystone species can maintain self-sustaining wild populations; however, they require ongoing management actions because threats are pervasive, recurrent and put them at risk of extinction. The origin of these threats are rooted in the changing socio-economic, political and spatial organization of society in India. Tigers have become extinct in some areas because of extrinsic factors such as habitat destruction, poaching, disease, floods, fires and drought, decline of prey species for the same reasons, as well as intrinsic factors such as demographic stochasticity and genetic deterioration.\n\nRecognizing the conservation reliance of tigers, Project Tiger is establishing a national science-based framework for monitoring tiger population trends in order to manage the species more effectively. India now has 28 tiger reserves, located in 17 states. These reserves cover including 1.14% of the total land area of the country. These reserves are kept free of biotic disturbances, forestry operations, collection of minor forest products, grazing and human disturbance. The populations of tigers in these reserves now constitute some of the most important tiger source populations in the country.\n\nThe magnitude and pace of human impacts on the environment make it unlikely that substantial progress will be made in delisting many species unless the definition of \"recovery\" includes some form of active management. Preventing delisted species from again being at risk of extinction may require continuing, species-specific management actions. Viewing \"recovery\" of \"conservation-reliant species\" as a continuum of phases rather a simple \"recovered/not recovered\" status may enhance the ability to manage such species within the framework of the Endangered Species Act. With ongoing loss of habitat, disruption of natural cycles, increasing impacts of non-native invasive species, it is probable that the number of conservation-reliant species will increase.\n\nIt has been proposed that development of \"recovery management agreements\", with legally and biologically defensible contracts would provide for continuing conservation management following delisting. The use of such formalized agreements will facilitate shared management responsibilities between federal wildlife agencies and other federal agencies, and with state, local, and tribal governments, as well as with private entities that have demonstrated the capability to meet the needs of conservation-reliant species.\n", "id": "21650435", "title": "Conservation-reliant species"}
{"url": "https://en.wikipedia.org/wiki?curid=47150296", "text": "Aquatic Conservation: Marine and Freshwater Ecosystems\n\nAquatic Conservation: Marine and Freshwater Ecosystems is a bimonthly peer-reviewed scientific journal published by Wiley-Blackwell. The journal is dedicated to publishing original papers that relate specifically to freshwater, brackish or marine habitats and encouraging work that spans these ecosystems. According to the \"Journal Citation Reports\", the journal has a 2014 impact factor of 2.136.\n", "id": "47150296", "title": "Aquatic Conservation: Marine and Freshwater Ecosystems"}
{"url": "https://en.wikipedia.org/wiki?curid=1079955", "text": "WildCRU\n\nThe Wildlife Conservation Research Unit (WildCRU) is part of the Department of Zoology at the University of Oxford in England. Its mission is to achieve practical solutions to conservation problems through original scientific research, training conservation scientists to conduct research, putting scientific knowledge into practice, and educating and involving the public to achieve lasting solutions.\n\nThe Unit was founded in 1986 by Professor David W. Macdonald. Members come from more than 30 countries and many have returned to hold influential roles in conservation. WildCRU research has been used to advise policy-makers worldwide. More than 300 scientific papers and 25 reports have been published, over a hundred fruitful collaborations have been fostered, and over 45 students have completed doctoral theses.\n\nWildCRU projects use all four elements of their Conservation Quartet: research to understand the problem, education to explain it, community involvement to ensure participation and acceptance, and implementation of a solution. The approach is interdisciplinary, linking to public health, community development and animal welfare. In a new initiative concerning ‘biodiversity and business’, WildCRU is working directly to influence policy making processes in industry.\n\nCurrent project areas include saving endangered species, resolving conflict, reconciling farming and wildlife, researching fundamental ecology, and managing wildlife diseases, pests and invasive species.\n\nSpecific projects include protecting the Ethiopian wolf, Grevy's zebra and endemic birds in the Galapagos Islands, finding solutions to bushmeat exploitation in West Africa, community conservation education in Africa, sustainable farming, badger ecology and behavior, and the impact of American mink on native wildlife in Britain, Belarus, and Argentina.\n\nWildCRU is located in Tubney House, Abingdon Road, Tubney, Oxfordshire.\n\n\n", "id": "1079955", "title": "WildCRU"}
{"url": "https://en.wikipedia.org/wiki?curid=37514462", "text": "David Philipp\n\nDavid P. Philipp is an American-born biologist known for his work on conservation genetics, reproductive ecology, and the effects of angling on fish populations. He is a conservation geneticist and Director of the Fisheries Genetics Lab at the Illinois Natural History Survey, an Adjunct Professor at the University of Illinois, and the Chair of the Fisheries Conservation Foundation. Philipp has supervised a number of graduate students including Steven J. Cooke, Cory Suski, Derek Aday, Jeff Koppelman, Jana Svec, Jimmy Ludden, Dale Burkett, Sascha Danylchuk and Jeff Stein.\n\nPhilipp's research examines genetics, reproduction, and spatial ecology of fishes, and the effects of fisheries interactions on these dynamics in North America and the Caribbean. His early research examined centrarchid population genetics, gene expression, reproductive physiology, and strategies, heritability of fish behaviour, and life history strategies.\n\nMore recently, Philipp’s research has focused on the effects of fisheries interactions and environmental stressors on reproductive success, physiology, behavior, and survival of fishes.\n\nPhilipp's research revealed that populations of largemouth bass, \"Micropterus salmoides\", in most of North America composite a separate species from the Florida bass, \"M. floridanus\", in Florida, and that stocking programs introducing Florida bass outside their native range have detrimental genetic effects on largemouth bass populations. Another research program showed that angling targets individual largemouth bass with certain behavioural and physiological characteristics, and in the process can cause evolutionary change in populations including reduced parental care and reproductive success, as well as reduced angling success rates. Philipps is also involved with research programs in The Bahamas examining spatial ecology and the effects of fisheries interactions on bonefish.\n\nPhilipp is a co-founder and Chair of the Fisheries Conservation Foundation, a nonprofit organization founded in 2003 to promote the work of aquatic scientists, environmental professionals, and resource managers to policy makers and the public to ensure the sustainability of freshwater and marine ecosystems through well-informed management practices. Specific campaigns include: Flats Conservation, Rivers of Success, Shark Conservation, Coastal 2100, North American Black Bass Coalition, and Responsible Angling, which promote awareness and conservation for a wide range of environmentally and economically important fish species and habitats. The Foundation is also highly involved with conservation initiatives in The Bahamas, with projects including the Bahamas Flats Fishing Alliance that aims to assemble multiple stakeholders to promote the conservation of valuable flats fisheries, and The Island School Poster Series, which engages high school students in important current environmental issues.\n\nPhilipp, D. P. & Ridgway, M. S. (editors). Black Bass: Ecology, Conservation, and Management. American Fisheries Society. 740 pp. (2003).\n\nCooke, S. J. & Philipp, D. P. (editors). Centrarchid fishes: Diversity, Biology, and Conservation. John Wiley & Sons. 560 pp. (2009).\n\nParkos, J. J., Wahl. D. H., & Philipp, D. P. Influence of behavior and mating success on brood-specific contribution to fish recruitment. Ecological Applications 21, 2576–2586 (2011).\n\nBrooks, E. J., et al. The physiological response of the Caribbean reef shark (Carcharhinus perezi) to longline capture. Comparative Biochemistry and Physiology Part A, 159, 1–6 (2011)\n\nBarthel, B. L. et al. Genetic relationships among populations of Florida bass. Transactions of the American Fisheries Society 139, 1615–1641 (2010). \nPhilipp, D. P. et al. Selection for vulnerability to angling in largemouth bass. Trans. Am. Fish. Soc. 138, 189–199 (2009).\n\nCooke, S. J., Suski, C. D., Ostrand, K. G., Wahl, D. H. & Philipp, D. P. Physiological and behavioral consequences of long-term artificial selection for vulnerability to recreational angling in a teleost fish. Physiological and Biochemical Zoology 80, 480–490 (2007).\n\nCooke, S. J. & Philipp, D. P. Behavior and mortality of caught-and-released bonefish (Albula spp.) in Bahamian waters with implications for a sustainable recreational fishery. Biol. Conserv. 118, 599–607 (2004).\n\n1997 Jennings, M. J., Claussen, J. E., & Philipp, D. P. Effect of population size structure on reproductive investment of male bluegill. N. Am. J. Fish. Manage 17, 516–524 (1997).\n\nPhilipp, D. P., Toline, C. A., Philipp, D. B. F., & Phelan, F.P. The impact of catch-and-release angling on the reproductive success of smallmouth bass and largemouth bass. N. Am. J. Fish. Manage. 17, 557–567 (1997).\n\nPhilipp, D. P. Genetic implications of introducing Florida largemouth bass. Can. J. Fish Aq. Sci. 48, 58–65 (1991).\n\nPhilipp, D. P., Childers, W. F. & Whitt, G. S. A biochemical genetic evaluation of the northern and Florida subspecies of largemouth bass. Trans. Am. Fish. Soc. 112, 1–20 (1983).\n", "id": "37514462", "title": "David Philipp"}
{"url": "https://en.wikipedia.org/wiki?curid=48594435", "text": "Dark diversity\n\nDark diversity is the set of species that are absent from a study site but present in the surrounding region and potentially able to inhabit particular ecological conditions.\n\nDark diversity is part of the species pool concept. A species pool is defined as set of all species that able to inhabit particular site and that are present in the surrounding region or landscape. Dark diversity comprises species that belong to a particular species pool but that are not currently present at a site. Dark diversity is related to \"habitat-specific\" or \"filtered\" species pool which only includes species that can both disperse to and potentially inhabit the study site. For example, if fish diversity in a coral reef site has been sampled, dark diversity includes all fish species from the surrounding region that are currently absent but can potentially disperse to and colonize the study site.\n\nDark diversity name is borrowed from dark matter: matter which cannot be seen and directly measured, but its existence and properties are inferred from its gravitational effects on visible matter. Similarly, dark diversity cannot be seen directly when only the sample is observed, but it is present if broader scale is considered, and its existence and properties can be estimated when proper data is available. With dark matter we can better understand distribution and dynamics of galaxies, with dark diversity we can understand composition and dynamics of ecological communities.\n\nDark diversity is the counterpart of observed diversity (alpha diversity) present in a sample. Dark diversity is habitat-specific in respect that the study site must contain favorable ecological conditions for species belonging to dark diversity. The habitat concept can be narrower (e.g. microhabitat in an old-growth forest) or broader (e.g. terrestrial habitat). Thus, habitat specificity does not mean that all species in dark diversity can inhabit all localities within study sample, but there must be ecologically suitable parts.\n\nHabitat-specificity is making the distinction between dark diversity and beta diversity. If beta diversity is the association between alpha and gamma diversity, dark diversity connects alpha diversity and habitat-specific (filtered) species pool. Habitat-specific species pool only these which can potentially inhabit focal study site.\nObserved diversity can be studied at any scale, and sites with varying heterogeneity. This is also true for dark diversity. Consequently, as local observed diversity can be linked to very different sample sizes, dark diversity can be applied at any study scale (1x1 m sample in a vegetation, bird count transect in a landscape, 50x50 km UTM grid cell).\n\nRegion size determines likelihood of dispersal to study site and selecting appropriate scale depends on research question. For a more general study, a scale comparable to biogeographic region can be used (e.g. a small country, a state, or radius of few hundred km). If we want to know which species potentially can inhabit study site in the near future (for example 10 years), landscape scale is appropriate.\n\nTo separate ecologically suitable species, different methods can be used. Environmental niche modelling can be applied for a large number of species. Expert opinion can be used. Data on species' habitat preferences is available in books, e.g. bird nesting habitats. This can also be quantitative, for example plant species indicator values, according to Ellenberg. A recently developed method estimates dark diversity from species co-occurrence matrices. An online tool is available for the co-occurrence method.\n\nDark diversity allows meaningful comparisons of biodiversity. The community completeness index can be used: log(observed diversity / dark diversity). This express the local diversity at the relative scale, filtering out the effect of regional species pool. For example, if completeness of plant diversity was studied at the European scale, it did not exhibit the latitudinal pattern seen with observed richness and species pool values. Instead, high completeness was characteristic to regions with lower human impact, indicating that anthropogenic factors are among the most important local scale biodiversity determinants in Europe.\n\nDark diversity studies can be combined with functional ecology to understand why species pool is poorly realized in a locality. For example, if functional traits were compared between grassland species in observed diversity and dark diversity, it become evident, that dark diversity species have in general poorer dispersal abilities.\n\nDark diversity can be useful in prioritizing nature conservation, to identify in different regions most complete sites. Dark diversity helps to estimate the relative loss of local diversity, but also restoration progress. Dark diversity of alien species, weeds and pathogens can be useful to prepare for future invasions in time.\n\nRecently, dark diversity concept was used in to explain mechanisms behind plant diversity-productivity relationship.\n\n", "id": "48594435", "title": "Dark diversity"}
{"url": "https://en.wikipedia.org/wiki?curid=477117", "text": "Species reintroduction\n\nSpecies reintroduction is the deliberate release of a species into the wild, from captivity or other areas where the organism survives. The goal of species reintroduction is to establish a healthy, genetically diverse, self-sustaining population to an area where it has been extirpated, or to augment an existing population. A species that needs reintroduction is usually one whose existence has become threatened or endangered in the wild. However, reintroduction of a species can also be for pest control. For example, wolves being reintroduced to a wild area because of an overpopulation of elk or deer. Because reintroduction may involve returning native species to localities where they had been extirpated, some prefer the term \"reestablishment\".\n\nHumans have been reintroducing species for food and pest control for thousands of years. However, the practice of reintroducing for conservation is much younger, starting in the 20th century.\n\nThere are a variety of approaches to species reintroduction. The optimal strategy will depend on the biology of the organism. The first matter to address in choosing a method is sourcing individuals \"in situ\", wild populations, or \"ex situ\", such as a zoo or botanic garden.\n\n\"In situ\" sourcing for restorations involves removing individuals from an existing wild population and moving them to the new site where they were formerly extirpated. Ideally, populations should be sourced from \"in situ\" when possible as there are numerous risks with reintroducing organisms in the wild from captive population. In order to ensure that the reintroduced populations have the best chance of surviving, the population the individuals are collected from should closely resemble the extirpated population genetically and ecologically. Generally, sourcing from nearby populations with similar habitat to the reintroduction site will maximize the chance that reintroduced individuals will be similar to the original population.\n\nOne consideration for \"in situ\" sourcing is at which life stage the organisms should be collected, transported, and reintroduced. For instance, with plants, it is often ideal to transport them as seeds as they have the best chance of surviving translocation at this stage. Some plants are difficult to establish as seed however and may need to be translocated as juveniles or adults.\n\nIn situations where \"in situ\" collection of individuals is not feasible, for instance too few individuals exist in the wild, \"ex situ\" collections may be used. There are a number of types of \"ex situ\" collections. \nGermplasm may be stored in the form of seed banks, sperm and egg banks, cryopreservation, and tissue culture. These method allows the storage of many individuals and have high potential for reintroduction. Since this method allows for storage of a high number of individuals, it maximizes genetic diversity. Once collected, the material can last for relatively long periods in storage.However some species lose viability when stored as seed. However tissue culture and cryopreservation techniques have only been perfected for a few species.\nOrganisms may also be kept in living collections. Living collections are more costly than storing germplasm and hence can support only a fraction of the individuals that \"ex situ\" sourcing can. When sourcing for living collections, the risks increase. There are fewer individuals so loss of genetic diversity becomes a concern. The individuals may also become adapted to captivity so efforts should be made to replicate wild conditions and time spent in captivity should be minimized whenever possible.\n\nReintroduction biology is a relatively young discipline and continues to be a work in progress. There is still no general and broadly accepted definition of reintroduction success, it has been proposed that the criteria widely used to assess the conservation status of endangered taxa, such as the IUCN Red List criteria, should be used to assess reintroduction success. Successful reintroduction programs should yield viable and self-sustainable populations in the long-term. The IUCN/SSC Re-introduction Specialist Group & Environment Agency, in their 2011 Global Re-introduction Perspectives, compiled reintroduction case studies from around the world. 184 case studies were reported on a range of species which included invertebrates, fish, amphibians, reptiles, birds, mammals, and plants. Assessments from all of the studies included goals, success indicators, project summary, major difficulties faced, major lessons learned, and success of project with reasons for success or failure. A similar assessment focused solely on plants found high rates of success for rare species reintroductions. An analysis of data from the Center for Plant Conservation International Reintroduction Registry found that, for the 49 cases where data were available, 92% of the reintroduced plant populations survived two years.\nThe Siberian tiger population has rebounded from 40 individuals in the 1940s to around 500 in 2007. The Siberian tiger population is now the largest un-fragmented tiger population in the world. Yet, a high proportion of translocations and reintroductions have not been successful in establishing viable populations\nFor instance, in China reintroduction of captive Giant Pandas have had mixed effects. The initial pandas released from captivity all died quickly after reintroduction. Even now that they have improved their ability to reintroduce pandas, concern remains over how well they captive bred pandas will fare with their wild relatives.\n\nMany factors can attribute to the success or failure of a reintroduction. Predators, food, pathogens, competitors, and weather can all affect a reintroduced population's ability to grow, survive, and reproduce. Animals raised in captivity may experience stress during captivity or translocation, which can weaken their immune systems.\nThe IUCN reintroduction guidelines emphasize the need for an assessment of the availability of suitable habitat as a key component of reintroduction planning. Poor assessment of the release site can increase the chances that the species will reject the site and perhaps move to a less suitable environment. This can decrease the species fitness and thus decrease chances for survival. They state that restoration of the original habitat and amelioration of causes of extinction must be explored and considered as essential conditions for these projects. Unfortunately, the monitoring period that should follow reintroductions often remains neglected.\n\nWhen a species has been extirpated from a site where it previously existed, individuals for the reintroduced population must be sourced from elsewhere. When sourcing for reintroductions, it is important to consider local adaptation, adaptation to captivity (for \"ex situ\" conservation), the possibility of inbreeding depression and outbreeding depression, and the genetic diversity of the source population.\n\nIf plants or animals are moved from one part of their range to another, they may not be sufficiently adapted to local environmental conditions, and may suffer from reduced fitness as a result. This issue is further complicated by projected climatic shifts induced by climate change, and has led to the development of new seed sourcing protocols for plants that attempt to predict future changes in climatic conditions, and select plants best adapted to those conditions. Historically, sourcing plant material for reintroductions has followed the rule \"local is best,\" as the best way to preserve local adaptations, with individuals for reintroductions selected from the most geographically proximate population. To that end, conservation agencies have developed seed transfer zones that serve as guidelines for how far plant material can be transported before it will perform poorly. Seed transfer zones take into account proximity, ecological conditions, and climatic conditions in order to predict how plant performance will vary from one zone to the next. A study of the reintroduction of \"Castilleja levisecta\" found that the source populations most physically near the reintroduction site performed the poorest in a field experiment, while those from the source population whose ecological conditions most closely matched the reintroduction site performed best, demonstrating the importance of matching the evolved adaptations of a population to the conditions at the reintroduction site.\n\nSome reintroduction programs use plants or animals from captive populations to form a reintroduced population. When reintroducing individuals from a captive population to the wild, there is a risk that they have adapted to captivity. Animals can adapt to captivity by showing reduced stress tolerance, increased tameness, and loss of local adaptations. Plants also can show adaptations to captivity through changes in drought tolerance, nutrient requirements, and seed dormancy requirements. Such adaptations can lead to reduced fitness following reintroduction, and can be minimized during captivity by maximizing the number of new individuals added to captive populations, maximizing generation length, and minimizing selection pressure, number of generations, heritability, and the size of the captive population. For plants, minimizing adaptation to captivity is usually achieved by sourcing plant material from a seed bank, where individuals are preserved as wild-collected seeds, and have not had the chance to adapt to conditions in captivity.\n\nIf the species slated for reintroduction is rare in the wild, it is likely to have unusually low population numbers, and care should be taken to avoid inbreeding and inbreeding depression. Inbreeding can change the frequency of allele distribution in a population, and potentially result in a change to crucial genetic diversity. Additionally, outbreeding depression can occur if a reintroduced population can hybridize with existing populations in the wild, which can result in offspring with reduced fitness, and less adaptation to local conditions. To minimize both, practitioners should source for individuals in a way that captures as much genetic diversity as possible, and attempt to match source site conditions to local site conditions as much as possible.\n\nCapturing as much genetic diversity as possible, measured as heterozygosity, is a good rule of thumb to follow in species reintroductions. Some protocols suggest that sourcing approximately 30 individuals from a population will capture 95% of the genetic diversity. Maintaining that genetic diversity throughout the reintroduction process is crucial to avoiding the loss of essential local adaptations and maximizing fitness of the reintroduced population.\n\nA cooperative approach to reintroduction by ecologists and biologists could improve research techniques. For both preparation and monitoring of reintroductions, increasing contacts between academic population biologists and wildlife managers is encouraged within the Survival Species Commission and the IUCN. The IUCN states that a re-introduction requires a multidisciplinary approach involving a team of persons drawn from a variety of backgrounds. A survey by Wolf et al. in 1998 indicated that 64% of reintroduction projects have used subjective opinion to assess habitat quality. This means that most reintroduction evaluation has been based on human anecdotal evidence and not enough has been based on statistical findings. Seddon et al. (2007) suggest that researchers contemplating future reintroductions should specify goals, overall ecological purpose, and inherent technical and biological limitations of a given reintroduction, and planning and evaluation processes should incorporate both experimental and modeling approaches.\n\nMonitoring the health of individuals, as well as the survival, is important; both before and after the reintroduction. Intervention may be necessary if the situation proves unfavorable. Population dynamics models that integrate demographic parameters and behavioral data recorded in the field can lead to simulations and tests of a priori hypotheses. Using previous results to design further decisions and experiments is a central concept of adaptive management. In other words, learning by doing can help in future projects. Population ecologists should therefore collaborate with biologists, ecologists, and wildlife management to improve reintroduction programs.\n\nIt may be very hard to reintroduce species into the wild, even if their natural habitats were restored. Survival techniques, which are normally passed from parents to offspring during parenting, are lost. The genetics of the species is saved, but the natural memetics of the species is not.\n\nBeginning in the 1980s, biologists have learned that many mammals and birds need to learn new behaviors survive in the wild. Thus, reintroduction programmes have to be planned carefully, ensuring that the animals have the necessary survival skills. Biologists must also study the animals after the reintroduction to learn whether the animals are surviving and breeding, what effects the reintroduction has on the ecosystem, and how to improve the process.\n\nStill, a vast number of animals may need to be reintroduced into the wild to be sure that enough of them learn how to survive. For instance, in reintroducing houbara bustards into the wild in the United Arab Emirates, more than 5,000 birds per year are used.\n\nThe RSG is a network of specialists whose aim is to combat the ongoing and massive loss of biodiversity by using re-introductions as a responsible tool for the management and restoration of biodiversity. It does this by actively developing and promoting sound inter-disciplinary scientific information, policy, and practice to establish viable wild populations in their natural habitats.\nThe role of the RSG is to promote the re-establishment of viable populations in the wild of animals and plants. The need for this role was felt due to the increased demand from re-introduction practitioners, the global conservation community and increase in re-introduction projects worldwide.\n\nIncreasing numbers of animal and plant species are becoming rare, or even extinct in the wild. In an attempt to re-establish populations, species can – in some instances – be re-introduced into an area, either through translocation from existing wild populations, or by re-introducing captive-bred animals or artificially propagated plants.\n\n\n\n\n\n\n\n\n\n\n\n\n", "id": "477117", "title": "Species reintroduction"}
{"url": "https://en.wikipedia.org/wiki?curid=40251056", "text": "North American Invasive Species Network\n\nThe North American Invasive Species Network (NAISN) is an American non-profit organization formed in 2010 by a group of government scientists and universities in North America. The network integrates various invasive species institutes, centers, laboratories and networks from the US, Canada and Mexico to help meet the needs of public conservation land and waterway resource managers. \nMembership is targeted toward regional centers and institutes, research labs, and/or other groups and individuals with invasive species interests and qualification. Because invasive species are not restricted by jurisdictional boundary lines, it was formed as a single international network. Currently there are eight invasive species organizations in collaboration with NAISN.\n\nIn 1997, a letter o-written by Don C. Schmitz, Dr. James T. Carlton, Dr. Daniel Simberloff, and Dr. Phyllis N. Windle, and signed by more than 500 scientists, resource and agriculture officials, urged the U.S. government to form a commission to recommend new strategies to prevent and manage invasive species. One of the its recommendations was to form a center analogous to the Centers for Disease Control and Prevention (CDC) to help coordinate the multi-jurisdictional aspects of invasive species management in the U.S. The letter resulted in Executive Order 13112 on February 3, 1999, calling for the establishment of a national plan and creating the National Invasive Species Council.\nAs a result of a November 2010 workshop, led by Don C. Schmitz and Dan Simberloff, seven invasive species centers or institutes and one federally funded Canadian research network agreed to become part of the North American Invasive Species Network (NAISN). Since then, NAISN has added another Canadian member\n\nIn 2013, eight invasive species centers and institutes, and one regional network, are part of the North American Invasive Species Network (NAISN) either as a hub (1) or a node (2). \n\nIn 2011, NAISN was established as a non-profit organization in the United States (501(C)3) to unify and connect these existing invasive species efforts into a single network, . Participating member organizations, groups, or individuals can participate as Hubs1, Nodes2, or Affiliates3.\n\nIn April 2012, the third NAISN workshop was held to develop a five-year business strategic plan It is envisioned that, as NAISN grows and expands, the Network will work to enhance information exchange among scientists, government agencies, and private landowners through the use of a comprehensive website modeled after the Centers for Disease Control and Prevention (CDC) website, and the aggregation of information from over 250 current databases that contain information of invasive species . NAISN will also begin to track invasive species expenditures through annual surveys of federal, provincial, state, municipal and tribal governments and oversee a comprehensive analysis of economic impacts of invasive species; such information could readily be used by policy-makers and elected officials. Finally, NAISN will provide a single source for the news media and develop and implement national public awareness campaigns about invasive species.\n\n\n", "id": "40251056", "title": "North American Invasive Species Network"}
{"url": "https://en.wikipedia.org/wiki?curid=45086", "text": "Biodiversity\n\nBiodiversity, a portmanteau of \"bio\" (life) and \"diversity\", generally refers to the variety and variability of life on Earth. According to the United Nations Environment Programme (UNEP), biodiversity typically measures variation at the genetic, the species, and the ecosystem level. Terrestrial biodiversity tends to be greater near the equator, which seems to be the result of the warm climate and high primary productivity. Biodiversity is not distributed evenly on Earth, and is richest in the tropics. These tropical forest ecosystems cover less than 10 percent of earth's surface, and contain about 90 percent of the world's species. Marine biodiversity tends to be highest along coasts in the Western Pacific, where sea surface temperature is highest and in the mid-latitudinal band in all oceans. There are latitudinal gradients in species diversity. Biodiversity generally tends to cluster in hotspots, and has been increasing through time, but will be likely to slow in the future.\n\nRapid environmental changes typically cause mass extinctions. More than 99.9 percent of all species that ever lived on Earth, amounting to over five billion species, are estimated to be extinct. Estimates on the number of Earth's current species range from 10 million to 14 million, of which about 1.2 million have been documented and over 86 percent have not yet been described. More recently, in May 2016, scientists reported that 1 trillion species are estimated to be on Earth currently with only one-thousandth of one percent described. The total amount of related DNA base pairs on Earth is estimated at 5.0 x 10 and weighs 50 billion tonnes. In comparison, the total mass of the biosphere has been estimated to be as much as 4 TtC (trillion tons of carbon). In July 2016, scientists reported identifying a set of 355 genes from the Last Universal Common Ancestor (LUCA) of all organisms living on Earth.\n\nThe age of the Earth is about 4.54 billion years. The earliest undisputed evidence of life on Earth dates at least from 3.5 billion years ago, during the Eoarchean Era after a geological crust started to solidify following the earlier molten Hadean Eon. There are microbial mat fossils found in 3.48 billion-year-old sandstone discovered in Western Australia. Other early physical evidence of a biogenic substance is graphite in 3.7 billion-year-old meta-sedimentary rocks discovered in Western Greenland. More recently, in 2015, \"remains of biotic life\" were found in 4.1 billion-year-old rocks in Western Australia. According to one of the researchers, \"If life arose relatively quickly on Earth .. then it could be common in the universe.\"\n\nSince life began on Earth, five major mass extinctions and several minor events have led to large and sudden drops in biodiversity. The Phanerozoic eon (the last 540 million years) marked a rapid growth in biodiversity via the Cambrian explosion—a period during which the majority of multicellular phyla first appeared. The next 400 million years included repeated, massive biodiversity losses classified as mass extinction events. In the Carboniferous, rainforest collapse led to a great loss of plant and animal life. The Permian–Triassic extinction event, 251 million years ago, was the worst; vertebrate recovery took 30 million years. The most recent, the Cretaceous–Paleogene extinction event, occurred 65 million years ago and has often attracted more attention than others because it resulted in the extinction of the dinosaurs.\n\nThe period since the emergence of humans has displayed an ongoing biodiversity reduction and an accompanying loss of genetic diversity. Named the Holocene extinction, the reduction is caused primarily by human impacts, particularly habitat destruction. Conversely, biodiversity positively impacts human health in a number of ways, although a few negative effects are studied.\n\nThe United Nations designated 2011–2020 as the United Nations Decade on Biodiversity.\n\nThe term biological diversity was used first by wildlife scientist and conservationist Raymond F. Dasmann in the year 1968 lay book \"A Different Kind of Country\" advocating conservation. The term was widely adopted only after more than a decade, when in the 1980s it came into common usage in science and environmental policy. Thomas Lovejoy, in the foreword to the book \"Conservation Biology\", introduced the term to the scientific community. Until then the term \"natural diversity\" was common, introduced by The Science Division of The Nature Conservancy in an important 1975 study, \"The Preservation of Natural Diversity.\" By the early 1980s TNC's Science program and its head, Robert E. Jenkins, Lovejoy and other leading conservation scientists at the time in America advocated the use of the term \"biological diversity\".\n\nThe term's contracted form \"biodiversity\" may have been coined by W.G. Rosen in 1985 while planning the 1986 \"National Forum on Biological Diversity\" organized by the National Research Council (NRC). It first appeared in a publication in 1988 when sociobiologist E. O. Wilson used it as the title of the proceedings of that forum.\n\nSince this period the term has achieved widespread use among biologists, environmentalists, political leaders and concerned citizens.\n\nA similar term in the United States is \"\"natural heritage.\"\" It pre-dates the others and is more accepted by the wider audience interested in conservation. Broader than biodiversity, it includes geology and landforms.\n\n\"Biodiversity\" is most commonly used to replace the more clearly defined and long established terms, species diversity and species richness. Biologists most often define biodiversity as the \"totality of genes, species and ecosystems of a region\". An advantage of this definition is that it seems to describe most circumstances and presents a unified view of the traditional types of biological variety previously identified:\n\n\nThis multilevel construct is consistent with Datman and Lovejoy. An explicit definition consistent with this interpretation was first given in a paper by Bruce A. Wilcox commissioned by the International Union for the Conservation of Nature and Natural Resources (IUCN) for the 1982 World National Parks Conference. Wilcox's definition was \"Biological diversity is the variety of life forms...at all levels of biological systems (i.e., molecular, organismic, population, species and ecosystem)...\".\nThe 1992 United Nations Earth Summit defined \"biological diversity\" as \"the variability among living organisms from all sources, including, 'inter alia', terrestrial, marine and other aquatic ecosystems and the ecological complexes of which they are part: this includes diversity within species, between species and of ecosystems\". This definition is used in the United Nations Convention on Biological Diversity.\n\nOne textbook's definition is \"variation of life at all levels of biological organization\".\n\nBiodiversity can be defined genetically as the diversity of alleles, genes and organisms. They study processes such as mutation and gene transfer that drive evolution.\n\nMeasuring diversity at one level in a group of organisms may not precisely correspond to diversity at other levels. However, tetrapod (terrestrial vertebrates) taxonomic and ecological diversity shows a very close correlation.\n\nBiodiversity is not evenly distributed, rather it varies greatly across the globe as well as within regions. Among other factors, the diversity of all living things (biota) depends on temperature, precipitation, altitude, soils, geography and the presence of other species. The study of the spatial distribution of organisms, species and ecosystems, is the science of biogeography.\n\nDiversity consistently measures higher in the tropics and in other localized regions such as the Cape Floristic Region and lower in polar regions generally. Rain forests that have had wet climates for a long time, such as Yasuní National Park in Ecuador, have particularly high biodiversity.\n\nTerrestrial biodiversity is thought to be up to 25 times greater than ocean biodiversity. A recently discovered method put the total number of species on Earth at 8.7 million, of which 2.1 million were estimated to live in the ocean. However, this estimate seems to under-represent the diversity of microorganisms.\n\nGenerally, there is an increase in biodiversity from the poles to the tropics. Thus localities at lower latitudes have more species than localities at higher latitudes. This is often referred to as the latitudinal gradient in species diversity. Several ecological mechanisms may contribute to the gradient, but the ultimate factor behind many of them is the greater mean temperature at the equator compared to that of the poles.\n\nEven though terrestrial biodiversity declines from the equator to the poles, some studies claim that this characteristic is unverified in aquatic ecosystems, especially in marine ecosystems. The latitudinal distribution of parasites does not appear to follow this rule.\n\nIn 2016, an alternative hypothesis (\"the fractal biodiversity\") was proposed to explain the biodiversity latitudinal gradient . In this study, the species pool size and the fractal nature of ecosystems were combined to clarify some general patterns of this gradient. This hypothesis considers temperature, moisture, and net primary production (NPP) as the main variables of an ecosystem niche and as the axis of the ecological hypervolume. In this way, it is possible to build fractal hypervolumes, whose fractal dimension rises up to three moving towards the equator.\n\nA biodiversity hotspot is a region with a high level of endemic species that has experienced great habitat loss. The term hotspot was introduced in 1988 by Norman Myers. While hotspots are spread all over the world, the majority are forest areas and most are located in the tropics.\n\nBrazil's Atlantic Forest is considered one such hotspot, containing roughly 20,000 plant species, 1,350 vertebrates and millions of insects, about half of which occur nowhere else. The island of Madagascar and India are also particularly notable. Colombia is characterized by high biodiversity, with the highest rate of species by area unit worldwide and it has the largest number of endemics (species that are not found naturally anywhere else) of any country. About 10% of the species of the Earth can be found in Colombia, including over 1,900 species of bird, more than in Europe and North America combined, Colombia has 10% of the world's mammals species, 14% of the amphibian species and 18% of the bird species of the world. Madagascar dry deciduous forests and lowland rainforests possess a high ratio of endemism. Since the island separated from mainland Africa 66 million years ago, many species and ecosystems have evolved independently. Indonesia's 17,000 islands cover and contain 10% of the world's flowering plants, 12% of mammals and 17% of reptiles, amphibians and birds—along with nearly 240 million people. Many regions of high biodiversity and/or endemism arise from specialized habitats which require unusual adaptations, for example, alpine environments in high mountains, or Northern European peat bogs.\n\nAccurately measuring differences in biodiversity can be difficult. Selection bias amongst researchers may contribute to biased empirical research for modern estimates of biodiversity. In 1768, Rev. Gilbert White succinctly observed of his Selborne, Hampshire \"\"all nature is so full, that that district produces the most variety which is the most examined.\"\"\n\nBiodiversity is the result of 3.5 billion years of evolution. The origin of life has not been definitely established by science, however some evidence suggests that life may already have been well-established only a few hundred million years after the formation of the Earth. Until approximately 600 million years ago, all life consisted of microorganisms – archaea, bacteria, and single-celled protozoans and protists.\n\nThe history of biodiversity during the Phanerozoic (the last 540 million years), starts with rapid growth during the Cambrian explosion—a period during which nearly every phylum of multicellular organisms first appeared. Over the next 400 million years or so, invertebrate diversity showed little overall trend and vertebrate diversity shows an overall exponential trend. This dramatic rise in diversity was marked by periodic, massive losses of diversity classified as mass extinction events. A significant loss occurred when rainforests collapsed in the carboniferous. The worst was the Permian-Triassic extinction event, 251 million years ago. Vertebrates took 30 million years to recover from this event.\n\nThe fossil record suggests that the last few million years featured the greatest biodiversity in history. However, not all scientists support this view, since there is uncertainty as to how strongly the fossil record is biased by the greater availability and preservation of recent geologic sections. Some scientists believe that corrected for sampling artifacts, modern biodiversity may not be much different from biodiversity 300 million years ago., whereas others consider the fossil record reasonably reflective of the diversification of life. Estimates of the present global macroscopic species diversity vary from 2 million to 100 million, with a best estimate of somewhere near 9 million, the vast majority arthropods. Diversity appears to increase continually in the absence of natural selection.\n\nThe existence of a \"global carrying capacity\", limiting the amount of life that can live at once, is debated, as is the question of whether such a limit would also cap the number of species. While records of life in the sea shows a logistic pattern of growth, life on land (insects, plants and tetrapods)shows an exponential rise in diversity. As one author states, \"Tetrapods have not yet invaded 64 per cent of potentially habitable modes and it could be that without human influence the ecological and taxonomic diversity of tetrapods would continue to increase in an exponential fashion until most or all of the available ecospace is filled.\"\n\nIt also appears that the diversity continue to increase over time, especially after mass extinctions.\n\nOn the other hand, changes through the Phanerozoic correlate much better with the hyperbolic model (widely used in population biology, demography and macrosociology, as well as fossil biodiversity) than with exponential and logistic models. The latter models imply that changes in diversity are guided by a first-order positive feedback (more ancestors, more descendants) and/or a negative feedback arising from resource limitation. Hyperbolic model implies a second-order positive feedback. The hyperbolic pattern of the world population growth arises from a second-order positive feedback between the population size and the rate of technological growth. The hyperbolic character of biodiversity growth can be similarly accounted for by a feedback between diversity and community structure complexity. The similarity between the curves of biodiversity and human population probably comes from the fact that both are derived from the interference of the hyperbolic trend with cyclical and stochastic dynamics.\n\nMost biologists agree however that the period since human emergence is part of a new mass extinction, named the Holocene extinction event, caused primarily by the impact humans are having on the environment. It has been argued that the present rate of extinction is sufficient to eliminate most species on the planet Earth within 100 years.\n\nWith the \"Biodiversity-related Niches Differentiation Theory\", Roberto Cazzolla Gatti recently proposed that species themselves are the architects of biodiversity, by proportionally increasing the number of potentially available niches in a given ecosystem. This study led to the idea that biodiversity is autocatalytic. An ecosystem of interdependent species can be, therefore, considered as an emergent autocatalytic set (a self-sustaining network of mutually “catalytic” entities), where one (group of) species enables the existence of (i.e., creates niches for) other species. This view offers a possible answer to the fundamental question of why so many species can coexist in the same ecosystem.\n\nNew species are regularly discovered (on average between 5–10,000 new species each year, most of them insects) and many, though discovered, are not yet classified (estimates are that nearly 90% of all arthropods are not yet classified). Most of the terrestrial diversity is found in tropical forests and in general, land has more species than the ocean; some 8.7 million species may exists on Earth, of which some 2.1 million live in the ocean.\n\n\"Ecosystem services are the suite of benefits that ecosystems provide to humanity.\" The natural species, or biota, are the caretakers of all ecosystems. It is as if the natural world is an enormous bank account of capital assets capable of paying life sustaining dividends indefinitely, but only if the capital is maintained.\n\nThese services come in three flavors:\n\nThere have been many claims about biodiversity's effect on these ecosystem services, especially provisioning and regulating services. After an exhaustive survey through peer-reviewed literature to evaluate 36 different claims about biodiversity's effect on ecosystem services, 14 of those claims have been validated, 6 demonstrate mixed support or are unsupported, 3 are incorrect and 13 lack enough evidence to draw definitive conclusions.\n\n\n\n\n\n\n\n\n\nOther sources have reported somewhat conflicting results and in 1997 Robert Costanza and his colleagues reported the estimated global value of ecosystem services (not captured in traditional markets) at an average of $33 trillion annually.\n\nSince the stone age, species loss has accelerated above the average basal rate, driven by human activity. Estimates of species losses are at a rate 100-10,000 times as fast as is typical in the fossil record.\nBiodiversity also affords many non-material benefits including spiritual and aesthetic values, knowledge systems and education.\n\nAgricultural diversity can be divided into two categories: intraspecific diversity, which includes the genetic variety within a single species, like the potato (\"Solanum tuberosum\") that is composed of many different forms and types (e.g.: in the U.S. we might compare russet potatoes with new potatoes or purple potatoes, all different, but all part of the same species, \"S. tuberosum\").\n\nThe other category of agricultural diversity is called interspecific diversity and refers to the number and types of different species. Thinking about this diversity we might note that many small vegetable farmers grow many different crops like potatoes and also carrots, peppers, lettuce etc.\n\nAgricultural diversity can also be divided by whether it is ‘planned’ diversity or ‘associated’ diversity. This is a functional classification that we impose and not an intrinsic feature of life or diversity. Planned diversity includes the crops which a farmer has encouraged, planted or raised (e.g.: crops, covers, symbionts and livestock, among others), which can be contrasted with the associated diversity that arrives among the crops, uninvited (e.g.: herbivores, weed species and pathogens, among others).\n\nThe control of associated biodiversity is one of the great agricultural challenges that farmers face. On monoculture farms, the approach is generally to eradicate associated diversity using a suite of biologically destructive pesticides, mechanized tools and transgenic engineering techniques, then to rotate crops. Although some polyculture farmers use the same techniques, they also employ integrated pest management strategies as well as strategies that are more labor-intensive, but generally less dependent on capital, biotechnology and energy.\n\nInterspecific crop diversity is, in part, responsible for offering variety in what we eat. Intraspecific diversity, the variety of alleles within a single species, also offers us choice in our diets. If a crop fails in a monoculture, we rely on agricultural diversity to replant the land with something new. If a wheat crop is destroyed by a pest we may plant a hardier variety of wheat the next year, relying on intraspecific diversity. We may forgo wheat production in that area and plant a different species altogether, relying on interspecific diversity. Even an agricultural society which primarily grows monocultures, relies on biodiversity at some point.\n\nMonoculture was a contributing factor to several agricultural disasters, including the European wine industry collapse in the late 19th century and the US southern corn leaf blight epidemic of 1970.\n\nAlthough about 80 percent of humans' food supply comes from just 20 kinds of plants, humans use at least 40,000 species. Many people depend on these species for food, shelter and clothing. Earth's surviving biodiversity provides resources for increasing the range of food and other products suitable for human use, although the present extinction rate shrinks that potential.\n\nBiodiversity's relevance to human health is becoming an international political issue, as scientific evidence builds on the global health implications of biodiversity loss.\n\nThe growing demand and lack of drinkable water on the planet presents an additional challenge to the future of human health. Partly, the problem lies in the success of water suppliers to increase supplies and failure of groups promoting preservation of water resources. While the distribution of clean water increases, in some parts of the world it remains unequal. According to \"2008 World Population Data Sheet\", only 62% of least developed countries are able to access clean water.\n\nSome of the health issues influenced by biodiversity include dietary health and nutrition security, infectious disease, medical science and medicinal resources, social and psychological health. Biodiversity is also known to have an important role in reducing disaster risk and in post-disaster relief and recovery efforts.\n\nBiodiversity provides critical support for drug discovery and the availability of medicinal resources. A significant proportion of drugs are derived, directly or indirectly, from biological sources: at least 50% of the pharmaceutical compounds on the US market are derived from plants, animals and micro-organisms, while about 80% of the world population depends on medicines from nature (used in either modern or traditional medical practice) for primary healthcare. Only a tiny fraction of wild species has been investigated for medical potential. Biodiversity has been critical to advances throughout the field of bionics. Evidence from market analysis and biodiversity science indicates that the decline in output from the pharmaceutical sector since the mid-1980s can be attributed to a move away from natural product exploration (\"bioprospecting\") in favor of genomics and synthetic chemistry, indeed claims about the value of undiscovered pharmaceuticals may not provide enough incentive for companies in free markets to search for them because of the high cost of development; meanwhile, natural products have a long history of supporting significant economic and health innovation. Marine ecosystems are particularly important, although inappropriate bioprospecting can increase biodiversity loss, as well as violating the laws of the communities and states from which the resources are taken.\n\nMany industrial materials derive directly from biological sources. These include building materials, fibers, dyes, rubber and oil. Biodiversity is also important to the security of resources such as water, timber, paper, fiber and food. As a result, biodiversity loss is a significant risk factor in business development and a threat to long term economic sustainability.\n\nBiodiversity enriches leisure activities such as hiking, birdwatching or natural history study. Biodiversity inspires musicians, painters, sculptors, writers and other artists. Many cultures view themselves as an integral part of the natural world which requires them to respect other living organisms.\n\nPopular activities such as gardening, fishkeeping and specimen collecting strongly depend on biodiversity. The number of species involved in such pursuits is in the tens of thousands, though the majority do not enter commerce.\n\nThe relationships between the original natural areas of these often exotic animals and plants and commercial collectors, suppliers, breeders, propagators and those who promote their understanding and enjoyment are complex and poorly understood. The general public responds well to exposure to rare and unusual organisms, reflecting their inherent value.\n\nPhilosophically it could be argued that biodiversity has intrinsic aesthetic and spiritual value to mankind \"in and of itself\". This idea can be used as a counterweight to the notion that tropical forests and other ecological realms are only worthy of conservation because of the services they provide.\n\nBiodiversity supports many ecosystem services:\n\n\"There is now unequivocal evidence that biodiversity loss reduces the efficiency by which ecological communities capture biologically essential resources, produce biomass, decompose and recycle biologically essential nutrients... There is mounting evidence that biodiversity increases the stability of ecosystem functions through time... Diverse communities are more productive because they contain key species that have a large influence on productivity and differences in functional traits among organisms increase total resource capture... The impacts of diversity loss on ecological processes might be sufficiently large to rival the impacts of many other global drivers of environmental change... Maintaining multiple ecosystem processes at multiple places and times requires higher levels of biodiversity than does a single process at a single place and time.\"\n\nIt plays a part in regulating the chemistry of our atmosphere and water supply. Biodiversity is directly involved in water purification, recycling nutrients and providing fertile soils. Experiments with controlled environments have shown that humans cannot easily build ecosystems to support human needs; for example insect pollination cannot be mimicked, though there have been attempts to create artificial pollinators using unmanned aerial vehicles. The economic activity of pollination alone represented between $2.1-14.6 billions in 2003.\n\nAccording to Mora and colleagues, the total number of terrestrial species is estimated to be around 8.7 million while the number of oceanic species is much lower, estimated at 2.2 million. The authors note that these estimates are strongest for eukaryotic organisms and likely represent the lower bound of prokaryote diversity. Other estimates include:\n\nSince the rate of extinction has increased, many extant species may become extinct before they are described. Not surprisingly, in the animalia the most studied groups are birds and mammals, whereas fishes and arthropods are the least studied animals groups.\n\nDuring the last century, decreases in biodiversity have been increasingly observed. In 2007, German Federal Environment Minister Sigmar Gabriel cited estimates that up to 30% of all species will be extinct by 2050. Of these, about one eighth of known plant species are threatened with extinction. Estimates reach as high as 140,000 species per year (based on Species-area theory). This figure indicates unsustainable ecological practices, because few species emerge each year. Almost all scientists acknowledge that the rate of species loss is greater now than at any time in human history, with extinctions occurring at rates hundreds of times higher than background extinction rates. As of 2012, some studies suggest that 25% of all mammal species could be extinct in 20 years.\n\nIn absolute terms, the planet has lost 52% of its biodiversity since 1970 according to a 2014 study by the World Wildlife Fund. The Living Planet Report 2014 claims that \"the number of mammals, birds, reptiles, amphibians and fish across the globe is, on average, about half the size it was 40 years ago\". Of that number, 39% accounts for the terrestrial wildlife gone, 39% for the marine wildlife gone and 76% for the freshwater wildlife gone. Biodiversity took the biggest hit in Latin America, plummeting 83 percent. High-income countries showed a 10% increase in biodiversity, which was canceled out by a loss in low-income countries. This is despite the fact that high-income countries use five times the ecological resources of low-income countries, which was explained as a result of process whereby wealthy nations are outsourcing resource depletion to poorer nations, which are suffering the greatest ecosystem losses.\n\nA 2017 study published in \"PLOS One\" found that the biomass of insect life in Germany had declined by three-quarters in the last 25 years. Dave Goulson of Sussex University stated that their study suggested that humans \"appear to be making vast tracts of land inhospitable to most forms of life, and are currently on course for ecological Armageddon. If we lose the insects then everything is going to collapse.\"\n\nIn 2006 many species were formally classified as rare or endangered or threatened; moreover, scientists have estimated that millions more species are at risk which have not been formally recognized. About 40 percent of the 40,177 species assessed using the IUCN Red List criteria are now listed as threatened with extinction—a total of 16,119.\n\nJared Diamond describes an \"Evil Quartet\" of habitat destruction, overkill, introduced species and secondary extinctions. Edward O. Wilson prefers the acronym HIPPO, standing for Habitat destruction, Invasive species, Pollution, human over-Population and Over-harvesting. The most authoritative classification in use today is IUCN's Classification of Direct Threats which has been adopted by major international conservation organizations such as the US Nature Conservancy, the World Wildlife Fund, Conservation International and BirdLife International.\n\nHabitat destruction has played a key role in extinctions, especially related to tropical forest destruction. Factors contributing to habitat loss are: overconsumption, overpopulation, land use change, deforestation, pollution (air pollution, water pollution, soil contamination) and global warming or climate change.\n\nHabitat size and numbers of species are systematically related. Physically larger species and those living at lower latitudes or in forests or oceans are more sensitive to reduction in habitat area. Conversion to \"trivial\" standardized ecosystems (e.g., monoculture following deforestation) effectively destroys habitat for the more diverse species that preceded the conversion. In some countries lack of property rights or lax law/regulatory enforcement necessarily leads to biodiversity loss (degradation costs having to be supported by the community).\n\nA 2007 study conducted by the National Science Foundation found that biodiversity and genetic diversity are codependent—that diversity among species requires diversity within a species and vice versa. \"If any one type is removed from the system, the cycle can break down and the community becomes dominated by a single species.\"\nAt present, the most threatened ecosystems are found in fresh water, according to the Millennium Ecosystem Assessment 2005, which was confirmed by the \"Freshwater Animal Diversity Assessment\", organised by the biodiversity platform and the French \"Institut de recherche pour le développement\" (MNHNP).\n\nCo-extinctions are a form of habitat destruction. Co-extinction occurs when the extinction or decline in one accompanies the other, such as in plants and beetles.\n\nBarriers such as large rivers, seas, oceans, mountains and deserts encourage diversity by enabling independent evolution on either side of the barrier, via the process of allopatric speciation. The term invasive species is applied to species that breach the natural barriers that would normally keep them constrained. Without barriers, such species occupy new territory, often supplanting native species by occupying their niches, or by using resources that would normally sustain native species.\n\nThe number of species invasions has been on the rise at least since the beginning of the 1900s. Species are increasingly being moved by humans (on purpose and accidentally). In some cases the invaders are causing drastic changes and damage to their new habitats (e.g.: zebra mussels and the emerald ash borer in the Great Lakes region and the lion fish along the North American Atlantic coast). Some evidence suggests that invasive species are competitive in their new habitats because they are subject to less pathogen disturbance. Others report confounding evidence that occasionally suggest that species-rich communities harbor many native and exotic species simultaneously while some say that diverse ecosystems are more resilient and resist invasive plants and animals. An important question is, \"do invasive species cause extinctions?\" Many studies cite effects of invasive species on natives, but not extinctions. Invasive species seem to increase local (i.e.: alpha diversity) diversity, which decreases turnover of diversity (i.e.: beta diversity). Overall gamma diversity may be lowered because species are going extinct because of other causes, but even some of the most insidious invaders (e.g.: Dutch elm disease, emerald ash borer, chestnut blight in North America) have not caused their host species to become extinct. Extirpation, population decline and homogenization of regional biodiversity are much more common. Human activities have frequently been the cause of invasive species circumventing their barriers, by introducing them for food and other purposes. Human activities therefore allow species to migrate to new areas (and thus become invasive) occurred on time scales much shorter than historically have been required for a species to extend its range.\n\nNot all introduced species are invasive, nor all invasive species deliberately introduced. In cases such as the zebra mussel, invasion of US waterways was unintentional. In other cases, such as mongooses in Hawaii, the introduction is deliberate but ineffective (nocturnal rats were not vulnerable to the diurnal mongoose). In other cases, such as oil palms in Indonesia and Malaysia, the introduction produces substantial economic benefits, but the benefits are accompanied by costly unintended consequences.\n\nFinally, an introduced species may unintentionally injure a species that depends on the species it replaces. In Belgium, Prunus spinosa from Eastern Europe leafs much sooner than its West European counterparts, disrupting the feeding habits of the \"Thecla betulae\" butterfly (which feeds on the leaves). Introducing new species often leaves endemic and other local species unable to compete with the exotic species and unable to survive. The exotic organisms may be predators, parasites, or may simply outcompete indigenous species for nutrients, water and light.\n\nAt present, several countries have already imported so many exotic species, particularly agricultural and ornamental plants, that their own indigenous fauna/flora may be outnumbered. For example, the introduction of kudzu from Southeast Asia to Canada and the United States has threatened biodiversity in certain areas.\n\nEndemic species can be threatened with extinction through the process of genetic pollution, i.e. uncontrolled hybridization, introgression and genetic swamping. Genetic pollution leads to homogenization or replacement of local genomes as a result of either a numerical and/or fitness advantage of an introduced species.\nHybridization and introgression are side-effects of introduction and invasion. These phenomena can be especially detrimental to rare species that come into contact with more abundant ones. The abundant species can interbreed with the rare species, swamping its gene pool. This problem is not always apparent from morphological (outward appearance) observations alone. Some degree of gene flow is normal adaptation and not all gene and genotype constellations can be preserved. However, hybridization with or without introgression may, nevertheless, threaten a rare species' existence.\n\nOverexploitation occurs when a resource is consumed at an unsustainable rate. This occurs on land in the form of overhunting, excessive logging, poor soil conservation in agriculture and the illegal wildlife trade.\n\nAbout 25% of world fisheries are now overfished to the point where their current biomass is less than the level that maximizes their sustainable yield.\n\nThe overkill hypothesis, a pattern of large animal extinctions connected with human migration patterns, can be used explain why megafaunal extinctions can occur within a relatively short time period.\n\nIn agriculture and animal husbandry, the Green Revolution popularized the use of conventional hybridization to increase yield. Often hybridized breeds originated in developed countries and were further hybridized with local varieties in the developing world to create high yield strains resistant to local climate and diseases. Local governments and industry have been pushing hybridization. Formerly huge gene pools of various wild and indigenous breeds have collapsed causing widespread genetic erosion and genetic pollution. This has resulted in loss of genetic diversity and biodiversity as a whole.\n\nGenetically modified organisms contain genetic material that is altered through genetic engineering. Genetically modified crops have become a common source for genetic pollution in not only wild varieties, but also in domesticated varieties derived from classical hybridization.\n\nGenetic erosion and genetic pollution have the potential to destroy unique genotypes, threatening future access to food security. A decrease in genetic diversity weakens the ability of crops and livestock to be hybridized to resist disease and survive changes in climate.\n\nGlobal warming is also considered to be a major potential threat to global biodiversity in the future. For example, coral reefs - which are biodiversity hotspots - will be lost within the century if global warming continues at the current trend.\n\nClimate change has seen many claims about potential to affect biodiversity but evidence supporting the statement is tenuous. Increasing atmospheric carbon dioxide certainly affects plant morphology and is acidifying oceans, and temperature affects species ranges, phenology, and weather, but the major impacts that have been predicted are still just \"potential\" impacts. We have not documented major extinctions yet, even as climate change drastically alters the biology of many species.\n\nIn 2004, an international collaborative study on four continents estimated that 10 percent of species would become extinct by 2050 because of global warming. \"We need to limit climate change or we wind up with a lot of species in trouble, possibly extinct,\" said Dr. Lee Hannah, a co-author of the paper and chief climate change biologist at the Center for Applied Biodiversity Science at Conservation International.\n\nA recent study predicts that up to 35% of the world terrestrial carnivores and ungulates will be at higher risk of extinction by 2050 because of the joint effects of predicted climate and land-use change under business-as-usual human development scenarios.\n\nFrom 1950 to 2011, world population increased from 2.5 billion to 7 billion and is forecast to reach a plateau of more than 9 billion during the 21st century. Some recent forecasts place the possible number of people on the planet at 11 billion or 15 billion by 2100. Sir David King, former chief scientific adviser to the UK government, told a parliamentary inquiry: \"\"It is self-evident that the massive growth in the human population through the 20th century has had more impact on biodiversity than any other single factor.\"\" At least until the middle of the 21st century, worldwide losses of pristine biodiverse land will probably depend much on the worldwide human birth rate. Biologists such as Paul R. Ehrlich and Stuart Pimm have noted that human population growth and overconsumption are the main drivers of species extinction.\n\nAccording to a 2014 study by the World Wildlife Fund, the global human population already exceeds planet's biocapacity - it would take the equivalent of 1.5 Earths of biocapacity to meet our current demands. The report further points that if everyone on the planet had the Footprint of the average resident of Qatar, we would need 4.8 Earths and if we lived the lifestyle of a typical resident of the USA, we would need 3.9 Earths.\n\nRates of decline in biodiversity in this sixth mass extinction match or exceed rates of loss in the five previous mass extinction events in the fossil record. Loss of biodiversity results in the loss of natural capital that supplies ecosystem goods and services. From the perspective of the method known as Natural Economy the economic value of 17 ecosystem services for Earth's biosphere (calculated in 1997) has an estimated value of US$33 trillion (3.3x10) per year.\n\nConservation biology matured in the mid-20th century as ecologists, naturalists and other scientists began to research and address issues pertaining to global biodiversity declines.\n\nThe conservation ethic advocates management of natural resources for the purpose of sustaining biodiversity in species, ecosystems, the evolutionary process and human culture and society.\n\nConservation biology is reforming around strategic plans to protect biodiversity. Preserving global biodiversity is a priority in strategic conservation plans that are designed to engage public policy and concerns affecting local, regional and global scales of communities, ecosystems and cultures. Action plans identify ways of sustaining human well-being, employing natural capital, market capital and ecosystem services.\n\nIn the EU Directive 1999/22/EC zoos are described as having a role in the preservation of the biodiversity of wildlife animals by conducting research or participation in breeding programs.\n\nRemoval of exotic species will allow the species that they have negatively impacted to recover their ecological niches. Exotic species that have become pests can be identified taxonomically (e.g., with Digital Automated Identification SYstem (DAISY), using the barcode of life). Removal is practical only given large groups of individuals due to the economic cost.\n\nAs sustainable populations of the remaining native species in an area become assured, \"missing\" species that are candidates for reintroduction can be identified using databases such as the \"Encyclopedia of Life\" and the Global Biodiversity Information Facility.\n\n\nProtected areas is meant for affording protection to wild animals and their habitat which also includes forest reserves and biosphere reserves. Protected areas have been set up all over the world with the specific aim of protecting and conserving plants and animals.\n\nNational park and nature reserve is the area selected by governments or private organizations for special protection against damage or degradation with the objective of biodiversity and landscape conservation. National parks are usually owned and managed by national or state governments. A limit is placed on the number of visitors permitted to enter certain fragile areas. Designated trails or roads are created. The visitors are allowed to enter only for study, cultural and recreation purposes. Forestry operations, grazing of animals and hunting of animals are regulated. Exploitation of habitat or wildlife is banned.\n\nWildlife sanctuary aims only at conservation of species and have the following features:\n\n\nThe forests play a vital role in harbouring more than 45,000 floral and 81,000 faunal species of which 5150 floral and 1837 faunal species are endemic. Plant and animal species confined to a specific geographical area are called endemic species. In reserved forests, rights to activities like hunting and grazing are sometimes given to communities living on the fringes of the forest, who sustain their livelihood partially or wholly from forest resources or products. The unclassed forests covers 6.4 percent of the total forest area and they are marked by the following characteristics:\n\n\n\nIn zoological parks or zoos, live animals are kept for public recreation, education and conservation purposes. Modern zoos offer veterinary facilities, provide opportunities for threatened species to breed in captivity and usually build environments that simulate the native habitats of the animals in their care. Zoos play a major role in creating awareness among common people about the need to conserve nature.\n\nBotanical garden is a garden in which plants are grown and displayed primarily for scientific and educational purposes. It consists of a collection of living plants, grown outdoors or under glass in greenhouses and conservatories. In addition, it includes a collection of dried plants or herbarium and such facilities as lecture rooms, laboratories, libraries, museums and experimental or research plantings.\n\nFocusing on limited areas of higher potential biodiversity promises greater immediate return on investment than spreading resources evenly or focusing on areas of little diversity but greater interest in biodiversity.\n\nA second strategy focuses on areas that retain most of their original diversity, which typically require little or no restoration. These are typically non-urbanized, non-agricultural areas. Tropical areas often fit both criteria, given their natively high diversity and relative lack of development.\n\n\nGlobal agreements such as the Convention on Biological Diversity, give \"sovereign national rights over biological resources\" (not property). The agreements commit countries to \"conserve biodiversity\", \"develop resources for sustainability\" and \"share the benefits\" resulting from their use. Biodiverse countries that allow bioprospecting or collection of natural products, expect a share of the benefits rather than allowing the individual or institution that discovers/exploits the resource to capture them privately. Bioprospecting can become a type of biopiracy when such principles are not respected.\n\nSovereignty principles can rely upon what is better known as Access and Benefit Sharing Agreements (ABAs). The Convention on Biodiversity implies informed consent between the source country and the collector, to establish which resource will be used and for what and to settle on a fair agreement on benefit sharing.\n\nBiodiversity is taken into account in some political and judicial decisions:\n\nUniform approval for use of biodiversity as a legal standard has not been achieved, however. Bosselman argues that biodiversity should not be used as a legal standard, claiming that the remaining areas of scientific uncertainty cause unacceptable administrative waste and increase litigation without promoting preservation goals.\n\nIndia passed the Biological Diversity Act in 2002 for the conservation of biological diversity in India. The Act also provides mechanisms for equitable sharing of benefits from the use of traditional biological resources and knowledge.\n\nLess than 1% of all species that have been described have been studied beyond simply noting their existence. The vast majority of Earth's species are microbial. Contemporary biodiversity physics is \"firmly fixated on the visible [macroscopic] world\". For example, microbial life is metabolically and environmentally more diverse than multicellular life (see e.g., extremophile). \"On the tree of life, based on analyses of small-subunit ribosomal RNA, visible life consists of barely noticeable twigs. The inverse relationship of size and population recurs higher on the evolutionary ladder—\"to a first approximation, all multicellular species on Earth are insects\". Insect extinction rates are high—supporting the Holocene extinction hypothesis.\nThe number of morphological attributes that can be scored for diversity study is generally limited and prone to environmental influences; thereby reducing the fine resolution required to ascertain the phylogenetic relationships. DNA based markers- microsatellites otherwise known as \"simple sequence repeats\" (SSR) were therefore used for the diversity studies of certain species and their wild relatives.\n\nIn the case of cowpea, a study conducted to assess the level of genetic diversity in cowpea germplasm and related wide species, where the relatedness among various taxa were compared, primers useful for classification of taxa identified, and the origin and phylogeny of cultivated cowpea classified show that SSR markers are useful in validating with species classification and revealing the center of diversity.\n\n\n\n\n\n", "id": "45086", "title": "Biodiversity"}
{"url": "https://en.wikipedia.org/wiki?curid=186345", "text": "Ex situ conservation\n\n\"Ex situ\" conservation literally means, \"off-site conservation\". It is the process of protecting an endangered species, variety or breed, of plant or animal outside its natural habitat; for example, by removing part of the population from a threatened habitat and placing it in a new location, which may be a wild area or within the care of humans. The degree to which humans control or modify the natural dynamics of the managed population varies widely, and this may include alteration of living environments, reproductive patterns, access to resources, and protection from predation and mortality. \"Ex situ\" management can occur within or outside a species' natural geographic range. Individuals maintained \"ex situ\" exist outside an ecological niche. This means that they are not under the same selection pressures as wild populations, and they may undergo artificial selection if maintained \"ex situ\" for multiple generations.\n\nAgricultural biodiversity is also conserved in \"ex situ\" collections. This is primarily in the form of gene banks where samples are stored in order to conserve the genetic resources of major crop plants and their wild relatives.\n\nThat means ex-situ conservation is a process of conserving endangered plants or animals in the human care by giving them their own environment. Intex of Nepal some example are one horned rhinoceros, golden michelia.\n\nBotanical gardens, and zoos are the most conventional methods of Ex situ conservation, all of which house whole, protected specimens for breeding and reintroduction into the wild when necessary and possible. These facilities provide not only housing and care for specimens of endangered species, but also have an educational value. They inform the public of the threatened status of endangered species and of those factors which cause the threat, with the hope of creating public interest in stopping and reversing those factors which jeopardize a species' survival in the first place. They are the most publicly visited ex situ conservation sites, with the WZCS (World Zoo Conservation Strategy) estimating that the 1100 organized zoos in the world receive more than 600 million visitors annually. Globally there is an estimated total of 2,107 aquaria and zoos in 125 countries. Additionally many private collectors or other not-for-profit groups hold animals and they engage in conservation or reintroduction efforts. Similarly there are approximately 2,000 botanical gardens in 148 counties cultivating or storing an estimated 80,000 taxa of plants.\n\nThe storage of seeds, pollen, tissue, or embryos in liquid nitrogen. This method can be used for virtually indefinite storage of material without deterioration over a much greater time-period relative to all other methods of \"ex situ\" conservation. Cryopreservation is also used for the conservation of livestock genetics through Cryoconservation of animal genetic resources. Technical limitations prevent the cryopreservation of many species, but cryobiology is a field of active research, and many studies concerning plants are underway.\n\nThe storage of seeds in a temperature and moisture controlled environment. This technique is used for taxa with orthodox seeds that tolerate desiccation. Seed bank facilities vary from sealed boxes to climate controlled walk-in freezers or vaults. Taxa with recalcitrant seeds that do not tolerate desiccation are typically not held in seed banks for extended periods of time.\n\nSomatic tissue can be stored \"in vitro\" for short periods of time. This is done in a light and temperature controlled environment that regulates the growth of cells. As a e\"x situ\" conservation technique tissue culture is primary used for clonal propagation of vegetative tissue or immature seeds. This allows for the proliferation of clonal plants from a relatively small amount of parent tissue.\n\nAn extensive open-air planting used maintain genetic diversity of wild, agricultural, or forestry species. Typically species that are either difficult or impossible to conserve in seed banks are conserved in field gene banks. Field gene banks may also be used grow and select progeny of species stored by other \"ex situ\" techniques.\n\nPlants under horticultural care in a constructed landscape, typically a botanic garden or arboreta. This technique is similar to a field gene bank in that plants are maintained in the ambient environment, but the collections are typically not as genetically diverse or extensive. These collections are susceptible to hybridization, artificial selection, genetic drift, and disease transmission. Species that cannot be conserved by other \"ex situ\" techniques are often included in cultivated collections.\n\nPlants are under horticulture care, but the environment is managed to near natural conditions. This occurs with either restored or semi-natural environments. This technique is primarily used for taxa that are rare or in areas where habitat has been severely degraded.\n\nEndangered animal species and breeds are preserved using similar techniques. Animal species can be preserved in genebanks, which consist of cryogenic facilities used to store living sperm, eggs, or embryos. For example, the Zoological Society of San Diego has established a \"frozen zoo\" to store such samples using cryopreservation techniques from more than 355 species, including mammals, reptiles, and birds.\n\nA potential technique for aiding in reproduction of endangered species is interspecific pregnancy, implanting embryos of an endangered species into the womb of a female of a related species, carrying it to term. It has been carried out for the Spanish ibex.\n\nCaptive populations are subject to problems such as inbreeding depression, loss of genetic diversity and adaptations to captivity. It is important to manage captive populations in a way that minimizes these issues so that the individuals to be introduced will resemble the original founders as closely as possible, which will increase the chances of successful reintroductions. During the initial growth phase, the population size is rapidly expanded until a target population size is reached. The target population size is the number of individuals that are required to maintain appropriate levels of genetic diversity, which is generally considered to by 90% of the current genetic diversity after 100 years. The number of individuals required to meet this goal varies based on potential growth rate, effective size, current genetic diversity, and generation time. Once the target population size is reached, the focus shifts to maintaining the population and avoiding genetic issues within the captive population.\n\nManaging populations based on minimizing mean kinship values is often an effective way to increase genetic diversity and to avoid inbreeding within captive populations. Kinship is the probability that two alleles will be identical by descent when one allele is taken randomly from each mating individual. The mean kinship value is the average kinship value between a given individual and every other member of the population. Mean kinship values can help determine which individuals should be mated. In choosing individuals for breeding, it is important to choose individuals with the lowest mean kinship values because these individuals are least related to the rest of the population and have the least common alleles. This ensures that rarer alleles are passed on, which helps to increase genetic diversity. It is also important to avoid mating two individuals with very different mean kinship values because such pairings propagate both the rare alleles that are present in the individual with the low mean kinship value as well as the common alleles that are present in the individual with the high mean kinship value. This genetic management technique requires that ancestry is known, so in circumstances where ancestry is unknown, it might be necessary to use molecular genetics such as microsatellite data to help resolve unknowns.\n\nGenetic diversity is often lost within captive populations due to the founder effect and subsequent small population sizes. Minimizing the loss of genetic diversity within the captive population is an important component of \"ex situ\" conservation and is critical for successful reintroductions and the long term success of the species, since more diverse populations have higher adaptive potential. The loss of genetic diversity due to the founder effect can be minimized by ensuring that the founder population is large enough and genetically representative of the wild population. This is often difficult because removing large numbers of individuals from the wild populations may further reduce the genetic diversity of a species that is already of conservation concern. Maximizing the captive population size and the effective population size can decrease the loss of genetic diversity by minimizing the random loss of alleles due to genetic drift . Minimizing the number of generations in captivity is another effective method for reducing the loss of genetic diversity in captive populations.\n\nSelection favors different traits in captive populations than it does in wild populations, so this may result in adaptations that are beneficial in captivity but are deleterious in the wild. This reduces the success of re-introductions, so it is important to manage captive populations in order to reduce adaptations to captivity. Adaptations to captivity can be reduced by minimizing the number of generations in captivity and by maximizing the number of migrants from wild populations. Minimizing selection on captive populations by creating an environment that is similar to their natural environment is another method of reducing adaptations to captivity, but it is important to find a balance between an environment that minimizes adaptation to captivity and an environment that permits adequate reproduction. Adaptations to captivity can also be reduced by managing the captive population as a series of population fragments. In this management strategy, the captive population is split into several sub-populations or fragments which are maintained separately. Smaller populations have lower adaptive potentials, so the population fragments are less likely to accumulate adaptations associated with captivity. The fragments are maintained separately until inbreeding becomes a concern. Immigrants are then exchanged between the fragments to reduce inbreeding, and then the fragments are managed separately again.\n\nGenetic disorders are often an issue within captive populations due to the fact that the populations are usually established from a small number of founders. In large, outbreeding populations, the frequencies of most deleterious alleles are relatively low, but when a population undergoes a bottleneck during the founding of a captive population, previously rare alleles may survive and increase in number. Further inbreeding within the captive population may also increase the likelihood that deleterious alleles will be expressed due to increasing homozygosity within the population. The high occurrence of genetic disorders within a captive population can threaten both the survival of the captive population and its eventual reintroduction back into the wild. If the genetic disorder is dominant, it may be possible to eliminate the disease completely in a single generation by avoiding breeding of the affected individuals. However, if the genetic disorder is recessive, it may not be possible to completely eliminate the allele due to its presence in unaffected heterozygotes. In this case, the best option is to attempt to minimize the frequency of the allele by selectively choosing mating pairs. In the process of eliminating genetic disorders, it is important to consider that when certain individuals are prevented from breeding, alleles and therefore genetic diversity are removed from the population; if these alleles aren't present in other individuals, they may be lost completely. Preventing certain individuals from the breeding also reduces the effective population size, which is associated with problems such as the loss of genetic diversity and increased inbreeding.\n\nShowy Indian clover, \"Trifolium amoenum\", is an example of a species that was thought to be extinct, but was rediscovered in 1993 in the form of a single plant at a site in western Sonoma County. Seeds were harvested and currently grown in ex situ facilities.\n\nThe Wollemi pine is another example of a plant that is being preserved via \"ex situ\" conservation, as they are being grown in nurseries to be sold to the general public.\n\n\"Ex situ\" conservation, while helpful in humankind's efforts to sustain and protect our environment, is rarely enough to save a species from extinction. It is to be used as a last resort, or as a supplement to in situ conservation because it cannot recreate the habitat as a whole: the entire genetic variation of a species, its symbiotic counterparts, or those elements which, over time, might help a species adapt to its changing surroundings. Instead, \"ex situ\" conservation removes the species from its natural ecological contexts, preserving it under semi-isolated conditions whereby natural evolution and adaptation processes are either temporarily halted or altered by introducing the specimen to an unnatural habitat. In the case of cryogenic storage methods, the preserved specimen's adaptation processes are (quite literally) frozen altogether. The downside to this is that, when re-released, the species may lack the genetic adaptations and mutations which would allow it to thrive in its ever-changing natural habitat.\n\nFurthermore, \"ex situ\" conservation techniques are often costly, with cryogenic storage being economically infeasible in most cases since species stored in this manner cannot provide a profit but instead slowly drain the financial resources of the government or organization determined to operate them. Seedbanks are ineffective for certain plant genera with recalcitrant seeds that do not remain fertile for long periods of time. Diseases and pests foreign to the species, to which the species has no natural defense, may also cripple crops of protected plants in \"ex situ\" plantations and in animals living in \"ex situ\" breeding grounds. These factors, combined with the specific environmental needs of many species, some of which are nearly impossible to recreate by man, make \"ex situ\" conservation impossible for a great number of the world's endangered flora and fauna.\n\n\n", "id": "186345", "title": "Ex situ conservation"}
{"url": "https://en.wikipedia.org/wiki?curid=29651355", "text": "Animal protectionism\n\nAnimal protectionism is a position within animal rights theory that favors incremental change in pursuit of non-human animal interests. It is contrasted with abolitionism, the position that human beings have no moral right to use animals, and ought to have no legal right, no matter how the animals are treated.\n\nAnimal protectionists agree with abolitionists that the animal welfare model of animal protection—whereby animals may be used as food, clothing, entertainment and in experiments so long as their suffering is regulated—has failed ethically and politically, but argue that its philosophy can be reformulated. Robert Garner of the University of Leicester, a leading academic protectionist, argues that animal use may in some circumstances be justified, though it should be better regulated, and that the pursuit of better treatment and incremental change is consistent with holding an abolitionist ideology. Gary Francione, professor of law at Rutgers School of Law-Newark and a leading abolitionist, calls this approach \"new welfarism.\" He regards it as counter-productive because it wrongly persuades the public that the animals they use are being treated kindly, and that continued use is therefore justifiable. Francione regards the abolitionist position as the only one that can properly be called animal rights.\nOne of the arguments put forward by abolitionists against protectionism is that small improvements in animal welfare serve to salve consciences by persuading the public that their use of animals is not unethical. Welfare reform can therefore be counter-productive. Abolitionists also argue that real reform is invariably unsuccessful, because industries that depend on animal use will not implement change that harms their profit margin. That is, the property status of animals prohibits reform that will harm their owners' interests. For that reason, abolitionists argue, it is the property status of animals that must be removed.\n\nRobert Garner argues against this that welfare reform is not simply a staging post on the way to abolition, but is in itself desirable. An approach that is based on the right of animals not to suffer could, in theory, be satisfied with a welfare system in which animal suffering, if not animal use, was minimized, though he concedes that this is unlikely. He also argues that Francione has not shown that improvements in welfare persuade the public that all is well. Rather, he argues, reform has the effect of raising public consciousness about the interests of animals.\n\n", "id": "29651355", "title": "Animal protectionism"}
{"url": "https://en.wikipedia.org/wiki?curid=52088705", "text": "Prairie remnant\n\nA prairie remnant commonly refers to grassland areas in the western and midwestern United States and Canada that remain to some extent undisturbed by European settlement. Prairie remnants range in levels of degradation but nearly all contain at least some semblance of the pre-Columbian local plant assemblage of a particular region. Prairie remnants have become increasingly threatened due to the threats of agricultural, urban and suburban development, pollution, fire suppression and especially the incursion of invasive species.\n\nPrairie remnants offer valuable varieties of rare species thus providing excellent opportunities for restoration ecology projects. Many restoration projects are simply recreations of prairie habitats, but restoring prairie remnants provides the preservation of more complete ecological structures that were naturally created after the end of the last ice age. Remnants can also serve as platforms for additional surrounding ecological restoration activities.\n\nIt has been estimated that 99% of tallgrass prairie habitats in North America have been destroyed mainly due to conversion to agriculture. Tallgrass prairies are generally composed of a mixture of native grasses, sedges, and forbs but are usually dominated by grasses.\nThe shortgrass prairie is an ecosystem located in the Great Plains of North America. The prairie includes lands to the west as far as the eastern foothills of the Rocky Mountains and extends east as far as Nebraska and north into Saskatchewan. The prairie stretches through parts of Alberta, Wyoming, Montana, North Dakota, South Dakota, and Kansas, and passes south through the high plains of Colorado, Oklahoma, Texas, and New Mexico.\n", "id": "52088705", "title": "Prairie remnant"}
{"url": "https://en.wikipedia.org/wiki?curid=1512214", "text": "Germplasm\n\nGermplasm are living genetic resources such as seeds or tissues that are maintained for the purpose of animal and plant breeding, preservation, and other research uses. These resources may take the form of seed collections stored in seed banks, trees growing in nurseries, animal breeding lines maintained in animal breeding programs or gene banks, etc. Germplasm collections can range from collections of wild species to elite, domesticated breeding lines that have undergone extensive human selection. Germplasm collection is important for the maintenance of biological diversity and food security. \n\n\n\n", "id": "1512214", "title": "Germplasm"}
{"url": "https://en.wikipedia.org/wiki?curid=53835641", "text": "Ocean Outcomes\n\nOcean Outcomes (O2) is an international nonprofit organization which works with commercial fisheries, seafood industry, local communities, government, NGOs, and other fishery stakeholders to develop and implement solutions towards more sustainable fisheries. O2's work includes fishery assessments, fishery improvement projects (FIPs), buyer engagement programs, supply chain analysis, and other contractual fishery-related work. Founded in 2015, O2 has team members and fishery projects across Northeast Asia, including on the ground operations in China, Japan, and South Korea.\n\nWhile O2 launched as an independent organization in 2015, O2's sustainable fisheries work dates back to the early 2000s as State of the Salmon, a science-based program created in 2003 in collaboration with Ecotrust and Wild Salmon Center which used data to track the health and trends of wild salmon populations. This data was then analyzed, and used to inform salmon management and conservation throughout the Pacific Rim. As O2, this sustainable fisheries work has expanded beyond salmon fisheries to include tuna, crab, perch, and other species, and beyond salmon-specific projects to include Illegal, unreported and unregulated fishing (IUU), supply chain analysis, traceability, and other initiatives, including the first-ever fishery improvement project in Japan.\n\n", "id": "53835641", "title": "Ocean Outcomes"}
{"url": "https://en.wikipedia.org/wiki?curid=1259241", "text": "Habitat fragmentation\n\nHabitat fragmentation describes the emergence of discontinuities (fragmentation) in an organism's preferred environment (habitat), causing population fragmentation and ecosystem decay. Habitat fragmentation can be caused by geological processes that slowly alter the layout of the physical environment (suspected of being one of the major causes of speciation), or by human activity such as land conversion, which can alter the environment much faster and causes extinctions of many species.\n\nThe term habitat fragmentation includes five discrete phenomena:\n\n\"fragmentation ... not only causes loss of the amount of habitat, but by creating small, isolated patches it also changes the properties of the remaining habitat\" (van den Berg et al. 2001). Habitat fragmentation is the landscape level of the phenomenon, and patch level process. Thus meaning, it covers; the patch areas, edge effects, and patch shape complexity.\n\nEvidence of habitat destruction through natural processes such as volcanism, fire, and climate change is found in the fossil record. For example, habitat fragmentation of tropical rainforests in Euramerica 300 million years ago led to a great loss of amphibian diversity, but simultaneously the drier climate spurred on a burst of diversity among reptiles.\n\nHabitat fragmentation is frequently caused by humans when vegetation is cleared for human activities such as agriculture, rural development, urbanization and the creation of hydroelectric reservoirs. Habitats which were once continuous become divided into separate fragments. After intensive clearing, the separate fragments tend to be very small islands isolated from each other by cropland, pasture, pavement, or even barren land. The latter is often the result of slash and burn farming in tropical forests. In the wheat belt of central western New South Wales, Australia, 90% of the native vegetation has been cleared and over 99% of the tall grass prairie of North America has been cleared, resulting in extreme habitat fragmentation.\n\nOne of the major ways that habitat fragmentation affects biodiversity is by reducing the amount of suitable habitat available for organisms. Habitat fragmentation often involves both habitat destruction and the subdivision of previously continuous habitat. Plants and other sessile organisms are disproportionately affected by some types of habitat fragmentation because they cannot respond quickly to the altered spatial configuration of the habitat.\n\nAs the remaining habitat patches are smaller, they tend to support smaller populations of species. Small populations are at an increased risk of a variety of genetic consequences that influence their long-term survival. \nRemnant populations often contain only a subset of the genetic diversity found in the previously continuous habitat. Processes that act upon underlying genetic diversity such as adaptation have a smaller pool of fitness-maintaining alleles to survive in the face of environmental change.\n\nPopulations can maintain genetic diversity through migration. In continuous habitats, migrants have few barriers to establish themselves in suitable sites. In fragmented habitats however, the separation between suitable sites disrupts migration, and therefore gene flow, limiting a populations capacity to supplement the reduced genetic diversity of the remnant populations.\nWith lower migration, inbreeding becomes of increasing concern as the level of homozygosity increases, facilitating the expression of deleterious alleles that reduce the fitness of the population called inbreeding depression.\n\nThe percentage preservation of contiguous habitats is closely related to both genetic and species biodiversity preservation. Generally a 10% remnant contiguous habitat will result in a 50% biodiversity loss.\n\nHabitat loss, which can occur through the process of habitat fragmentation, is considered to be the greatest threat to species. But, the effect of the configuration of habitat patches within the landscape, independent of the effect of the amount of habitat within the landscape (referred to as fragmentation per se), has been suggested to be small. A review of empirical studies found that, of the 381 reported significant effect of habitat fragmentation per se on species occurrences, abundances or diversity in the scientific literature, 76% were positive whereas 24% were negative. Despite these results, the scientific literature tends to emphasize negative effects more than positive effects. Positive effects of habitat fragmentation per se imply that several small patches of habitat can have higher conservation value than a single large patch of equivalent size. Land sharing strategies could therefore have more positive impacts on species than land sparing strategies.\n\nArea is the primary determinant of the number of species in a fragment and the relative contributions of demographic and genetic processes to the risk of global population extinction depend on habitat configuration, stochastic environmental variation and species features. Minor fluctuations in climate, resources, or other factors that would be unremarkable and quickly corrected in large populations can be catastrophic in small, isolated populations. Thus fragmentation of habitat is an important cause of species extinction. Population dynamics of subdivided populations tend to vary asynchronously. In an unfragmented landscape a declining population can be \"rescued\" by immigration from a nearby expanding population. In fragmented landscapes, the distance between fragments may prevent this from happening. Additionally, unoccupied fragments of habitat that are separated from a source of immigrants by some barrier are less likely to be repopulated than adjoining fragments. Even small species such as the Columbia spotted frog are reliant on the rescue effect. Studies showed 25% of juveniles travel a distance over 200m compared to 4% of adults. Of these, 95% remain in their new locale, demonstrating that this journey is necessary for survival.\n\nAdditionally, habitat fragmentation leads to edge effects. Microclimatic changes in light, temperature and wind can alter the ecology around the fragment, and in the interior and exterior portions of the fragment. Fires become more likely in the area as humidity drops and temperature and wind levels rise. Exotic and pest species may establish themselves easily in such disturbed environments, and the proximity of domestic animals often upsets the natural ecology. Also, habitat along the edge of a fragment has a different climate and favours different species from the interior habitat. Small fragments are therefore unfavourable for species which require interior habitat.\n\nHabitat fragmentation is often a cause of species becoming threatened or endangered. The existence of viable habitat is critical to the survival of any species, and in many cases the fragmentation of any remaining habitat can lead to difficult decisions for conservation biologists. Given a limited amount of resources available for conservation is it preferable to protect the existing isolated patches of habitat or to buy back land to get the largest possible continuous piece of land. In rare cases a conservation reliant species may gain some measure of disease protection by being distributed in isolated habitats. This ongoing debate is often referred to as SLOSS (Single Large or Several Small).\n\nOne solution to the problem of habitat fragmentation is to link the fragments by preserving or planting corridors of native vegetation. In some cases, a bridge or underpass may be enough to join two fragments. This has the potential to mitigate the problem of isolation but not the loss of interior habitat. \n\nAnother mitigation measure is the enlargement of small remnants in order to increase the amount of interior habitat. This may be impractical since developed land is often more expensive and could require significant time and effort to restore.\n\nThe best solution is generally dependent on the particular species or ecosystem that is being considered. More mobile species, like most birds, do not need connected habitat while some smaller animals, like rodents, may be more exposed to predation in open land. These questions generally fall under the headings of metapopulations island biogeography.\n\nForest fragmentation is a form of habitat fragmentation where forests are reduced (either naturally or man-made) to relatively small, isolated patches of forest known as forest fragments or forest remnants. The intervening matrix that separates the remaining woodland patches can be natural open areas, farmland, or developed areas. Following the principles of island biogeography, remnant woodlands act like islands of forest in a sea of pastures, fields, subdivisions, shopping malls, etc. These fragments will then begin to undergo the process of ecosystem decay.\n\nForest fragmentation also includes less subtle forms of discontinuities such as utility right-of-ways (ROWs). Utility ROWs are of ecological interest because they have become pervasive in many forest communities, spanning areas as large as 5 million acres in the United States. Utility ROWs include electricity transmission ROWs, gas pipeline and telecommunication ROWs. Electricity transmission ROWs are created to prevent vegetation interference with transmission lines. Some studies have shown that electricity transmission ROWs harbor more plant species than adjoining forest areas, due to alterations in the microclimate in and around the corridor. Discontinuities in forest areas associated with utility right-of-ways can serve as biodiversity havens for native bees and grassland species, as the right-of-ways are preserved in an early successional stage.\n\nForest fragmentation is one of the greatest threats to biodiversity in forests, especially in the tropics. The problem of habitat destruction that caused the fragmentation in the first place is compounded by:\n\nThe effect of fragmentation on the flora and fauna of a forest patch depends on a) the size of the patch, and b) its degree of isolation. Isolation depends on the distance to the nearest similar patch, and the contrast with the surrounding areas. For example, if a cleared area is reforested or allowed to regenerate, the increasing structural diversity of the vegetation will lessen the isolation of the forest fragments. However, when formerly forested lands are converted permanently to pastures, agricultural fields, or human-inhabited developed areas, the remaining forest fragments, and the biota within them, are often highly isolated.\n\nForest patches that are smaller or more isolated will lose species faster than those that are larger or less isolated. A large number of small forest \"islands\" typically cannot support the same biodiversity that a single contiguous forest would hold, even if their combined area is much greater than the single forest. However, forest islands in rural landscapes greatly increase their biodiversity.\n\n\n", "id": "1259241", "title": "Habitat fragmentation"}
{"url": "https://en.wikipedia.org/wiki?curid=55777147", "text": "Primate Conservation (journal)\n\nPrimate Conservation is a journal published by the IUCN Species Survival Commission's Primate Specialist Group about the world's primates. First published as a mimeographed newsletter in 1981, the journal today publishes conservation research and papers on primate species, particularly status surveys and studies on distribution and ecology. Besides these regular papers, the journal has also been a significant place for primatologists to publish descriptions of new primate species in \"Primate Conservation\". \n\nFrom South America, this includes the Caquetá titi (\"Callicebus caquetensis\") described in 2010 and the Madidi titi (\"Plecturocebus aureipalatii\", Syn.: \"Callicebus aureipalatii\"). From the island of Madagascar, new lemur species scientifically described in the pages of the journal include the Montagne d'Ambre dwarf lemur or Andy Sabin's dwarf lemur (\"Cheirogaleus andysabini\"), the Ankarana dwarf lemur \"Cheirogaleus shethi,\" and two new spcies of mouse lemurs (\"Microcebus\").\n", "id": "55777147", "title": "Primate Conservation (journal)"}
{"url": "https://en.wikipedia.org/wiki?curid=1676889", "text": "Aeroplankton\n\nAeroplankton (or aerial plankton) are tiny lifeforms that float and drift in the air, carried by the current of the wind; they are the atmospheric analogue to oceanic plankton.\n\nMost of the living things that make up aeroplankton are very small to microscopic in size, and many can be difficult to identify because of their tiny size. Scientists can collect them for study in traps and sweep nets from aircraft, kites or balloons. \n\nThe aeroplankton comprises numerous microbes, including viruses, about 1000 different species of bacteria, around 40,000 varieties of fungi, and hundreds of species of protists, algae, mosses and liverworts that live some part of their life cycle as aeroplankton, often as spores, pollen, and wind-scattered seeds. \n\nA large number of small animals, mainly arthropods (such as insects and spiders), are also carried upwards into the atmosphere by air currents and may be found floating several thousand feet up. Aphids, for example, are frequently found at high altitudes.\n\nMany species of spiders deliberately use the wind to propel themselves. The spider will find a vantage point (such as a branch, fence or surface) and, pointing its abdomen upward, eject fine threads of silk from its spinnerets. At some point, the force exerted by moving air upon the silk threads is great enough to launch the spider into the air. This is called ballooning. Such ballooning spiders (e.g. Linyphiidae) are capable of drifting many miles away from where they started. The flexibility of their silk draglines can aid the aerodynamics of their flight, causing the spiders to drift an unpredictable and sometimes long distance.\n\n\n", "id": "1676889", "title": "Aeroplankton"}
{"url": "https://en.wikipedia.org/wiki?curid=1079126", "text": "Hock (anatomy)\n\nThe hock, or gambrel, is the joint between the tarsal bones and tibia of a digitigrade or unguligrade quadrupedal mammal, such as a horse, cat, or dog. This joint may include articulations between tarsal bones and the fibula in some species (such as cats), while in others the fibula has been greatly reduced and is only found as a vestigial remnant fused to the distal portion of the tibia (as in horses) . It is the anatomical homologue of the ankle of the human foot. While homologous joints occur in other tetrapods, the term is generally restricted to mammals, particularly long-legged domesticated species.\n\nAlthough the \"tarsus\" refers specifically to the bones and joints of the hock, most people working with horses refer to the \"hock\" in such a way to include the bones, joints, and soft tissue of the area. The hock is especially important in equine anatomy, due to the great strain it receives when the horse is worked. Jumping, and movements that require collection, are some of the more stressful activities.\n\nIn the horse, the hock consists of multiple joints, namely:\n\nIn the horse, the hock consists of the following bones\n\n\n\"Also see equine conformation\"\n\nBecause the hock takes a great deal of strain in all performance disciplines, correct conformation is essential if the horse is to have a sound and productive working life. Common conformational defects include sickle hocks, post-legged conformation/straight hocks, cow hocks, and bowed hocks. Depending on the use of the horse, some defects may be more acceptable than others.\n\n", "id": "1079126", "title": "Hock (anatomy)"}
{"url": "https://en.wikipedia.org/wiki?curid=4757", "text": "Bestiary\n\nA bestiary, or bestiarum vocabulum, is a compendium of beasts. Originating in the Ancient world, bestiaries were made popular in the Middle Ages in illustrated volumes that described various animals and even rocks. The natural history and illustration of each beast was usually accompanied by a moral lesson. This reflected the belief that the world itself was the Word of God, and that every living thing had its own special meaning. For example, the pelican, which was believed to tear open its breast to bring its young to life with its own blood, was a living representation of Jesus. The bestiary, then, is also a reference to the symbolic language of animals in Western Christian art and literature.\n\nThe earliest bestiary in the form in which it was later popularized was an anonymous 2nd century Greek volume called the \"Physiologus\", which itself summarized ancient knowledge and wisdom about animals in the writings of classical authors such as Aristotle's \"Historia Animalium\" and various works by Herodotus, Pliny the Elder, Solinus, Aelian and other naturalists.\n\nFollowing the \"Physiologus\", Saint Isidore of Seville (Book XII of the \"Etymologiae\") and Saint Ambrose expanded the religious message with reference to passages from the Bible and the Septuagint. They and other authors freely expanded or modified pre-existing models, constantly refining the moral content without interest or access to much more detail regarding the factual content. Nevertheless, the often fanciful accounts of these beasts were widely read and generally believed to be true. A few observations found in bestiaries, such as the migration of birds, were discounted by the natural philosophers of later centuries, only to be rediscovered in the modern scientific era.\n\nMediaeval bestiaries are remarkably similar in sequence of the animals of which they treat. Bestiaries were particularly popular in England and France around the 12th century and were mainly compilations of earlier texts. The Aberdeen Bestiary is one of the best known of over 50 manuscript bestiaries surviving today.\n\nBestiaries influenced early heraldry in the Middle Ages, giving ideas for charges and also for the artistic form. Bestiaries continue to give inspiration to coats of arms created in our time.\n\nTwo illuminated Psalters, the Queen Mary Psalter (British Library Ms. Royal 2B, vii) and the Isabella Psalter (State Library, Munich), contain full Bestiary cycles. The bestiary in the Queen Mary Psalter is found in the \"marginal\" decorations that occupy about the bottom quarter of the page, and are unusually extensive and coherent in this work. In fact the bestiary has been expanded beyond the source in the Norman bestiary of Guillaume le Clerc to ninety animals. Some are placed in the text to make correspondences with the psalm they are illustrating.\n\nThe Italian artist Leonardo da Vinci also made his own bestiary.\n\nA \"volucrary\" is a similar collection of the symbols of birds that is sometimes found in conjunction with bestiaries. The most widely known volucrary in the Renaissance was Johannes de Cuba's \"Gart der Gesundheit\" which describes 122 birds and which was printed in 1485.\n\nMedieval bestiaries often contained detailed descriptions and illustrations of species native to Western Europe, exotic animals and what in modern times are considered to be imaginary animals. Descriptions of the animals included the physical characteristics associated with the creature, although these were often physiologically incorrect, along with the Christian morals that the animal represented. The description was then normally followed with an artistic illustration of the animal as described in the bestiary.\n\nBestiaries were organized in different ways based upon the text. The descriptions could be organized by animal groupings, such as terrestrial and marine creatures, or presented in an alphabetical manner. However, the texts gave no distinction between existing and imaginary animals. Descriptions of creatures such as dragons, unicorns, basilisk, griffin and caladrius were common in such works and found intermingled amongst accounts of bears, boars, deer, lions, and elephants.\n\nThis lack of separation has often been associated with the assumption that people during this time believed in what the modern period classifies as nonexistent or \"imaginary creatures\". However, this assumption is currently under debate, with various explanations being offered.\n\nSome scholars, such as Pamela Gravestock, have written on the theory that Medieval people didn't actually think such creatures existed but instead focused on the belief in the importance of the Christian morals these creatures represented and that the importance of the moral didn't change regardless if the animal existed or not.\n\nThe contents of Medieval bestiaries were often obtained and created from combining older textual sources and accounts of animals, such as the \"Physiologus\", with newer observations and writings. In this way, the content of such written works was constantly added to and built upon.\n\nIn modern times, artists such as Henri de Toulouse-Lautrec and Saul Steinberg have produced their own bestiaries. Jorge Luis Borges wrote a contemporary bestiary of sorts, the \"Book of Imaginary Beings\", which collects imaginary beasts from bestiaries and fiction. Nicholas Christopher wrote a literary novel called \"The Bestiary\" (Dial, 2007) that describes a lonely young man's efforts to track down the world's most complete bestiary. John Henry Fleming's \"Fearsome Creatures of Florida\" (Pocol Press, 2009) borrows from the medieval bestiary tradition to impart moral lessons about the environment. Caspar Henderson's The Book of Barely Imagined Beings (Granta 2012, Chicago University Press 2013), subtitled \"A 21st Century Bestiary,\" explores how humans imagine animals in a time of rapid environmental change. In July 2014, Jonathan Scott wrote The Blessed Book of Beasts, Eastern Christian Publications, featuring 101 animals from the various translations of the Bible, in keeping with the tradition of the bestiary found in the writings of the Saints, including Saint John Chrysostom.\n\n\n", "id": "4757", "title": "Bestiary"}
{"url": "https://en.wikipedia.org/wiki?curid=2212081", "text": "Inspissation\n\nInspissation is the process of thickening by dehydration.\n\nInspissation is the process used when heating high-protein containing media; for example to enable recovery of bacteria for testing. Once inspissation has occurred, any stained bacteria, such as Mycobacteria, can then be isolated.\n\nA \"Serum inspissation\" or \"Fractional sterilization\" is a process of heating an article on 3 successive days as follows:\nIn cystic fibrosis, inspissation of secretions in the respiratory and gastrointestinal tracts is a major mechanism of causing the disease.\n\n", "id": "2212081", "title": "Inspissation"}
{"url": "https://en.wikipedia.org/wiki?curid=2907440", "text": "Gloger's rule\n\nGloger's rule is an ecogeographical rule which states that within a species of endotherms, more heavily pigmented forms tend to be found in more humid environments, e.g. near the equator. It was named after the zoologist Constantin Wilhelm Lambert Gloger, who first remarked upon this phenomenon in 1833 in a review of covariation of climate and avian plumage color. (Erwin Stresemann notes that the idea was already expressed by Pallas in \"Zoographia Rosso-Asiatica\" (1811)) Gloger found that birds in more humid habitats tended to be darker than their relatives from regions with higher aridity. Over 90% of 52 North American bird species studies conform to this rule.\n\nOne explanation of Gloger's rule in the case of birds appears to be the increased resistance of dark feathers to feather- or hair-degrading bacteria such as \"Bacillus licheniformis\". Feathers in humid environments have a greater bacterial load, and humid environments are more suitable for microbial growth; dark feathers or hair are more difficult to break down. More resilient eumelanins – dark brown to black – are deposited in hot and humid regions, whereas in arid regions, pheomelanins – reddish to sandy color – predominate due to the benefit of crypsis.\n\nAmong mammals, there is a marked tendency in equatorial and tropical regions to have a darker skin color than poleward relatives. In this case, the underlying cause is probably the need to better protect against excessive solar UV radiation at lower latitudes. However absorption of a certain amount of UV radiation is necessary for the production of certain vitamins, notably vitamin D (\"see also\" Osteomalacia).\n\nThis principle is also vividly demonstrated among human populations. Populations that evolved in sunnier environments closer to the equator tend to be darker-pigmented than populations originating farther from the equator. There are exceptions, however; among the most well known are the Tibetans and Inuit, who have darker skin than might be expected from their native latitudes. In the first case, this is apparently an adaptation to the extremely high UV irradiation on the Tibetan Plateau, whereas in the second case, the necessity to absorb UV radiation is alleviated by the Inuit's diet naturally rich in vitamin D.\n\n\n", "id": "2907440", "title": "Gloger's rule"}
{"url": "https://en.wikipedia.org/wiki?curid=2664877", "text": "Modified triadan system\n\nThe Modified Triadan System is a scheme of dental nomenculature that can be used widely across different animal species. It has now gained wide acceptance and is used worldwide among veterinary surgeons.\n\nEach tooth is given a three digit number.\n\nThe first number relates to the quadrant of the mouth in which the tooth lies. \n\nIf it is a deciduous tooth that is being referred to then a different number is used as below.\n\nThe second and third numbers refer to the location of the tooth from front to back (or rostral to caudal).\n\nThis starts at 01 and goes up to 11 for many species depending on the total number of teeth.\n\nFor diagrams of the modified triadan system in dogs see .\n\nBelow is a diagram of the modified triadan system in horses.\n\n\n", "id": "2664877", "title": "Modified triadan system"}
