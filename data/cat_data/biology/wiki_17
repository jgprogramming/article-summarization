{"url": "https://en.wikipedia.org/wiki?curid=12339", "text": "Genetically modified organism\n\nA genetically modified organism (GMO) is any organism whose genetic material has been altered using genetic engineering techniques (i.e., a genetically \"engineered\" organism). GMOs are used to produce many medications and genetically modified foods and are widely used in scientific research and the production of other goods. The term GMO is very close to the technical legal term, 'living modified organism', defined in the Cartagena Protocol on Biosafety, which regulates international trade in living GMOs (specifically, \"any living organism that possesses a novel combination of genetic material obtained through the use of modern biotechnology\").\n\nA more specifically defined type of GMO is a \"transgenic organism.\" This is an organism whose genetic makeup has been altered by the addition of genetic material from an unrelated organism. This should not be confused with the more general way in which \"GMO\" is used to classify genetically altered organisms, as typically GMOs are organisms whose genetic makeup has been altered without the addition of genetic material from an unrelated organism.\n\nThe first genetically modified mouse was created in 1974, and the first plant was produced in 1983.\nGenetic modification involves the mutation, insertion, or deletion of genes. Inserted genes usually come from a different species in a form of horizontal gene-transfer. In nature this can occur when exogenous DNA penetrates the cell membrane for any reason. This can be accomplished artificially by:\n\n\nOther methods exploit natural forms of gene transfer, such as the ability of \"Agrobacterium\" to transfer genetic material to plants,\nor the ability of lentiviruses to transfer genes to animal cells.\n\nHumans have domesticated plants and animals since around 12,000 BCE, using selective breeding or artificial selection (as contrasted with natural selection). The process of selective breeding, in which organisms with desired traits (and thus with the desired genes) are used to breed the next generation and organisms lacking the trait are not bred, is a precursor to the modern concept of genetic modification. Various advancements in genetics allowed humans to directly alter the DNA and therefore genes of organisms. In 1972 Paul Berg created the first recombinant DNA molecule when he combined DNA from a monkey virus with that of the lambda virus.\n\nHerbert Boyer and Stanley Cohen made the first genetically modified organism (GMO) in 1973. They took a gene from a bacterium that provided resistance to the antibiotic kanamycin, inserted it into a plasmid and then induced another bacteria to uptake the plasmid. The bacteria was then able to survive in the presence of kanamycin. Boyer and Cohen expressed other genes in bacteria. This included genes from the toad Xenopus laevis in 1974, creating the first GMO expressing a gene from an organism from different kingdom.\nIn 1974 Rudolf Jaenisch created a transgenic mouse by introducing foreign DNA into its embryo, making it the world’s first transgenic animal. However it took another eight years before transgenic mice were developed that passed the transgene to their offspring. Genetically modified mice were created in 1984 that carried cloned oncogenes, predisposing them to developing cancer. Mice with genes knocked out (knockout mouse) were created in 1989. The first transgenic livestock were produced in 1985 and the first animal to synthesise transgenic proteins in their milk were mice, engineered to produce human tissue plasminogen activator in 1987.\n\nIn 1983 the first genetically engineered plant was developed by Michael W. Bevan, Richard B. Flavell and Mary-Dell Chilton. They infected tobacco with \"Agrobacterium\" transformed with an antibiotic resistance gene and through tissue culture techniques were able to grow a new plant containing the resistance gene. The gene gun was invented in 1987, allowing transformation of plants not susceptible to \"Agrobacterium\" infection. In 2000, Vitamin A-enriched golden rice, was the first plant developed with increased nutrient value.\n\nIn 1976 Genentech, the first genetic engineering company was founded by Herbert Boyer and Robert Swanson; a year later, the company produced a human protein (somatostatin) in \"E.coli\". Genentech announced the production of genetically engineered human insulin in 1978. The insulin produced by bacteria, branded humulin, was approved for release by the Food and Drug Administration in 1982. In 1988 the first human antibodies were produced in plants. In 1987, the ice-minus strain of \"Pseudomonas syringae\" became the first genetically modified organism to be released into the environment when a strawberry field and a potato field in California were sprayed with it.\n\nThe first genetically modified crop, an antibiotic-resistant tobacco plant, was produced in 1982. China was the first country to commercialize transgenic plants, introducing a virus-resistant tobacco in 1992. In 1994 Calgene attained approval to commercially release the Flavr Savr tomato, the first genetically modified food. Also in 1994, the European Union approved tobacco engineered to be resistant to the herbicide bromoxynil, making it the first genetically engineered crop commercialized in Europe. An insect resistant Potato was approved for release in the USA in 1995, and by 1996 approval had been granted to commercially grow 8 transgenic crops and one flower crop (carnation) in 6 countries plus the EU.\n\nIn 2010, scientists at the J. Craig Venter Institute, announced that they had created the first synthetic bacterial genome. They named it Synthia and it was the world's first synthetic life form.\n\nThe first genetically modified animal to be commercialised was the GloFish, a Zebra fish with a fluorescent gene added that allows it to glow in the dark under ultraviolet light. The first genetically modified animal to be approved for food use was AquAdvantage salmon in 2015. The salmon were transformed with a growth hormone-regulating gene from a Pacific Chinook salmon and a promoter from an ocean pout enabling it to grow year-round instead of only during spring and summer.\n\nGMOs are used in biological and medical research, production of pharmaceutical drugs, experimental medicine (e.g. gene therapy and vaccines against the Ebola virus), and agriculture (e.g. golden rice, resistance to herbicides), with developing uses in conservation. The term \"genetically modified organism\" does not always imply, but can include, targeted insertions of genes from one species into another. For example, a gene from a jellyfish, encoding a fluorescent protein called GFP, or green fluorescent protein, can be physically linked and thus co-expressed with mammalian genes to identify the location of the protein encoded by the GFP-tagged gene in the mammalian cell. Such methods are useful tools for biologists in many areas of research, including those who study the mechanisms of human and other diseases or fundamental biological processes in eukaryotic or prokaryotic cells.\n\nBacteria were the first organisms to be modified in the laboratory, due to the relative ease of modifying their genetics.\n\nThey continue to be important model organisms for experiments in genetic engineering. In the field of synthetic biology, they have been used to test various synthetic approaches, from synthesizing genomes to creating novel nucleotides.\n\nThese organisms are now used for several purposes, and are particularly important in producing large amounts of pure human proteins for use in medicine.\n\nGenetically modified bacteria are used to produce the protein insulin to treat diabetes. Similar bacteria have been used to produce biofuels, clotting factors to treat haemophilia, and human growth hormone to treat various forms of dwarfism.\n\nIn 2017 researchers genetically modified a virus to express spinach defensin proteins. The virus was injected into orange trees to combat citrus greening disease that had reduced orange production 70% since 2005.\n\nIn addition, various genetically engineered micro-organisms are routinely used as sources of enzymes for the manufacture of a variety of processed foods. These include alpha-amylase from bacteria, which converts starch to simple sugars, chymosin from bacteria or fungi, which clots milk protein for cheese making, and pectinesterase from fungi, which improves fruit juice clarity.\n\nTransgenic plants have been engineered for scientific research, to create new colours in plants, and to create different crops.\n\nIn research, plants are engineered to help discover the functions of certain genes. One way to do this is to knock out the gene of interest and see what phenotype develops. Another strategy is to attach the gene to a strong promoter and see what happens when it is over expressed. A common technique used to find out where the gene is expressed is to attach it to GUS or a similar reporter gene that allows visualisation of the location.'\nAfter thirteen years of collaborative research, an Australian company – Florigene, and a Japanese company – Suntory, created a blue rose (actually lavender or mauve) in 2004. The genetic engineering involved three alterations – adding two genes, and interfering with another. One of the added genes was for the blue plant pigment delphinidin cloned from the pansy. The researchers then used RNA interference (RNAi) technology to depress all color production by endogenous genes by blocking a crucial protein in color production, called dihydroflavonol 4-reductase (DFR), and adding a variant of that protein that would not be blocked by the RNAi but that would allow the delphinidin to work. The roses are sold in Japan, the United States, and Canada. Florigene has also created and sells lavender-colored carnations that are genetically engineered in a similar way.\n\nSimple plants and plant cells have been genetically engineered for production of biopharmaceuticals in bioreactors as opposed to cultivating plants in open fields. Work has been done with duckweed \"Lemna minor\", the algae \"Chlamydomonas reinhardtii\" and the moss \"Physcomitrella patens\".\nAn Israeli company, Protalix, has developed a method to produce therapeutics in cultured transgenic carrot and tobacco cells. Protalix and its partner, Pfizer, received FDA approval to market its drug Elelyso, a treatment for Gaucher's disease, in 2012.\n\nGenetically modified crops (GM crops, or biotech crops) are plants used in agriculture, the DNA of which has been modified using genetic engineering techniques. In most cases the aim is to introduce a new trait to the plant which does not occur naturally in the species. Examples in food crops include resistance to certain pests, diseases, or environmental conditions, reduction of spoilage, or resistance to chemical treatments (e.g. resistance to a herbicide), or improving the nutrient profile of the crop. Examples in non-food crops include production of pharmaceutical agents, biofuels, and other industrially useful goods, as well as for bioremediation.\n\nFarmers have widely adopted GM technology. Between 1996 and 2013, the total surface area of land cultivated with GM crops increased by a factor of 100, from to 1,750,000 km (432 million acres). 10% of the world's croplands were planted with GM crops in 2010. In the US, by 2014, 94% of the planted area of soybeans, 96% of cotton and 93% of corn were genetically modified varieties. In recent years GM crops expanded rapidly in developing countries. In 2013 approximately 18 million farmers grew 54% of worldwide GM crops in developing countries.\n\nFor discussions of issues about GM crops and GM food, see the Controversies section below and the article on genetically modified food controversies.\n\nCisgenesis, sometimes also called intragenesis, is a product designation for a category of genetically engineered plants. A variety of classification schemes have been proposed that order genetically modified organisms based on the nature of introduced genotypical changes rather than the process of genetic engineering.\n\nWhile some genetically modified plants are developed by the introduction of a gene originating from distant, sexually incompatible species into the host genome, cisgenic plants contain genes that have been isolated either directly from the host species or from sexually compatible species. The new genes are introduced using recombinant DNA methods and gene transfer. Some scientists hope that the approval process of cisgenic plants might be simpler than that of proper transgenics, but it remains to be seen.\n\nGenetically modified organisms have been proposed to aid conservation of plant species threatened by extinction. Many trees face the threat of invasive plants and diseases, such as the emerald ash borer in North American and the fungal disease, Ceratocystis platani, in European plane trees. A suggested solution to increase the resilience of threatened tree species is to genetically modify individuals by transferring resistant genes. Papaya trees are an example of a species that was successfully conserved using genetic modification. The papaya ringspot virus (PRSV) devastated papaya trees in Hawaii in the twentieth century until transgenic papaya plants were given pathogen-derived resistance.\n\nHowever, genetic modification for conservation in plants remains mainly speculative and further experimentation is needed before the technique can be widely implemented. A main concern with using genetic modification for conservation purposes is that a transgenic species may no longer bear enough resemblance to the original species to truly claim that the original species is being conserved. Instead, the transgenic species may be genetically different enough to be considered a new species, thus diminishing the conservation worth of genetic modification.\n\nGenetically modified mammals are an important category of genetically modified organisms. Ralph L. Brinster and Richard Palmiter developed the techniques responsible for transgenic mice, rats, rabbits, sheep, and pigs in the early 1980s, and established many of the first transgenic models of human disease, including the first carcinoma caused by a transgene. The process of genetically engineering animals is a slow, tedious, and expensive process. However, new technologies are making genetic modifications easier and more precise.\n\nThe first transgenic (genetically modified) animal was produced by injecting DNA into mouse embryos then implanting the embryos in female mice.\n\nGenetically modified animals currently being developed can be placed into six different broad classes based on the intended purpose of the genetic modification:\n\nTransgenic animals are used as experimental models to perform phenotypic and for testing in biomedical research.\n\nGenetically modified (genetically engineered) animals are becoming more vital to the discovery and development of cures and treatments for many serious diseases. By altering the DNA or transferring DNA to an animal, we can develop certain proteins that may be used in medical treatment. Stable expressions of human proteins have been developed in many animals, including sheep, pigs, and rats. Human-alpha-1-antitrypsin, which has been tested in sheep and is used in treating humans with this deficiency and transgenic pigs with human-histo-compatibility have been studied in the hopes that the organs will be suitable for transplant with less chances of rejection.\n\nScientists have genetically engineered several organisms, including some mammals, to include green fluorescent protein (GFP), first observed in the jellyfish, \"Aequorea victoria\" in 1962, for medical research purposes (Chalfie, Shimoura, and Tsien were awarded the Nobel prize in Chemistry in 2008 for the discovery and development of GFP). For example, fluorescent pigs have been bred to study human organ transplants (xenotransplantation), regenerating ocular photoreceptor cells, and other topics. In 2011 a Japanese-American team created green-fluorescent cats to find therapies for HIV/AIDS and other diseases as feline immunodeficiency virus (FIV) is related to HIV.\n\nIn 2009, scientists in Japan announced that they had successfully transferred a gene into a primate species (marmosets) and produced a stable line of breeding transgenic primates for the first time. Their first research target for these marmosets was Parkinson's disease, but they were also considering amyotrophic lateral sclerosis and Huntington's disease.\n\nWithin the field known as pharming, intensive research has been conducted to develop transgenic animals that produce biotherapeutics. On 6 February 2009, the U.S. Food and Drug Administration approved the first human biological drug produced from such an animal, a goat. The drug, ATryn, is an anticoagulant which reduces the probability of blood clots during surgery or childbirth. It is extracted from the goat's milk.\n\nSome animals are also genetically modified so that they can provide organs that are suitable and safe to transplant into humans (xenotransplants). An example are pigs that are genetically modified so that their organs can no longer carry retroviruses (which can pose a danger to humans, when transplanted into them).\nOther genetically modified pigs have had alpha galactosidase transferase knocked out and fortified with hCD46 and the hTM molecule. Pig lungs from genetically modified pigs for instance are already being considered for transplantation into humans. Besides use of genetic modification to allow the providing of safer animal organs for transplantation, genetic modification can also be used to allow the animal to grow human organs inside their body. Such animals, which are hence composed of a mixture of cells from more than one species, are called \"chimera's\" One project, undertaken by Pablo Ross of the University of California, involves the growing of a human pancreas inside a pig.\n\nIn 2006, a pig was engineered to produce omega-3 fatty acids through the expression of a roundworm gene.\n\nEnviropig was a genetically enhanced line of Yorkshire pigs in Canada created with the capability of digesting plant phosphorus more efficiently than conventional Yorkshire pigs. The project ended in 2012. These pigs produced the enzyme phytase, which breaks down the indigestible phosphorus, in their saliva. The enzyme was introduced into the pig chromosome by pronuclear microinjection. With this enzyme, the animal is able to digest cereal grain phosphorus. The use of these pigs would reduce the potential of water pollution since they excrete from 30 to 70.7% less phosphorus in manure depending upon the age and diet. The lower concentrations of phosphorus in surface runoff reduces algal growth, because phosphorus is the limiting nutrient for algae. Because algae consume large amounts of oxygen, it can result in dead zones for fish.\n\nIn 2011, Chinese scientists generated dairy cows genetically engineered with genes from human beings to produce milk that would be the same as human breast milk. This could potentially benefit mothers who cannot produce breast milk but want their children to have breast milk rather than formula. Aside from milk production, the researchers claim these transgenic cows to be identical to regular cows. Two months later scientists from Argentina presented Rosita, a transgenic cow incorporating two human genes, to produce milk with similar properties as human breast milk. In 2012, researchers from New Zealand also developed a genetically engineered cow that produced allergy-free milk.\n\nGoats have been genetically engineered to produce milk with strong spiderweb-like silk proteins in their milk.\n\nGene therapy, uses genetically modified viruses to deliver genes which can cure disease in humans. Although gene therapy is still relatively new, it has had some successes. It has been used to treat genetic disorders such as severe combined immunodeficiency, and Leber's congenital amaurosis. Treatments are also being developed for a range of other currently incurable diseases, such as cystic fibrosis, sickle cell anemia, Parkinson's disease, cancer, diabetes, heart disease and muscular dystrophy.\n\nGenetically modified organisms have been used to conserve European wild rabbits in the Iberian peninsula and Australia. In both cases, the genetically modified organism used was a myxoma virus, but for opposite purposes: to protect the endangered population in Europe with immunizations and to regulate the overabundant population in Australia with contraceptives.\n\nIn the Iberian peninsula, the European wild rabbit population has experienced a sharp decline from viral diseases and overhunting. To protect the species from viral diseases, the myxoma virus was genetically modified to immunize the rabbits. The European wild rabbit population in Australia faces the opposite problem: lack of natural predators has made the introduced species invasive. The same myxoma virus was genetically modified to lower fertility in the Australian rabbit population.\n\nGenetically modified fish are used for scientific research and as pets, and are being considered for use as food and as aquatic pollution sensors.\n\nGM fish are widely used in basic research in genetics and development. Two species of fish, zebrafish and medaka, are most commonly modified because they have optically clear chorions (membranes in the egg), rapidly develop, and the 1-cell embryo is easy to see and microinject with transgenic DNA.\n\nThe GloFish is a patented brand of genetically modified (GM) fluorescent zebrafish with bright red, green, and orange fluorescent color. Although not originally developed for the ornamental fish trade, it became the first genetically modified animal to become publicly available as a pet when it was introduced for sale in 2003. They were quickly banned for sale in California.\n\nGM fish have been developed with promoters driving an over-production of \"all fish\" growth hormone for use in the aquaculture industry to increase the speed of development and potentially reduce fishing pressure on wild stocks. This has resulted in dramatic growth enhancement in several species, including salmon, trout and tilapia. AquaBounty Technologies, a biotechnology company working on bringing a GM salmon to market, claims that their GM AquAdvantage salmon can mature in half the time as wild salmon. AquaBounty applied for regulatory approval to market their GM salmon in the US, and was approved in November 2015. On 25 November 2013 Canada approved commercial scale production and export of GM Salmon eggs but they are not approved for human consumption in Canada.\n\nSeveral academic groups have been developing GM zebrafish to detect aquatic pollution. The lab that originated the GloFish discussed above originally developed them to change color in the presence of pollutants, to be used as environmental sensors. A lab at University of Cincinnati has been developing GM zebrafish for the same purpose, as has a lab at Tulane University.\n\nRecent research on pain in fish has resulted in concerns being raised that genetic-modifications induced for scientific research may have detrimental effects on the welfare of fish.\n\nGenetically modified frogs are used for scientific research and are widely used in basic research including genetics and early development. Two species of frog, \"Xenopus laevis\" and \"Xenopus tropicalis\", are most commonly used.\n\nGM frogs are also being used as pollution sensors, especially for endocrine disrupting chemicals.\n\nIn biological research, transgenic fruit flies (\"Drosophila melanogaster\") are model organisms used to study the effects of genetic changes on development. Fruit flies are often preferred over other animals due to their short life cycle, low maintenance requirements, and relatively simple genome compared to many vertebrates.\n\nIn 2010, scientists created \"malaria-resistant mosquitoes\" in the laboratory. The World Health Organization estimated that malaria killed almost one million people in 2008. Genetically modified male mosquitoes containing a lethal gene have been developed to combat the spread of dengue fever and the Zika virus. \"Aedes aegypti\" mosquitoes, the single most important carrier of dengue fever and the Zika virus, were reduced by 80% in a 2010 trial of these GM mosquitoes in the Cayman Islands and by 90% in a 2015 trial in Bahia, Brazil. In comparison, the Florida Keys Mosquito Control District has achieved only 30%-60% population reduction with traps and pesticide spraying. In 2016 FDA approved a genetically modified mosquito intervention for Key West, Florida. UK firm Oxitec proposed the release of millions of modified male (non-biting) mosquitoes to compete with wild males for mates. The males are engineered so that their offspring die before maturing, helping to eradicate mosquito-borne disease. Final approval was to be based on a local referendum to be held in November. Andrea Crisanti, a molecular biologist at Imperial College in London is working on ways to stop the A. gambiae mosquito from transmitting disease.\n\nA strain of \"Pectinophora gossypiella\" (Pink bollworm) has been genetically engineered to express a red fluorescent protein. This allows researchers to monitor bollworms that have been sterilized by radiation and released to reduce bollworm infestation. The strain has been field tested for over three years and has been approved for release.\n\nCnidaria such as \"Hydra\" and the sea anemone \"Nematostella vectensis\" are attractive model organisms to study the evolution of immunity and certain developmental processes. An important technical breakthrough was the development of procedures for generation of stable transgenic hydras and sea anemones by embryo microinjection.\n\nThe regulation of genetic engineering concerns the approaches taken by governments to assess and manage the risks associated with the use of genetic engineering technology and the development and release of genetically modified organisms (GMO), including genetically modified crops and genetically modified fish. There are differences in the regulation of GMOs between countries, with some of the most marked differences occurring between the USA and Europe. Regulation varies in a given country depending on the intended use of the products of the genetic engineering. For example, a crop not intended for food use is generally not reviewed by authorities responsible for food safety. The European Union differentiates between approval for cultivation within the EU and approval for import and processing. While only a few GMOs have been approved for cultivation in the EU a number of GMOs have been approved for import and processing. The cultivation of GMOs has triggered a debate about the market for GMOs in Europe. Depending on the coexistence regulations, incentives for cultivation of GM crops differ.\n\nThere is controversy over GMOs, especially with regard to their use in producing food. The dispute involves buyers, biotechnology companies, governmental regulators, nongovernmental organizations, and scientists. The key areas of controversy related to GMO food are whether GM food should be labeled, the role of government regulators, the effect of GM crops on health and the environment, the effect on pesticide resistance, the impact of GM crops for farmers, and the role of GM crops in feeding the world population. In 2014, sales of products that had been labeled as non-GMO grew 30 percent to $1.1 billion.\n\nThere is a scientific consensus that currently available food derived from GM crops poses no greater risk to human health than conventional food, but that each GM food needs to be tested on a case-by-case basis before introduction. Nonetheless, members of the public are much less likely than scientists to perceive GM foods as safe. The legal and regulatory status of GM foods varies by country, with some nations banning or restricting them, and others permitting them with widely differing degrees of regulation.\n\nNo reports of ill effects have been proven in the human population from ingesting GM food. Although labeling of GMO products in the marketplace is required in many countries, it is not required in the United States and no distinction between marketed GMO and non-GMO foods is recognized by the US FDA. In a May 2014 article in \"The Economist\" it was argued that, while GM foods could potentially help feed 842 million malnourished people globally, laws such as the one passed in Vermont, to require labeling of foods containing genetically modified ingredients, could have the unintended consequence of interrupting the process of spreading GM technologies to impoverished countries that suffer with food security problems.\n\nThe Organic Consumers Association, and the Union of Concerned Scientists, and Greenpeace stated that risks have not been adequately identified and managed, and they have questioned the objectivity of regulatory authorities. Some health groups say there are unanswered questions regarding the potential long-term impact on human health from food derived from GMOs, and propose mandatory labeling or a moratorium on such products. Concerns include contamination of the non-genetically modified food supply, effects of GMOs on the environment and nature, the rigor of the regulatory process, and consolidation of control of the food supply in companies that make and sell GMOs, or concerns over the use of herbicides with glyphosate.\n\n", "id": "12339", "title": "Genetically modified organism"}
{"url": "https://en.wikipedia.org/wiki?curid=4128491", "text": "Dot blot\n\nA dot blot (or slot blot) is a technique in molecular biology used to detect biomolecules, and for detecting, analyzing, and identifying proteins. It represents a simplification of the northern blot, Southern blot, or western blot methods. In a dot blot the biomolecules to be detected are not first separated by electrophoresis. Instead, a mixture containing the molecule to be detected is applied directly on a membrane as a dot, and then is spotted through circular templates directly onto the membrane or paper substrate. This differs from the western blot because protein samples are not separated electrophoretically. This is then followed by detection by either nucleotide probes (for a northern blot and southern blot) or antibodies (for a western blot).\n\nThe technique offers significant savings in time, as chromatography or gel electrophoresis, and the complex blotting procedures for the gel are not required. However, it offers no information on the size of the target biomolecule. Furthermore, if two molecules of different sizes are detected, they will still appear as a single dot. Dot blots therefore can only confirm the presence or absence of a biomolecule (or biomolecules) which can be detected by the DNA probes or the antibody.\n\nBecause a dot blot does not require any specific instruments, lots of dot blot assays are developed using antibodies with high specificity to detect different protein targets. Dot blot is also used to evaluate or screen the effectiveness of the antibodies. \n\nThe following is a general outline of an antigen-antibody-antibody dot blot assay protocol. Specific concentrations need to be determined for each assay. Other types of dot blot assays, such as antibody-antigen-antibody can be performed in a similar fashion. \n\n1. spot 1-2 microliters of antigen on to a piece of membrane, let air dry for 30 min or longer;\n\n2. incubate with blocking buffer for 30 min -2 hr;\n\n3. rinse with rinsing buffer, 3x5 min;\n\n4. incubate with primary antibody, 30 min - 2 hr;\n\n5. rinse with rinsing buffer, 3x5 min;\n\n6. incubate with enzyme-labeled secondary antibody, 30 min - 2 hr;\n\n7. rinse with rinsing buffer, 3x5 min;\n\n8. add enzyme substrate, wait 5-10 min;\n\n9. detect by eye or with colorimetric or chemiluminescent imaging system.\n\nThe dot blot was originally performed on a piece of nitrocellulose membrane or PVDF membrane. After the protein samples are spotted onto the membrane, the membrane is placed in a plastic container and sequentially incubated in blocking buffer, antibody solution, or rinsing buffer on a shaker. Finally, for chemiluminescence imaging, the piece of membrane is wrapped in a transparent plastic film filled with enzyme substrate. \n\nA vacuum-based dot blot apparatus (Bio-dot or Bio-slot from BioRad) has been used to facilitate the rinsing and incubating process by using vacuum to extract the solution from underneath the membrane, which is assembled in between several layers of plates to ensure good seal between sample wells, hold waste solution, and deliver suction force. For chemiluminescence signal detection, the apparatus is dissembled and the membrane is taken out and wrapped in a transparent plastic film filled with enzyme substrate. \n\nVitrozm's 96 well Zoom Blot method uses an absorption plug to wick away the solution from the membranes, which are individually assembled in each well. The Zoom Plate is a disposable self-standing device, without any external vacuum or set up apparatus, which allows dot blots to be performed much easier and faster. The user never needs to handle a piece of membrane as in older methods. Zoom Blot's 96 well plate format allows convenient signal detection and quantification using 96 well plate reader or imaging system.\n\nThe sensitive dot blot test can be used to detect the \"Chlamydia trachomatis\" infection and \nother sexually transmitted diseases. The dot blot is used to detect Antidiacyltrehalose antibodies in tuberculosis patients and typhoid fever.\n\n\n\n", "id": "4128491", "title": "Dot blot"}
{"url": "https://en.wikipedia.org/wiki?curid=474372", "text": "Two-dimensional gel electrophoresis\n\nTwo-dimensional gel electrophoresis, abbreviated as 2-DE or 2-D electrophoresis, is a form of gel electrophoresis commonly used to analyze proteins. Mixtures of proteins are separated by two properties in two dimensions on 2D gels. 2-DE was first independently introduced by O'Farrell and Klose in 1975.\n\n2-D electrophoresis begins with electrophoresis in the first dimension and then separates the molecules perpendicularly from the first to create an electropherogram in the second dimension. In electrophoresis in the first dimension, molecules are separated linearly according to their isoelectric point. In the second dimension, the molecules are then separated at 90 degrees from the first electropherogram according to molecular mass. Since it is unlikely that two molecules will be similar in two distinct properties, molecules are more effectively separated in 2-D electrophoresis than in 1-D electrophoresis.\n\nThe two dimensions that proteins are separated into using this technique can be isoelectric point, protein complex mass in the native state, and protein mass.\n\nSeparation of the proteins by isoelectric point is called isoelectric focusing (IEF). Thereby, a gradient of pH is applied to a gel and an electric potential is applied across the gel, making one end more positive than the other. At all pH values other than their isoelectric point, proteins will be charged. If they are positively charged, they will be pulled towards the more negative end of the gel and if they are negatively charged they will be pulled to the more positive end of the gel. The proteins applied in the first dimension will move along the gel and will accumulate at their isoelectric point; that is, the point at which the overall charge on the protein is 0 (a neutral charge).\n\nFor the analysis of the functioning of proteins in a cell, the knowledge of their cooperation is essential. Most often proteins act together in complexes to be fully functional. The analysis of this sub organelle organisation of the cell requires techniques conserving the native state of the protein complexes. In native polyacrylamide gel electrophoresis (native PAGE), proteins remain in their native state and are separated in the electric field following their mass and the mass of their complexes respectively. To obtain a separation by size and not by net charge, as in IEF, an additional charge is transferred to the proteins by the use of Coomassie Brilliant Blue or lithium dodecyl sulfate. After completion of the first dimension the complexes are destroyed by applying the denaturing SDS-PAGE in the second dimension, where the proteins of which the complexes are composed of are separated by their mass.\n\nBefore separating the proteins by mass, they are treated with sodium dodecyl sulfate (SDS) along with other reagents (SDS-PAGE in 1-D). This denatures the proteins (that is, it unfolds them into long, straight molecules) and binds a number of SDS molecules roughly proportional to the protein's length. Because a protein's length (when unfolded) is roughly proportional to its mass, this is equivalent to saying that it attaches a number of SDS molecules roughly proportional to the protein's mass. Since the SDS molecules are negatively charged, the result of this is that all of the proteins will have approximately the same mass-to-charge ratio as each other. In addition, proteins will not migrate when they have no charge (a result of the isoelectric focusing step) therefore the coating of the protein in SDS (negatively charged) allows migration of the proteins in the second dimension (SDS-PAGE, it is not compatible for use in the first dimension as it is charged and a nonionic or zwitterionic detergent needs to be used).\nIn the second dimension, an electric potential is again applied, but at a 90 degree angle from the first field. The proteins will be attracted to the more positive side of the gel (because SDS is negatively charged) proportionally to their mass-to-charge ratio. As previously explained, this ratio will be nearly the same for all proteins. The proteins' progress will be slowed by frictional forces. The gel therefore acts like a molecular sieve when the current is applied, separating the proteins on the basis of their molecular weight with larger proteins being retained higher in the gel and smaller proteins being able to pass through the sieve and reach lower regions of the gel.\n\nThe result of this is a gel with proteins spread out on its surface. These proteins can then be detected by a variety of means, but the most commonly used stains are silver and Coomassie Brilliant Blue staining. In the former case, a silver colloid is applied to the gel. The silver binds to cysteine groups within the protein. The silver is darkened by exposure to ultra-violet light. The amount of silver can be related to the darkness, and therefore the amount of protein at a given location on the gel. This measurement can only give approximate amounts, but is adequate for most purposes. Silver staining is 100x more sensitive than Coomassie Brilliant Blue with a 40-fold range of linearity.\n\nMolecules other than proteins can be separated by 2D electrophoresis. In supercoiling assays, coiled DNA is separated in the first dimension and denatured by a DNA intercalator (such as ethidium bromide or the less carcinogenic chloroquine) in the second. This is comparable to the combination of native PAGE /SDS-PAGE in protein separation.\n\nA common technique is to use an Immobilized pH gradient (IPG) in the first dimension. This technique is referred to as IPG-DALT. The sample is first separated onto IPG gel (which is commercially available) then the gel is cut into slices for each sample which is then equilibrated in SDS-mercaptoethanol and applied to an SDS-PAGE gel for resolution in the second dimension. Typically IPG-DALT is not used for quantification of proteins due to the loss of low molecular weight components during the transfer to the SDS-PAGE gel.\n\nSee Isoelectric focusing\n\n \n\nIn quantitative proteomics, these tools primarily analyze bio-markers by quantifying individual proteins, and showing the separation between one or more protein \"spots\" on a scanned image of a 2-DE gel. Additionally, these tools match spots between gels of similar samples to show, for example, proteomic differences between early and advanced stages of an illness. Software packages include Delta2D, ImageMaster, Melanie, PDQuest, Progenesis and REDFIN – among others. While this technology is widely utilized, the intelligence has not been perfected. For example, while PDQuest and Progenesis tend to agree on the quantification and analysis of well-defined well-separated protein spots, they deliver different results and analysis tendencies with less-defined less-separated spots.\n\nChallenges for automatic software-based analysis include incompletely separated (overlapping) spots (less-defined and/or separated), weak spots / noise (e.g., \"ghost spots\"), running differences between gels (e.g., protein migrates to different positions on different gels), unmatched/undetected spots, leading to missing values, mismatched spots\n, errors in quantification (several distinct spots may be erroneously detected as a single spot by the software and/or parts of a spot may be excluded from quantification), and differences in software algorithms and therefore analysis tendencies\n\nGenerated picking lists can be used for the automated in-gel digestion of protein spots, and subsequent identification of the proteins by mass spectrometry.\n\nFor an overview of the current approach for software analysis of 2DE gel images see or.\n\n\n", "id": "474372", "title": "Two-dimensional gel electrophoresis"}
{"url": "https://en.wikipedia.org/wiki?curid=49256492", "text": "Zfp82 zinc finger protein\n\nZFP82 zinc finger protein is a protein that in humans is encoded by the ZFP82 gene.\n", "id": "49256492", "title": "Zfp82 zinc finger protein"}
{"url": "https://en.wikipedia.org/wiki?curid=49253142", "text": "Zinc finger protein 112\n\nZinc finger protein 112 is a protein that in humans is encoded by the ZNF112 gene.\n", "id": "49253142", "title": "Zinc finger protein 112"}
{"url": "https://en.wikipedia.org/wiki?curid=49263113", "text": "Zinc finger protein 180\n\nZinc finger protein 180 is a protein that is encoded in humans by the ZNF180 gene.\n\nZinc finger proteins have been shown to interact with nucleic acids and to have diverse functions. The zinc finger domain is a conserved amino acid sequence motif containing two specifically positioned cysteines and two histidines that are involved in coordinating zinc. Kruppel-related proteins form one family of zinc finger proteins. See MIM 604749 for additional information on zinc finger proteins.\n", "id": "49263113", "title": "Zinc finger protein 180"}
{"url": "https://en.wikipedia.org/wiki?curid=49253092", "text": "Zinc finger protein 208\n\nZinc finger protein 208 is a protein that in humans is encoded by the ZNF208 gene.\n\nZinc finger proteins (ZNFs), such as ZNF208, bind DNA and, through this binding, regulate gene transcription. Most ZNFs contain conserved C2H2 motifs and are classified as Kruppel-type zinc fingers. A conserved protein motif, termed the Kruppel-associated box (KRAB) domain, mediates protein-protein interactions (Eichler et al., 1998 [PubMed 9724325]). See ZNF91 (MIM 603971) for further information on ZNFs.\n", "id": "49253092", "title": "Zinc finger protein 208"}
{"url": "https://en.wikipedia.org/wiki?curid=49253125", "text": "Zinc finger protein 226\n\nZinc finger protein 226 is a protein that in humans is encoded by the ZNF226 gene.\n", "id": "49253125", "title": "Zinc finger protein 226"}
{"url": "https://en.wikipedia.org/wiki?curid=49256520", "text": "Zinc finger protein 395\n\nZinc finger protein 395 is a protein that in humans is encoded by the ZNF395 gene.\n", "id": "49256520", "title": "Zinc finger protein 395"}
{"url": "https://en.wikipedia.org/wiki?curid=49253158", "text": "Zinc finger protein 426\n\nZinc finger protein 426 is a protein that in humans is encoded by the ZNF426 gene.\n\nKaposi's sarcoma-associated herpesvirus (KSHV) can be reactivated from latency by the viral protein RTA. The protein encoded by this gene is a zinc finger transcriptional repressor that interacts with RTA to modulate RTA-mediated reactivation of KSHV. While the encoded protein can repress KSHV reactivation, RTA can induce degradation of this protein through the ubiquitin-proteasome pathway to overcome the repression. Several transcript variants encoding different isoforms have been found for this gene.\n", "id": "49253158", "title": "Zinc finger protein 426"}
{"url": "https://en.wikipedia.org/wiki?curid=49240826", "text": "Zinc finger protein 557\n\nZinc finger protein 557 is a protein that in humans is encoded by the ZNF557 gene.\n", "id": "49240826", "title": "Zinc finger protein 557"}
{"url": "https://en.wikipedia.org/wiki?curid=49253170", "text": "Zinc finger protein 576\n\nZinc finger protein 576 is a protein that in humans is encoded by the ZNF576 gene.\n", "id": "49253170", "title": "Zinc finger protein 576"}
{"url": "https://en.wikipedia.org/wiki?curid=49253215", "text": "Zinc finger protein 613\n\nZinc finger protein 613 is a protein that in humans is encoded by the ZNF613 gene.\n", "id": "49253215", "title": "Zinc finger protein 613"}
{"url": "https://en.wikipedia.org/wiki?curid=49256509", "text": "Zinc finger protein 839\n\nZinc finger protein 839 is a protein that in humans is encoded by the ZNF839 gene.\n", "id": "49256509", "title": "Zinc finger protein 839"}
{"url": "https://en.wikipedia.org/wiki?curid=39619", "text": "Electroporation\n\nElectroporation, or electropermeabilization, is a microbiology technique in which an electrical field is applied to cells in order to increase the permeability of the cell membrane, allowing chemicals, drugs, or DNA to be introduced into the cell. In microbiology, the process of electroporation is often used to transform bacteria, yeast, or plant protoplasts by introducing new coding DNA. If bacteria and plasmids are mixed together, the plasmids can be transferred into the bacteria after electroporation, though depending on what is being transferred cell-penetrating peptides or CellSqueeze could also be used. Electroporation works by passing thousands of volts across a distance of one to two millimeters of suspended cells in an electroporation cuvette (1.0 – 1.5 kV, 250 – 750V/cm). Afterwards, the cells have to be handled carefully until they have had a chance to divide, producing new cells that contain reproduced plasmids. This process is approximately ten times more effective than chemical transformation.\n\nElectroporation is also highly efficient for the introduction of foreign genes into tissue culture cells, especially mammalian cells. For example, it is used in the process of producing knockout mice, as well as in tumor treatment, gene therapy, and cell-based therapy. The process of introducing foreign DNA into eukaryotic cells is known as transfection. Electroporation is highly effective for transfecting cells in suspension using electroporation cuvettes. Electroporation has proven efficient for use on tissues in vivo, for in utero applications as well as in ovo transfection. Adherent cells can also be transfected using electroporation, providing researchers with an alternative to trypsinizing their cells prior to transfection. One downside to electroporation, however, is that after the process the gene expression of over 7,000 genes can be affected. This can cause problems in studies where gene expression has to be controlled to ensure accurate and precise results.\n\nCell fusion is of interest not only as an essential process in cell biology, but also as a useful method in biotechnology and medicine. Artificially induced fusion can be used to investigate and treat different diseases, like diabetes regenerate axons of the central nerve system, and produce cells with desired properties, such as in cell vaccines for cancer immunotherapy. However, the first and most known application of cell fusion is production of monoclonal antibodies in hybridoma technology, where hybrid cell lines (hybridomas) are formed by fusing specific antibody-producing B lymphocytes with a myeloma (B lymphocyte cancer) cell line.\n\nElectroporation is performed with electroporators, purpose-built appliances which create an electrostatic field in a cell solution. The cell suspension is pipetted into a glass or plastic cuvette which has two aluminum electrodes on its sides. For bacterial electroporation, typically a suspension of around 50 microliters is used. Prior to electroporation, this suspension of bacteria is mixed with the plasmid to be transformed. The mixture is pipetted into the cuvette, the voltage and capacitance are set, and the cuvette is inserted into the electroporator. The process requires direct contact between the electrodes and the suspension. Immediately after electroporation, one milliliter of liquid medium is added to the bacteria (in the cuvette or in an Eppendorf tube), and the tube is incubated at the bacteria's optimal temperature for an hour or more to allow recovery of the cells and expression of the plasmid, followed by bacterial culture on agar plates.\n\nThe success of the electroporation depends greatly on the purity of the plasmid solution, especially on its salt content. Solutions with high salt concentrations might cause an electrical discharge (known as arcing), which often reduces the viability of the bacteria. For a further detailed investigation of the process, more attention should be paid to the output impedance of the porator device and the input impedance of the cells suspension (e.g. salt content).\n\nSince the cell membrane is not able to pass current (except in ion channels), it acts as an electrical capacitor. Subjecting membranes to a high-voltage electric field results in their temporary breakdown, resulting in pores that are large enough to allow macromolecules (such as DNA) to enter or leave the cell.\n\nThe first group to look at electroporation for medical applications was led by Lluis M Mir at the Institute Gustave Roussy. In this case, they looked at the use of reversible electroporation in conjunction with impermeable macromolecules. The first research looking at how nanosecond pulses might be used on human cells was conducted by researchers at Eastern Virginia Medical School and Old Dominion University, and published in 2003.\n\nWith regards to irreversible electroporation, the first successful treatment of malignant cutaneous tumors implanted in mice was completed in 2007 by a group of scientists who achieved complete tumor ablation in 12 out of 13 mice. They accomplished this by sending 80 pulses of 100 microseconds at 0.3 Hz with an electrical field magnitude of 2500 V/cm to treat the cutaneous tumors.\n\nA higher voltage of electroporation was found in pigs to irreversibly destroy target cells within a narrow range while leaving neighboring cells unaffected, and thus represents a promising new treatment for cancer, heart disease and other disease states that require removal of tissue. Irreversible electroporation (IRE) has since proven effective in treating human cancer, with surgeons at Johns Hopkins and other institutions now using the technology to treat pancreatic cancer previously thought to be unresectable.\n\nA recent technique called non-thermal irreversible electroporation (N-TIRE) has proven successful in treating many different types of tumors and other unwanted tissue. This procedure is done using small electrodes (about 1mm in diameter), placed either inside or surrounding the target tissue to apply short, repetitive bursts of electricity at a predetermined voltage and frequency. These bursts of electricity increase the resting transmembrane potential (TMP), so that nanopores form in the plasma membrane. When the electricity applied to the tissue is above the electric field threshold of the target tissue, the cells become permanently permeable from the formation of nanopores. As a result, the cells are unable to repair the damage and die due to a loss of homeostasis. N-TIRE is unique to other tumor ablation techniques in that it does not create thermal damage to the tissue around it.\n\nContrastingly, reversible electroporation occurs when the electricity applied with the electrodes is below the electric field threshold of the target tissue. Because the electricity applied is below the cells' threshold, it allows the cells to repair their phospholipid bilayer and continue on with their normal cell functions. Reversible electroporation is typically done with treatments that involve getting a drug or gene (or other molecule that is not normally permeable to the cell membrane) into the cell. Not all tissue has the same electric field threshold; therefore careful calculations need to be made prior to a treatment to ensure safety and efficacy.\n\nOne major advantage of using N-TIRE is that, when done correctly according to careful calculations, it only affects the target tissue. Proteins, the extracellular matrix, and critical structures such as blood vessels and nerves are all unaffected and left healthy by this treatment. This allows for a quicker recovery, and facilitates a more rapid replacement of dead tumor cells with healthy cells.\n\nBefore doing the procedure, scientists must carefully calculate exactly what needs to be done, and treat each patient on an individual case-by-case basis. To do this, imaging technology such as CT scans and MRI's are commonly used to create a 3D image of the tumor. From this information, they can approximate the volume of the tumor and decide on the best course of action including the insertion site of electrodes, the angle they are inserted in, the voltage needed, and more, using software technology. Often, a CT machine will be used to help with the placement of electrodes during the procedure, particularly when the electrodes are being used to treat tumors in the brain.\n\nThe entire procedure is very quick, typically taking about five minutes. The success rate of these procedures is high and is very promising for future treatment in humans. One disadvantage to using N-TIRE is that the electricity delivered from the electrodes can stimulate muscle cells to contract, which could have lethal consequences depending on the situation. Therefore, a paralytic agent must be used when performing the procedure. The paralytic agents that have been used in such research are successful; however, there is always some risk, albeit slight, when using anesthetics.\n\nA more recent technique has been developed called high-frequency irreversible electroporation (H-FIRE). This technique uses electrodes to apply bipolar bursts of electricity at a high frequency, as opposed to unipolar bursts of electricity at a low frequency. This type of procedure has the same tumor ablation success as N-TIRE. However, it has one distinct advantage, H-FIRE does not cause muscle contraction in the patient and therefore there is no need for a paralytic agent.\n\nElectroporation can also be used to help deliver drugs or genes into the cell by applying short and intense electric pulses that transiently permeabilize cell membrane, thus allowing transport of molecules otherwise not transported through a cellular membrane. This procedure is referred to as electrochemotherapy when the molecules to be transported are chemotherapeutic agents or gene electrotransfer when the molecule to be transported is DNA. Scientists from Karolinska Institutet and the University of Oxford use electroporation of exosomes to deliver siRNAs, antisense oligonucleotides, chemotherapeutic agents and proteins specifically to neurons after inject them systemically (in blood). Because these exosomes are able to cross the blood brain barrier, this protocol could solve the problem of poor delivery of medications to the central nervous system, and potentially treat Alzheimer's, Parkinson's Disease and brain cancer, among other conditions.\n\nElectroporation allows cellular introduction of large highly charged molecules such as DNA which would never passively diffuse across the hydrophobic bilayer core. This phenomenon indicates that the mechanism is the creation of nm-scale water-filled holes in the membrane. Although electroporation and dielectric breakdown both result from application of an electric field, the mechanisms involved are fundamentally different. In dielectric breakdown the barrier material is ionized, creating a conductive pathway. The material alteration is thus chemical in nature. In contrast, during electroporation the lipid molecules are not chemically altered but simply shift position, opening up a pore which acts as the conductive pathway through the bilayer as it is filled with water.\n\nElectroporation is a dynamic phenomenon that depends on the local transmembrane voltage at each point on the cell membrane. It is generally accepted that for a given pulse duration and shape, a specific transmembrane voltage threshold exists for the manifestation of the electroporation phenomenon (from 0.5 V to 1 V). This leads to the definition of an electric field magnitude threshold for electroporation (E). That is, only the cells within areas where E≧E are electroporated. If a second threshold (E) is reached or surpassed, electroporation will compromise the viability of the cells, \"i.e.\", irreversible electroporation (IRE).\nElectroporation is a multi-step process with several distinct phases. First, a short electrical pulse must be applied. Typical parameters would be 300–400 mV for < 1 ms across the membrane (note- the voltages used in cell experiments are typically much larger because they are being applied across large distances to the bulk solution so the resulting field across the actual membrane is only a small fraction of the applied bias). Upon application of this potential the membrane charges like a capacitor through the migration of ions from the surrounding solution. Once the critical field is achieved there is a rapid localized rearrangement in lipid morphology. The resulting structure is believed to be a \"pre-pore\" since it is not electrically conductive but leads rapidly to the creation of a conductive pore. Evidence for the existence of such pre-pores comes mostly from the \"flickering\" of pores, which suggests a transition between conductive and insulating states. It has been suggested that these pre-pores are small (~3 Å) hydrophobic defects. If this theory is correct, then the transition to a conductive state could be explained by a rearrangement at the pore edge, in which the lipid heads fold over to create a hydrophilic interface. Finally, these conductive pores can either heal, resealing the bilayer or expand, eventually rupturing it. The resultant fate depends on whether the critical defect size was exceeded which in turn depends on the applied field, local mechanical stress and bilayer edge energy.\n", "id": "39619", "title": "Electroporation"}
{"url": "https://en.wikipedia.org/wiki?curid=16002442", "text": "DNA adenine methyltransferase identification\n\nDamID (DNA adenine methyltransferase identification) is a molecular biology protocol used to map the binding sites of DNA- and chromatin-binding proteins in eukaryotes. DamID identifies binding sites by expressing the proposed DNA-binding protein as a fusion protein with DNA methyltransferase. Binding of the protein of interest to DNA localizes the methyltransferase in the region of the binding site. Adenosine methylation does not occur naturally in eukaryotes and therefore adenine methylation in any region can be concluded to have been caused by the fusion protein, implying the region is located near a binding site. DamID is an alternate method to ChIP-on-chip.\n\nN6-methyladenine (m6A) is the product of the addition of a methyl group (CH) at position 6 of the adenine. This modified nucleotide is absent from the vast majority of eukaryotes, but is widespread in bacterial genomes, as part of the restriction modification or DNA repair systems. In \"Escherichia coli\", adenine methylation is catalyzed by the adenine methyltransferase Dam (DNA adenine methyltransferase), which catalyses adenine methylation exclusively in the palindromic sequence GATC. Ectopic expression of Dam in eukaryotic cells leads to methylation of adenine in GATC sequences without any other noticeable side effect.\n\nBased on this, DamID consists in fusing Dam to a protein of interest (usually a protein that interacts with DNA such as transcription factors) or a chromatin component. The protein of interest thus targets Dam to its cognate \"in vivo\" binding site, resulting in the methylation of neighboring GATCs. The presence of m6A, coinciding with the binding sites of the proteins of interest, is revealed by \"methyl PCR\".\n\nIn this assay the genome is digested by DpnI, which cuts only methylated GATCs. Double-stranded adapters with a known sequence are then ligated to the ends generated by DpnI. A PCR with primers matching the adaptors is then carried out, leading to the specific amplification of genomic fragments flanked by methylated GATCs. In practice, ligation products are digested by DpnII prior PCR amplification. This enzyme cuts non-methylated GATCs, ensuring that only fragments flanked by \"consecutive\" methylated GATCs are amplified.\n\nChIP is an alternative method to assay protein binding at specific loci of the genome. Unlike ChIP, DamID does not require a specific antibody against the protein of interest. On the one hand, this allows to map proteins for which no such antibody is available. On the other hand, this makes it impossible to specifically map posttranslationally modified proteins.\n\nAnother fundamental difference is that ChIP assays where the protein of interests \"is\" at a given time, whereas DamID assays where it \"has been\". The reason is that m6A stays in the DNA after the Dam fusion protein goes away. For proteins that are either bound or unbound on their target sites this does not change the big picture. However, this can lead to strong differences in the case of proteins that slide along the DNA (\"e.g.\" RNA polymerase).\n\nDepending on how the experiment is carried out, DamID can be subject to plasmid methylation biases. Because plasmids are usually amplified in E. coli where Dam is naturally expressed, they are methylated on every GATC. In transient transfection experiments, the DNA of those plasmids is recovered along with the DNA of the transfected cells, meaning that fragments of the plasmid are amplified in the mePCR. Every sequence of the genome that shares homology or identity with the plasmid may thus appear to be bound by the protein of interest. In particular, this is true of the open reading frame of the protein of interest, which is present in both the plasmid and the genome. In microarray experiments, this bias can be used to ensure that the proper material was hybridized.\n\nApoptotic cells degrade their DNA in a characteristic nucleosome ladder pattern. This generates DNA fragments that can be ligated and amplified during the DamID procedure (van Steensel laboratory, unpublished observations). The influence of these nucleosomal fragments on the binding profile of a protein is not known.\n\nThe resolution of DamID is a function of the availability of GATC sequences in the genome. A protein can only be mapped within two consecutive GATC sites. The median spacing between GATC fragments is 205 bp in Drosophila (FlyBase release 5), 260 in mouse (Mm9), and 460 in human (HG19).\n\n", "id": "16002442", "title": "DNA adenine methyltransferase identification"}
{"url": "https://en.wikipedia.org/wiki?curid=48993834", "text": "Eukaryotic initiation factor 3\n\nEukaryotic initiation factor 3 (eIF3) is a multiprotein complex that functions during the initiation phase of eukaryotic translation. It is essential for most forms of cap-dependent and cap-independent translation initiation. In humans, eIF3 consists of 13 nonidentical subunits (eIF3a-m) with a combined molecular weight of ~800 kDa, making it the largest translation initiation factor. The eIF3 complex is broadly conserved across eukaryotes, but the conservation of individual subunits varies across organisms. For instance, while most mammalian eIF3 complexes are composed of 13 subunits, budding yeast's eIF3 has only six subunits (eIF3a, b, c, g, i, j).\n\neIF3 stimulates nearly all steps of translation initiation. eIF3 also appears to participate in other phases of translation, such as recycling, where it promotes the splitting of post-termination ribosomes. In specialized cases of reinitiation following uORFs, eIF3 may remain bounds to the ribosome through elongation and termination to promote subsequent initiation events.<ref name=\"Sonenberg/Hinnebusch Review\"></ref> Research has also indicated that eIF3 plays a role in programmed stop codon readthrough in yeast, by interacting with pre-termination complexes and interfering with decoding.\n\neIF3 binds the small ribosomal subunit (40S) at and near its solvent side and serves as a scaffold for several other initiation factors, the auxiliary factor DHX29, and mRNA. eIF3 is a component of the multifactor complex (MFC) and 43S and 48S preinitiation complexes (PICs). The interactions of eIF3 with other initiation factors can vary amongst species; for example, mammalian eIF3 directly interacts with the eIF4F complex (via eIF4G), while budding yeast lacks this connection. However, both mammalian and yeast eIF3 independently bind eIF1, eIF4B, and eIF5.\n\nSeveral subunits of eIF3 contain RNA recognition motifs (RRMs) and other RNA binding domains to form a multisubunit RNA binding interface through which eIF3 interacts with cellular and viral IRES mRNA, including the HCV IRES. eIF3 has also been shown to specifically bind mA modified RNA within 5'UTRs to promote cap-independent translation.\n\nAll five core subunits of budding yeast's eIF3 are present in heat-induced stress granules, along with several other translation factors.\n\nA functional eIF3 complex can be purified from native sources, or reconstituted from recombinantly expressed subunits. Individual subunits have been structurally characterized by X-ray crystallography and NMR, while complexes have been characterized by Cryo-EM. No structure of complete human eIF3 is available, but the nearly-full complex has been determined at medium resolution in the context of the 43S PIC. The structural core of mammalian eIF3 is often described as a five-lobed particle with anthropomorphic features, composed largely of the PCI/MPN octamer. The PCI domains are named for structural similarities between the proteasome cap (P), the COP9 signalosome (C), and eIF3 (I), while the MPN domains are named for structural similarity to the Mpr1-PadI N-terminal domains.\n\neIF3 serves as a hub for cellular signaling through S6K1 and mTOR/Raptor. In particular, eIF3 is bound by S6K1 in its inactive state, and activated mTOR/Raptor binds to eIF3 and phosphorylates S6K1 to promote its release from eIF3. Phosphorylated S6K1 is then free to phosphorylate a number of its own targets, including eIF4B, thus serving as a mechanism of translational control.\n\nIndividual subunits of eIF3 are overexpressed (a, b, c, h, i, and m) and underexpressed (e, f) in multiple human cancers. eIF3 has also been shown to bind a specific set of cell proliferation mRNAs and regulate their translation. eIF3 also functions in the life cycles of a number of important human pathogens, including HIV and HCV. In particular, the d-subunit of eIF3 is a substrate of HIV protease, and genetic knockdown of eIF3 subunits d, e, or f results in increased viral infectivity for unknown reasons.\n\nThe eIF3 subunits exist at equal stoichiometry within the complex, with the exception of eIF3J, which is loosely bound and non-essential for viability in several species. The subunits were originally organized alphabetically by molecular weight in mammals (A as the highest), but the arrangement of molecular weight can vary between species.\nMolecular weight of human subunits.\n\n", "id": "48993834", "title": "Eukaryotic initiation factor 3"}
{"url": "https://en.wikipedia.org/wiki?curid=49528672", "text": "Duplex sequencing\n\nDuplex sequencing is a library preparation and analysis method for next-generation sequencing (NGS) platforms that employs random tagging of double stranded DNA to detect mutations with higher accuracy and lower error rate. This method uses degenerate molecular tags in addition to sequencing adapters to recognize reads originating from each strand of DNA. The generated sequencing reads then will be analyzed using two methods: single strand consensus sequences (SSCSs) and Duplex consensus sequences (DCSs) assembly. Duplex sequencing theoretically can detect mutations with frequencies as low as 5 x 10 that is more than 10,000 fold higher in accuracy compared to the conventional next-generation sequencing methods.\n\nThe estimated error rate of standard next-generation sequencing platforms is 10 - 10 per base call. With this error rate billions of base calls that are produced by NGS will results in millions of the errors. The errors are introduced during sample preparation and sequencing such as polymerase , sequencing and image analysis errors. While the NGS platforms error rate is admissible to some applications such as detection of clonal variants, it is a major limit for applications that require higher accuracy for detection of low frequency variants such as detection of intra-organismal mosaicism, subclonal variants in genetically heterogeneous cancers or circulating tumor DNA.\n\nSeveral techniques have been developed that increase accuracy of NGS platforms such as barcoding techniques and circle sequencing method. The data generated by these methods the same as NGS platforms originate from single strand of DNA and therefore the errors that are introduced during PCR amplification, tissue processing or DNA extraction can still be distinguished as a true variant. Duplex sequencing method solve this problem by taking advantage of complementary nature of two strands of DNA and confirming only variants that are present in both strands of DNA. Since the probability of two errors happening at the same exact base pair in both strands and resulting in a complementary basepair is very low, duplex sequencing increases the accuracy of sequencing significantly.\n\nDuplex sequencing tagged adapters can be used in combination with majority of NGS adapters. In the figures and workflow section of this article Illumina sequencing adapters are used as an example in accordance to the original published protocol.\nTwo oligonucleotides are used for this step (Figure 1: Adapter oligos). One of the oligonucleotides contains a 12 nucleotide single stranded random tag sequence followed by a fixed 5' nucleotide sequence (Black sequence in figure 1). In this step oligonucleotides are annealed in a complementary region by incubation at the required temporal condition.\n\nThe adapters that annealed successfully are extended and synthesized by a DNA polymerase to complete a double stranded adapter containing complementary tags (Figure 1).\n\nThe extended double stranded adapters are cleaved by HpyCH4III at a specific located at 3’ side of the tag sequence and will results in a 3’-dT overhang that will be ligated to the 3’-dA overhang on DNA libraries in adapter ligation step (Figure 1).\n\nDouble stranded DNA is sheared using one of the methods: Sonication, enzymatic digestion or nebulization. Fragments are size selected using Ampure XP beads. Gel-based size selection is not recommended for this method since it can cause melting of DNA double strands and DNA damage as the results of UV exposure. The size selected fragments of DNA are subjected to 3’-end-dA-tailing.\n\nIn this step two tagged adapters are ligated from 3’-dT-tails to 3’-dA-tails on both sides of double stranded DNA library fragments. This process results in double stranded library fragments that contain two random tags in each side (Figure 1 and 2). The \"DNA:adapter\" ratio is crucial in determining the success of ligation.\n\nIn the last step of duplex sequencing library preparation, Illumina sequencing adapters are added to the tagged double stranded libraries by PCR amplification using primers containing sequencing adapters. During PCR amplification both complementary strands of DNA are amplified and generate two types of PCR products. Product 1 derive from strand 1 which have a unique tag sequence (called α in the figure 2) next to the Illumina adapter 1 and product 2 that have a unique tag (called β in the figure 2) next to illumina adapter 1. (Please note that in each strand, tag a is the retrograde, complementary version of tag b and vice versa). The libraries containing duplex tags and Illumina adapters are sequenced using Illumina TruSeq system. Reads that are originating from each single strand of DNA form a group of reads (tag families) that are sharing the same tag. The detected families of reads will be used in next step for analyzing sequencing data.\n\nAdapter ligation efficiency is very important in a successful duplex sequencing. Extra amount of libraries or adapters can affect the DNA:adapter balance and therefore result in inefficient ligation and excess amount of primer dimers, respectively. Therefore, it is important to keep the molar concentration of DNA:adapter to the optimal ratio that is 0.05.\n\nEfficiency of duplex sequencing depends on final number of DCSs which is directly related to number of reads in each family (family size). If the family size is too small then the DCS can not be assembled and if too many reads are sharing the same tag the data yield will be low. Family size is determined by the amount of DNA template for PCR amplification and dedicated sequencing lane fraction. The optimal tag family size is between 6 and 12 members. To obtain the optimal family size the amount of DNA template and dedicated sequencing lane fraction needs to be adjusted. The following formula takes into account the most important variables that can affect depth of coverage (N=40DG÷R) where \"N\" is number of reads, \"D\" is desired depth of coverage, \"G\" is size of DNA target in basepair and \"R\" is final read length.\n\nEach duplex sequencing read contains a fixed 5-nucleotide sequence (shown in figures in Black color) located upstream of the 12-nucleotide tag sequence. The reads are filtered out if they do not have the expected 5-nucleotide sequence or have more than nine identical or ambiguous bases within each tag. The two 12-nucleotide tags at each end of reads are combined and moved to the read header. Two families of reads are formed that originate from the two strands of DNA. One family contains reads with αβ header originating from strand 1 and the second family contains reads with βα header originating from strand 2 (Figure 2). Then the reads are trimmed by removing the fixed 5 bp sequence and 4 error prone nucleotides located at the sites of ligation and end repair. The remaining reads are assembled to consensus sequences using single strand consensus sequences (SSCSs) assembly and duplex consensus sequences (DCSs) assembly.\n\nTrimmed sequences from the previous step are aligned to the reference genome using Burrows-Wheeler aligner (BWA) and the unmapped reads are removed. The aligned reads that have the same 24 bp tag sequence and genomic region are detected and grouped together (Family αβ and βα in the figure 2). Each group represents a “tag family”. Tag families with lower than three members are removed from the analysis. To remove errors arise during PCR amplification or sequencing, mutations that are supported by less than 70% of the members (reads) are filtered out from the analysis. Then a consensus sequence is generated for each family using the identical sequences in each position of the remaining reads. The consensus sequence is called single strand consensus sequence (SSCS). The SSCS method increases the NGS accuracy to about 20 fold higher, however this method relies on the sequencing information from single strands of DNA and therefore is sensitive to the errors induced at the first round or before PCR amplification.\n\nThe reads from last step are realigned to the reference genome. In this method SSCS family pairs that have complementary tags will be grouped together (Family αβ and βα in figure 2). These reads originate from two complementary strands of DNA. High confidence sequences are selected based on the perfectly matched base calls of each family. The final sequence is called duplex consensus sequence (DCS). True mutations are those that match perfectly between complementary SSCSs. This step filter out remaining errors that raised during first round of PCR amplification or during sample preparation.\n\nHigh error rate (0.01-0.001) of standard NGS platforms that introduced during sample preparation or sequencing is a major limitation for detection of variants present in small fraction of cells. Due to the duplex tagging system and use of information in both strands of DNA, duplex sequencing has significantly decreased the error rate of sequencing about 10 million fold using both SSCS and DCS method.\n\nIt is challenging to identify rare variants accurately using standard NGS methods with the mutations rate of (10 - 10). Errors that happen early during sample preparation can be detected as rare variants. An example of such errors is C>A/G>T transversion that is detected in low frequencies using deep sequencing or targeted capture data and arise as the result of DNA oxidation during sample preparation. These types of false positive variants are filter out by duplex sequencing method since mutations need to be accurately matched in both strands of DNA to be validated as true mutations. Duplex sequencing can theoretically detect mutations with frequencies as low as 10 compare to 10 rate of standard NGS methods.\n\nAnother advantage of duplex sequencing is that it can be used in combination with majority of NGS platforms without making significant changes to the standard protocols.\n\nBecause duplex sequencing provide a significantly higher sequencing accuracy and uses information in both strands of DNA, this method needs a much higher sequencing depth and therefore is a costly approach. The high cost of duplex sequencing limits its application to targeted and amplicon sequencing at present time and will not be applicable for whole genome sequencing approaches. However, with decreasing cost of NGS, the application of duplex sequencing for larger DNA targets will be more feasible.\n\nDuplex sequencing is a new method and its efficiency was studied in limited applications such as detecting point mutations using targeted capture sequencing. More studies need to be performed to expand application and feasibility of duplex sequencing to more complex samples with large number of mutations, indels and copy number variations.\n\nDuplex sequencing and the significant increase of sequencing accuracy has important impacts on applications such as detection of rare human genetic variants, detection of subclonal mutations involve in mechanisms of resistance to therapy in genetically heterogeneous cancers, screening variants in circulating tumor DNA as a non-invasive biomarker and prenatal screening for detection of genetic abnormalities in fetus.\n\nAnother suggested application for duplex sequencing is detection of DNA/RNA copy numbers by estimating the relative frequency of variants. A method for counting PCR template molecules with application to next-generation sequencing.\n\nA list of required tools and packages for SSCS and DCS analysis can be found in software package.\n\n", "id": "49528672", "title": "Duplex sequencing"}
{"url": "https://en.wikipedia.org/wiki?curid=49497304", "text": "Eukaryotic initiation factor 4F\n\nEukaryotic initiation factor 4F (eIF4F) is a heterotrimeric protein complex that binds the 5' cap of messenger RNAs (mRNAs) to promote eukaryotic translation initiation. The eIF4F complex is composed of three non-identical subunits: the DEAD-box RNA helicase eIF4A, the cap-binding protein eIF4E, and the large \"scaffold\" protein eIF4G. The mammalian eIF4F complex was first described in 1983, and has been a major area of study into the molecular mechanisms of cap-dependent translation initiation ever since.\n\neIF4F is important for recruiting the small ribosomal subunit (40S) to the 5' cap of mRNAs during cap-dependent translation initiation. Components of the complex are also involved in cap-independent translation initiation; for instance, certain viral proteases cleave eIF4G to remove the eIF4E-binding region, thus inhibiting cap-dependent translation.\n\nStructures of eIF4F components have been solved individually and as partial complexes by a variety of methods, but no complete structure of eIF4F is currently available.\n\nIn mammals, the eIF4E•G•A trimeric complex can be directly purified from cells, while only the two subunit eIF4E•G can be purified from yeast cells. eIF4E binds the mG 5' cap and the eIF4G scaffold, connecting the mRNA 5' terminus to a hub of other initiation factors and mRNA. The interaction of eIF4G•A is thought to guide the formation of a single-stranded RNA landing pad for the 43S preinitiation complex (43S PIC) via eIF4A's RNA helicase activity.\n\nThe eIF4F proteins interact with a number of different binding partners, and there are multiple genetic isoforms of eIF4A, eIF4E, and eIF4G in the human genome. In mammals, eIF4F is bridged to the 40S ribosomal subunit by eIF3 via eIF4G, while budding yeast lacks this connection. Interactions between eIF4G and PABP are thought to mediate the circularization of mRNA particles.\nApproximate molecular weight for human proteins.\n\nThe eIF4E subunit of eIF4F is an important target of mTOR signaling through the eIF4E binding protein (4E-BP). Phosphorylation of 4E-BPs by mTOR prevents their binding to eIF4E, freeing eIF4E to bind eIF4G and participate in translation initiation.\n\n\n", "id": "49497304", "title": "Eukaryotic initiation factor 4F"}
{"url": "https://en.wikipedia.org/wiki?curid=253418", "text": "DNA computing\n\nDNA computing is a branch of computing which uses DNA, biochemistry, and molecular biology hardware, instead of the traditional silicon-based computer technologies. Research and development in this area concerns theory, experiments, and applications of DNA computing. The term \"molectronics\" has sometimes been used, but this term had already been used for an earlier technology, a then-unsuccessful rival of the first integrated circuits; this term has also been used more generally, for molecular-scale electronic technology.\n\nThis field was initially developed by Leonard Adleman of the University of Southern California, in 1994. Adleman demonstrated a proof-of-concept use of DNA as a form of computation which solved the seven-point Hamiltonian path problem. Since the initial Adleman experiments, advances have been made and various Turing machines have been proven to be constructible.\n\nWhile the initial interest was in using this novel approach to tackle NP-hard problems, it was soon realized that they may not be best suited for this type of computation, and several proposals have been made to find a \"killer application\" for this approach. In 1997, computer scientist Mitsunori Ogihara working with biologist Animesh Ray suggested one to be the evaluation of Boolean circuits and described an implementation.\n\nIn 2002, researchers from the Weizmann Institute of Science in Rehovot, Israel, unveiled a programmable molecular computing machine composed of enzymes and DNA molecules instead of silicon microchips. On April 28, 2004, Ehud Shapiro, Yaakov Benenson, Binyamin Gil, Uri Ben-Dor, and Rivka Adar at the Weizmann Institute announced in the journal Nature that they had constructed a DNA computer coupled with an input and output module which would theoretically be capable of diagnosing cancerous activity within a cell, and releasing an anti-cancer drug upon diagnosis.\n\nIn January 2013, researchers were able to store a JPEG photograph, a set of Shakespearean sonnets, and an audio file of Martin Luther King, Jr.'s speech I Have a Dream on DNA digital data storage.\n\nIn March 2013, researchers created a transcriptor (a biological transistor).\n\nIn August 2016, researchers used the CRISPR gene-editing system to insert a GIF of a galloping horse and rider into the DNA of living bacteria.\n\nThe organisation and complexity of all living beings is based on a coding system functioning with four key components of the DNA-molecule. Because of this, the DNA is very suited as a medium for data processing. According to different calculations a DNA-computer with one liter of fluid containing six grams of DNA could potentially have a memory capacity of 3072 exabytes. The theoretical maximum data transfer speed would also be enormous due to the massive parallelism of the calculations. Therefore, about 1000 petaFLOPS could be reached, while today's most powerful computers do not go above a few dozen (99 petaFLOPS being the current record).\n\nThe slow processing speed of a DNA-computer (the response time is measured in minutes, hours or days, rather than milliseconds) is compensated by its potential to make a high amount of multiple parallel computations. This allows the system to take a similar amount of time for a complex calculation as for a simple one. This is achieved by the fact that millions or billions of molecules interact with each other simultaneously. However, it is much harder to analyze the answers given by a DNA-Computer than by a digital one.\n\nIn 1994 Leonard Adleman presented the first prototype of a DNA-Computer. The was a test tube filled with 100 microliters of a DNA-solution. He managed to solve for example an instance of the directed Hamiltonian path problem.\n\nIn another experiment a simple version of the “travelling salesman problem” was “solved”. For this purpose, different DNA-fragments were created, each one of them representing a city that had to be visited. Every one of these fragments is capable of a linkage with the other fragments created. These DNA-fragments were produced and mixed in a test tube. Within seconds, the small fragments form bigger ones, representing the different travel routes. Through a chemical reaction (that lasts a few days), the DNA-fragments representing the longer routes were eliminated. The remains are the solution to the problem. However, current technical limitations prevent evaluation of the results. Therefore, the experiment isn’t suitable for application, but it is nevertheless a proof of concept.\n\nFirst results to these problems were obtained by Leonard Adleman (NASA JPL)\n\nIn 2002, J. Macdonald, D. Stefanovic and Mr. Stojanovic created a DNA computer able to play tic-tac-toe against a human player. The calculator consists of nine bins corresponding to the nine squares of the game. Each bin contains a substrate and various combinations of DNA enzymes. The substrate itself is composed of a DNA strand onto which was grafted a fluorescent chemical group at one end, and the other end, a repressor group. Fluorescence is only active if the molecules of the substrate are halved. The DNA enzyme simulate logical functions. For example, such a DNA will unfold if two specific types of DNA strand are introduced to reproduce the logic function AND.\n\nBy default, the computer is supposed to play first in the central square. The human player has then as a starter eight different types of DNA strands assigned to each of eight boxes that may be played. To indicate that box nr. i is being ticked, the human player pours into all bins the strands corresponding to input #i. These strands bind to certain DNA enzymes present in the bins, resulting in one of these two bins in the deformation of the DNA enzymes which binds to the substrate and cuts it. The corresponding bin becomes fluorescent, indicating which box is being played by the DNA computer. The various DNA enzymes are divided into various bins in such a way to ensure the victory of the DNA computer against the human player.\n\nDNA computing is a form of parallel computing in that it takes advantage of the many different molecules of DNA to try many different possibilities at once. For certain specialized problems, DNA computers are faster and smaller than any other computer built so far. Furthermore, particular mathematical computations have been demonstrated to work on a DNA computer. As an example, DNA molecules have been utilized to tackle the assignment problem.\n\nJian-Jun Shu and colleagues built a DNA GPS system and also conduct an experiment to show that magnetic fields can enhance charge transport through DNA (or protein), which may allow organisms to sense magnetic fields.\n\nAran Nayebi has provided a general implementation of Strassen's matrix multiplication algorithm on a DNA computer, although there are problems with scaling. In addition, Caltech researchers have created a circuit made from 130 unique DNA strands, which is able to calculate the square root of numbers up to 15. Recently, Salehi et al. showed that with a new coding referred to as \"\"fractional coding\"\", chemical reactions in general and DNA reactions in particular, can compute polynomials. In the fractional coding two DNA molecules are used to represent each variable.\n\nDNA computing does not provide any new capabilities from the standpoint of computability theory, the study of which problems are computationally solvable using different models of computation.\nFor example,\nif the space required for the solution of a problem grows exponentially with the size of the problem (EXPSPACE problems) on von Neumann machines, it still grows exponentially with the size of the problem on DNA machines.\nFor very large EXPSPACE problems, the amount of DNA required is too large to be practical.\n\nThere are multiple methods for building a computing device based on DNA, each with its own advantages and disadvantages. Most of these build the basic logic gates (AND, OR, NOT) associated with digital logic from a DNA basis. Some of the different bases include DNAzymes, deoxyoligonucleotides, enzymes, toehold exchange.\n\nCatalytic DNA (deoxyribozyme or DNAzyme) catalyze a reaction when interacting with the appropriate input, such as a matching oligonucleotide. These DNAzymes are used to build logic gates analogous to digital logic in silicon; however, DNAzymes are limited to 1-, 2-, and 3-input gates with no current implementation for evaluating statements in series.\n\nThe DNAzyme logic gate changes its structure when it binds to a matching oligonucleotide and the fluorogenic substrate it is bonded to is cleaved free. While other materials can be used, most models use a fluorescence-based substrate because it is very easy to detect, even at the single molecule limit. The amount of fluorescence can then be measured to tell whether or not a reaction took place. The DNAzyme that changes is then “used,” and cannot initiate any more reactions. Because of this, these reactions take place in a device such as a continuous stirred-tank reactor, where old product is removed and new molecules added.\n\nTwo commonly used DNAzymes are named E6 and 8-17. These are popular because they allow cleaving of a substrate in any arbitrary location. Stojanovic and MacDonald have used the E6 DNAzymes to build the MAYA I and MAYA II machines, respectively; Stojanovic has also demonstrated logic gates using the 8-17 DNAzyme. While these DNAzymes have been demonstrated to be useful for constructing logic gates, they are limited by the need for a metal cofactor to function, such as Zn or Mn, and thus are not useful in vivo.\n\nA design called a \"stem loop\", consisting of a single strand of DNA which has a loop at an end, are a dynamic structure that opens and closes when a piece of DNA bonds to the loop part. This effect has been exploited to create several logic gates. These logic gates have been used to create the computers MAYA I and MAYA II which can play tic-tac-toe to some extent.\n\nEnzyme based DNA computers are usually of the form of a simple Turing machine; there is analogous hardware, in the form of an enzyme, and software, in the form of DNA.\nBenenson, Shapiro and colleagues have demonstrated a DNA computer using the FokI enzyme and expanded on their work by going on to show automata that diagnose and react to prostate cancer: under expression of the genes PPAP2B and GSTP1 and an over expression of PIM1 and HPN. Their automata evaluated the expression of each gene, one gene at a time, and on positive diagnosis then released a single strand DNA molecule (ssDNA) that is an antisense for MDM2. MDM2 is a repressor of protein 53, which itself is a tumor suppressor. On negative diagnosis it was decided to release a suppressor of the positive diagnosis drug instead of doing nothing. A limitation of this implementation is that two separate automata are required, one to administer each drug. The entire process of evaluation until drug release took around an hour to complete. This method also requires transition molecules as well as the FokI enzyme to be present. The requirement for the FokI enzyme limits application \"in vivo\", at least for use in \"cells of higher organisms\". It should also be pointed out that the 'software' molecules can be reused in this case.\n\nDNA computers have also been constructed using the concept of toehold exchange. In this system, an input DNA strand binds to a sticky end, or toehold, on another DNA molecule, which allows it to displace another strand segment from the molecule. This allows the creation of modular logic components such as AND, OR, and NOT gates and signal amplifiers, which can be linked into arbitrarily large computers. This class of DNA computers does not require enzymes or any chemical capability of the DNA.\n\nDNA nanotechnology has been applied to the related field of DNA computing. DNA tiles can be designed to contain multiple sticky ends with sequences chosen so that they act as Wang tiles. A DX array has been demonstrated whose assembly encodes an XOR operation; this allows the DNA array to implement a cellular automaton which generates a fractal called the Sierpinski gasket. This shows that computation can be incorporated into the assembly of DNA arrays, increasing its scope beyond simple periodic arrays.\n\nA partnership between IBM and Caltech was established in 2009 aiming at \"DNA chips\" production. A Caltech group is working on the manufacturing of these nucleic-acid-based integrated circuits. One of these chips can compute whole square roots. A compiler has been written in Perl.\n\n\n", "id": "253418", "title": "DNA computing"}
{"url": "https://en.wikipedia.org/wiki?curid=1053589", "text": "Standard curve\n\nA standard curve, also known as a calibration curve, is a type of graph used as a quantitative research technique. Multiple samples with known properties are measured and graphed, which then allows the same properties to be determined for unknown samples by interpolation on the graph. The samples with known properties are the standards, and the graph is the standard curve. \n\nThe Bradford assay is a colorimetric assay that measures protein concentration. The reagent Coomassie Brilliant Blue turns blue when it binds to arginine and aromatic amino acids present in proteins, thus increasing the absorbance of the sample. The absorbance is measured using a spectrophotometer, at the maximum absorbance frequency (A) of the blue dye (which is 595 nm). In this case, the greater the absorbance, the higher the protein concentration.\n\nData for known concentrations of protein are used to make the standard curve, plotting concentration on the X axis, and the assay measurement on the Y axis. The same assay is then performed with samples of unknown concentration. To analyze the data, one locates the measurement on the Y-axis that corresponds to the assay measurement of the unknown substance and follows a line to intersect the standard curve. The corresponding value on the X-axis is the concentration of substance in the unknown sample.\n\n(pdf format) \n", "id": "1053589", "title": "Standard curve"}
{"url": "https://en.wikipedia.org/wiki?curid=50053777", "text": "Mammalian-wide interspersed repeat\n\nMammalian-wide interspersed repeats (MIRs) are transposable elements in the genomes of some organisms and belong to the group of Short interspersed nuclear elements (SINEs).\n\nMIRs are found in all mammals (including marsupials).\n\nIt is estimated that there are around 368,000 MIRs in the human genome.\n\nThe MIR consensus sequence is 260 basepairs long and has an A/T-rich 3' end.\n\nLike other Short interspersed nuclear elements (SINEs), MIR elements used the machinery of LINE elements for their propagation in the genome, which took place around 130 million years ago. They cannot retrotranspose anymore since the loss of activity of the required reverse transcriptase.\n\nMIR elements have been first described in 1989 and were first referred to as \"Mammalian interspersed repeats\" in 1992.\n", "id": "50053777", "title": "Mammalian-wide interspersed repeat"}
{"url": "https://en.wikipedia.org/wiki?curid=26139", "text": "Retroposon\n\nRetroposons are repetitive DNA fragments which are inserted into chromosomes after they had been reverse transcribed from any RNA molecule.\n\nIn contrast to retrotransposons, they never encode reverse transcriptase (RT) (but see below). Therefore, they are non-autonomous elements with regard to transposition activity (as opposed to transposons).\nNon-long terminal repeat (LTR) retrotransposons such as the human LINE1 elements are sometimes falsely referred to as retroposons. However, this depends on the author. For example, Howard Temin published the following definition: Retroposons encode RT but are devoid of long terminal repeats (LTRs), for example Long interspersed elements (LINEs). Retrotransposons also feature LTRs and retroviruses, in addition, are packaged as viral particles (virions). Retrosequences are non-autonomous elements devoid of RT. They are retroposed with the aid of the machinery of autonomous elements, such as LINEs; examples are Short interspersed nuclear elements (SINEs) or mRNA-derived retrogenes.\n\nRetroposition accounts for approximately 10,000 gene-duplication events in the human genome, of which approximately 2-10% are likely to be functional. Such genes are called retrogenes and represent a certain type of retroposon. A classical event is the retroposition of a spliced pre-mRNA molecule of the c-src gene into the proviral ancestor of the Rous Sarcoma Virus (RSV). The retroposed c-src pre-mRNA still contained a single intron and within RSV is now referred to as v-src gene.\n", "id": "26139", "title": "Retroposon"}
{"url": "https://en.wikipedia.org/wiki?curid=49982814", "text": "Short interspersed nuclear element\n\nShort Interspersed Nuclear Elements (SINEs) are non-autonomous, non-coding transposable elements (TEs) that are 50-500 base pairs long. The internal regions of SINEs originate from tRNA and remain highly conserved, suggesting positive pressure to preserve structure and function of SINEs. While SINEs are present in many species of vertebrates and invertebrates, SINEs are often lineage specific, making them useful markers of divergent evolution between species. Copy number variation and mutations in the SINE sequence make it possible to construct phylogenies based on differences in SINEs between species. SINEs are also implicated in certain types of genetic disease in humans and other eukaryotes.\n\nSINEs are classified as non-LTR retrotransposons because they do not contain long terminal repeats (LTRs). There are three types of SINEs common to vertebrates and invertebrates: CORE-SINEs, V-SINEs, and AmnSINEs. SINEs have 50-500 base pair internal regions which contain a tRNA-derived segment with A and B boxes that serve as an internal promoter for RNA polymerase III.\n\nSINEs use an RNA intermediate and reverse transcriptase to transpose into new parts of the genome. SINEs do not encode a functional reverse transcriptase and have to rely on the molecular machinery of other TEs for transposition. SINEs and other nuclear elements rely on the LINE-1 (L1) proteins for transposition throughout the genome. L1 is transcribed and retrotransposed most frequently in the germ-line and during early development; as a result SINEs move around the genome most during these periods. SINE transcription is down-regulated by transcription factors in somatic cells after early development, though stress can cause up-regulation of normally silent SINEs. SINEs can be transferred between individuals or species via horizontal transfer though a viral vector.\n\nInsertion of a SINE upstream of a coding region may result in exon shuffling or changes to the regulatory region of the gene. Insertion of a SINE into the coding sequence of a gene can have deleterious effects and unregulated transposition can cause genetic disease. The transposition and recombination of SINEs and other active nuclear elements is thought to be one of the major contributions of genetic diversity between lineages during speciation.\n\nAlu elements are the most common SINE in humans, with >1,000,000 copies throughout the genome. Alu element copy number differences can be used to distinguish between and construct phylogenies of primate species. Canines differ primarily in their abundance of SINEC_Cf repeats throughout the genome, rather than other gene or allele level mutations. These dog-specific SINEs may code for a splice acceptor site, altering the sequences that appear as exons or introns in each species.\n\nThere are >50 human diseases associated with SINEs. When inserted near or in exons, SINEs can cause improper splicing, become coding regions, or change the reading frame, often leading to disease phenotypes in humans and other animals. Insertion of Alu elements in the human genome is associated with breast cancer, colon cancer, leukemia, hemophilia, Dent’s Disease, cystic fibrosis, neurofibromatosis, and many others.\n", "id": "49982814", "title": "Short interspersed nuclear element"}
{"url": "https://en.wikipedia.org/wiki?curid=49736768", "text": "Blotting matrix\n\nA blotting matrix, in molecular biology and genetics, is the substrate onto which macromolecules, such as proteins, are transferred in a blot method. The matrices are generally chemically modified paper filters or microporous membrane filters. In a dot blot, macromolecules are applied directly to the matrix. Macromolecules can also be separated and transferred via gel electrophoresis.\n\nOne of the most common blotting matrices for protein analysis is nitrocellulose, which has a high affinity for proteins due to hydrophobic interactions. However, proteins with low molecular weight have a small affinity for nitrocellulose, limiting potential applications. This defect may be remedied by glutaraldehyde, which can covalently bond proteins to nitrocellulose. Another matrix is cellulose paper modified with diazophenylthiother, which can also facilitate covalent bonding of proteins. Nylon membranes are also used for protein blotting, although they may result in the binding of anionic dyes such as Coomassie blue and Amido black. Polyvinylidene fluoride membranes are also commonly used, due to their hydrophobicity.\n", "id": "49736768", "title": "Blotting matrix"}
{"url": "https://en.wikipedia.org/wiki?curid=50140772", "text": "International Molecular Exchange Consortium\n\nIn molecular biology the International Molecular Exchange Consortium (IMEx) is a group of the major public providers of molecular interaction data which collaborate to supply the user with a single, non-redundant set of molecular interactions, captured using a detailed curation model and made available in the PSI-MI standard formats. Participating databases include DIP, IntAct, the Molecular Interaction Database (MINT), MatrixDB, InnateDB, IID, HPIDB, UCL Cardiovascular Gene Annotation, MBInfo, Molecular Connections and UniProt. The group collates the interaction data and prevent duplicate entries in the various databases. The IMEx consortium also supports and contributes to the development of the HUPO-PSI-MI XML format, which is now widely implemented.\n\nIMEx website\n", "id": "50140772", "title": "International Molecular Exchange Consortium"}
{"url": "https://en.wikipedia.org/wiki?curid=43171894", "text": "Mal regulon\n\nThe Mal regulon are set of genes excited by catabolite activator protein commonly known as CAP. The genes code for maltose metabolizing enzymes. The genes encoding the enzymes are non-contiguous, and regulated by multiple promoters. Mal regulon is regulated by catabolite activator protein in a novel manner. The Mal promoters are regulated by a protein called MalT that requires ATP and maltotriose to function. Maltotriose is a maltose regulon inducer. MalEp and malKp are examples of mal promoters that depends on both CAP and MalT to function while pulAp, pulCp and malPp are examples of mal promoters that depends on MalT only and malTp is controlled only be CAP.\n", "id": "43171894", "title": "Mal regulon"}
{"url": "https://en.wikipedia.org/wiki?curid=36108896", "text": "Cathepsin zymography\n\nCathepsin zymography is a technique for quantifying enzymatic activity of the cathepsin family of cysteine proteases. It is based on SDS-PAGE whereby samples tested for cathepsin activity are loaded into a polyacrylamide gel and then separated by molecular weight. Gelatin is embedded in the gel itself, providing a substrate for the enzymes to hydrolyze. \n\nWhile the proform of cathepsins are generally stable, once activated, proteases such as cathepsin K are vulnerable to inactivation in neutral pH environments. This loss of activity complicates detection of these enzymes. Zymography, through its high sensitivity and multiplex nature allows for the simultaneous distinction between multiple cathepsins. Very small amounts of enzymatic activity can be elucidated and is capable of resolving a femtomole of cathepsin K activity.\n\nTissue samples are lysed in buffer supplemented with leupeptin to maintain enzymatic activity. The samples are standardized for protein concentration and then loaded into a polyacrylamide gel for SDS-PAGE. After separation of proteins by molecular weight is complete, the gel is incubated in a renaturing buffer to restore enzymatic activity. During loading, a non-reducing buffer was used to preserve protein disulfide bonds. After the renaturing period, the gel is then incubated in assay buffer to allow the now active cathepsins to proteolyze the gelatin impregnated in the gel. This process takes place overnight. The next day, the gel is analyzed for regions of gelatin degradation by coomassie blue staining. Patches of gel that are no longer blue following a destain wash are noted. These bands are then correlated to their respective molecular weights in order to identify which cathepsins were active in the sample.\n\nCathepsin K detection by zymography\n\nZymographic techniques for detection of cathepsins K, L, S, and V\n\nZymography for detection of cancer with cathepsins as biomarkers\n\n", "id": "36108896", "title": "Cathepsin zymography"}
{"url": "https://en.wikipedia.org/wiki?curid=50396981", "text": "Cellosaurus\n\nCellosaurus is an on-line knowledge resource on cell lines.\nIts scope includes immortalised cell lines, naturally immortal cell lines (example: embryonic stem cells) and finite life cell lines when those are distributed and used widely.\nThe Cellosaurus provides a wealth of manually curated information;\nfor each cell line it lists a recommended name, synonyms and the species of origin. \nOther types of information include standardised disease terminology (for cancer or genetic disorder cell lines),\nthe transformant used to immortalise a cell line, transfected or knocked-out genes, microsatellite instability, doubling time,\nimportant sequence variations, web links, publication references and cross-references to more than 70\ndifferent databases, ontologies, cell collections and other relevant resources.\n\nSince many cell lines used in research have been misidentified or contaminated,\nthe Cellosaurus keeps track of problematic cell lines, including all those listed in the\nInternational Cell Line Authentication Committee (ICLAC) tables.\n\nFor human as well as some dog cell lines, it provides short tandem repeat (STR) profile information,\nwhich is critical to the important process of cell line authentication.\n\nIt is developed by Amos Bairoch at the CALIPHO group of the Swiss Institute of Bioinformatics (SIB).\n\n", "id": "50396981", "title": "Cellosaurus"}
{"url": "https://en.wikipedia.org/wiki?curid=5097443", "text": "DNA supercoil\n\nDNA supercoiling refers to the over- or under-winding of a DNA strand, and is an expression of the strain on that strand. Supercoiling is important in a number of biological processes, such as compacting DNA, and by regulating access to the genetic code, DNA supercoiling strongly affects DNA metabolism and possibly gene expression. Additionally, certain enzymes such as topoisomerases are able to change DNA topology to facilitate functions such as DNA replication or transcription. Mathematical expressions are used to describe supercoiling by comparing different coiled states to relaxed B-form DNA.\n\nIn a \"relaxed\" double-helical segment of B-DNA, the two strands twist around the helical axis once every 10.4–10.5 base pairs of sequence. Adding or subtracting twists, as some enzymes can do, imposes strain. If a DNA segment under twist strain were closed into a circle by joining its two ends and then allowed to move freely, the circular DNA would contort into a new shape, such as a simple figure-eight. Such a contortion is a supercoil. The noun form \"supercoil\" is often used in the context of DNA topology.\n\nPositively supercoiled (overwound) DNA is transiently generated during DNA replication and transcription, and, if not promptly relaxed, inhibits (regulates) these processes. The simple figure eight is the simplest supercoil, and is the shape a circular DNA assumes to accommodate one too many or one too few helical twists. The two lobes of the figure eight will appear rotated either clockwise or counterclockwise with respect to one another, depending on whether the helix is over- or underwound. For each additional helical twist being accommodated, the lobes will show one more rotation about their axis. As a general rule, the DNA of most organisms is negatively supercoiled.\n\nLobal contortions of a circular DNA, such as the rotation of the figure-eight lobes above, are referred to as \"writhe\". The above example illustrates that twist and writhe are interconvertible. Supercoiling can be represented mathematically by the sum of twist and writhe. The twist is the number of helical turns in the DNA and the writhe is the number of times the double helix crosses over on itself (these are the supercoils). Extra helical twists are positive and lead to positive supercoiling, while subtractive twisting causes negative supercoiling. Many topoisomerase enzymes sense supercoiling and either generate or dissipate it as they change DNA topology. DNA of most organisms is negatively supercoiled.\n\nIn part because chromosomes may be very large, segments in the middle may act as if their ends are anchored. As a result, they may be unable to distribute excess twist to the rest of the chromosome or to absorb twist to recover from underwinding—the segments may become \"supercoiled\", in other words. In response to supercoiling, they will assume an amount of writhe, just as if their ends were joined.\n\nSupercoiled DNA forms two structures; a plectoneme or a toroid, or a combination of both. A negatively supercoiled DNA molecule will produce either a one-start left-handed helix, the toroid, or a two-start right-handed helix with terminal loops, the plectoneme. Plectonemes are typically more common in nature, and this is the shape most bacterial plasmids will take. For larger molecules it is common for hybrid structures to form – a loop on a toroid can extend into a plectoneme. If all the loops on a toroid extend then it becomes a branch point in the plectonemic structure. DNA supercoiling is important for DNA packaging within all cells, and seems to also play a role in gene expression.\n\nBased on the properties of intercalating molecules i.e., fluorescing upon binding to DNA and unwinding of DNA base-pairs, recently a single-molecule technique has been introduced to directly visualize individual plectonemes along supercoiled DNA which would further allow to study the interactions of DNA processing proteins with supercoiled DNA. In that study, Sytox Orange (an intercalating dye), has been used to induce supercoiling on surface tethered DNA molecules.\n\nDNA supercoiling is important for DNA packaging within all cells. Because the length of DNA can be thousands of times that of a cell, packaging this genetic material into the cell or nucleus (in eukaryotes) is a difficult feat. Supercoiling of DNA reduces the space and allows for DNA to be packaged. In prokaryotes, plectonemic supercoils are predominant, because of the circular chromosome and relatively small amount of genetic material. In eukaryotes, DNA supercoiling exists on many levels of both plectonemic and solenoidal supercoils, with the solenoidal supercoiling proving most effective in compacting the DNA. Solenoidal supercoiling is achieved with histones to form a 10 nm fiber. This fiber is further coiled into a 30 nm fiber, and further coiled upon itself numerous times more.\n\nDNA packaging is greatly increased during nuclear division events such as mitosis or meiosis, where DNA must be compacted and segregated to daughter cells. Condensins and cohesins are \"structural maintenance of chromosome\" (SMC) proteins that aid in the condensation of sister chromatids and the linkage of the centromere in sister chromatids. These SMC proteins induce positive supercoils.\n\nSupercoiling is also required for DNA/RNA synthesis. Because DNA must be unwound for DNA/RNA polymerase action, supercoils will result. The region ahead of the polymerase complex will be unwound; this stress is compensated with positive supercoils ahead of the complex. Behind the complex, DNA is rewound and there will be compensatory negative supercoils. Topoisomerases such as DNA gyrase (Type II Topoisomerase) play a role in relieving some of the stress during DNA/RNA synthesis.\n\nSpecialized proteins can unzip small segments of the DNA molecule when it is replicated or transcribed into RNA. But work published in 2015 illustrates how DNA opens on its own.\n\nSimply twisting DNA can expose internal bases to the outside, without the aid of any proteins. Also, transcription itself contorts DNA in living human cells, tightening some parts of the coil and loosening it in others. That stress triggers changes in shape, most notably opening up the helix to be read. Unfortunately, these interactions are very difficult to study because biological molecules morph shapes so easily. In 2008 it was noted that transcription twists DNA, leaving a trail of undercoiled (or negatively supercoiled) DNA in its wake. Moreover, they discovered that the DNA sequence itself effects how the molecule responds to supercoiling. For example, the researchers identified a specific sequence of DNA that regulates transcription speed; as the amount of supercoil rises and falls, it slows or speeds the pace at which molecular machinery reads DNA. It is hypothesized that these structural changes might trigger stress elsewhere along its length, which in turn might provide trigger points for replication or gene expression. This implies that it is a very dynamic process in which both DNA and proteins each influences how the other acts and reacts.\n\nIn nature, circular DNA is always isolated as a higher-order helix-upon-a-helix, known as a \"superhelix.\" In discussions of this subject, the Watson-Crick twist is referred to as a \"secondary\" winding, and the superhelices as a \"tertiary\" winding. The sketch at right indicates a \"relaxed\", or \"open circular\" Watson-Crick double-helix, and, next to it, a right-handed superhelix. The \"relaxed\" structure on the left is not found unless the chromosome is nicked; the superhelix is the form usually found in nature.\n\nFor purposes of mathematical computations, a right-handed superhelix is defined as having a \"negative\" number of superhelical turns, and a left-handed superhelix is defined as having a \"positive\" number of superhelical turns. In the drawing (shown at the right), both the secondary (\"i.e.,\" \"Watson-Crick\") winding and the tertiary (\"i.e.,\" \"superhelical\") winding are right-handed, hence the supertwists are negative (-3 in this example).\n\nThe superhelicity is presumed to be a result of underwinding, meaning that there is a deficiency in the number of secondary Watson-Crick twists. Such a chromosome will be strained, just as a macroscopic metal spring is strained when it is either overwound or unwound. In DNA which is thusly strained, supertwists will appear.\n\nDNA supercoiling can be described numerically by changes in the linking number Lk. The linking number is the most descriptive property of supercoiled DNA. Lk, the number of turns in the relaxed (B type) DNA plasmid/molecule, is determined by dividing the total base pairs of the molecule by the relaxed bp/turn which, depending on reference is 10.4; 10.5; 10.6. \nLk is merely the number of crosses a single strand makes across the other. L, known as the \"linking number\", is the number of Watson-Crick twists found in a circular chromosome in a (usually imaginary) planar projection. This number is physically \"locked in\" at the moment of covalent closure of the chromosome, and cannot be altered without strand breakage.\n\nThe topology of the DNA is described by the equation below in which the linking number is equivalent to the sum of TW, which is the number of twists or turns of the double helix, and Wr which is the number of coils or 'writhes'. If there is a closed DNA molecule, the sum of Tw and Wr, or the linking number, does not change. However, there may be complementary changes in TW and Wr without changing their sum. \n\nTw, called \"twist\", refers to the number of Watson-Crick twists in the chromosome when it is not constrained to lie in a plane. We have already seen that native DNA is usually found to be superhelical. If one goes around the superhelically twisted chromosome, counting secondary Watson-Crick twists, that number will be different from the number counted when the chromosome is constrained to lie flat. In general, the number of secondary twists in the native, supertwisted chromosome is expected to be the \"normal\" Watson-Crick winding number, meaning a single 10-base-pair helical twist for every 34 Å of DNA length.\n\nWr, called \"writhe\", is the number of superhelical twists. Since biological circular DNA is usually underwound, L will generally be \"less\" than Tw, which means that Wr will typically be \"negative.\"\n\nIf DNA is underwound, it will be under strain, exactly as a metal spring is strained when forcefully unwound, and that the appearance of supertwists will allow the chromosome to relieve its strain by taking on negative supertwists, which correct the secondary underwinding in accordance with the topology equation above.\n\nThe topology equation shows that there is a one-to-one relationship between changes in Tw and Wr. For example, if a secondary \"Watson-Crick\" twist is removed, then a right-handed supertwist must have been removed simultaneously (or, if the chromosome is relaxed, with no supertwists, then a left-handed supertwist must be added).\n\nThe change in the linking number, ΔLk, is the actual number of turns in the plasmid/molecule, Lk, minus the number of turns in the relaxed plasmid/molecule Lk.\nIf the DNA is negatively supercoiled ΔLk < 0. The negative supercoiling implies that the DNA is underwound.\n\nA standard expression independent of the molecule size is the \"specific linking difference\" or \"superhelical density\" denoted σ, that represents the number of turns added or removed relative to the total number of turns in the relaxed molecule/plasmid, indicating the level of supercoiling.\n\nThe Gibbs free energy associated with the coiling is given by the equation below\n\nThe difference in Gibbs free energy between the supercoiled circular DNA and uncoiled circular DNA with N > 2000 bp is approximated by:\nor, 16 cal/bp.\n\nSince the linking number \"L\" of supercoiled DNA is the number of times the two strands are intertwined (and both strands remain covalently intact), \"L\" cannot change. The reference state (or parameter) \"L\" of a circular DNA duplex is its relaxed state. In this state, its writhe \"W\" = 0. Since \"L = T + W\", in a relaxed state \"T = L\". Thus, if we have a 400 bp relaxed circular DNA duplex, \"L ~ 40\" (assuming ~10 bp per turn in B-DNA). Then \"T ~ 40\".\n\n\nNegative supercoils favor local unwinding of the DNA, allowing processes such as transcription, DNA replication, and recombination. Negative supercoiling is also thought to favour the transition between B-DNA and Z-DNA, and moderate the interactions of DNA binding proteins involved in gene regulation.\n\nThe topological properties of circular DNA are complex. In standard texts, these properties are invariably explained in terms of a helical model for DNA, but in 2008 it was noted that each topoisomer, negative or positive, adopts a unique and surprisingly wide distribution of three-dimensional conformations.\n\nWhen the sedimentation coefficient, s, of circular DNA is ascertained over a large range of pH, the following curves are seen. Three curves are shown here, representing three species of DNA. From top-to-bottom they are: \"Form IV\" (green), \"Form I\" (blue) and \"Form II\" (red).\n\n\"Form I\" (blue curve) is the traditional nomenclature used for the native form of duplex circular DNA, as recovered from viruses and intracellular plasmids. Form I is covalently closed, and any plectonemic winding which may be present is therefore locked in. If one or more nicks are introduced to Form I, free rotation of one strand with respect to the other becomes possible, and Form II (red curve) is seen.\n\nForm IV (green curve) is the product of alkali denaturation of Form I. Its structure is unknown, except that it is persistently duplex, and extremely dense.\n\nBetween pH 7 and pH 11.5, the sedimentation coefficient s, for Form I, is constant. Then it dips, and at a pH just below 12, reaches a minimum. With further increases in pH, s then returns to its former value. It doesn’t stop there, however, but continues to increase relentlessly. By pH 13, the value of s has risen to nearly 50, two to three times its value at pH 7, indicating an extremely compact structure.\n\nIf the pH is then lowered, the s value is not restored. Instead, one sees the upper, green curve. The DNA, now in the state known as Form IV, remains extremely dense, even if the pH is restored to the original physiologic range. As stated previously, the structure of Form IV is almost entirely unknown, and there is no currently accepted explanation for its extraordinary density. About all that is known about the tertiary structure is that it is duplex, but has no hydrogen bonding between bases.\n\nThese behaviors of Forms I and IV are considered to be due to the peculiar properties of duplex DNA which has been covalently closed into a double-stranded circle. If the covalent integrity is disrupted by even a single nick in one of the strands, all such topological behavior ceases, and one sees the lower Form II curve (Δ). For Form II, alterations in pH have very little effect on s. Its physical properties are, in general, identical to those of linear DNA. At pH 13, the strands of Form II simply separate, just as the strands of linear DNA do. The separated single strands have slightly different s values, but display no significant changes in s with further increases in pH.\n\nA complete explanation for these data is beyond the scope of this article. In brief, the alterations in s come about because of changes in the superhelicity of circular DNA. These changes in superhelicity are schematically illustrated by four little drawings which have been strategically superimposed upon the figure above.\n\nBriefly, the alterations of s seen in the pH titration curve above are widely thought to be due to changes in the superhelical winding of DNA under conditions of increasing pH. Up to pH 11.5, the purported \"underwinding\" produces a right-handed (\"negative\") supertwist. But as the pH increases, and the secondary helical structure begins to denature and unwind, the chromosome (if we may speak anthropomorphically) no longer \"wants\" to have the full Watson-Crick winding, but rather \"wants\", increasingly, to be \"underwound\". Since there is less and less strain to be relieved by superhelical winding, the superhelices therefore progressively disappear as the pH increases. At a pH just below 12, all incentive for superhelicity has expired, and the chromosome will appear as a relaxed, open circle.\n\nAt higher pH still, the chromosome, which is now denaturing in earnest, tends to unwind entirely, which it cannot do so (because L is covalently locked in). Under these conditions, what was once treated as \"underwinding\" has actually now become \"overwinding\". Once again there is strain, and once again it is (in part at least) relieved by superhelicity, but this time in the opposite direction (\"i.e.,\" left-handed or \"positive\"). Each left-handed tertiary supertwist removes a single, now \"undesirable\" right-handed Watson-Crick secondary twist.\n\nThe titration ends at pH 13, where Form IV appears.\n\n", "id": "5097443", "title": "DNA supercoil"}
{"url": "https://en.wikipedia.org/wiki?curid=49256303", "text": "EcoRI\n\n\"Eco\"RI (pronounced \"eco R one\") is a restriction endonuclease enzyme isolated from species \"E. coli.\" The \"Eco\" part of the enzyme's name originates from the species from which it was isolated, while the R represents the particular strain, in this case RY13. The last part of its name, the I, denotes that it was the first enzyme isolated from this strain. \"Eco\"RI is a restriction enzyme that cleaves DNA double helixes into fragments at specific sites. It is also a part of the restriction modification system.\n\nIn molecular biology it is used as a restriction enzyme. \"Eco\"RI creates 4 nucleotide sticky ends with 5' end overhangs of AATT. The nucleic acid recognition sequence where the enzyme cuts is G/AATTC, which has a palindromic, complementary sequence of CTTAA/G. The / in the sequence indicates which phosphodiester bond the enzyme will break in the DNA molecule. Other restriction enzymes, depending on their cut sites, can also leave 3' overhangs or blunt ends with no overhangs.\n\n\"Eco\"RI contains the PD..D/EXK motif within its active site like many restriction endonucleases.\nThe enzyme is a homodimer of a 31 kilodalton subunit consisting of one globular domain of the α/β architecture. Each subunit contains a loop which sticks out from the globular domain and wraps around the DNA when bound.\n\"Eco\"RI has been cocrystallized with the sequence it normally cuts. This crystal was used to solve the structure of the complex . The solved crystal structure shows that the subunits of the enzyme homodimer interact with the DNA symmetrically. In the complex, two α-helices from each subunit come together to form a four-helix bundle. On the interacting helices are residues Glu144 and Arg145, which interact together, forming a crosstalk ring that is believed to allow the enzyme's two active sites to communicate.\n\nRestriction enzymes, such as \"Eco\"RI, are used in a wide variety of molecular genetics techniques including cloning, DNA screening and deleting sections of DNA \"in vitro\". Restriction enzymes, like \"Eco\"RI, that generate sticky ends of DNA are often used to cut DNA prior to ligation, as the sticky ends make the ligation reaction more efficient. \"Eco\"RI can exhibit non-site-specific cutting, known as star activity, depending on the conditions present in the reaction. Conditions that can induce star activity when using \"Eco\"RI include low salt concentration, high glycerol concentration, excessive amounts of enzyme present in the reaction, high pH and contamination with certain organic solvents.\n\n", "id": "49256303", "title": "EcoRI"}
{"url": "https://en.wikipedia.org/wiki?curid=27110987", "text": "Gene therapy of the human retina\n\nRetinal gene therapy holds great promise in treating different forms of non-inherited and inherited blindness.\n\nIn 2008, three independent research groups reported that patients with the rare genetic retinal disease Leber's congenital amaurosis had been successfully treated using gene therapy with adeno-associated virus (AAV). In all three studies, an AAV vector was used to deliver a functional copy of the RPE65 gene, which restored vision in children suffering from LCA. These results were widely seen as a success in the gene therapy field, and have generated excitement and momentum for AAV-mediated applications in retinal disease.\n\nIn retinal gene therapy, the most widely used vectors for ocular gene delivery are based on adeno-associated virus. The great advantage in using adeno-associated virus for the gene therapy is that it poses minimal immune responses and mediates long-term transgene expression in a variety of retinal cell types. For example, tight junctions that form the blood-retina barrier, separate subretinal space from the blood supply, providing protection from microbes and decreasing most immune-mediated damages.\n\nIn 2008, three groups reported positive results of clinical trials using adeno-associated virus for Leber's congenital amaurosis. In these studies, an AAV vector encoding the RPE65 gene was delivered via a \"subretinal injection\", where a small amount of fluid is injected underneath the retina in a short surgical procedure.\n\nInitial results from all three studies indicate that AAV is safe in the retina, with no dose-limiting toxicities observed. Across the three trials, no serious adverse events were observed. Furthermore, patients in all three studies showed improvement in their visual function as measured by a number of methods. The methods used varied among the three trials, but included both functional methods such as visual acuity and functional mobility as well as objective measures that are less susceptible to bias, such as the pupil's ability to respond to light and improvements on functional MRI. Improvements were sustained over the long-term, with patients continuing to do well after more than 1.5 years.\n\nThe UPenn trial was led by a group of four principal investigators at the University of Pennsylvania and the Children's Hospital of Philadelphia: Jean E. Bennett, MD PhD, Albert Maguire MD, Katherine High MD, and J. Fraser Wright, PhD. In this trial, patients improved in terms of visual acuity, pupillometry, visual field, light sensitivity, mobility, and functional MRI. In the Phase 1/2 clinical trial, children as young as 8 years old were treated, and results indicated that younger patients had better results compared to older patients.\nA company called Spark therapeutics was spun out of the work done at the UPenn in 2013. Spark was granted a \"breakthrough-therapy\" designation by the FDA and in November 2014 the company was running a phase III trial of their gene therapy product SPK-RPE65. Spark planned to submit results to the FDA in 2016.\n\nThe Florida trial was conducted under the leadership of Dr. Samuel Jacobson and Dr. William Hauswirth, with funding support from the National Eye Institute. This trial treated adults over the age of 18. The treatment was delivered safely, and was associated with improvements in vision. Unlike the UPenn trial, the injection was not delivered underneath the fovea, but next to it. As patients' vision improved, they had the best vision in the injected area, rather than in the usual place at the fovea. This led to the development of a so-called \"pseudo-fovea\" that corresponded to the treated area.\n\nFollowing the successful clinical trials in LCA, researchers have been developing similar treatments using adeno-associated virus for age-related macular degeneration (AMD). To date, efforts have focused on long-term delivery of VEGF inhibitors to treat the wet form of macular degeneration. Whereas wet AMD is currently treated using frequent injections of recombinant protein into the eyeball, these goal of these treatments is long-term disease management following a single administration. One such study is being conducted at the Lions Eye Institute in Australia in collaboration with Avalanche Biotechnologies, a US-based biotechnology start-up. Another early-stage study is sponsored by Genzyme Corporation.\n\nIn October 2011, the first clinical trial was announced for the treatment of choroideremia. Dr. Robert MacLaren of the University of Oxford, who lead the trial, co-developed the treatment with Dr. Miguel Seabra of the Imperial College, London. This Phase 1/2 trial used subretinal AAV to restore the REP gene in affected patients.\nInitial results of the trial were reported in January 2014 as promising as all six patients had better vision.\n\nRecent research has shown that AAV can successfully restore color vision to treat color blindness in adult monkeys. Although this treatment has not yet entered clinical trials for humans, this work was considered a breakthrough for the ability to target cone photoreceptors.\n\nThe vertebrate neural retina composed of several layers and distinct cell types (see anatomy of the human retina). A number of these cell types are implicated in retinal diseases, including retinal ganglion cells, which degenerate in glaucoma, the rod and cone photoreceptors, which are responsive to light and degenerate in retinitis pigmentosa, macular degeneration, and other retinal diseases, and the retinal pigment epithelium (RPE), which supports the photoreceptors and is also implicated in retinitis pigmentosa and macular degeneration.\n\nIn retinal gene therapy, AAV is capable of \"transducing\" these various cell types by entering the cells and expressing the therapeutic DNA sequence. Since the cells of the retina are non-dividing, AAV continues to persist and provide expression of the therapeutic DNA sequence over a long time period that can last several years.\n\nAAV is capable of transducing multiple cell types within the retina. AAV serotype 2, the most well-studied type of AAV, is commonly administered in one of two routes: intravitreal or subretinal. Using the intravitreal route, AAV is injected in the vitreous humor of the eye. Using the subretinal route, AAV is injected underneath the retina, taking advantage of the potential space between the photoreceptors and RPE layer, in a short surgical procedure. Although this is more invasive than the intravitreal route, the fluid is absorbed by the RPE and the retina flattens in less than 14 hours without complications. Intravitreal AAV targets retinal ganglion cells and a few Muller glial cells. Subretinal AAV efficiently targets photoreceptors and RPE cells.\n\nThe reason that different routes of administration lead to different cell types being transfected (e.g., different tropism) is that the inner limiting membrane (ILM) and the various retinal layers act as physical barriers for the delivery of drugs and vectors to the deeper retinal layers. Thus overall, subretinal AAV is 5-10 times more efficient than delivery using the intravitreal route.\n\nOne important factor in gene delivery is developing altered cell tropisms to narrow or broaden rAAV-mediated gene delivery and to increase its efficiency in tissues. Specific properties like capsid conformation, cell targeting strategies can determine which cell types are affected and also the efficiency of the gene transfer process. Different kinds of modification can be undertaken. For example, modification by chemical, immunological or genetic changes that enables the AAV2 capsid to interact with specific cell surface molecules.\n\nInitial studies with AAV in the retina have utilized AAV serotype 2. Researchers are now beginning to develop new variants of AAV, based on naturally-occurring AAV serotypes and engineered AAV variants.\n\nSeveral naturally-occurring serotypes of AAV have been isolated that can transduce retinal cells. Following intravitreal injection, only AAV serotypes 2 and 8 were capable of transducing retinal ganglion cells. Occasional Muller cells were transduced by AAV serotypes 2, 8, and 9. Following subretinal injection, serotypes 2, 5, 7, and 8 efficiently transduced photoreceptors, and serotypes 1, 2, 5, 7, 8, and 9 efficiently transduce RPE cells.\n\nOne example of an engineered variant has recently been described that efficiently transduces Muller glia following intravitreal injection, and has been used to rescue an animal model of aggressive, autosomal-dominant retinitis pigmentosa.\n\nImportantly, the retina is immune-privileged, and thus does not experience a significant inflammation or immune-response when AAV is injected. Immune response to gene therapy vectors is what has caused previous attempts at gene therapy to fail, and is considered a key advantage of gene therapy in the eye. Re-administration has been successful in large animals, indicating that no long-lasting immune response is mounted.\n\nRecent data indicates that the subretinal route may be subject to a greater degree of immune privilege compared to the intravitreal route.\n\nExpression in various retinal cell types can be determined the promoter sequence. In order to restrict expression to a specific cell type, a tissue-specific or cell-type specific promoter can be used.\n\nFor example, in rat the murine rhodopsin gene drive the expression in AAV2, GFP reporter product was found only in rat photoreceptors, not in any other retinal cell type or in the adjacent RPE after subretinal injection. On the other hand, if ubiquitously expressed immediate-early cytomegalovirus (CMV) enhancer-promoter is expressed in a wide variety of transfected cell types. Other ubiquitous promoters such as the CBA promoter, a fusion of the chicken-actin promoter and CMV immediate-early enhancer, allows stable GFP reporter expression in both RPE and photoreceptor cells after subretinal injections.\n\nSometimes modulation of transgene expression may be necessary since strong constitutive expression of a therapeutic gene in retinal tissues could be deleterious for long-term retinal function. Different methods have been utilized for the expression modulation. One way is using exogenously regulatable promoter system in AAV vectors. For example, the tetracycline-inducible expression system uses a silencer/transactivator AAV2 vector and a separate inducible doxycline-responsive coinjection. When induction occurs by oral doxycycline, this system shows tight regulation of gene expression in both photoreceptor and RPE cells.\n\nOne study that was done by Royal College of Surgeons (RCS) in rat model shows that a recessive mutation in a receptor tyrposine kinase gene, mertk results in a premature stop codon and impaired phagocytosis function by RPE cells. This mutation causes the accumulation of outer segment debris in the subretinal space, which causes photoreceptor cell death. The model organism with this disease received a subretinal injection of AAV serotype 2 carrying a mouse Mertk cDNA under the control of either the CMV or RPE65 promoters. This treatment was found to prolong photoreceptor cell survival for several months and also the number of photoreceptor was 2.5 fold higher in AAV-Mertk- treated eyes compared with controls 9 weeks after injection, also they found decreased amount of debris in the subretinal space.\n\nThe protein RPE65 is used in the retinoid cycle where the all-trans-retinol within the rod outer segment is isomerized to its 11-cis form and oxidized to 11-cis retinal before it goes back to the photoreceptor and joins with opsin molecule to form functional rhodopsin. In animal knockout model (RPE65-/-), gene transfer experiment shows that early intraocular delivery of human RPE65 vector on embryonic day 14 shows efficient transduction of retinal pigment epithelium in the RPE65-/- knockout mice and rescues visual functions. This shows successful gene therapy can be attributed to early intraocular deliver to the diseased animal.\n\nJuvenile retinoschisis is a disease that affects the nerve tissue in the eye. This disease is an X-linked recessive degenerative disease of the central macula region, and it is caused by mutation in the RSI gene encoding the protein retinoschisin. Retinoschisin is produced in the photoreceptor and bipolar cells and it is critical in maintaining the synaptic integrity of the retina.\n\nSpecifically the AAV 5 vector containing the wild-type human RSI cDNA driven by a mouse opsin promoter showed long-term retinal functional and structural recovery. Also the retinal structural reliability improved greatly after the treatment, characterized by an increase in the outer nuclear layer thickness.\n\nRetinitis pigmentosa is an inherited disease which leads to progressive night blindness and loss of peripheral vision as a result of photoreceptor cell death. Most people who suffer from RP are born with rod cells that are either dead or dysfunctional, so they are effectively blind at nighttime, since these are the cells responsible for vision in low levels of light. What follows often is the death of cone cells, responsible for color vision and acuity, at light levels present during the day. Loss of cones leads to full blindness as early as five years old, but may not onset until many years later. There have been multiple hypotheses about how the lack of rod cells can lead to the death of cone cells. Pinpointing a mechanism for RP is difficult because there are more than 39 genetic loci and genes correlated with this disease. In an effort to find the cause of RP, there have been different gene therapy techniques applied to address each of the hypotheses.\n\nDifferent types of inheritance can attribute to this disease; autosomal recessive, autosomal dominant, X-linked type, etc. The main function of rhodopsin is initiating the phototransduction cascade. The opsin proteins are made in the photoreceptor inner segments, then transported to the outer segment, and eventually phagocytized by the RPE cells. When mutations occur in the rhodopsin the directional protein movement is affected because the mutations can affect protein folding, stability, and intracellular trafficking. One approach is introducing AAV-delivered ribozymes designed to target and destroy a mutant mRNA.\n\nThe way this system operates was shown in animal model that have a mutant rhodopsin gene. The injected AAV-ribozymes were optimized in vitro and used to cleave the mutant mRNA transcript of P23H (where most mutation occur) in vivo.\n\nAnother mutation in the rhodopsin structural protein, specifically peripherin 2 which is a membrane glycoprotein involved in the formation of photoreceptor outersegment disk, can lead to recessive RP and macular degeneration in human (19). In a mouse experiment, AAV2 carrying a wild-type peripherin 2 gene driven by a rhodopsin promoter was delivered to the mice by subretinal injection. The result showed improvement in photoreceptor structure and function which was detected by ERG (electroretinogram). The result showed improvement of photoreceptor structure and function which was detected by ERG. Also peripherin 2 was detected at the outer segment layer of the retina 2 weeks after injection and therapeutic effects were noted as soon as 3 weeks after injection. Interestingly, a well-defined outer segment containing both peripherin2 and rhodopsin was present 9-month after injection.\n\nSince apoptosis can be the cause of photoreceptor death in most of the retinal dystrophies. It has been known that survival factors and antiapoptoic reagents can be an alternative treatment if the mutation is unknown for gene replacement therapy. Some scientists have experimented with treating this issue by injecting substitute trophic factors into the eye. One group of researchers injected the rod derived cone viability factor (RdCVF) protein (encoded for by the Nxnl1 (Txnl6) gene) into the eye of the most commonly occurring dominant RP mutation rat models. This treatment demonstrated success in promoting the survival of cone activity, but the treatment served even more significantly to prevent progression of the disease by increasing the actual function of the cones. Experiments were also carried out to study whether supplying AAV2 vectors with cDNA for glial cell line-derived neurotrophic factor (GDNF) can have an anti-apoptosis effect on the rod cells.\nIn looking at an animal model, the opsin transgene contains a truncated protein lacking the last 15 amino acids of the C terminus, which causes alteration in rhodopsin transport to the outer segment and leads to retinal degeneration. When the AAV2-CBA-GDNF vector is administered to the subretinal space, photoreceptor stabilized and rod photoreceptors increased and this was seen in the improved function of the ERG analysis. Successful experiments in animals have also been carried out using ciliary neurotrophic factor (CNTF), and CNTF is currently being used as a treatment in human clinical trials.\n\nOcular neovascularization (NV) is the abnormal formation of new capillaries from already existing blood vessels in the eye, and this is a characteristics for ocular diseases such as diabetic retinopathy (DR), retinopathy of prematurity (ROP) and (wet form) age-related macular degeneration (AMD). One of the main players in these diseases is VEGF (Vascular endothelial growth factor) which is known to induce vessel leakage and which is also known to be angiogenic. In normal tissues VEGF stimulates endothelial cell proliferation in a dose dependent manner, but such activity is lost with other angiogenic factors.\n\nMany angiostatic factors have been shown to counteract the effect of increasing local VEGF. The naturally occurring form of soluble Flt-1 has been shown to reverse neovascularization in rats, mice, and monkeys.\n\nPigment epithelium-derived factor (PEDF) also acts as an inhibitor of angiogenesis. The secretion of PEDF is noticeably decreased under hypoxic conditions allowing the endothelial mitogenic activity of VEGF to dominate, suggesting that the loss of PEDF plays a central role in the development of ischemia-driven NV. One interesting clinical finding shows that the levels of PEDF in aqueous humor of human are decreased with increasing age, indicating that the reduction may lead to the development of AMD. In animal model, an AAV with human PEDF cDNA under the control of the CMV promoter prevented choroidal and retinal NV ( 24).\n\nThe finding suggests that the AAV-mediated expression of angiostatic factors can be implemented to treat NV. This approach could be useful as an alternative to frequent injections of recombinant protein into the eye. In addition, PEDF and sFlt-1 may be able to diffuse through sclera tissue, allowing for the potential to be relatively independent of the intraocular site of administration.\n", "id": "27110987", "title": "Gene therapy of the human retina"}
{"url": "https://en.wikipedia.org/wiki?curid=41697085", "text": "Putative gene\n\nA putative gene is a segment of DNA whose protein, and its function, is not known, but based on its open reading frame, it is believed to be a gene.\n\n\n", "id": "41697085", "title": "Putative gene"}
{"url": "https://en.wikipedia.org/wiki?curid=35256679", "text": "Community fingerprinting\n\nCommunity fingerprinting is a set of molecular biology techniques that can be used to quickly profile the diversity of a microbial community. Rather than directly identifying or counting individual cells in an environmental sample, these techniques show how many variants of a gene are present. In general, it is assumed that each different gene variant represents a different type of microbe. Community fingerprinting is used by microbiologists studying a variety of microbial systems (e.g. marine, freshwater, soil, and human microbial communities) to measure biodiversity or track changes in community structure over time. The method analyzes environmental samples by assaying genomic DNA. This approach offers an alternative to microbial culturing, which is important because most microbes cannot be cultured in the laboratory. Community fingerprinting does not result in identification of individual microbe species; instead, it presents an overall picture of a microbial community. These methods are now largely being replaced by high throughput sequencing, such as targeted microbiome analysis (e.g., 16s rRNA sequencing) and metagenomics.\n\nA fingerprinting analysis begins with an environmental sample (e.g. seawater or soil), from which total DNA is extracted. (Total DNA contains a mix of genetic material from all the microbes present in the sample.) A particular gene or DNA region is then selected as a target for analysis, under the assumption that each microbe species will have a different gene variant (also called a \"phylotype\"). Different methods (see below) can be used to visualize the phylotypes present in a sample. Because the aim of community fingerprinting is to gain an overall understanding of community structure, it is a particularly useful technique for analyzing time-series data collected from the field. For example, one could study the pattern of microbial succession in a habitat, or one could examine the response of a microbial community to an environmental perturbation, such as the release of a pollutant. Depending on what information is desired, different genes may be targeted. The most common are small subunit ribosomal RNA (rRNA) genes, such as 16S rRNA. These genes are frequently used in microbial phylogenetic analyses, so well-established techniques exist for their study. Other genes of interest might be those that are key in various metabolic processes.\n\nThe advantages of community fingerprinting are that it can be performed quickly and relatively cheaply, and the analyses can accommodate a large number of samples simultaneously. These properties make community fingerprinting especially useful for monitoring changes in microbial communities over time. Also, fingerprinting techniques do not require one to have \"a priori\" sequence data for organisms in a sample.\nA disadvantage of community fingerprinting is that it results in largely qualitative, not quantitative data. When using qualitative data, it can be difficult to compare patterns observed in different studies or between different investigators. Also, community fingerprinting does not directly identify taxa in an environmental sample, though the data output from certain techniques (e.g. DGGE) can be analyzed further if one desires identification. Some authors point to poor reproducibility of results for certain fingerprinting methods, while other authors have criticized the inaccuracy of abundance estimates and the inability of some techniques to capture the presence of rare taxa. For example, it is difficult for the DGGE method to detect microbes that comprise less than 0.5%-1% of a bacterial community.\n\nThis section presents three methods of community fingerprinting.\n\nTerminal restriction fragment length polymorphism (T-RFLP) is a method that uses fluorescently-labeled DNA fragments to produce a community fingerprint. This section presents a brief explanation of T-RFLP \"in the specific context of community fingerprinting\". For a more detailed explanation, refer to the T-RFLP article.\n\nTo perform T-RFLP (Figure 1), one must select a target gene (e.g. the 16S rRNA gene) to amplify by PCR. At least one primer used in the PCR reaction is fluorescently labeled at the 5´ end. After PCR amplification, each copied DNA segment carries the fluorescent label. Next, restriction enzymes are used to cut the amplified DNA at specific recognition sites. The underlying assumption is that each microbe in the sample will have a different sequence on the target gene, so a restriction enzyme will cut each microbe's DNA in a different place. (Each different restriction site is considered to represent a single operational taxonomic unit [OTU]). Thus, the enzyme will produce one fragment length for each type of microbe present in the sample. The result of digestion is a set of restriction fragments of different lengths, each of which is fluorescently labeled at one end. These are known as \"terminal fragments\" because they are labeled at the end where the PCR primer attached. (The unlabeled ends are not recorded in the final analysis.) Next, the fragments are separated by size through either gel or capillary electrophoresis. Laser detection captures the size and fluorescence-intensity patterns of the terminal fragments. DNA standards of known size and fluorescence are included in the analysis as references. By setting a minimum threshold for fluorescence, background noise will be excluded.\nThe output of the laser detection step is an electropherogram that shows a series of peaks, with fragment length on the horizontal axis and fluorescence intensity on the vertical axis (Figure 1). A second output is a data table that lists the migration time of the fragments, the size in base pairs of each peak, and the height of and area under each peak.\n\nThe theoretical basis of T-RFLP assumes that peaks at different positions along the horizontal axis represent different types of organisms (or OTUs). The area under each fluorescence intensity peak is a proxy for relative abundance of each phylotype in the community. However, a number of caveats must be taken into account. Different types of organisms may share a restriction site in the gene of interest; if that is the case, these organisms would not be distinguished as different peaks on the electropherogram. Furthermore, area under a peak represents relative abundance rather than absolute abundance, and there are biases in abundance measurement and PCR amplification. For example, organisms that are scarce in the original total DNA sample will not be amplified enough to be detected in the final analysis. This leads to underestimation of community diversity. Liu \"et al.\" cite other possible factors that may distort results, including \"differences in gene copy number between species and biases introduced during cell lysis, DNA extraction, and PCR amplification\" (p. 4521). For those who seek detailed technical information, Marsh provides a catalog of potential biases that could be introduced in each step of the T-RFLP process.\n\nThe major advantages of T-RFLP are that it is fast and can easily accommodate many samples. Also, the visual output simplifies comparison of community structure patterns across different samples. A disadvantage is the broad, qualitative nature of the data output, which must be interpreted with the above caveats in mind. Also, direct identification of microbes in a sample is not possible through T-RFLP.\n\nDisayathanoowat \"et al.\" used T-RFLP to assess the microbial gut community, or microbiome, in two species of honeybees in Thailand. They found that the two species harbor different microbial communities and that the microbiome changes over the lifetime of the bees.\n\nJoo \"et al.\" tested T-RFLP as a method for phytoplankton monitoring. The authors collected environmental water samples from reservoirs in a time series. After comparison of samples with known terminal restriction fragments (from a database built from cultures), they concluded that T-RFLP can be used effectively as a technique for monitoring \"changes\" in the phytoplankton community. However, diversity and abundance estimates were found to be less accurate than those found through other methods.\n\nDenaturing gradient gel electrophoresis (DGGE) is a microbial fingerprinting technique that separates amplicons of roughly the same size based on sequence properties (Figure 2). These properties dictate the threshold at which DNA denatures. The DGGE gel uses a gradient DNA denaturant (a mixture of urea and formamide), or a linear temperature gradient. When the fragment reaches its melting point (threshold of enough denaturant), it stops moving. This is due to the fact that a partially melted double-stranded DNA can no longer migrate through the gel. A GC clamp (about 40 bases with high GC content) is used as a special primer to anchor the PCR fragments together once they have denatured.\nEach lane on a gel represents one microbial community. The shared bands among the samples are the same size and roughly the same position on the gel. The gene variants that are not shared amongst microbial community samples do not match up horizontally with others. For example, if the gene of interest is 16S rRNA, as it was when the technique was first described, the PCR-amplified fragments will be in the same vertical location because they are all roughly the same size. Another target gene may have greater variation in length, but the denaturant gradient uses a second element (of melting point) to further distinguish between the samples. The DGGE gel will separate genes of the same size based on base sequence.\n\nThis technique shows to what extent microbial communities are the same or different in taxonomic composition. Each band in a different location on the gel represents a different phylotype (one unique sequence of a phylogenetic marker gene). For microbial communities this method profiles many individual 16S rRNA sequences. The number of bands at differing horizontal positions can be used to estimate the level of biodiversity in that sample and infer phylogenetic affiliation. In order to know more about phylogenetic affiliation, one could excise those bands from the gel and then sequence them.\n\nThe use of denaturing profile serves as a way to separate DNA fragments of similar sizes. This is beneficial in assessing microbial diversity due to the fact that the 16S rRNA gene does not vary much in size across bacterial phyla. The DGGE gel provides a quick way of looking at biodiversity in a microbial sample and does not preclude the option of sequencing the bands of interest. This method does not require that the microbes be cultured in the lab and does not require any sequence data needed to design probes for hybridization methods. The main disadvantage is that this is a qualitative assessment of biodiversity and one must sequence the genes in order to make inferences about the phylogenetic relatedness. Another disadvantage is that the GC clamp can be variable each time it is synthesized. This leads to the potential for different DGGE profiles for the same 16S rRNA sequence.\n\nStephen \"et al.\" utilized DGGE for a rapid analysis of Proteobacteria in soil. They obtained an initial assessment of microbial diversity in their environmental samples from soil maintained for 36 years at the various pH values. They combined DGGE and hybridization techniques by probing the DNA fragments to obtain more detail about the natural populations. In this study, they were looking at a group of closely related bacterial types, all autotrophic β–proteobacterial ammonia oxidizers. The 16S rDNA samples yielded ambiguous overlapping bands when run out on a gel. The ambiguous overlapping bands were separated with cluster-specific radiolabelled probes, which yielded information of the relative abundance of the different genotypes in samples.\n\nWard \"et al.\" examined cyanobacterial mat communities in a Yellowstone hot spring by using DGGE analysis of 16S rRNA gene segments of aerobic chemoorganotrophic populations. DGGE allowed them to profile the community gaining new insight to diversity. They characterized the bands of interest by purifying and sequencing and detected many lineages previously unknown to be present.\n\n(Automated) ribosomal intergenic spacer analysis, or (A)RISA (Figure 3), takes advantage of the fact that prokaryotic DNA encodes for two highly conserved genes, the 16SrRNA gene and the 23SrRNA gene. These encode the small and large subunit genes in the rRNA operon. Between these two genes, there is an internal transcribed spacer (ITS) region. Due to the fact it is non-coding for proteins, it is a highly variable nucleotide sequence and length. Once DNA is isolated from a community, PCR amplifies this spacer region. The fragments can be run out on a gel (RISA), or the fluorescent primers can be translated into peaks in abundance of the different fragments lengths on an electropherogram (ARISA). \nDue to variable non-coding regions, the output for RISA is a gel with different banding patterns, and output for ARISA is an electropherogram with different peaks (similar to T-RFLP).\n\nThe brightness of the fluorescently labeled primers correlates to how prevalent that bacterial type is in the community. The banding pattern on the gel can be interpreted as a community-specific profile. Each DNA band or peak indicates at least one representative of that organism. In RISA, the bands on gel that do not match up in length represent different organisms in the community because they have different spacer regions between the two highly conserved genes. The electropherogram shows peaks correlating to the relative abundance of that spacer region in the sample.\n\nARISA can have a higher resolution in detecting microbial diversity as compared to T-RFLP. This fingerprinting method is a quick and sensitive method to estimate microbial diversity. The observed length heterogeneities can be compared to databases for overlap with culturable organisms. One can design phylum-level oligonucleotide primers to get at questions regarding phylogenetic groups. One disadvantage to ARISA is the fact that a single organism may contribute more than one peak to the community profile. Unrelated organisms can also have similar spacer lengths, which leads to underestimates of community diversity. Due to these biases, researchers often use this method on multiple samples from each community in order to get an average assessment.\n\nRanjard \"et al.\" discuss several examples of types of studies in which RISA can be used. They cite several studies that have used this technique to fingerprint bacterial communities following such disturbances as antibiotic treatment, mercury stress and deforestation. They also demonstrated the successful use of ARISA for characterizing fungal communities, which is an aspect of microbial ecology that remains to be fully explored.\n\nSchloss \"et al.\" conducted a study examining environmental variables and linking them to changes in the microbial ecology of a compost pile. They used ARISA to profile the community structure and look at microbial succession over stages in the composting process. They took DNA samples and sequenced the 16S rRNA gene to identify community members at the different phases of the process. Then they used ARISA to look at community-wide changes and then matched up the 16S rRNA gene sequence with the most common ARISA fragments to identify these microbial community members.\n", "id": "35256679", "title": "Community fingerprinting"}
{"url": "https://en.wikipedia.org/wiki?curid=589968", "text": "Gel electrophoresis of proteins\n\nProtein electrophoresis is a method for analysing the proteins in a fluid or an extract. The electrophoresis may be performed with a small volume of sample in a number of alternative ways with or without a supporting medium: SDS polyacrylamide gel electrophoresis (in short: gel electrophoresis, PAGE, or SDS-electrophoresis), free-flow electrophoresis, electrofocusing, isotachophoresis, affinity electrophoresis, immunoelectrophoresis, counterelectrophoresis, and capillary electrophoresis. Each method has many variations with individual advantages and limitations. Gel electrophoresis is often performed in combination with electroblotting immunoblotting to give additional information about a specific protein. Because of practical limitations, protein electrophoresis is generally not suited as a preparative method.\n\nSDS-PAGE, sodium dodecyl sulfate polyacrylamide gel electrophoresis, describes a collection of related techniques to separate proteins according to their electrophoretic mobility (a function of the length of a polypeptide chain and its charge) while in the denatured (unfolded) state. In most proteins, the binding of SDS to the polypeptide chain imparts an even distribution of charge per unit mass, thereby resulting in a fractionation by approximate size during electrophoresis.\n\nSDS is a strong detergent agent used to denature native proteins to unfolded, individual polypeptides. When a protein mixture is heated to 100 °C in presence of SDS, the detergent wraps around the polypeptide backbone. In this process, the intrinsic charges of polypeptides becomes negligible when compared to the negative charges contributed by SDS. Thus polypeptides after treatment become rod-like structures possessing a uniform charge density, that is same net negative charge per unit length. The electrophoretic mobilities of these proteins will be a linear function of the logarithms of their molecular weights.\n\nNative gels, also known as non-denaturing gels, analyze proteins that are still in their folded state. Thus, the electrophoretic mobility depends not only on the charge-to-mass ratio, but also on the physical shape and size of the protein.\n\nBN-PAGE is a native PAGE technique, where the Coomassie Brilliant Blue dye provides the necessary charges to the protein complexes for the electrophoretic separation. The disadvantage of Coomassie is that in binding to proteins it can act like a detergent causing complexes to dissociate. Another drawback is the potential quenching of chemoluminescence (e.g. in subsequent western blot detection or activity assays) or fluorescence of proteins with prosthetic groups (e.g. heme or chlorophyll) or labelled with fluorescent dyes.\n\nCN-PAGE (commonly referred to as Native PAGE) separates acidic water-soluble and membrane proteins in a polyacrylamide gradient gel. It uses no charged dye so the electrophoretic mobility of proteins in CN-PAGE (in contrast to the charge shift technique BN-PAGE) is related to the intrinsic charge of the proteins. The migration distance depends on the protein charge, its size and the pore size of the gel. In many cases this method has lower resolution than BN-PAGE, but CN-PAGE offers advantages whenever Coomassie dye would interfere with further analytical techniques, for example it has been described as a very efficient microscale separation technique for FRET analyses. Also CN-PAGE is milder than BN-PAGE so it can retain labile supramolecular assemblies of membrane protein complexes that are dissociated under the conditions of BN-PAGE.\n\nThe folded protein complexes of interest separate cleanly and predictably due to the chemical and physical properties of the polyacrylamide gel. The separated proteins are continuously eluted into a physiological eluent and transported to a fraction collector. In a few specific PAGE fractions metal cofactors can be identified and absolutely quantified by high-resolution ICP-MS. The natural structures of the isolated metalloproteins are elucidated by solution NMR spectroscopy.\n\nMost protein separations are performed using a \"discontinuous\" (or DISC) buffer system that significantly enhances the sharpness of the bands within the gel. During electrophoresis in a discontinuous gel system, an ion gradient is formed in the early stage of electrophoresis that causes all of the proteins to focus into a single sharp band. The formation of the ion gradient is achieved by choosing a pH value at which the ions of the buffer are only moderately charged compared to the SDS-coated proteins. These conditions provide an environment in which Kohlrausch's reactions determine the molar conductivity. As a result, SDS-coated proteins are concentrated to several fold in a thin zone of the order of 19 μm within a few minutes. At this stage all proteins migrate at the same migration speed by isotachophoresis. This occurs in a region of the gel that has larger pores so that the gel matrix does not retard the migration during the focusing or \"stacking\" event. Separation of the proteins by size is achieved in the lower, \"resolving\" region of the gel. The resolving gel typically has a much smaller pore size, which leads to a sieving effect that now determines the electrophoretic mobility of the proteins. At the same time, the separating part of the gel also has a pH value in which the buffer ions on average carry a greater charge, causing them to \"outrun\" the SDS-covered proteins and eliminate the ion gradient and thereby the stacking effect.\n\nA very widespread discontinuous buffer system is the tris-glycine or \"Laemmli\" system that stacks at a pH of 6.8 and resolves at a pH of ~8.3-9.0. A drawback of this system is that these pH values may promote disulfide bond formation between cysteine residues in the proteins because the pKa of cysteine ranges from 8-9 and because reducing agent present in the loading buffer doesn't co-migrate with the proteins. Recent advances in buffering technology alleviate this problem by resolving the proteins at a pH well below the pKa of cysteine (e.g., bis-tris, pH 6.5) and include reducing agents (e.g. sodium bisulfite) that move into the gel ahead of the proteins to maintain a reducing environment. An additional benefit of using buffers with lower pH values is that the acrylamide gel is more stable at lower pH values, so the gels can be stored for long periods of time before use.\n\nAs voltage is applied, the anions (and negatively charged sample molecules) migrate toward the positive electrode (anode) in the lower chamber, the leading ion is Cl ( high mobility and high concentration); glycinate is the trailing ion (low mobility and low concentration). SDS-protein particles do not migrate freely at the border between the Cl of the gel buffer and the Gly of the cathode buffer. Friedrich Kohlrausch found that Ohm's law also applies to dissolved electrolytes. Because of the voltage drop between the Cl and Glycine-buffers, proteins are compressed (stacked) into micrometer thin layers. The boundary moves through a pore gradient and the protein stack gradually disperses due to a frictional resistance increase of the gel matrix. Stacking and unstacking occurs continuously in the gradient gel, for every protein at a different position. For a complete protein unstacking the polyacrylamide-gel concentration must exceed 16% T. The two-gel system of \"Laemmli\" is a simple gradient gel. The pH discontinuity of the buffers is of no significance for the separation quality, and a \"stacking-gel\" with a different pH is not needed.\n\nThe most popular protein stain is Coomassie Brilliant Blue. It is an anionic dye, which non-specifically binds to proteins. Proteins in the gel are fixed by acetic acid and simultaneously stained. The excess dye incorporated into the gel can be removed by destaining with the same solution without the dye. The proteins are detected as blue bands on a clear background.\n\nWhen more sensitive method than staining by Coomassie is needed silver staining is usually used. Silver staining is a sensitive procedure to detect trace amounts of proteins in gels, but can also visualize nucleic acid or polysaccharides.\n\nSimilarly as in nucleic acid gel electrophoresis, tracking dye is often used. Anionic dyes of a known electrophoretic mobility are usually included in the sample buffer. A very common tracking dye is Bromophenol blue. This dye is coloured at alkali and neutral pH and is a small negatively charged molecule that moves towards the anode. Being a highly mobile molecule it moves ahead of most proteins.\n\nIn medicine, protein electrophoresis is a method of analysing the proteins mainly in blood serum. Before the widespread use of gel electrophoresis, protein electrophoresis was performed as free-flow electrophoresis (on paper) or as immunoelectrophoresis.\n\nTraditionally, two classes of blood proteins are considered: serum albumin and globulin. They are generally equal in proportion, but albumin as a molecule is much smaller and lightly, negatively-charged, leading to an accumulation of albumin on the electrophoretic gel. A small band before albumin represents transthyretin (also named prealbumin). Some forms of medication or body chemicals can cause their own band, but it usually is small. Abnormal bands (spikes) are seen in monoclonal gammopathy of undetermined significance and multiple myeloma, and are useful in the diagnosis of these conditions.\n\nThe globulins are classified by their banding pattern (with their main representatives):\n\nNormal present medical procedure involves determination of numerous proteins in plasma including hormones and enzymes, some of them also determined by electrophoresis. However, gel electrophoresis is mainly a research tool, also when the subject is blood proteins.\n\n\n", "id": "589968", "title": "Gel electrophoresis of proteins"}
{"url": "https://en.wikipedia.org/wiki?curid=20086199", "text": "The Proteolysis Map\n\nThe Proteolysis MAP (PMAP) is an integrated web resource focused on proteases.\n\nPMAP is to aid the protease researchers in reasoning about proteolytic networks and metabolic pathways.\n\nPMAP was originally created at the Burnham Institute for Medical Research, La Jolla, California. In 2004 the National Institutes of Health (NIH) selected a team led by Jeffrey W. Smith, to establish the Center on Proteolytic Pathways (CPP). As part of the NIH Roadmap for Biomedical research, the center develops technology to study the behavior of proteins and to disburse that knowledge to the scientific community at large.\n\nProteases are a class of enzymes that regulate much of what happens in the human body, both inside the cell and out, by cleaving peptide bonds in proteins. Through this activity, they govern the four essential cell functions: differentiation, motility, division and cell death — and activate important extracellular episodes, such as the biochemical cascade effect in blood clotting. Simply stated, life could not exist without them. Extensive on-line classification system for proteases (also referred as peptidases) is deposited in the MEROPS database.\n\nProteolytic pathways, or proteolysis, are the series of events controlled by proteases that occur in response to specific stimuli. In addition to the clotting of blood, the production of insulin can be viewed as a proteolytic pathway, as the activation, regulation and inhibition of that protein is the result of proteases reacting to changing glucose levels and triggering other proteases downstream.\n\nPMAP integrates five databases.\nProteaseDB and SubstrateDB, are driven by an automated annotation pipeline that generates dynamic ‘Molecule Pages’, rich in molecular information. CutDB has information on more than 6,600 proteolytic events, and ProfileDB is dedicated to information of the substrate recognition specificity of proteases. PathwayDB, just begun accumulation of metabolic pathways whose function can be dynamically modeled in a rule-based manner. Hypothetical networks are inferred by semi-automated culling from the literature. Additionally, protease software tools are available for the analysis of individual proteases and proteome-wide data sets.\n\nPopular destinations in PMAP are Protease Molecule Pages and Substrate Molecule Pages. Protease Molecule Pages show recent news in PubMed literature of the protease, known proteolytic events, protein domain location and protein structure view, as well as a cross annotation in other bioinformatic databases section. Substrate Molecule Pages display protein domains and experimentally derived protease cut-sites for a given protein target of interest.\n\n\n", "id": "20086199", "title": "The Proteolysis Map"}
{"url": "https://en.wikipedia.org/wiki?curid=50177303", "text": "Synchronous coefficient of drag alteration\n\nSynchronous coefficient of drag alteration (SCODA) is a biotechnology method for purifying, separating and/or concentrating bio-molecules. SCODA has the ability to separate molecules whose mobility (or drag) can be altered in sync with a driving field. This technique has been primarily used for concentrating and purifying DNA, where DNA mobility changes with an applied electrophoretic field. Electrophoretic SCODA has also been demonstrated with RNA and proteins.\n\nAs shown below, the SCODA principle applies to any particle driven by a force field in which the particle's mobility is altered in sync with the driving field.\n\nFor explanatory purposes consider an electrophoretic particle moving (driven) in an electric field. Let:\n\nandformula_2\n\ndenote an electric field and the velocity of the particle in such a field. If formula_4 is constant the time average of formula_5.\n\nIf formula_4 is not constant as a function of time and if formula_4 has a frequency component proportional to formula_8 the time average of formula_9 need not be zero.\n\nConsider the following example:\n\nSubstituting (3) in (2) and computing the time average, formula_11, we obtain:\n\nThus, it is possible to have the particle experience a non-zero time average velocity, in other words, a net electrophoretic drift, even when the time average of the applied electric field is zero.\n\nConsider a particle under a force field that has a velocity parallel to the field direction and a speed proportional to the square of the magnitude of the electric field (any other non-linearity can be employed):\n\nThe effective mobility of the particle (the relationship between small changes in drift velocity formula_14 with respect to small changes in electric field formula_15) can be expressed in Cartesian coordinates as:\n\nCombining (5), (6) and (7) we get:\n\nFurther consider the field E is applied in a plane and it rotates counter-clockwise at angular frequency formula_20, such that the field components are:\n\nSubstituting (10) and (11) in (8) and (9) and simplifying using trigonometric identities results in a sum of constant terms, sine and cosine, at angular frequency formula_23. The next calculations will be performed such that only the cosine terms at angular frequency formula_23 will yield non-zero net drift velocity - therefore we need only evaluate these terms, which will be abbreviated formula_2 and formula_26. The following is obtained:\n\nLet formula_29 and formula_30 take the form of a small quadrupole field of intensity formula_31 that varies in a sinusoidal manner proportional to formula_32 such that:\n\nSubstituting (14) and (15) into (12) and (13) and taking the time average we obtain:\n\nwhich can be summarized in vector notation to:\n\nEquation (18) shows that for all positions formula_38 the time averaged velocity is in the direction toward the origin (concentrating the particles towards the origin), with speed proportional to the mobility coefficient k, the strength of the rotating field E and the strength of the perturbing quadrupole field formula_31.\n\nDNA molecules are unique in that they are long, charged polymers which when in a separation medium, such as agarose gel, can exhibit highly non-linear velocity profiles in response to an electric field. As such, DNA is easily separated from other molecules that are not both charged and strongly non-linear, using SCODA\n\nTo perform SCODA concentration of DNA molecules, the sample must be embedded in the separation media (gel) in locations where the electrophoretic field is of optimal intensity. This initial translocation of the sample into the optimal concentration position is referred to as \"injection\". The optimal position is determined by the gel geometry and location of the SCODA driving electrodes. Initially the sample is located in a buffer solution in the sample chamber, adjacent to the concentration gel. Injection is achieved by the application of a controlled DC electrophoretic field across the sample chamber which results in all charged particles being transferred into the concentration gel. To obtain a good stacking of the sample (i.e. tight DNA band) multiple methods can be employed. One example is to exploit the conductivity ratio between the sample chamber buffer and the concentration gel buffer. If the sample chamber buffer has a low conductivity and the concentration gel buffer has a high conductivity this results in a sharp drop off in electric field at the gel-buffer interface which promotes stacking.\n\nOnce the DNA is positioned optimally in the concentration gel the SCODA rotating fields are applied. The frequency of the fields can be tuned such that only specific DNA lengths are concentrated. To prevent boiling during the concentration stage due to Joule heating the separation medium may be actively cooled. It is also possible to reverse the phase of SCODA fields, so that molecules are de-focused.\n\nAs only particles that exhibit non-linear velocity experience the SCODA concentrating force, small charged particles that respond linearly to electrophoretic fields are not concentrated. These particles instead of spiraling towards the center of the SCODA gel orbit at a constant radius. If a weak DC field is superimposed on the SCODA rotating fields these particles will be \"washed\" off from the SCODA gel resulting in highly pure DNA remaining in the gel center.\n\nThe SCODA DNA force results in the DNA sample concentrating in the center of the SCODA gel. To extract the DNA an extraction well can be pre-formed in the gel and filled with buffer. As the DNA does not experience non-linear mobility in buffer it accumulates in the extraction well. At the end of the concentration and purification stage the sample can then be pipetted out from this well.\n\nThe electrophoretic SCODA force is gentle enough to maintain the integrity of high molecular weight DNA as it is concentrated towards the center of the SCODA gel. Depending on the length of the DNA in the sample different protocols can be used to concentrate DNA over 1 Mb in length.\n\nDNA concentration and purification has been achieved directly from tar sands samples resuspended in buffer using the SCODA technique. DNA sequencing was subsequently performed and tentatively over 200 distinct bacterial genomes have been identified. SCODA has also been used for purification of DNA from many other environmental sources.\n\nThe non-linear mobility of DNA in gel can be further controlled by embedding in the SCODA gel DNA oligonucleotides complementary to DNA fragments in the sample. This then results in highly specific non-linear velocities for the sample DNA that matches the gel-embedded DNA. This artificial specific non-linearity is then used to selectively concentrate only sequences of interest while rejecting all other DNA sequences in the sample. Over 1,000,000-fold enrichment of single nucleotide variants over wild-type have been demonstrated.\n\nAn application of this technique is the detection of rare DNA tumour-derived DNA (ctDNA) from blood samples.\n\n", "id": "50177303", "title": "Synchronous coefficient of drag alteration"}
{"url": "https://en.wikipedia.org/wiki?curid=51165385", "text": "TCP-seq\n\nTranslation complex profile sequencing (TCP-seq) is a molecular biology method for obtaining snapshots of momentary distribution of protein synthesis complexes along messenger RNA (mRNA) chains.\n\nExpression of genetic code in all life forms consists of two major processes, synthesis of copies of the genetic code recorded in DNA into the form of mRNA (transcription), and protein synthesis itself (translation), whereby the code copies in mRNA are decoded into amino acid sequences of the respective proteins. Both transcription and translation are highly regulated processes essentially controlling everything of what happens in live cells (and multicellular organisms, consequently).\n\nControl of translation is especially important in eukaryotic cells where it forms part of post-transcriptional regulatory networks of genes expression. This additional functionality is reflected in the increased complexity of the translation process, making it a hard object to investigate. Yet details on when and what mRNA is translated and what mechanisms are responsible for this control are key to understanding of normal and pathological cell functionality. TCP-seq can be used to obtain this information.\n\nWith the advent of the high-throughput DNA and RNA sequence identification methods (such as Illumina sequencing), it became possible to efficiently analyse nucleotide sequences of large numbers of relatively short DNA and RNA fragments. Sequences of these fragments can be superimposed to reconstruct the source. Alternatively, if the source sequence is already known, the fragments can be found within it (“mapped”), and their individual numbers counted. Thus, if an initial stage exists whereby the fragments are differentially present or selected (“enriched”), this approach can be used to quantitatively describe such stage over even a very large number or length of the input sequences, most usually encompassing the entire DNA or RNA of the cell.\n\nTCP-seq is based on these capabilities of the high-throughput RNA sequencing and further uses the nucleic acid protection phenomenon. The protection is manifested as resistance to depolymerisation or modification of stretches of nucleic acids (particularly, RNA) that are tightly bound to or engulfed with other biomolecules, which thus leave their “footprints” over the nucleic acid strand. These “footprint” fragments therefore represent location on nucleic acid chain where the interaction occurs. By sequencing and mapping the fragments back to the source sequence, it is possible to precisely identify the locations and counts of these intermolecular contacts.\n\nIn case of TCP-seq, ribosomes and ribosomal subunits engaged in interaction with mRNA are first fast chemically crosslinked to it with formaldehyde to preserve existing state of interactions (“snapshot” of distribution) and to block any possible non-equilibrium processes. The crosslinking can be performed directly in, but not restricted to, live cells. The RNA is then partially degraded (\"e.g.\" with ribonuclease) so that only fragments protected by the ribosomes or ribosomal subunits are left. The protected fragments are then purified according to the sedimentation dynamics of the attached ribosomes or ribosomal subunits, de-blocked, sequenced and mapped to the source transcriptome, giving the original locations of the translation complexes over mRNA.\n\nTCP-seq merges several elements typical to other transcriptome-wide analyses of its kind. In particular, polysome profiling and ribosome (translation) profiling approaches are also employed to identify mRNA involved in polysome formation and locations of elongating ribosomes over coding regions of transcripts, correspondingly. These methods, however, do not use chemical stabilisation of translation complexes and purification of the covalently bound intermediates from the live cells. TCP-seq thus can be considered more as a functional equivalent of ChIP-seq and similar methods of investigating momentary interactions of DNA that are redesigned to be applicable for translation.\n\nThe advantages of the method include:\nThe disadvantages include:\n\nThe method is currently being developed and was applied to investigate translation dynamics in live yeast cells and is extending, rather than simply combining, the capabilities of the previous techniques. The only other transcriptome-wide method for mapping ribosome positions over mRNA with nucleotide precision is ribosome (translation) profiling. However, it captures positions of only elongating ribosomes, and most dynamic and functionally important intermediates of translation at the initiation stage are not detected.\n\nTCP-seq was designed to specifically target these blind spots. It can essentially provide the same level of details for elongation phase as ribosome (translation) profiling, but also includes recording of initiation, termination and recycling intermediates (and basically any other possible translation complexes as long as the ribosome or its subunits are contacting and protecting the mRNA) of protein synthesis that previously remained out of the reach. Therefore, TCP-seq provides a single approach for a complete insight into the translation process of a biological sample. This particular aspect of the method can be expected to be developed further as the dynamics of ribosomal scanning on mRNA during translation initiation is generally unknown for the most of life. Current dataset containing TCP-seq data for translation initiation is available for yeast \"Saccharomyces cerevisiae\", and likely to be extended for other organisms in the future.\n", "id": "51165385", "title": "TCP-seq"}
{"url": "https://en.wikipedia.org/wiki?curid=22224112", "text": "TBST\n\nIn molecular biology, TBST (or TTBS) is a mixture of tris-buffered saline (TBS) and Polysorbate 20 (also known as Tween 20). It is a buffer used for washing nitrocellulose membrane in western blotting and microtiter plate wells in ELISA assays.\n\nThe following is a sample recipe for TBST:\nAdjust pH with HCl to pH 7.4–7.6\n\nThe simplest way to prepare a TBS-Tween solution is to use TBS-T tablets. They are formulated to give a ready to use TBST solution upon dissolution in 500 ml of deionized water.\n\nhttp://www.seattlechildrens.org/pdf/wholemount-IHC-protocol-1.pdf", "id": "22224112", "title": "TBST"}
{"url": "https://en.wikipedia.org/wiki?curid=339488", "text": "Cloning vector\n\nA cloning vector is a small piece of DNA, taken from a virus, a plasmid, or the cell of a higher organism, that can be stably maintained in an organism, and into which a foreign DNA fragment can be inserted for cloning purposes. The vector therefore contains features that allow for the convenient insertion or removal of a DNA fragment to or from vector, for example by treating the vector and the foreign DNA with a restriction enzyme that cuts the DNA. DNA fragments thus generated contain either blunt ends or overhangs known as sticky ends, and vector DNA and foreign DNA with compatible ends can then be joined together by molecular ligation. After a DNA fragment has been cloned into a cloning vector, it may be further subcloned into another vector designed for more specific use.\n\nThere are many types of cloning vectors, but the most commonly used ones are genetically engineered plasmids. Cloning is generally first performed using \"Escherichia coli\", and cloning vectors in \"E. coli\" include plasmids, bacteriophages (such as phage λ), cosmids, and bacterial artificial chromosomes (BACs). Some DNA, however, cannot be stably maintained in \"E. coli\", for example very large DNA fragments, and other organisms such as yeast may be used. Cloning vectors in yeast include yeast artificial chromosomes (YACs).\n\nAll commonly used cloning vectors in molecular biology have key features necessary for their function, such as a suitable cloning site and selectable marker. Others may have additional features specific to their use. For reason of ease and convenience, cloning is often performed using \"E. coli\". Thus, the cloning vectors used often have elements necessary for their propagation and maintenance in \"E. coli\", such as a functional origin of replication (ori). The ColE1 origin of replication is found in many plasmids. Some vectors also include elements that allow them to be maintained in another organism in addition to \"E. coli\", and these vectors are called shuttle vector.\n\nAll cloning vectors have features that allow a gene to be conveniently inserted into the vector or removed from it. This may be a multiple cloning site (MCS) or polylinker, which contains many unique restriction sites. The restriction sites in the MCS are first cleaved by restriction enzymes, then a PCR-amplified target gene also digested with the same enzymes is ligated into the vectors using DNA ligase. The target DNA sequence can be inserted into the vector in a specific direction if so desired. The restriction sites may be further used for sub-cloning into another vector if necessary.\n\nOther cloning vectors may use topoisomerase instead of ligase and cloning may be done more rapidly without the need for restriction digest of the vector or insert. In this TOPO cloning method a linearized vector is activated by attaching topoisomerase I to its ends, and this \"TOPO-activated\" vector may then accept a PCR product by ligating both the 5' ends of the PCR product, releasing the topoisomerase and forming a circular vector in the process. Another method of cloning without the use of DNA digest and ligase is by DNA recombination, for example as used in the Gateway cloning system. The gene, once cloned into the cloning vector (called entry clone in this method), may be conveniently introduced into a variety of expression vectors by recombination.\n\nA selectable marker is carried by the vector to allow the selection of positively transformed cells. Antibiotic resistance is often used as marker, an example being the beta-lactamase gene, which confers resistance to the penicillin group of beta-lactam antibiotics like ampicillin. Some vectors contain two selectable markers, for example the plasmid pACYC177 has both ampicillin and kanamycin resistance gene. Shuttle vector which is designed to be maintained in two different organisms may also require two selectable markers, although some selectable markers such as resistance to zeocin and hygromycin B are effective in different cell types. Auxotrophic selection markers that allow an auxotrophic organism to grow in minimal growth medium may also be used; examples of these are \"LEU2\" and \"URA3\" which are used with their corresponding auxotrophic strains of yeast.\n\nAnother kind of selectable marker allows for the positive selection of plasmid with cloned gene. This may involve the use of a gene lethal to the host cells, such as barnase, Ccda, and the parD/parE toxins. This typically works by disrupting or removing the lethal gene during the cloning process, and unsuccessful clones where the lethal gene still remains intact would kill the host cells, therefore only successful clones are selected.\n\nReporter genes are used in some cloning vectors to facilitate the screening of successful clones by using features of these genes that allow successful clone to be easily identified. Such features present in cloning vectors may be the \"lacZ\"α fragment for α complementation in blue-white selection, and/or marker gene or reporter genes in frame with and flanking the MCS to facilitate the production of fusion proteins. Examples of fusion partners that may be used for screening are the green fluorescent protein (GFP) and luciferase.\n\nA cloning vector need not contain suitable elements for the expression of a cloned target gene, such as a promoter and ribosomal binding site (RBS), many however do, and may then work as an expression vector. The target DNA may be inserted into a site that is under the control of a particular promoter necessary for the expression of the target gene in the chosen host. Where the promoter is present, the expression of the gene is preferably tightly controlled and inducible so that proteins are only produced when required. Some commonly used promoters are the T7 and \"lac\" promoters. The presence of a promoter is necessary when screening techniques such as blue-white selection are used.\n\nCloning vectors without promoter and RBS for the cloned DNA sequence are sometimes used, for example when cloning genes whose products are toxic to \"E. coli\" cells. Promoter and RBS for the cloned DNA sequence are also unnecessary when first making a genomic or cDNA library of clones since the cloned genes are normally subcloned into a more appropriate expression vector if their expression is required.\n\nSome vectors are designed for transcription only with no heterologous protein expressed, for example for \"in vitro\" mRNA production. These vectors are called transcription vectors. They may lack the sequences necessary for polyadenylation and termination, therefore may not be used for protein production.\n\nA large number of cloning vectors are available, and choosing the vector may depend a number of factors, such as the size of the insert, copy number and cloning method. Large insert may not be stably maintained in a general cloning vector, especially for those with a high copy number, therefore cloning large fragments may require more specialized cloning vector.\n\nPlasmids are autonomously replicating circular extra-chromosomal DNA. They are the standard cloning vectors and the ones most commonly used. Most general plasmids may be used to clone DNA insert of up to 15 kb in size. One of the earliest commonly used cloning vectors is the pBR322 plasmid. Other cloning vectors include the pUC series of plasmids, and a large number of different cloning plasmid vectors are available. Many plasmids have high copy number, for example pUC19 which has a copy number of 500-700 copies per cell, and high copy number is useful as it produces greater yield of recombinant plasmid for subsequent manipulation. However low-copy-number plasmids may be preferably used in certain circumstances, for example, when the protein from the cloned gene is toxic to the cells.\n\nSome plasmids contain an M13 bacteriophage origin of replication and may be used to generate single-stranded DNA. These are called phagemid, and examples are the pBluescript series of cloning vectors.\n\nThe bacteriophages used for cloning are the phage λ and M13 phage. There is an upper limit on the amount of DNA that can be packed into a phage (a maximum of 53 kb), therefore to allow foreign DNA to be inserted into phage DNA, phage cloning vectors may need to have some non-essential genes deleted, for example the genes for lysogeny since using phage λ as a cloning vector involves only the lytic cycle. There are two kinds of λ phage vectors - insertion vector and replacement vector. Insertion vectors contain a unique cleavage site whereby foreign DNA with size of 5–11 kb may be inserted. In replacement vectors, the cleavage sites flank a region containing genes not essential for the lytic cycle, and this region may be deleted and replaced by the DNA insert in the cloning process, and a larger sized DNA of 8–24 kb may be inserted.\n\nThere is also a lower size limit for DNA that can be packed into a phage, and vector DNA that is too small cannot be properly packaged into the phage. This property can be used for selection - vector without insert may be too small, therefore only vectors with insert may be selected for propagation.\n\nCosmids are plasmids that incorporate a segment of bacteriophage λ DNA that has the cohesive end site (cos) which contains elements required for packaging DNA into λ particles. It is normally used to clone large DNA fragments between 28 and 45 Kb.\n\nInsert size of up to 350 kb can be cloned in bacterial artificial chromosome (BAC). BACs are maintained in \"E. coli\" with a copy number of only 1 per cell. BACs are based on F plasmid, another artificial chromosome called the PAC is based on the P1 phage.\n\nInsert of up to 3,000 kb may be carried by yeast artificial chromosome.\n\nHuman artificial chromosome may be potentially useful as a gene transfer vectors for gene delivery into human cells, and a tool for expression studies and determining human chromosome function. It can carry very large DNA fragment (there is no upper limit on size for practical purposes), therefore it does not have the problem of limited cloning capacity of other vectors, and it also avoids possible insertional mutagenesis caused by integration into host chromosomes by viral vector.\n\nMany general purpose vectors such as pUC19 usually include a system for detecting the presence of a cloned DNA fragment, based on the loss of an easily scored phenotype. The most widely used is the gene coding for \"E. coli\" β-galactosidase, whose activity can easily be detected by the ability of the enzyme it encodes to hydrolyze the soluble, colourless substrate X-gal (5-bromo-4-chloro-3-indolyl-beta-d-galactoside) into an insoluble, blue product (5,5'-dibromo-4,4'-dichloro indigo). Cloning a fragment of DNA within the vector-based \"lacZα\" sequence of the β-galactosidase prevents the production of an active enzyme. If X-gal is included in the selective agar plates, transformant colonies are generally blue in the case of a vector with no inserted DNA and white in the case of a vector containing a fragment of cloned DNA.\n\n", "id": "339488", "title": "Cloning vector"}
{"url": "https://en.wikipedia.org/wiki?curid=51331174", "text": "EMBO Membership\n\nMembership of the European Molecular Biology Organization (EMBO) is an award for scientists granted by the European Molecular Biology Organization (EMBO) in recognition of:\n\n, 84 EMBO Members and Associate Members have been awarded Nobel Prizes in either Physiology or Medicine, Chemistry or Physics. See for examples of EMBO members.\n\nElections for membership are held annually with candidates for membership being nominated and elected exclusively by existing EMBO members, membership cannot be applied for directly. Three types of membership exist:\n\n", "id": "51331174", "title": "EMBO Membership"}
{"url": "https://en.wikipedia.org/wiki?curid=48349765", "text": "Bomb pulse\n\nThe bomb pulse is the sudden increase of carbon-14 (C) in the Earth's atmosphere due to the hundreds of aboveground nuclear bombs tests that started in 1945 and intensified between 1950 until 1963, when the Limited Test Ban Treaty was signed by the United States, the Soviet Union and the United Kingdom. These hundreds of blasts were followed by a doubling of the concentration of C in the atmosphere. Since then, the concentration of C has decreased towards the previous level. Carbon-14, the radioisotope of carbon-12, is naturally developed in trace amounts in the atmosphere and it can be detected in all living organisms. Carbon of all types is continually used to form the molecules of the cells of organisms. Doubling of the concentration of C in the atmosphere is reflected in the tissues and cells of all organisms that lived around the period of nuclear testing. This property has many applications in the fields of biology and forensics.\n\nThe radioisotope carbon-14 is constantly formed from nitrogen-14 (N) in the higher atmosphere by incoming cosmic rays which generate neutrons. These neutrons collide with N to produce C which then combines with oxygen to form CO. This radioactive CO spreads through the lower atmosphere and the oceans where it is absorbed by the plants and the animals that eat the plants. The radioisotope C thus becomes part of the biosphere so that all living organisms contain a certain amount of C. Nuclear testing caused a rapid increase in atmospheric C (see figure), since the explosion of an atomic bomb also creates neutrons which collide again with N and produce C. Since the ban on nuclear testing in 1963, atmospheric C is slowly decreasing at a pace of 1% annually. This continuous decrease permits scientists to determine among others the age of deceased people and allows them to study cell activity in tissues. By measuring the amount of C in a population of cells and comparing that to the amount of C in the atmosphere during or after the bomb pulse, scientists can estimate when the cells were created and how often they've turned over since then.\n\nRadiocarbon dating has been used since 1946 to determine the age of organic material as old as 50,000 years. As the organism dies, the exchange of C with the environment ceases and the incorporated C decays. Given the decay of this isotope (the half-life of C is about 5,730 years), the amount of C left in the dead organism permits to calculate how long ago it died. Bomb pulse dating should be considered a special form of carbon dating. As discussed above and in the Radiolab episode, \"Elements\" (section 'Carbon'), in bomb pulse dating the slow absorption of atmospheric C by the biosphere, can be considered as a chronometer. Starting from the pulse around the years 1963 (see figure), atmospheric radiocarbon decreased with 1% a year. So in bomb pulse dating it is the amount of C in the atmosphere that is decreasing and not the amount of C in a dead organisms, as is the case in classical radiocarbon dating. This decrease in atmospheric C can be measured in cells and tissues and has permitted scientists to determine the age of individual cells and of deceased people. These applications are very similar to the experiments conducted with pulse-chase analysis in which cellular processes are examined over time by exposing the cells to a labeled compound (pulse) and then to the same compound in an unlabeled form (chase). Radioactivity is a commonly used label in these experiments. An important difference between pulse-chase analysis and bomb-pulse dating is the absence of the chase in the latter.\n\nAround the year 2030 the bomb pulse will die out. Every organism born after this period will not bear any bomb pulse traces and their cells cannot be timed. Radioactive pulses cannot be administered to people to study the turnover of their cells so the bomb pulse may be considered as a useful side effect of nuclear testing.\n\nThe fact that cells and tissues reflect the doubling of C in the atmosphere during and after nuclear testing, has been of great use for several biological studies, for forensics and even for the determination of the year in which certain wine was produced.\n\nBiological studies carried out by Kirsty Spalding demonstrated that neuronal cells are essentially static and do not regenerate during life. She also showed that the number of fat cells is set during childhood and adolescence. Considering the amount of C present in DNA she could establish that 10% of fat cells are renewed annually. The bomb pulse has been used also to determine the age of Greenland sharks by measuring the incorporation of C in the eye lens during development. After having determined the age and measured the length of sharks born around the bomb pulse, it was possible to create a mathematical model in which length and age of the sharks were correlated in order to deduce the age of the larger sharks. The study showed that the Greenland shark, with an age of 392 +/- 120 years, is the oldest known vertebrate.\n\nAt the moment of death, carbon uptake is ended. Considering that after the bomb pulse C was rapidly diminishing with a rate of 1% per year, it has been possible to establish the time of death of two women in a court case by examining tissues with a rapid turnover. Another important application has been the identification of victims of the Southeast Asian tsunami 2004 by examining their teeth.\n\nAtmospheric bomb C has been used to validate tree ring ages and to date recent trees that have no annual growth rings.\n\n", "id": "48349765", "title": "Bomb pulse"}
{"url": "https://en.wikipedia.org/wiki?curid=1357514", "text": "Recombinant DNA\n\nRecombinant DNA (rDNA) molecules are DNA molecules formed by laboratory methods of genetic recombination (such as molecular cloning) to bring together genetic material from multiple sources, creating sequences that would not otherwise be found in the genome. Recombinant DNA is possible because DNA molecules from all organisms share the same chemical structure. They differ only in the nucleotide sequence within that identical overall structure.\n\nRecombinant DNA is the general name for a piece of DNA that has been created by the combination of at least two strands. Recombinant DNA molecules are sometimes called chimeric DNA, because they can be made of material from two different species, like the mythical chimera. R-DNA technology uses palindromic sequences and leads to the production of sticky and blunt ends.\n\nThe DNA sequences used in the construction of recombinant DNA molecules can originate from any species. For example, plant DNA may be joined to bacterial DNA, or human DNA may be joined with fungal DNA. In addition, DNA sequences that do not occur anywhere in nature may be created by the chemical synthesis of DNA, and incorporated into recombinant molecules. Using recombinant DNA technology and synthetic DNA, literally any DNA sequence may be created and introduced into any of a very wide range of living organisms.\n\nProteins that can result from the expression of recombinant DNA within living cells are termed \"recombinant proteins\". When recombinant DNA encoding a protein is introduced into a host organism, the recombinant protein is not necessarily produced. Expression of foreign proteins requires the use of specialized expression vectors and often necessitates significant restructuring by\nforeign coding sequences.\n\nRecombinant DNA differs from genetic recombination in that the former results from artificial methods in the test tube, while the latter is a normal biological process that results in the remixing of existing DNA sequences in essentially all organisms.\n\nMolecular cloning is the laboratory process used to create recombinant DNA. It is one of two most widely used methods, along with polymerase chain reaction (PCR), used to direct the replication of any specific DNA sequence chosen by the experimentalist. There are two fundamental differences between the methods. One is that molecular cloning involves replication of the DNA within a living cell, while PCR replicates DNA in the test tube, free of living cells. The other difference is that cloning involves cutting and pasting DNA sequences, while PCR amplifies by copying an existing sequence.\n\nFormation of recombinant DNA requires a cloning vector, a DNA molecule that replicates within a living cell. Vectors are generally derived from plasmids or viruses, and represent relatively small segments of DNA that contain necessary genetic signals for replication, as well as additional elements for convenience in inserting foreign DNA, identifying cells that contain recombinant DNA, and, where appropriate, expressing the foreign DNA. The choice of vector for molecular cloning depends on the choice of host organism, the size of the DNA to be cloned, and whether and how the foreign DNA is to be expressed. The DNA segments can be combined by using a variety of methods, such as restriction enzyme/ligase cloning or Gibson assembly.\n\nIn standard cloning protocols, the cloning of any DNA fragment essentially involves seven steps: (1) Choice of host organism and cloning vector, (2) Preparation of vector DNA, (3) Preparation of DNA to be cloned, (4) Creation of recombinant DNA, (5) Introduction of recombinant DNA into the host organism, (6) Selection of organisms containing recombinant DNA, and (7) Screening for clones with desired DNA inserts and biological properties.\n\"These steps are described in some detail in a related article (molecular cloning).\"\n\nFollowing transplantation into the host organism, the foreign DNA contained within the recombinant DNA construct may or may not be expressed. That is, the DNA may simply be replicated without expression, or it may be transcribed and translated and a recombinant protein is produced. Generally speaking, expression of a foreign gene requires restructuring the gene to include sequences that are required for producing an mRNA molecule that can be used by the host's translational apparatus (e.g. promoter, translational initiation signal, and transcriptional terminator). Specific changes to the host organism may be made to improve expression of the ectopic gene. In addition, changes may be needed to the coding sequences as well, to optimize translation, make the protein soluble, direct the recombinant protein to the proper cellular or extracellular location, and stabilize the protein from degradation.\n\nIn most cases, organisms containing recombinant DNA have apparently normal phenotypes. That is, their appearance, behavior and metabolism are usually unchanged, and the only way to demonstrate the presence of recombinant sequences is to examine the DNA itself, typically using a polymerase chain reaction (PCR) test. Significant exceptions exist, and are discussed below.\n\nIf the rDNA sequences encode a gene that is expressed, then the presence of RNA and/or protein products of the recombinant gene can be detected, typically using RT-PCR or western hybridization methods. Gross phenotypic changes are not the norm, unless the recombinant gene has been chosen and modified so as to generate biological activity in the host organism. Additional phenotypes that are encountered include toxicity to the host organism induced by the recombinant gene product, especially if it is over-expressed or expressed within inappropriate cells or tissues.\n\nIn some cases, recombinant DNA can have deleterious effects even if it is not expressed. One mechanism by which this happens is insertional inactivation, in which the rDNA becomes inserted into a host cell's gene. In some cases, researchers use this phenomenon to \"knock out\" genes to determine their biological function and importance. Another mechanism by which rDNA insertion into chromosomal DNA can affect gene expression is by inappropriate activation of previously unexpressed host cell genes. This can happen, for example, when a recombinant DNA fragment containing an active promoter becomes located next to a previously silent host cell gene, or when a host cell gene that functions to restrain gene expression undergoes insertional inactivation by recombinant DNA.\n\nRecombinant DNA is widely used in biotechnology, medicine and research. Today, recombinant proteins and other products that result from the use of DNA technology are found in essentially every western pharmacy, doctor's or veterinarian's office, medical testing laboratory, and biological research laboratory. In addition, organisms that have been manipulated using recombinant DNA technology, as well as products derived from those organisms, have found their way into many farms, supermarkets, home medicine cabinets, and even pet shops, such as those that sell GloFish and other genetically modified animals.\n\nThe most common application of recombinant DNA is in basic research, in which the technology is important to most current work in the biological and biomedical sciences. Recombinant DNA is used to identify, map and sequence genes, and to determine their function. rDNA probes are employed in analyzing gene expression within individual cells, and throughout the tissues of whole organisms. Recombinant proteins are widely used as reagents in laboratory experiments and to generate antibody probes for examining protein synthesis within cells and organisms.\n\nMany additional practical applications of recombinant DNA are found in industry, food production, human and veterinary medicine, agriculture, and bioengineering. Some specific examples are identified below.\n\n\nThe idea of recombinant DNA was first proposed by Peter Lobban, a graduate student of Prof. Dale Kaiser in the Biochemistry Department at Stanford University Medical School. The first publications describing the successful production and intracellular replication of recombinant DNA appeared in 1972 and 1973. Stanford University applied for a US patent on recombinant DNA in 1974, listing the inventors as Stanley N. Cohen and Herbert W. Boyer; this patent was awarded in 1980. The first licensed drug generated using recombinant DNA technology was human insulin, developed by Genentech and Licensed by Eli Lilly and Company.\n\nScientists associated with the initial development of recombinant DNA methods recognized that the potential existed for organisms containing recombinant DNA to have undesirable or dangerous properties. At the 1975 Asilomar Conference on Recombinant DNA, these concerns were discussed and a voluntary moratorium on recombinant DNA research was initiated for experiments that were considered particularly risky. This moratorium was widely observed until the National Institutes of Health (USA) developed and issued formal guidelines for rDNA work. Today, recombinant DNA molecules and recombinant proteins are usually not regarded as dangerous. However, concerns remain about some organisms that express recombinant DNA, particularly when they leave the laboratory and are introduced into the environment or food chain. These concerns are discussed in the articles on genetically modified organisms and genetically modified food controversies.\n\n\n\n", "id": "1357514", "title": "Recombinant DNA"}
{"url": "https://en.wikipedia.org/wiki?curid=51608872", "text": "CST Complex\n\nThe CST Complex is a cellular multiprotein complex that in budding yeast (Saccharomyces cerevisiae) is composed of the proteins Cdc13, Stn1, and Ten1, whereas in mammals the CST Complex consists of the proteins CTC1, STN1, and TEN1.\n\nFor budding yeast as well as for mammals, CST is a protein heterotrimer, consisting of three distinct proteins. Yeast Stn1 and Ten1 are orthologous proteins to mammalian STN1 and TEN1. But yeast Cdc13 and mammalian CTC1 are very different in amino acid sequence, length, and to some extent in function.\n\nFor both budding yeast and mammals, the CST complex contributes to telomere maintenance, but this function is more crucial for budding yeast, where the CST complex performs the functions that shelterin performs in vertebrates. At least four factors contribute to telomere maintenance: telomerase, shelterin, TERRA and the CST Complex. CST protection of telomeres for mammals occurs under conditions of replication stress. But when not replicating DNA, mammals primarily require shelterin for telomere protection. T-loops and G-quadruplexes are described as the two tertiary DNA structures that protect telomere ends and regulate telomere length. In fungus, the CST complex has been shown to unfold higher order G-tailed structures, such as occur with telomere exposure during DNA replication.\n\n", "id": "51608872", "title": "CST Complex"}
{"url": "https://en.wikipedia.org/wiki?curid=12832", "text": "G protein–coupled receptor\n\nG protein–coupled receptors (GPCRs) which are also known as seven-(pass)-transmembrane domain receptors, 7TM receptors, heptahelical receptors, serpentine receptor, and G protein–linked receptors (GPLR), constitute a large protein family of receptors that detect molecules outside the cell and activate internal signal transduction pathways and, ultimately, cellular responses. Coupling with G proteins, they are called seven-transmembrane receptors because they pass through the cell membrane seven times.\n\nG protein–coupled receptors are found only in eukaryotes, including yeast, choanoflagellates, and animals. The ligands that bind and activate these receptors include light-sensitive compounds, odors, pheromones, hormones, and neurotransmitters, and vary in size from small molecules to peptides to large proteins. G protein–coupled receptors are involved in many diseases, and are also the target of approximately 34% of all modern medicinal drugs.\n\nThere are two principal signal transduction pathways involving the G protein–coupled receptors: \nWhen a ligand binds to the GPCR it causes a conformational change in the GPCR, which allows it to act as a guanine nucleotide exchange factor (GEF). The GPCR can then activate an associated G protein by exchanging the GDP bound to the G protein for a GTP. The G protein's α subunit, together with the bound GTP, can then dissociate from the β and γ subunits to further affect intracellular signaling proteins or target functional proteins directly depending on the α subunit type (G, G, G, G).\n\nThe 2012 Nobel Prize in Chemistry was awarded to Brian Kobilka and Robert Lefkowitz for their work that was \"crucial for understanding how G protein–coupled receptors function\". There have been at least seven other Nobel Prizes awarded for some aspect of G protein–mediated signaling. As of 2012, two of the top ten global best-selling drugs (Advair Diskus and Abilify) act by targeting G protein–coupled receptors.\n\nThe exact size of the GPCR superfamily is unknown, but nearly 800 different human genes (or ~ 4% of the entire protein-coding genome) have been predicted to code for them from genome sequence analysis. Although numerous classification schemes have been proposed, the superfamily was classically divided into three main classes (A, B and C) with no detectable shared sequence homology between classes.\n\nThe largest class by far is class A, which accounts for nearly 85% of the GPCR genes. Of class A GPCRs, over half of these are predicted to encode olfactory receptors, while the remaining receptors are liganded by known endogenous compounds or are classified as orphan receptors. Despite the lack of sequence homology between classes, all GPCRs have a common structure and mechanism of signal transduction. The very large rhodopsin A group has been further subdivided into 19 subgroups (A1-A19).\n\nMore recently, an alternative classification system called GRAFS (Glutamate, Rhodopsin, \"Adhesion\", Frizzled/Taste2, Secretin) has been proposed. According to the classical A-F system, GPCRs can be grouped into 6 classes based on sequence homology and functional similarity:\n\nAn early study based on available DNA sequence suggested that the human genome encodes roughly 750 G protein–coupled receptors, about 350 of which detect hormones, growth factors, and other endogenous ligands. Approximately 150 of the GPCRs found in the human genome have unknown functions.\n\nSome web-servers and bioinformatics prediction methods have been used for predicting the classification of GPCRs according to their amino acid sequence alone, by means of the pseudo amino acid composition approach.\n\nGPCRs are involved in a wide variety of physiological processes. Some examples of their physiological roles include:\n\n\nGPCRs are integral membrane proteins that possess seven membrane-spanning domains or transmembrane helices. The extracellular parts of the receptor can be glycosylated. These extracellular loops also contain two highly conserved cysteine residues that form disulfide bonds to stabilize the receptor structure. Some seven-transmembrane helix proteins (channelrhodopsin) that resemble GPCRs may contain ion channels, within their protein.\n\nSimilar to GPCRs, the adiponectin receptors 1 and 2 (ADIPOR1 and ADIPOR2) also possess 7 transmembrane domains. However, ADIPOR1 and ADIPOR2 are oriented oppositely to GPCRs in the membrane (i.e. GPCRs usually have an extracellular N-terminus, cytoplasmic C-terminus, whereas ADIPORs are inverted) and do not associate with G proteins.\n\nEarly structural models for GPCRs were based on their weak analogy to bacteriorhodopsin, for which a structure had been determined by both electron diffraction (, ) and X ray-based crystallography (). In 2000, the first crystal structure of a mammalian GPCR, that of bovine rhodopsin (), was solved. While the main feature, the seven-transmembrane helices, is conserved, the relative orientation of the helices differ significantly from that of bacteriorhodopsin. In 2007, the first structure of a human GPCR was solved (, ). This was followed immediately by a higher resolution structure of the same receptor (). This human β-adrenergic receptor GPCR structure proved highly similar to the bovine rhodopsin in terms of the relative orientation of the seven-transmembrane helices. However, the conformation of the second extracellular loop is entirely different between the two structures. Since this loop constitutes the \"lid\" that covers the top of the ligand binding site, this conformational difference highlights the difficulties in constructing homology models of other GPCRs based only on the rhodopsin structure.\n\nThe structures of activated or agonist-bound GPCRs have also been determined. These structures indicate how ligand binding at the extracellular side of a receptor leads to conformational changes in the cytoplasmic side of the receptor. The biggest change is an outward movement of the cytoplasmic part of the 5th and 6th transmembrane helix (TM5 and TM6). The structure of activated beta-2 adrenergic receptor in complex with G confirmed that the Gα binds to a cavity created by this movement.\n\nA structure database, GPCR-HGmod, was recently constructed which contains 3D structural models of all human G-protein coupled receptors, built by the GPCR-I-TASSER pipeline through homology modeling and ab initio structure prediction.\n\nIn terms of structure, GPCRs are characterized by an extracellular N-terminus, followed by seven transmembrane (7-TM) α-helices (TM-1 to TM-7) connected by three intracellular (IL-1 to IL-3) and three extracellular loops (EL-1 to EL-3), and finally an intracellular C-terminus. The GPCR arranges itself into a tertiary structure resembling a barrel, with the seven transmembrane helices forming a cavity within the plasma membrane that serves a ligand-binding domain that is often covered by EL-2. Ligands may also bind elsewhere, however, as is the case for bulkier ligands (e.g., proteins or large peptides), which instead interact with the extracellular loops, or, as illustrated by the class C metabotropic glutamate receptors (mGluRs), the N-terminal tail. The class C GPCRs are distinguished by their large N-terminal tail, which also contains a ligand-binding domain. Upon glutamate-binding to an mGluR, the N-terminal tail undergoes a conformational change that leads to its interaction with the residues of the extracellular loops and TM domains. The eventual effect of all three types of agonist-induced activation is a change in the relative orientations of the TM helices (likened to a twisting motion) leading to a wider intracellular surface and \"revelation\" of residues of the intracellular helices and TM domains crucial to signal transduction function (i.e., G-protein coupling). Inverse agonists and antagonists may also bind to a number of different sites, but the eventual effect must be prevention of this TM helix reorientation.\n\nThe structure of the N- and C-terminal tails of GPCRs may also serve important functions beyond ligand-binding. For example, The C-terminus of M muscarinic receptors is sufficient, and the six-amino-acid polybasic (KKKRRK) domain in the C-terminus is necessary for its preassembly with G proteins. In particular, the C-terminus often contains serine (Ser) or threonine (Thr) residues that, when phosphorylated, increase the affinity of the intracellular surface for the binding of scaffolding proteins called β-arrestins (β-arr). Once bound, β-arrestins both sterically prevent G-protein coupling and may recruit other proteins, leading to the creation of signaling complexes involved in extracellular-signal regulated kinase (ERK) pathway activation or receptor endocytosis (internalization). As the phosphorylation of these Ser and Thr residues often occurs as a result of GPCR activation, the β-arr-mediated G-protein-decoupling and internalization of GPCRs are important mechanisms of desensitization. In addition, internalized \"mega-complexes\" consisting of a single GPCR, β-arr(in the tail conformation), and heterotrimeric G protein exist and may account for protein signaling from endosomes.\n\nA final common structural theme among GPCRs is palmitoylation of one or more sites of the C-terminal tail or the intracellular loops. Palmitoylation is the covalent modification of cysteine (Cys) residues via addition of hydrophobic acyl groups, and has the effect of targeting the receptor to cholesterol- and sphingolipid-rich microdomains of the plasma membrane called lipid rafts. As many of the downstream transducer and effector molecules of GPCRs (including those involved in negative feedback pathways) are also targeted to lipid rafts, this has the effect of facilitating rapid receptor signaling.\n\nGPCRs respond to extracellular signals mediated by a huge diversity of agonists, ranging from proteins to biogenic amines to protons, but all transduce this signal via a mechanism of G-protein coupling. This is made possible by a guanine-nucleotide exchange factor (GEF) domain primarily formed by a combination of IL-2 and IL-3 along with adjacent residues of the associated TM helices.\n\nThe G protein–coupled receptor is activated by an external signal in the form of a ligand or other signal mediator. This creates a conformational change in the receptor, causing activation of a G protein. Further effect depends on the type of G protein. G proteins are subsequently inactivated by GTPase activating proteins, known as RGS proteins.\n\nGPCRs include:\nreceptors for sensory signal mediators (e.g., light and olfactory stimulatory molecules); \nadenosine, bombesin, bradykinin, endothelin, γ-aminobutyric acid (GABA), hepatocyte growth factor (HGF), melanocortins, neuropeptide Y, opioid peptides, opsins, somatostatin, GH, tachykinins, members of the vasoactive intestinal peptide family, and vasopressin; \nbiogenic amines (e.g., dopamine, epinephrine, norepinephrine, histamine, glutamate (metabotropic effect), glucagon, acetylcholine (muscarinic effect), and serotonin); \nchemokines; \nlipid mediators of inflammation (e.g., prostaglandins, prostanoids, platelet-activating factor, and leukotrienes);\nand peptide hormones (e.g., calcitonin, C5a anaphylatoxin, follicle-stimulating hormone (FSH), gonadotropin-releasing hormone (GnRH), neurokinin, thyrotropin-releasing hormone (TRH), cannabinoids, and oxytocin). \nGPCRs that act as receptors for stimuli that have not yet been identified are known as orphan receptors.\n\nHowever, in other types of receptors that have been studied, wherein ligands bind externally to the membrane, the ligands of GPCRs typically bind within the transmembrane domain. However, protease-activated receptors are activated by cleavage of part of their extracellular domain.\n\nThe transduction of the signal through the membrane by the receptor is not completely understood. It is known that in the inactive state, the GPCR is bound to a heterotrimeric G protein complex. Binding of an agonist to the GPCR results in a conformational change in the receptor that is transmitted to the bound G subunit of the heterotrimeric G protein via . The activated G subunit exchanges GTP in place of GDP which in turn triggers the dissociation of G subunit from the G dimer and from the receptor. The dissociated G and G subunits interact with other intracellular proteins to continue the signal transduction cascade while the freed GPCR is able to rebind to another heterotrimeric G protein to form a new complex that is ready to initiate another round of signal transduction.\n\nIt is believed that a receptor molecule exists in a conformational equilibrium between active and inactive biophysical states. The binding of ligands to the receptor may shift the equilibrium toward the active receptor states. Three types of ligands exist: Agonists are ligands that shift the equilibrium in favour of active states; inverse agonists are ligands that shift the equilibrium in favour of inactive states; and neutral antagonists are ligands that do not affect the equilibrium. It is not yet known how exactly the active and inactive states differ from each other.\n\nWhen the receptor is inactive, the GEF domain may be bound to an also inactive α-subunit of a heterotrimeric G-protein. These \"G-proteins\" are a trimer of α, β, and γ subunits (known as Gα, Gβ, and Gγ, respectively) that is rendered inactive when reversibly bound to Guanosine diphosphate (GDP) (or, alternatively, no guanine nucleotide) but active when bound to Guanosine triphosphate (GTP). Upon receptor activation, the GEF domain, in turn, allosterically activates the G-protein by facilitating the exchange of a molecule of GDP for GTP at the G-protein's α-subunit. The cell maintains a 10:1 ratio of cytosolic GTP:GDP so exchange for GTP is ensured. At this point, the subunits of the G-protein dissociate from the receptor, as well as each other, to yield a Gα-GTP monomer and a tightly interacting Gβγ dimer, which are now free to modulate the activity of other intracellular proteins. The extent to which they may diffuse, however, is limited due to the palmitoylation of Gα and the presence of an isoprenoid moiety that has been covalently added to the C-termini of Gγ.\n\nBecause Gα also has slow GTP→GDP hydrolysis capability, the inactive form of the α-subunit (Gα-GDP) is eventually regenerated, thus allowing reassociation with a Gβγ dimer to form the \"resting\" G-protein, which can again bind to a GPCR and await activation. The rate of GTP hydrolysis is often accelerated due to the actions of another family of allosteric modulating proteins called Regulators of G-protein Signaling, or RGS proteins, which are a type of GTPase-Activating Protein, or GAP. In fact, many of the primary effector proteins (e.g., adenylate cyclases) that become activated/inactivated upon interaction with Gα-GTP also have GAP activity. Thus, even at this early stage in the process, GPCR-initiated signaling has the capacity for self-termination.\n\nGPCRs downstream signals have been shown to possibly interact with integrin signals, such as FAK. Integrin signaling will phosphorylate FAK, which can then decrease GPCR Gαs activity.\n\nIf a receptor in an active state encounters a G protein, it may activate it. Some evidence suggests that receptors and G proteins are actually pre-coupled. For example, binding of G proteins to receptors affects the receptor's affinity for ligands. Activated G proteins are bound to GTP.\n\nFurther signal transduction depends on the type of G protein. The enzyme adenylate cyclase is an example of a cellular protein that can be regulated by a G protein, in this case the G protein G. Adenylate cyclase activity is activated when it binds to a subunit of the activated G protein. Activation of adenylate cyclase ends when the G protein returns to the GDP-bound state.\n\nAdenylate cyclases (of which 9 membrane-bound and one cytosolic forms are known in humans) may also be activated or inhibited in other ways (e.g., Ca2+/Calmodulin binding), which can modify the activity of these enzymes in an additive or synergistic fashion along with the G proteins.\n\nThe signaling pathways activated through a GPCR are limited by the primary sequence and tertiary structure of the GPCR itself but ultimately determined by the particular conformation stabilized by a particular ligand, as well as the availability of transducer molecules. Currently, GPCRs are considered to utilize two primary types of transducers: G-proteins and β-arrestins. Because β-arr's have high affinity only to the phosphorylated form of most GPCRs (see above or below), the majority of signaling is ultimately dependent upon G-protein activation. However, the possibility for interaction does allow for G-protein-independent signaling to occur.\n\nThere are three main G-protein-mediated signaling pathways, mediated by four sub-classes of G-proteins distinguished from each other by sequence homology (G, G, G, and G). Each sub-class of G-protein consists of multiple proteins, each the product of multiple genes or splice variations that may imbue them with differences ranging from subtle to distinct with regard to signaling properties, but in general they appear reasonably grouped into four classes. Because the signal transducing properties of the various possible βγ combinations do not appear to radically differ from one another, these classes are defined according to the isoform of their α-subunit.\n\nWhile most GPCRs are capable of activating more than one Gα-subtype, they also show a preference for one subtype over another. When the subtype activated depends on the ligand that is bound to the GPCR, this is called functional selectivity (also known as agonist-directed trafficking, or conformation-specific agonism). However, the binding of any single particular agonist may also initiate activation of multiple different G-proteins, as it may be capable of stabilizing more than one conformation of the GPCR's GEF domain, even over the course of a single interaction. In addition, a conformation that preferably activates one isoform of Gα may activate another if the preferred is less available. Furthermore, feedback pathways may result in receptor modifications (e.g., phosphorylation) that alter the G-protein preference. Regardless of these various nuances, the GPCR's preferred coupling partner is usually defined according to the G-protein most obviously activated by the endogenous ligand under most physiological or experimental conditions.\n\n\nThe above descriptions ignore the effects of Gβγ–signalling, which can also be important, in particular in the case of activated G-coupled GPCRs. The primary effectors of Gβγ are various ion channels, such as G-protein-regulated inwardly rectifying K channels (GIRKs), P/Q- and N-type voltage-gated Ca channels, as well as some isoforms of AC and PLC, along with some phosphoinositide-3-kinase (PI3K) isoforms.\n\nAlthough they are classically thought of working only together, GPCRs may signal through G-protein-independent mechanisms, and heterotrimeric G-proteins may play functional roles independent of GPCRs. GPCRs may signal independently through many proteins already mentioned for their roles in G-protein-dependent signaling such as β-arrs, GRKs, and Srcs. In addition, further scaffolding proteins involved in subcellular localization of GPCRs (e.g., PDZ-domain-containing proteins) may also act as signal transducers. Most often the effector is a member of the MAPK family.\n\nIn the late 1990s, evidence began accumulating to suggest that some GPCRs are able to signal without G proteins. The ERK2 mitogen-activated protein kinase, a key signal transduction mediator downstream of receptor activation in many pathways, has been shown to be activated in response to cAMP-mediated receptor activation in the slime mold \"D. discoideum\" despite the absence of the associated G protein α- and β-subunits.\n\nIn mammalian cells, the much-studied β-adrenoceptor has been demonstrated to activate the ERK2 pathway after arrestin-mediated uncoupling of G-protein-mediated signaling. Therefore, it seems likely that some mechanisms previously believed related purely to receptor desensitisation are actually examples of receptors switching their signaling pathway, rather than simply being switched off.\n\nIn kidney cells, the bradykinin receptor B2 has been shown to interact directly with a protein tyrosine phosphatase. The presence of a tyrosine-phosphorylated ITIM (immunoreceptor tyrosine-based inhibitory motif) sequence in the B2 receptor is necessary to mediate this interaction and subsequently the antiproliferative effect of bradykinin.\n\nAlthough it is a relatively immature area of research, it appears that heterotrimeric G-proteins may also take part in non-GPCR signaling. There is evidence for roles as signal transducers in nearly all other types of receptor-mediated signaling, including integrins, receptor tyrosine kinases (RTKs), cytokine receptors (JAK/STATs), as well as modulation of various other \"accessory\" proteins such as GEFs, guanine-nucleotide dissociation inhibitors (GDIs) and protein phosphatases. There may even be specific proteins of these classes whose primary function is as part of GPCR-independent pathways, termed activators of G-protein signalling (AGS). Both the ubiquity of these interactions and the importance of Gα vs. Gβγ subunits to these processes are still unclear.\n\nThere are two principal signal transduction pathways involving the G protein-linked receptors: the cAMP signal pathway and the phosphatidylinositol signal pathway.\n\nThe cAMP signal transduction contains 5 main characters: stimulative hormone receptor (Rs) or inhibitory hormone receptor (Ri); stimulative regulative G-protein (Gs) or inhibitory regulative G-protein (Gi); adenylyl cyclase; protein kinase A (PKA); and cAMP phosphodiesterase.\n\nStimulative hormone receptor (Rs) is a receptor that can bind with stimulative signal molecules, while inhibitory hormone receptor (Ri) is a receptor that can bind with inhibitory signal molecules.\n\nStimulative regulative G-protein is a G-protein linked to stimulative hormone receptor (Rs), and its α subunit upon activation could stimulate the activity of an enzyme or other intracellular metabolism. On the contrary, inhibitory regulative G-protein is linked to an inhibitory hormone receptor, and its α subunit upon activation could inhibit the activity of an enzyme or other intracellular metabolism.\n\nAdenylyl cyclase is a 12-transmembrane glycoprotein that catalyzes ATP to form cAMP with the help of cofactor Mg or Mn. The cAMP produced is a second messenger in cellular metabolism and is an allosteric activator of protein kinase A.\n\nProtein kinase A is an important enzyme in cell metabolism due to its ability to regulate cell metabolism by phosphorylating specific committed enzymes in the metabolic pathway. It can also regulate specific gene expression, cellular secretion, and membrane permeability. The protein enzyme contains two catalytic subunits and two regulatory subunits. When there is no cAMP，the complex is inactive. When cAMP binds to the regulatory subunits, their conformation is altered, causing the dissociation of the regulatory subunits, which activates protein kinase A and allows further biological effects.\n\nThese signals then can be terminated by cAMP phosphodiesterase, which is an enzyme that degrades cAMP to 5'-AMP and inactivates protein kinase A.\n\nIn the phosphatidylinositol signal pathway, the extracellular signal molecule binds with the G-protein receptor (G) on the cell surface and activates phospholipase C, which is located on the plasma membrane. The lipase hydrolyzes phosphatidylinositol 4,5-bisphosphate (PIP2) into two second messengers: inositol 1,4,5-trisphosphate (IP3) and diacylglycerol (DAG). IP3 binds with the IP3 receptor in the membrane of the smooth endoplasmic reticulum and mitochondria to open Ca channels. DAG helps activate protein kinase C (PKC), which phosphorylates many other proteins, changing their catalytic activities, leading to cellular responses.\n\nThe effects of Ca are also remarkable: it cooperates with DAG in activating PKC and can activate the CaM kinase pathway, in which calcium-modulated protein calmodulin (CaM) binds Ca, undergoes a change in conformation, and activates CaM kinase II, which has unique ability to increase its binding affinity to CaM by autophosphorylation, making CaM unavailable for the activation of other enzymes. The kinase then phosphorylates target enzymes, regulating their activities. The two signal pathways are connected together by Ca-CaM, which is also a regulatory subunit of adenylyl cyclase and phosphodiesterase in the cAMP signal pathway.\n\nGPCRs become desensitized when exposed to their ligand for a long period of time. There are two recognized forms of desensitization: 1) homologous desensitization, in which the activated GPCR is downregulated; and 2) heterologous desensitization, wherein the activated GPCR causes downregulation of a different GPCR. The key reaction of this downregulation is the phosphorylation of the intracellular (or cytoplasmic) receptor domain by protein kinases.\n\nCyclic AMP-dependent protein kinases (protein kinase A) are activated by the signal chain coming from the G protein (that was activated by the receptor) via adenylate cyclase and cyclic AMP (cAMP). In a \"feedback mechanism\", these activated kinases phosphorylate the receptor. The longer the receptor remains active the more kinases are activated and the more receptors are phosphorylated. In β-adrenoceptors, this phosphorylation results in the switching of the coupling from the G class of G-protein to the G class. cAMP-dependent PKA mediated phosphorylation can cause heterologous desensitisation in receptors other than those activated.\n\nThe G protein-coupled receptor kinases (GRKs) are protein kinases that phosphorylate only active GPCRs. G-protein-coupled receptor kinases (GRKs) are key modulators of G-protein-coupled receptor (GPCR) signaling. They constitute a family of seven mammalian serine-threonine protein kinases that phosphorylate agonist-bound receptor. GRKs-mediated receptor phosphorylation rapidly initiates profound impairment of receptor signaling and desensitization. Activity of GRKs and subcellular targeting is tightly regulated by interaction with receptor domains, G protein subunits, lipids, anchoring proteins and calcium-sensitive proteins.\n\nPhosphorylation of the receptor can have two consequences:\n\n\nAs mentioned above, G-proteins may terminate their own activation due to their intrinsic GTP→GDP hydrolysis capability. However, this reaction proceeds at a slow rate (≈.02 times/sec) and, thus, it would take around 50 seconds for any single G-protein to deactivate if other factors did not come into play. Indeed, there are around 30 isoforms of RGS proteins that, when bound to Gα through their GAP domain, accelerate the hydrolysis rate to ≈30 times/sec. This 1500-fold increase in rate allows for the cell to respond to external signals with high speed, as well as spatial resolution due to limited amount of second messenger that can be generated and limited distance a G-protein can diffuse in .03 seconds. For the most part, the RGS proteins are promiscuous in their ability to activate G-proteins, while which RGS is involved in a given signaling pathway seems more determined by the tissue and GPCR involved than anything else. In addition, RGS proteins have the additional function of increasing the rate of GTP-GDP exchange at GPCRs, (i.e., as a sort of co-GEF) further contributing to the time resolution of GPCR signaling.\n\nIn addition, the GPCR may be desensitized itself. This can occur as:\n\n\nOnce β-arrestin is bound to a GPCR, it undergoes a conformational change allowing it to serve as a scaffolding protein for an adaptor complex termed AP-2, which in turn recruits another protein called clathrin. If enough receptors in the local area recruit clathrin in this manner, they aggregate and the membrane buds inwardly as a result of interactions between the molecules of clathrin, in a process called opsonization. Once the pit has been pinched off the plasma membrane due to the actions of two other proteins called amphiphysin and dynamin, it is now an endocytic vesicle. At this point, the adapter molecules and clathrin have dissociated, and the receptor is either trafficked back to the plasma membrane or targeted to lysosomes for degradation.\n\nAt any point in this process, the β-arrestins may also recruit other proteins—such as the non-receptor tyrosine kinase (nRTK), c-SRC—which may activate ERK1/2, or other mitogen-activated protein kinase (MAPK) signaling through, for example, phosphorylation of the small GTP-ase, Ras, or recruit the proteins of the ERK cascade directly (i.e., Raf-1, MEK, ERK-1/2) at which point signaling is initiated due to their close proximity to one another. Another target of c-SRC are the dynamin molecules involved in endocytosis. Dynamins polymerize around the neck of an incoming vesicle, and their phosphorylation by c-SRC provides the energy necessary for the conformational change allowing the final \"pinching off\" from the membrane.\n\nReceptor desensitization is mediated through a combination phosphorylation, β-arr binding, and endocytosis as described above. Downregulation occurs when endocytosed receptor is embedded in an endosome that is trafficked to merge with an organelle called a lysosome. Because lysosomal membranes are rich in proton pumps, their interiors have low pH (≈4.8 vs. the pH≈7.2 cytosol), which acts to denature the GPCRs. In addition, lysosomes contain many degradative enzymes, including proteases, which can function only at such low pH, and so the peptide bonds joining the residues of the GPCR together may be cleaved. Whether or not a given receptor is trafficked to a lysosome, detained in endosomes, or trafficked back to the plasma membrane depends on a variety of factors, including receptor type and magnitude of the signal.\nGPCR regulation is additionally mediated by gene transcription factors. These factors can increase or decrease gene transcription and thus increase or decrease the generation of new receptors (up- or down-regulation) that travel to the cell membrane.\n\nG-protein-coupled receptor oligomerisation is a widespread phenomenon. One of the best-studied examples is the metabotropic GABA receptor. This so-called constitutive receptor is formed by heterodimerization of GABAR1 and GABAR2 subunits. Expression of the GABAR1 without the GABAR2 in heterologous systems leads to retention of the subunit in the endoplasmic reticulum. Expression of the GABAR2 subunit alone, meanwhile, leads to surface expression of the subunit, although with no functional activity (i.e., the receptor does not bind agonist and cannot initiate a response following exposure to agonist). Expression of the two subunits together leads to plasma membrane expression of functional receptor. It has been shown that GABAR2 binding to GABAR1 causes masking of a retention signal of functional receptors.\n\nSignal transduction mediated by the superfamily of GPCRs dates back to the origin of multicellularity. Mammalian-like GPCRs are found in fungi, and have been classified according to the GRAFS classification system based on GPCR fingerprints. Identification of the superfamily members across the eukaryotic domain, and comparison of the family-specific motifs, have shown that the superfamily of GPCRs have a common origin. Characteristic motifs indicate that three of the five GRAFS families, \"Rhodopsin\", \"Adhesion\", and \"Frizzled\", evolved from the \"Dictyostelium discoideum\" cAMP receptors before the split of Opisthokonts. Later, the \"Secretin\" family evolved from the \"Adhesion\" GPCR receptor family before the split of nematodes.\n\n\n\n", "id": "12832", "title": "G protein–coupled receptor"}
{"url": "https://en.wikipedia.org/wiki?curid=51902988", "text": "Coverage (genetics)\n\nCoverage (or depth) in DNA sequencing is the number of reads that include a given nucleotide in the reconstructed sequence. Deep sequencing refers to the general concept of aiming for high number of replicate reads of each region of a sequence.\n\nEven though the sequencing accuracy for each individual nucleotide is very high, the very large number of nucleotides in the genome means that if an individual genome is only sequenced once, there will be a significant number of sequencing errors. Furthermore, many positions in a genome contain rare single-nucleotide polymorphisms (SNPs). Hence to distinguish between sequencing errors and true SNPs, it is necessary to increase the sequencing accuracy even further by sequencing individual genomes a large number of times.\n\nThe term \"ultra-deep\" can sometimes also refer to higher coverage (>100-fold), which allows for detection of sequence variants in mixed populations. In the extreme, error-corrected sequencing approaches such as Maximum-Depth Sequencing can make it so that coverage of a given region approaches the throughput of a sequencing machine, allowing coverages of >10^8.\n\nDeep sequencing of transcriptomes, also known as RNA-Seq, provides both the sequence and frequency of RNA molecules that are present at any particular time in a specific cell type, tissue or organ. Counting the number of mRNAs that are encoded by individual genes provides an indicator of protein-coding potential, a major contributor to phenotype. Improving methods for RNA sequencing is an active area of research both in terms of experimental and computational methods.\n\nThe average coverage for a whole genome can be calculated from the length of the original genome (\"G\"), the number of reads (\"N\"), and the average read length (\"L\") as formula_1. For example, a hypothetical genome with 2,000 base pairs reconstructed from 8 reads with an average length of 500 nucleotides will have 2× redundancy. This parameter also enables one to estimate other quantities, such as the percentage of the genome covered by reads (sometimes also called coverage). A high coverage in shotgun sequencing is desired because it can overcome errors in base calling and assembly. The subject of DNA sequencing theory addresses the relationships of such quantities.\n\nSometimes a distinction is made between \"sequence coverage\" and \"physical coverage\". Where sequence coverage is the average number of times a base is read, physical coverage is the average number of times a base is read or spanned by mate paired reads.\n", "id": "51902988", "title": "Coverage (genetics)"}
{"url": "https://en.wikipedia.org/wiki?curid=23974", "text": "Plasmid\n\nA plasmid is a small DNA molecule within a cell that is physically separated from a chromosomal DNA and can replicate independently. They are most commonly found as small circular, double-stranded DNA molecules in bacteria; however, plasmids are sometimes present in archaea and eukaryotic organisms. In nature, plasmids often carry genes that may benefit the survival of the organism, for example antibiotic resistance. While the chromosomes are big and contain all the essential genetic information for living under normal conditions, plasmids usually are very small and contain only additional genes that may be useful to the organism under certain situations or particular conditions. Artificial plasmids are widely used as vectors in molecular cloning, serving to drive the replication of recombinant DNA sequences within host organisms.\n\nPlasmids are considered \"replicons\", units of DNA capable of replicating autonomously within a suitable host. However, plasmids, like viruses, are not generally classified as life. Plasmids are transmitted from one bacterium to another (even of another species) mostly through conjugation . This host-to-host transfer of genetic material is one mechanism of horizontal gene transfer, and plasmids are considered part of the mobilome. Unlike viruses (which encase their genetic material in a protective protein coat called a capsid), plasmids are \"naked\" DNA and do not encode genes necessary to encase the genetic material for transfer to a new host. However, some classes of plasmids encode the conjugative \"sex\" pilus necessary for their own transfer. The size of the plasmid varies from 1 to over 200 kbp, and the number of identical plasmids in a single cell can range anywhere from one to thousands under some circumstances.\n\nThe relationship between microbes and plasmid DNA is neither parasitic nor mutualistic, because each implies the presence of an independent species living in a detrimental or commensal state with the host organism. Rather, plasmids provide a mechanism for horizontal gene transfer within a population of microbes and typically provide a selective advantage under a given environmental state. Plasmids may carry genes that provide resistance to naturally occurring antibiotics in a competitive environmental niche, or the proteins produced may act as toxins under similar circumstances, or allow the organism to utilize particular organic compounds that would be advantageous when nutrients are scarce.\n\nThe term \"plasmid\" was introduced in 1952 by the American molecular biologist Joshua Lederberg to refer to \"any extrachromosomal hereditary determinant.\" The term's early usage included any bacterial genetic material that exists extrachromosomally for at least part of its replication cycle, but because that description includes bacterial viruses, the notion of plasmid was refined over time to comprise genetic elements that reproduce autonomously.\nIn order for plasmids to replicate independently within a cell, they must possess a stretch of DNA that can act as an origin of replication. The self-replicating unit, in this case the plasmid, is called a replicon. A typical bacterial replicon may consist of a number of elements, such as the gene for plasmid-specific replication initiation protein (Rep), repeating units called iterons, DnaA boxes, and an adjacent AT-rich region. Smaller plasmids make use of the host replicative enzymes to make copies of themselves, while larger plasmids may carry genes specific for the replication of those plasmids. A few types of plasmids can also insert into the host chromosome, and these integrative plasmids are sometimes referred to as episomes in prokaryotes.\n\nPlasmids almost always carry at least one gene. Many of the genes carried by a plasmid are beneficial for the host cells, for example: enabling the host cell to survive in an environment that would otherwise be lethal or restrictive for growth. Some of these genes encode traits for antibiotic resistance or resistance to heavy metal, while others may produce virulence factors that enable a bacterium to colonize a host and overcome its defences, or have specific metabolic functions that allow the bacterium to utilize a particular nutrient, including the ability to degrade recalcitrant or toxic organic compounds. Plasmids can also provide bacteria with the ability to fix nitrogen. Some plasmids, however, have no observable effect on the phenotype of the host cell or its benefit to the host cells cannot be determined, and these plasmids are called cryptic plasmids.\n\nNaturally occurring plasmids vary greatly in their physical properties. Their size can range from very small mini-plasmids of less than a 1 kilobase pairs (Kbp), to very large megaplasmids of several megabase pairs (Mbp). At the upper end, little can differentiate between a megaplasmid and a minichromosome. Plasmids are generally circular, however examples of linear plasmids are also known. These linear plasmids require specialized mechanisms to replicate their ends.\n\nPlasmids may be present in an individual cell in varying number, ranging from one to several hundreds. The normal number of copies of plasmid that may be found in a single cell is called the copy number, and is determined by how the replication initiation is regulated and the size of the molecule. Larger plasmids tend to have lower copy numbers. Low-copy-number plasmids that exist only as one or a few copies in each bacterium are, upon cell division, in danger of being lost in one of the segregating bacteria. Such single-copy plasmids have systems that attempt to actively distribute a copy to both daughter cells. These systems, which include the parABS system and parMRC system, are often referred to as the partition system or partition function of a plasmid.\n\nPlasmids may be classified in a number of ways. Plasmids can be broadly classified into conjugative plasmids and non-conjugative plasmids. Conjugative plasmids contain a set of transfer or \"tra\" genes which promote sexual conjugation between different cells. In the complex process of conjugation, plasmid may be transferred from one bacterium to another via sex pili encoded by some of the \"tra\" genes (see figure). Non-conjugative plasmids are incapable of initiating conjugation, hence they can be transferred only with the assistance of conjugative plasmids. An intermediate class of plasmids are mobilizable, and carry only a subset of the genes required for transfer. They can parasitize a conjugative plasmid, transferring at high frequency only in its presence.\n\nPlasmids can also be classified into incompatibility groups. A microbe can harbour different types of plasmids, however, different plasmids can only exist in a single bacterial cell if they are compatible. If two plasmids are not compatible, one or the other will be rapidly lost from the cell. Different plasmids may therefore be assigned to different incompatibility groups depending on whether they can coexist together. Incompatible plasmids (belonging to the same incompatibility group) normally share the same replication or partition mechanisms and can thus not be kept together in a single cell.\n\nAnother way to classify plasmids is by function. There are five main classes:\n\nPlasmids can belong to more than one of these functional groups.\n\nArtificially constructed plasmids may be used as vectors in genetic engineering. These plasmids serve as important tools in genetics and biotechnology labs, where they are commonly used to clone and amplify (make many copies of) or express particular genes. A wide variety of plasmids are commercially available for such uses. The gene to be replicated is normally inserted into a plasmid that typically contains a number of features for their use. These include a gene that confers resistance to particular antibiotics (ampicillin is most frequently used for bacterial strains), an origin of replication to allow the bacterial cells to replicate the plasmid DNA, and a suitable site for cloning (referred to as a multiple cloning site). \n\nPlasmids are the most-commonly used bacterial cloning vectors. These cloning vectors contain a site that allows DNA fragments to be inserted, for example a multiple cloning site or polylinker which has several commonly used restriction sites to which DNA fragments may be ligated. After the gene of interest is inserted, the plasmids are introduced into bacteria by a process called transformation. These plasmids contain a selectable marker, usually an antibiotic resistance gene, which confer on the bacteria an ability to survive and proliferate in a selective growth medium containing the particular antibiotics. The cells after transformation are exposed to the selective media, and only cells containing the plasmid may survive. In this way, the antibiotics act as a filter to select only the bacteria containing the plasmid DNA. The vector may also contain other marker genes or reporter genes to facilitate selection of plasmid with cloned insert. Bacteria containing the plasmid can then be grown in large amounts, harvested, and the plasmid of interest may then be isolated using various methods of plasmid preparation.\n\nA plasmid cloning vector is typically used to clone DNA fragments of up to 15 kbp. To clone longer lengths of DNA, lambda phage with lysogeny genes deleted, cosmids, bacterial artificial chromosomes, or yeast artificial chromosomes are used.\n\nAnother major use of plasmids is to make large amounts of proteins. In this case, researchers grow bacteria containing a plasmid harboring the gene of interest. Just as the bacterium produces proteins to confer its antibiotic resistance, it can also be induced to produce large amounts of proteins from the inserted gene. This is a cheap and easy way of mass-producing the protein the gene codes for, for example, insulin.\n\nPlasmid may also be used for gene transfer into human cells as potential treatment in gene therapy so that it may express the protein that is lacking in the cells. Some strategies of gene therapy require the insertion of therapeutic genes at pre-selected chromosomal target sites within the human genome. Plasmid vectors are one of many approaches that could be used for this purpose. Zinc finger nucleases (ZFNs) offer a way to cause a site-specific double-strand break to the DNA genome and cause homologous recombination. Plasmids encoding ZFN could help deliver a therapeutic gene to a specific site so that cell damage, cancer-causing mutations, or an immune response is avoided.\n\nPlasmids were historically used to genetically engineer the embryonic stem cells of rats in order to create rat genetic disease models. The limited efficiency of plasmid-based techniques precluded their use in the creation of more accurate human cell models. However, developments in Adeno-associated virus recombination techniques, and Zinc finger nucleases, have enabled the creation of a new generation of isogenic human disease models.\n\nThe term \"episome\" was introduced by François Jacob and Élie Wollman in 1958 to refer to extra-chromosomal genetic material that may replicate autonomously or become integrated into the chromosome. Since the term was introduced, however, its use has shifted as \"plasmid\" has become the preferred term for autonomously replicating extrachromosomal DNA. At a 1968 symposium in London some participants suggested that the term \"episome\" be abandoned, although others continued to use the term with a shift in meaning.\n\nToday some authors use \"episome\" in the context of prokaryotes to refer to a plasmid that is capable of integrating into the chromosome. The integrative plasmids may be replicated and stably maintained in a cell through multiple generations, but always at some stage they exist as an independent plasmid molecule. In the context of eukaryotes, the term \"episomes\" is used to mean a non-integrated extrachromosomal closed circular DNA molecule that may be replicated in the nucleus. Viruses are the most common examples of this, such as herpesviruses, adenoviruses, and polyomaviruses, but some are plasmids. Other examples include aberrant chromosomal fragments, such as double minute chromosomes, that can arise during artificial gene amplifications or in pathologic processes (e.g., cancer cell transformation). Episomes in eukaryotes behave similarly to plasmids in prokaryotes in that the DNA is stably maintained and replicated with the host cell. Cytoplasmic viral episomes (as in poxvirus infections) can also occur. Some episomes, such as herpesviruses, replicate in a rolling circle mechanism, similar to bacterial phage viruses. Others replicate through a bidirectional replication mechanism (\"Theta type\" plasmids). In either case, episomes remain physically separate from host cell chromosomes. Several cancer viruses, including Epstein-Barr virus and Kaposi's sarcoma-associated herpesvirus, are maintained as latent, chromosomally distinct episomes in cancer cells, where the viruses express oncogenes that promote cancer cell proliferation. In cancers, these episomes passively replicate together with host chromosomes when the cell divides. When these viral episomes initiate lytic replication to generate multiple virus particles, they in general activate cellular innate immunity defense mechanisms that kill the host cell.\n\nSome plasmids or microbial hosts include an addiction system or postsegregational killing system (PSK), such as the hok/sok (host killing/suppressor of killing) system of plasmid R1 in \"Escherichia coli\". This variant produces both a long-lived poison and a short-lived antidote. Several types of plasmid addiction systems (toxin/ antitoxin, metabolism-based, ORT systems) were described in the literature and used in biotechnical (fermentation) or biomedical (vaccine therapy) applications. Daughter cells that retain a copy of the plasmid survive, while a daughter cell that fails to inherit the plasmid dies or suffers a reduced growth-rate because of the lingering poison from the parent cell. Finally, the overall productivity could be enhanced.\n\nIn contrast, virtually all biotechnologically used plasmids (such as pUC18, pBR322 and derived vectors) do not contain toxin-antitoxin addiction systems and thus need to be kept under antibiotic pressure to avoid plasmid loss.\n\nYeasts naturally harbour various plasmids. Notable among them are 2 µm plasmids — small circular plasmids often used for genetic engineering of yeast — and linear pGKL plasmids from \"Kluyveromyces lactis\", that are responsible for killer phenotypes.\n\nOther types of plasmids are often related to yeast cloning vectors that include:\n\nAs alluded to above, plasmids are often used to purify a specific sequence, since they can easily be purified away from the rest of the genome. For their use as vectors, and for molecular cloning, plasmids often need to be isolated.\n\nThere are several methods to isolate plasmid DNA from bacteria, the archetypes of which are the miniprep and the maxiprep/bulkprep. The former can be used to quickly find out whether the plasmid is correct in any of several bacterial clones. The yield is a small amount of impure plasmid DNA, which is sufficient for analysis by restriction digest and for some cloning techniques.\n\nIn the latter, much larger volumes of bacterial suspension are grown from which a maxi-prep can be performed. In essence, this is a scaled-up miniprep followed by additional purification. This results in relatively large amounts (several hundreds micrograms) of very pure plasmid DNA.\n\nIn recent times, many commercial kits have been created to perform plasmid extraction at various scales, purity, and levels of automation. Commercial services can prepare plasmid DNA at quoted prices below $300/mg in milligram quantities and $15/mg in gram quantities ().\n\nPlasmid DNA may appear in one of five conformations, which (for a given size) run at different speeds in a gel during electrophoresis. The conformations are listed below in order of electrophoretic mobility (speed for a given applied voltage) from slowest to fastest:\n\nThe rate of migration for small linear fragments is directly proportional to the voltage applied at low voltages. At higher voltages, larger fragments migrate at continuously increasing yet different rates. Thus, the resolution of a gel decreases with increased voltage.\n\nAt a specified, low voltage, the migration rate of small linear DNA fragments is a function of their length. Large linear fragments (over 20 kb or so) migrate at a certain fixed rate regardless of length. This is because the molecules 'resperate', with the bulk of the molecule following the leading end through the gel matrix. Restriction digests are frequently used to analyse purified plasmids. These enzymes specifically break the DNA at certain short sequences. The resulting linear fragments form 'bands' after gel electrophoresis. It is possible to purify certain fragments by cutting the bands out of the gel and dissolving the gel to release the DNA fragments.\n\nBecause of its tight conformation, supercoiled DNA migrates faster through a gel than linear or open-circular DNA.\n\nThe use of plasmids as a technique in molecular biology is supported by bioinformatics software. These programs record the DNA sequence of plasmid vectors, help to predict cut sites of restriction enzymes, and to plan manipulations. Examples of software packages that handle plasmid maps are ApE, Clone Manager, GeneConstructionKit, Geneious, Genome Compiler, LabGenius, Lasergene, MacVector, pDraw32, Serial Cloner, VectorFriends, Vector NTI, and WebDSV. These software help conduct entire experiments in silico before doing wet experiments.\n\nMany plasmids have been created over the years and researchers have given out plasmids to plasmid databases such as the non profit organisations Addgene and BCCM/LMBP. One can find and request plasmids from those databases in order to continue research.\nResearcher also often upload sequences of plasmids in the NCBI database. Using the NCBI database sequences of specific plasmids can be looked up.\n\n\n\n\n", "id": "23974", "title": "Plasmid"}
{"url": "https://en.wikipedia.org/wiki?curid=45560295", "text": "Hybridization assay\n\nA hybridization assay comprises any form of quantifiable hybridization, \"i.e.\" the quantitative annealing of two complementary strands of nucleic acids, known as nucleic acid hybridization.\n\nIn the context of biochemistry and drug development, a hybridization assay is a type of Ligand Binding Assay (LBA) used to quantify nucleic acids in biological matrices. Hybridization assays can be in solution or on a solid support such as 96-well plates or labelled beads.\n\nHybridization assays involve labelled nucleic acid probes to identify related DNA or RNA molecules (i.e. with significantly high degree of sequence similarity) within a complex mixture of unlabelled nucleic acid molecules. Antisense oligonucleotides, siRNA, and other oligonucleotide and nucleic acid based biotherapeutics can be quantified with hybridization assays.\n\nSignalling of hybridization methods can be performed using oligonucleotide probes modified in-synthesis with haptens and small molecule ligands which act homologous to the capture and detection antibodies. As with traditional ELISA, conjugates to horse radish peroxidase (HRP) or alkaline phosphatase (AP) can be used as secondary antibodies.\n\nIn the sandwich hybridization ELISA assay format, the antigen ligand and antibodies in ELISA are replaced with a nucleic acid analyte, complementary oligonucleotide capture and detection probes.\n\nGenerally, in the case of nucleic acid hybridization, monovalent salt concentration and temperature are controlled for hybridization and wash stringency, contrary to a traditional ELISA, where the salt concentration will usually be fixed for the binding and wash steps (i.e. PBS or TBS). Thus, optimal salt concentration in hybridization assays varies dependent upon the length and base composition of the analyte, capture and detection probes.\n\nThe competitive hybridization assay is similar to a traditional competitive immunoassay. Like other hybridization assays, it relies on complementarity, where the capture probe competes between the analyte and the tracer–a labelled oligonucleotide analog to the analyte.\n\nIn the hybridization-ligation assay a template probe replaces the capture probe in the sandwich assay for immobilization to the solid support. The template probe is fully complementary to the oligonucleotide analyte and is intended to serve as a substrate for T4 DNA ligase-mediated ligation. The template probe has in addition an additional stretch complementary to a ligation probe so that the ligation probe will ligate onto the 3'-end of the analyte. Albeit generic, the ligation probe is similar to a detection probe in that it is labelled with, for example, digoxigenin for downstream signalling. Stringent, low/no salt wash will remove un-ligated products.\n\nThe ligation of the analyte to the ligation probe makes the method specific for the 3'-end of the analyte, ligation by T4 DNA ligase being much less efficient over a bulge loop, which would happen for a 3' metabolite N-1 version of the analyte, for example. The specificity of the hybridization-ligation assay for ligation at the 3'-end is particularly relevant because the predominant nucleases in blood are 3' to 5' exonucleases.\n\nOne limitation of the method is that it requires a free 3'-end hydroxyl which may not be available when targeting moieties are attached to the 3'-end, for example. Further, more exotic nucleic acid chemistries with oligonucleotide drugs may impact upon the activity of the ligase, which needs to be determined on a case-by-case basis.\n\nThe dual ligation hybridization assay (DLA) extends the specificity of the hybridization-ligation assay to a specific method for the parent compound. Despite hybridization-ligation assay's robustness, sensitivity and added specificity for the 3'-end of the oligonculeotide analyte, the hybridization-ligation assay is not specific for the 5' end of the analyte.\n\nThe DLA is intended to quantify the full-length, parent oligonucleotide compound only, with both intact 5' and 3' ends. DLA probes are ligated at the 5' and 3' ends of the analyte by the joint action of T4 DNA ligase and T4 polynucleotide kinase. The kinase phosphorylates the 5'-end of the analyte and the ligase will join the capture probe to the analyte to the detection probe. The capture and detection probes in the DLA can thus be termed ligation probes. As for the hybridization-ligation assay, the DLA is specific for the parent compound because the efficiency of ligation over a bulge loop is low, and thus the DLA detects the full-length analyte with both intact 5' and 3'-ends. The DLA can also be used for the determination of individual metabolites in biological matrices.\n\nThe limitations with the hybridization-ligation assay also apply to the dual ligation assay, with the 5'-end in addition to the 3'-end requiring to have a free hydroxyl (or a phosphate group). Further, T4 DNA ligases are incompatible with ligation of RNA molecules as a donor (i.e. RNA at the 5' end of the ligation). Therefore, second generation antisense that comprise 2'-O-methyl RNA, 2'-O-methoxyethyl or locked nucleic acids may not be compatible with the dual ligation assay.\n\nThe nuclease hybridization assay, also called S1 nuclease cutting assay, is a nuclease protection assay-based hybridization ELISA. The assay is using S1 nuclease, which degrades single-stranded DNA and RNA into oligo- or mononucleotides, leaving intact double-stranded DNA and RNA.\n\nIn the nuclease hybridization assay, the oligonucleotide analyte is captured onto the solid support such as a 96-well plate via a fully complementary cutting probe. After enzymatic processing by S1 nuclease, the free cutting probe and the cutting probe hybridized to metabolites, \"i.e.\" shortmers of the analyte are degraded, allowing signal to be generated only from the full-length cutting probe-analyte duplex.\n\nThe assay is well tolerant to diverse chemistries, as exemplified by the development of a nuclease assay for morpholino oligonucleotides.\n", "id": "45560295", "title": "Hybridization assay"}
{"url": "https://en.wikipedia.org/wiki?curid=12891", "text": "Gene therapy\n\nGene therapy is the therapeutic delivery of nucleic acid into a patient's cells as a drug to treat disease. The first attempt at modifying human DNA was performed in 1980 by Martin Cline, but the first successful nuclear gene transfer in humans, approved by the National Institutes of Health, was performed in May 1989. The first therapeutic use of gene transfer as well as the first direct insertion of human DNA into the nuclear genome was performed by French Anderson in a trial starting in September 1990.\n\nBetween 1989 and February 2016, over 2,300 clinical trials had been conducted, more than half of them in phase I.\n\nNot all medical procedures that introduce alterations to a patient's genetic makeup can be considered gene therapy. Bone marrow transplantation and organ transplants in general have been found to introduce foreign DNA into patients. Gene therapy is defined by the precision of the procedure and the intention of direct therapeutic effects.\n\nGene therapy was conceptualized in 1972, by authors who urged caution before commencing human gene therapy studies.\n\nThe first attempt, an unsuccessful one, at gene therapy (as well as the first case of medical transfer of foreign genes into humans not counting organ transplantation) was performed by Martin Cline on 10 July 1980. Cline claimed that one of the genes in his patients was active six months later, though he never published this data or had it verified and even if he is correct, it's unlikely it produced any significant beneficial effects treating beta-thalassemia.\n\nAfter extensive research on animals throughout the 1980s and a 1989 bacterial gene tagging trial on humans, the first gene therapy widely accepted as a success was demonstrated in a trial that started on 14 September 1990, when Ashi DeSilva was treated for ADA-SCID.\n\nThe first somatic treatment that produced a permanent genetic change was performed in 1993.\n\nThis procedure was referred to sensationally and somewhat inaccurately in the media as a \"three parent baby\", though mtDNA is not the primary human genome and has little effect on an organism's individual characteristics beyond powering their cells.\n\nGene therapy is a way to fix a genetic problem at its source. The polymers are either translated into proteins, interfere with target gene expression, or possibly correct genetic mutations.\n\nThe most common form uses DNA that encodes a functional, therapeutic gene to replace a mutated gene. The polymer molecule is packaged within a \"vector\", which carries the molecule inside cells.\n\nEarly clinical failures led to dismissals of gene therapy. Clinical successes since 2006 regained researchers' attention, although as of 2014, it was still largely an experimental technique. These include treatment of retinal diseases Leber's congenital amaurosis and choroideremia, X-linked SCID, ADA-SCID, adrenoleukodystrophy, chronic lymphocytic leukemia (CLL), acute lymphocytic leukemia (ALL), multiple myeloma, haemophilia, and Parkinson's disease. Between 2013 and April 2014, US companies invested over $600 million in the field.\n\nThe first commercial gene therapy, Gendicine, was approved in China in 2003 for the treatment of certain cancers. In 2011 Neovasculgen was registered in Russia as the first-in-class gene-therapy drug for treatment of peripheral artery disease, including critical limb ischemia.\nIn 2012 Glybera, a treatment for a rare inherited disorder, became the first treatment to be approved for clinical use in either Europe or the United States after its endorsement by the European Commission.\n\nFollowing early advances in genetic engineering of bacteria, cells, and small animals, scientists started considering how to apply it to medicine. Two main approaches were considered – replacing or disrupting defective genes. Scientists focused on diseases caused by single-gene defects, such as cystic fibrosis, haemophilia, muscular dystrophy, thalassemia, and sickle cell anemia. Glybera treats one such disease, caused by a defect in lipoprotein lipase.\n\nDNA must be administered, reach the damaged cells, enter the cell and either express or disrupt a protein. Multiple delivery techniques have been explored. The initial approach incorporated DNA into an engineered virus to deliver the DNA into a chromosome. Naked DNA approaches have also been explored, especially in the context of vaccine development.\n\nGenerally, efforts focused on administering a gene that causes a needed protein to be expressed. More recently, increased understanding of nuclease function has led to more direct DNA editing, using techniques such as zinc finger nucleases and CRISPR. The vector incorporates genes into chromosomes. The expressed nucleases then knock out and replace genes in the chromosome. As of 2014 these approaches involve removing cells from patients, editing a chromosome and returning the transformed cells to patients.\n\nGene editing is a potential approach to alter the human genome to treat genetic diseases, viral diseases, and cancer. As of 2016 these approaches were still years from being medicine.\n\nGene therapy may be classified into two types:\n\nIn somatic cell gene therapy (SCGT), the therapeutic genes are transferred into any cell other than a gamete, germ cell, gametocyte, or undifferentiated stem cell. Any such modifications affect the individual patient only, and are not inherited by offspring. Somatic gene therapy represents mainstream basic and clinical research, in which therapeutic DNA (either integrated in the genome or as an external episome or plasmid) is used to treat disease.\n\nOver 600 clinical trials utilizing SCGT are underway in the US. Most focus on severe genetic disorders, including immunodeficiencies, haemophilia, thalassaemia, and cystic fibrosis. Such single gene disorders are good candidates for somatic cell therapy. The complete correction of a genetic disorder or the replacement of multiple genes is not yet possible. Only a few of the trials are in the advanced stages.\n\nIn germline gene therapy (GGT), germ cells (sperm or egg cells) are modified by the introduction of functional genes into their genomes. Modifying a germ cell causes all the organism's cells to contain the modified gene. The change is therefore heritable and passed on to later generations. Australia, Canada, Germany, Israel, Switzerland, and the Netherlands prohibit GGT for application in human beings, for technical and ethical reasons, including insufficient knowledge about possible risks to future generations and higher risks versus SCGT. The US has no federal controls specifically addressing human genetic modification (beyond FDA regulations for therapies in general).\n\nThe delivery of DNA into cells can be accomplished by multiple methods. The two major classes are recombinant viruses (sometimes called biological nanoparticles or viral vectors) and naked DNA or DNA complexes (non-viral methods).\n\nIn order to replicate, viruses introduce their genetic material into the host cell, tricking the host's cellular machinery into using it as blueprints for viral proteins. Retroviruses go a stage further by having their genetic material copied into the genome of the host cell. Scientists exploit this by substituting a virus's genetic material with therapeutic DNA. (The term 'DNA' may be an oversimplification, as some viruses contain RNA, and gene therapy could take this form as well.) A number of viruses have been used for human gene therapy, including retroviruses, adenoviruses, herpes simplex, vaccinia, and adeno-associated virus. Like the genetic material (DNA or RNA) in viruses, therapeutic DNA can be designed to simply serve as a temporary blueprint that is degraded naturally or (at least theoretically) to enter the host's genome, becoming a permanent part of the host's DNA in infected cells.\n\nNon-viral methods present certain advantages over viral methods, such as large scale production and low host immunogenicity. However, non-viral methods initially produced lower levels of transfection and gene expression, and thus lower therapeutic efficacy. Later technology remedied this deficiency.\n\nMethods for non-viral gene therapy include the injection of naked DNA, electroporation, the gene gun, sonoporation, magnetofection, the use of oligonucleotides, lipoplexes, dendrimers, and inorganic nanoparticles.\n\nSome of the unsolved problems include:\n\nThree patients' deaths have been reported in gene therapy trials, putting the field under close scrutiny. The first was that of Jesse Gelsinger in 1999. Jesse Gelsinger died because of immune rejection response. One X-SCID patient died of leukemia in 2003. In 2007, a rheumatoid arthritis patient died from an infection; the subsequent investigation concluded that the death was not related to gene therapy.\n\nIn 1972 Friedmann and Roblin authored a paper in \"Science\" titled \"Gene therapy for human genetic disease?\" Rogers (1970) was cited for proposing that \"exogenous good DNA\" be used to replace the defective DNA in those who suffer from genetic defects.\n\nIn 1984 a retrovirus vector system was designed that could efficiently insert foreign genes into mammalian chromosomes.\n\nThe first approved gene therapy clinical research in the US took place on 14 September 1990, at the National Institutes of Health (NIH), under the direction of William French Anderson. Four-year-old Ashanti DeSilva received treatment for a genetic defect that left her with ADA-SCID, a severe immune system deficiency. The effects were temporary, but successful.\n\nCancer gene therapy was introduced in 1992/93 (Trojan et al. 1993). The treatment of glioblastoma multiforme, the malignant brain tumor whose outcome is always fatal, was done using a vector expressing antisense IGF-I RNA (clinical trial approved by NIH protocolno.1602 November 24, 1993, and by the FDA in 1994). This therapy also represents the beginning of cancer immunogene therapy, a treatment which proves to be effective due to the anti-tumor mechanism of IGF-I antisense, which is related to strong immune and apoptotic phenomena.\n\nIn 1992 Claudio Bordignon, working at the Vita-Salute San Raffaele University, performed the first gene therapy procedure using hematopoietic stem cells as vectors to deliver genes intended to correct hereditary diseases. In 2002 this work led to the publication of the first successful gene therapy treatment for adenosine deaminase deficiency (ADA-SCID). The success of a multi-center trial for treating children with SCID (severe combined immune deficiency or \"bubble boy\" disease) from 2000 and 2002, was questioned when two of the ten children treated at the trial's Paris center developed a leukemia-like condition. Clinical trials were halted temporarily in 2002, but resumed after regulatory review of the protocol in the US, the United Kingdom, France, Italy, and Germany.\n\nIn 1993 Andrew Gobea was born with SCID following prenatal genetic screening. Blood was removed from his mother's placenta and umbilical cord immediately after birth, to acquire stem cells. The allele that codes for adenosine deaminase (ADA) was obtained and inserted into a retrovirus. Retroviruses and stem cells were mixed, after which the viruses inserted the gene into the stem cell chromosomes. Stem cells containing the working ADA gene were injected into Andrew's blood. Injections of the ADA enzyme were also given weekly. For four years T cells (white blood cells), produced by stem cells, made ADA enzymes using the ADA gene. After four years more treatment was needed.\n\nJesse Gelsinger's death in 1999 impeded gene therapy research in the US. As a result, the FDA suspended several clinical trials pending the reevaluation of ethical and procedural practices.\n\nThe modified cancer gene therapy strategy of antisense IGF-I RNA (NIH n˚ 1602) using antisense / triple helix anti IGF-I approach was registered in 2002 by Wiley gene therapy clinical trial - n˚ 635 and 636. The approach has shown promising results in the treatment of six different malignant tumors: glioblastoma, cancers of liver, colon, prostate, uterus, and ovary (Collaborative NATO Science Programme on Gene Therapy USA, France, Poland n˚ LST 980517 conducted by J. Trojan) (Trojan et al., 2012). This anti–gene antisense/triple helix therapy has proven to be efficient, due to the mechanism stopping simultaneously IGF-I expression on translation and transcription levels, strengthening anti-tumor immune and apoptotic phenomena.\n\nSickle-cell disease can be treated in mice. The mice – which have essentially the same defect that causes human cases – used a viral vector to induce production of fetal hemoglobin (HbF), which normally ceases to be produced shortly after birth. In humans, the use of hydroxyurea to stimulate the production of HbF temporarily alleviates sickle cell symptoms. The researchers demonstrated this treatment to be a more permanent means to increase therapeutic HbF production.\n\nA new gene therapy approach repaired errors in messenger RNA derived from defective genes. This technique has the potential to treat thalassaemia, cystic fibrosis and some cancers.\n\nResearchers created liposomes 25 nanometers across that can carry therapeutic DNA through pores in the nuclear membrane.\n\nIn 2003 a research team inserted genes into the brain for the first time. They used liposomes coated in a polymer called polyethylene glycol, which, unlike viral vectors, are small enough to cross the blood–brain barrier.\n\nShort pieces of double-stranded RNA (short, interfering RNAs or siRNAs) are used by cells to degrade RNA of a particular sequence. If a siRNA is designed to match the RNA copied from a faulty gene, then the abnormal protein product of that gene will not be produced.\n\nGendicine is a cancer gene therapy that delivers the tumor suppressor gene p53 using an engineered adenovirus. In 2003, it was approved in China for the treatment of head and neck squamous cell carcinoma.\n\nIn March researchers announced the successful use of gene therapy to treat two adult patients for X-linked chronic granulomatous disease, a disease which affects myeloid cells and damages the immune system. The study is the first to show that gene therapy can treat the myeloid system.\n\nIn May a team reported a way to prevent the immune system from rejecting a newly delivered gene. Similar to organ transplantation, gene therapy has been plagued by this problem. The immune system normally recognizes the new gene as foreign and rejects the cells carrying it. The research utilized a newly uncovered network of genes regulated by molecules known as microRNAs. This natural function selectively obscured their therapeutic gene in immune system cells and protected it from discovery. Mice infected with the gene containing an immune-cell microRNA target sequence did not reject the gene.\n\nIn August scientists successfully treated metastatic melanoma in two patients using killer T cells genetically retargeted to attack the cancer cells.\n\nIn November researchers reported on the use of VRX496, a gene-based immunotherapy for the treatment of HIV that uses a lentiviral vector to deliver an antisense gene against the HIV envelope. In a phase I clinical trial, five subjects with chronic HIV infection who had failed to respond to at least two antiretroviral regimens were treated. A single intravenous infusion of autologous CD4 T cells genetically modified with VRX496 was well tolerated. All patients had stable or decreased viral load; four of the five patients had stable or increased CD4 T cell counts. All five patients had stable or increased immune response to HIV antigens and other pathogens. This was the first evaluation of a lentiviral vector administered in a US human clinical trial.\n\nIn May researchers announced the first gene therapy trial for inherited retinal disease. The first operation was carried out on a 23-year-old British male, Robert Johnson, in early 2007.\n\nLeber's congenital amaurosis is an inherited blinding disease caused by mutations in the RPE65 gene. The results of a small clinical trial in children were published in April. Delivery of recombinant adeno-associated virus (AAV) carrying RPE65 yielded positive results. In May two more groups reported positive results in independent clinical trials using gene therapy to treat the condition. In all three clinical trials, patients recovered functional vision without apparent side-effects.\n\nIn September researchers were able to give trichromatic vision to squirrel monkeys. In November 2009, researchers halted a fatal genetic disorder called adrenoleukodystrophy in two children using a lentivirus vector to deliver a functioning version of ABCD1, the gene that is mutated in the disorder.\n\nAn April paper reported that gene therapy addressed achromatopsia (color blindness) in dogs by targeting cone photoreceptors. Cone function and day vision were restored for at least 33 months in two young specimens. The therapy was less efficient for older dogs.\n\nIn September it was announced that an 18-year-old male patient in France with beta-thalassemia major had been successfully treated. Beta-thalassemia major is an inherited blood disease in which beta haemoglobin is missing and patients are dependent on regular lifelong blood transfusions. The technique used a lentiviral vector to transduce the human ß-globin gene into purified blood and marrow cells obtained from the patient in June 2007. The patient's haemoglobin levels were stable at 9 to 10 g/dL. About a third of the hemoglobin contained the form introduced by the viral vector and blood transfusions were not needed. Further clinical trials were planned. Bone marrow transplants are the only cure for thalassemia, but 75% of patients do not find a matching donor.\n\nCancer immunogene therapy using modified anti – gene, antisense / triple helix approach was introduced in South America in 2010/11 in La Sabana University, Bogota (Ethical Committee 14 December 2010, no P-004-10). Considering the ethical aspect of gene diagnostic and gene therapy targeting IGF-I, the IGF-I expressing tumors i.e. lung and epidermis cancers, were treated (Trojan et al. 2016).\n\nIn 2007 and 2008, a man (Timothy Ray Brown) was cured of HIV by repeated hematopoietic stem cell transplantation (see also allogeneic stem cell transplantation, allogeneic bone marrow transplantation, allotransplantation) with double-delta-32 mutation which disables the CCR5 receptor. This cure was accepted by the medical community in 2011. It required complete ablation of existing bone marrow, which is very debilitating.\n\nIn August two of three subjects of a pilot study were confirmed to have been cured from chronic lymphocytic leukemia (CLL). The therapy used genetically modified T cells to attack cells that expressed the CD19 protein to fight the disease. In 2013, the researchers announced that 26 of 59 patients had achieved complete remission and the original patient had remained tumor-free.\n\nHuman HGF plasmid DNA therapy of cardiomyocytes is being examined as a potential treatment for coronary artery disease as well as treatment for the damage that occurs to the heart after myocardial infarction.\n\nIn 2011 Neovasculgen was registered in Russia as the first-in-class gene-therapy drug for treatment of peripheral artery disease, including critical limb ischemia; it delivers the gene encoding for VEGF. Neovasculogen is a plasmid encoding the CMV promoter and the 165 amino acid form of VEGF.\n\nThe FDA approved Phase 1 clinical trials on thalassemia major patients in the US for 10 participants in July. The study was expected to continue until 2015.\n\nIn July 2012, the European Medicines Agency recommended approval of a gene therapy treatment for the first time in either Europe or the United States. The treatment used Alipogene tiparvovec (Glybera) to compensate for lipoprotein lipase deficiency, which can cause severe pancreatitis. The recommendation was endorsed by the European Commission in November 2012 and commercial rollout began in late 2014. Alipogene tiparvovec was expected to cost around $1.6 million per treatment in 2012, revised to $1 million in 2015, making it the most expensive medicine in the world at the time. As of 2016, only one person had been treated with drug.\n\nIn December 2012, it was reported that 10 of 13 patients with multiple myeloma were in remission \"or very close to it\" three months after being injected with a treatment involving genetically engineered T cells to target proteins NY-ESO-1 and LAGE-1, which exist only on cancerous myeloma cells.\n\nIn March researchers reported that three of five adult subjects who had acute lymphocytic leukemia (ALL) had been in remission for five months to two years after being treated with genetically modified T cells which attacked cells with CD19 genes on their surface, i.e. all B-cells, cancerous or not. The researchers believed that the patients' immune systems would make normal T-cells and B-cells after a couple of months. They were also given bone marrow. One patient relapsed and died and one died of a blood clot unrelated to the disease.\n\nFollowing encouraging Phase 1 trials, in April, researchers announced they were starting Phase 2 clinical trials (called CUPID2 and SERCA-LVAD) on 250 patients at several hospitals to combat heart disease. The therapy was designed to increase the levels of SERCA2, a protein in heart muscles, improving muscle function. The FDA granted this a Breakthrough Therapy Designation to accelerate the trial and approval process. In 2016 it was reported that no improvement was found from the CUPID 2 trial.\n\nIn July researchers reported promising results for six children with two severe hereditary diseases had been treated with a partially deactivated lentivirus to replace a faulty gene and after 7–32 months. Three of the children had metachromatic leukodystrophy, which causes children to lose cognitive and motor skills. The other children had Wiskott-Aldrich syndrome, which leaves them to open to infection, autoimmune diseases, and cancer. Follow up trials with gene therapy on another six children with Wiskott-Aldrich syndrome were also reported as promising.\n\nIn October researchers reported that two children born with adenosine deaminase severe combined immunodeficiency disease (ADA-SCID) had been treated with genetically engineered stem cells 18 months previously and that their immune systems were showing signs of full recovery. Another three children were making progress. In 2014 a further 18 children with ADA-SCID were cured by gene therapy. ADA-SCID children have no functioning immune system and are sometimes known as \"bubble children.\"\n\nAlso in October researchers reported that they had treated six haemophilia sufferers in early 2011 using an adeno-associated virus. Over two years later all six were producing clotting factor.\n\nIn January researchers reported that six choroideremia patients had been treated with adeno-associated virus with a copy of REP1. Over a six-month to two-year period all had improved their sight. By 2016, 32 patients had been treated with positive results and researchers were hopeful the treatment would be long-lasting. Choroideremia is an inherited genetic eye disease with no approved treatment, leading to loss of sight.\n\nIn March researchers reported that 12 HIV patients had been treated since 2009 in a trial with a genetically engineered virus with a rare mutation (CCR5 deficiency) known to protect against HIV with promising results.\n\nClinical trials of gene therapy for sickle cell disease were started in 2014. There is a need for high quality randomised controlled trials assessing the risks and benefits involved with gene therapy for people with sickle cell disease.\n\nIn February LentiGlobin BB305, a gene therapy treatment undergoing clinical trials for treatment of beta thalassemia gained FDA \"breakthrough\" status after several patients were able to forgo the frequent blood transfusions usually required to treat the disease.\n\nIn March researchers delivered a recombinant gene encoding a broadly neutralizing antibody into monkeys infected with simian HIV; the monkeys' cells produced the antibody, which cleared them of HIV. The technique is named immunoprophylaxis by gene transfer (IGT). Animal tests for antibodies to ebola, malaria, influenza, and hepatitis were underway.\n\nIn March, scientists, including an inventor of CRISPR, Jennifer Doudna, urged a worldwide moratorium on germline gene therapy, writing \"scientists should avoid even attempting, in lax jurisdictions, germline genome modification for clinical application in humans\" until the full implications \"are discussed among scientific and governmental organizations\".\n\nIn October, researchers announced that they had treated a baby girl, Layla Richards, with an experimental treatment using donor T-cells genetically engineered using TALEN to attack cancer cells. One year after the treatment she was still free of her cancer (a highly aggressive form of acute lymphoblastic leukaemia [ALL]). Children with highly aggressive ALL normally have a very poor prognosis and Layla's disease had been regarded as terminal before the treatment.\n\nIn December, scientists of major world academies called for a moratorium on inheritable human genome edits, including those related to CRISPR-Cas9 technologies but that basic research including embryo gene editing should continue.\n\nIn April the Committee for Medicinal Products for Human Use of the European Medicines Agency endorsed a gene therapy treatment called Strimvelis and the European Commission approved it in June. This treats children born with ADA-SCID and who have no functioning immune system—sometimes called the \"bubble baby\" disease. This was the second gene therapy treatment to be approved in Europe.\n\nIn October, Chinese scientists reported they had started a trial to genetically modify T-cells from 10 adult patients with lung cancer and reinject the modified T-cells back into their bodies to attack the cancer cells. The T-cells had the PD-1 protein (which stops or slows the immune response) removed using CRISPR-Cas9.\n\nA 2016 Cochrane systematic review looking at data from four trials on topical cystic fibrosis transmembrane conductance regulator (CFTR) gene therapy does not support its clinical use as a mist inhaled into the lungs to treat cystic fibrosis patients with lung infections. One of the four trials did find weak evidence that liposome-based CFTR gene transfer therapy may lead to a small respiratory improvement for people with CF. This weak evidence is not enough to make a clinical recommendation for routine CFTR gene therapy.\n\nIn February Kite Pharma announced results from a clinical trial of CAR-T cells in around a hundred people with advanced Non-Hodgkin lymphoma.\n\nIn March, French scientists reported on clinical research of gene therapy to treat sickle-cell disease.\n\nIn August, the FDA approved tisagenlecleucel for acute lymphoblastic leukemia. Tisagenlecleucel is an adoptive cell transfer therapy for B-cell acute lymphoblastic leukemia; T cells from a person with cancer are removed, genetically engineered to make a specific T-cell receptor (a chimeric T cell receptor, or \"CAR-T\") that reacts to the cancer, and are administered back to the person. The T cells are engineered to target a protein called CD19 that is common on B cells. This is the first form of gene therapy to be approved in the United States. In October, a similar therapy called axicabtagene ciloleucel was approved for non-Hodgkin lymphoma.\n\nIn December the results of using an adeno-associated virus with blood clotting factor VIII to treat nine haemophilia A patients were published. Six of the seven patients on the high dose regime increased the level of the blood clotting VIII to normal levels. The low and medium dose regimes had no effect on the patient's blood clotting levels.\n\nIn December, the FDA approved Luxturna, the first \"in vivo\" gene therapy, for the treatment of blindness due to Leber's congenital amaurosis. The price of this treatment was 850,000 US dollars for both eyes. CRISPR gene editing technology has also been used on mice to treat deafness due to the DFNA36 mutation, which also affects humans.\n\nSpeculated uses for gene therapy include:\n\nGene Therapy techniques have the potential to provide alternative treatments for those with infertility. Recently, successful experimentation on mice has proven that fertility can be restored by using the gene therapy method, CRISPR. Spermatogenical stem cells from another organism were transplanted into the testes of an infertile male mouse. The stem cells re-established spermatogenesis and fertility.\n\nAthletes might adopt gene therapy technologies to improve their performance. Gene doping is not known to occur, but multiple gene therapies may have such effects. Kayser et al. argue that gene doping could level the playing field if all athletes receive equal access. Critics claim that any therapeutic intervention for non-therapeutic/enhancement purposes compromises the ethical foundations of medicine and sports.\n\nGenetic engineering could be used to cure diseases, but also to change physical appearance, metabolism, and even improve physical capabilities and mental faculties such as memory and intelligence. Ethical claims about germline engineering include beliefs that every fetus has a right to remain genetically unmodified, that parents hold the right to genetically modify their offspring, and that every child has the right to be born free of preventable diseases. For parents, genetic engineering could be seen as another child enhancement technique to add to diet, exercise, education, training, cosmetics, and plastic surgery. Another theorist claims that moral concerns limit but do not prohibit germline engineering.\n\nPossible regulatory schemes include a complete ban, provision to everyone, or professional self-regulation. The American Medical Association’s Council on Ethical and Judicial Affairs stated that \"genetic interventions to enhance traits should be considered permissible only in severely restricted situations: (1) clear and meaningful benefits to the fetus or child; (2) no trade-off with other characteristics or traits; and (3) equal access to the genetic technology, irrespective of income or other socioeconomic characteristics.\"\n\nAs early in the history of biotechnology as 1990, there have been scientists opposed to attempts to modify the human germline using these new tools, and such concerns have continued as technology progressed. With the advent of new techniques like CRISPR, in March 2015 a group of scientists urged a worldwide moratorium on clinical use of gene editing technologies to edit the human genome in a way that can be inherited. In April 2015, researchers sparked controversy when they reported results of basic research to edit the DNA of non-viable human embryos using CRISPR. A committee of the American National Academy of Sciences and National Academy of Medicine gave qualified support to human genome editing in 2017 once answers have been found to safety and efficiency problems \"but only for serious conditions under stringent oversight.\"\n\nRegulations covering genetic modification are part of general guidelines about human-involved biomedical research. There are no international treaties which are legally binding in this area, but there are recommendations for national laws from various bodies.\n\nThe Helsinki Declaration (Ethical Principles for Medical Research Involving Human Subjects) was amended by the World Medical Association's General Assembly in 2008. This document provides principles physicians and researchers must consider when involving humans as research subjects. The Statement on Gene Therapy Research initiated by the Human Genome Organization (HUGO) in 2001 provides a legal baseline for all countries. HUGO’s document emphasizes human freedom and adherence to human rights, and offers recommendations for somatic gene therapy, including the importance of recognizing public concerns about such research.\n\nNo federal legislation lays out protocols or restrictions about human genetic engineering. This subject is governed by overlapping regulations from local and federal agencies, including the Department of Health and Human Services, the FDA and NIH's Recombinant DNA Advisory Committee. Researchers seeking federal funds for an investigational new drug application, (commonly the case for somatic human genetic engineering,) must obey international and federal guidelines for the protection of human subjects.\n\nNIH serves as the main gene therapy regulator for federally funded research. Privately funded research is advised to follow these regulations. NIH provides funding for research that develops or enhances genetic engineering techniques and to evaluate the ethics and quality in current research. The NIH maintains a mandatory registry of human genetic engineering research protocols that includes all federally funded projects.\n\nAn NIH advisory committee published a set of guidelines on gene manipulation. The guidelines discuss lab safety as well as human test subjects and various experimental types that involve genetic changes. Several sections specifically pertain to human genetic engineering, including Section III-C-1. This section describes required review processes and other aspects when seeking approval to begin clinical research involving genetic transfer into a human patient. The protocol for a gene therapy clinical trial must be approved by the NIH's Recombinant DNA Advisory Committee prior to any clinical trial beginning; this is different from any other kind of clinical trial.\nAs with other kinds of drugs, the FDA regulates the quality and safety of gene therapy products and supervises how these products are used clinically. Therapeutic alteration of the human genome falls under the same regulatory requirements as any other medical treatment. Research involving human subjects, such as clinical trials, must be reviewed and approved by the FDA and an Institutional Review Board.\n\nGene therapy is the basis for the plotline of the film \"I Am Legend\" and the TV show \"Will Gene Therapy Change the Human Race?\". It is also used in Stargate as a means of allowing humans to use Ancient technology.\n\n\n", "id": "12891", "title": "Gene therapy"}
{"url": "https://en.wikipedia.org/wiki?curid=1197980", "text": "Downregulation and upregulation\n\nIn the biological context of organisms' production of gene products, downregulation is the process by which a cell decreases the quantity of a cellular component, such as RNA or protein, in response to an external stimulus. The complementary process that involves increases of such components is called upregulation.\n\nAn example of downregulation is the cellular decrease in the number of receptors to a molecule, such as a hormone or neurotransmitter, which reduces the cell's sensitivity to the molecule. This is an example of a locally acting (negative feedback) mechanism.\n\nAn example of upregulation is the response of liver cells exposed to such xenobiotic molecules as dioxin. In this situation, the cells increase their production of cytochrome P450 enzymes, which in turn increases their degradation of these molecules.\n\nAll living cells have the ability to receive and process signals that originate outside of their membranes, which they do by means of proteins called receptors, usually found on a cell's surface imbedded in the plasma membrane. When such signals bind to a receptor, they effectively direct the cell to do something, such as dividing, dying, or allowing substances to be created, or to enter or exit the cell. A cell's ability to respond to a chemical message depends on the presence of receptors tuned to that message. The more receptors a cell has that are tuned to the message, the more the cell will respond to it.\n\nReceptors are created, or expressed, by the DNA of the cell, and they can be increased, or upregulated, when the signal is weak, or decreased, or downregulated, when it is strong.\n\nDownregulation of receptors happens when receptors have been chronically exposed to an excessive amount of neurotransmitters, whether endogenous or drugs. This results in ligand-induced desensitization or internalization of that receptor. It is usually exhibited by various hormone receptors. Upregulation of receptors, on the other hand, results in super-sensitized cells especially after repeated exposure to an antagonistic drug or prolonged absence of the ligand.\n\nSome receptor agonists may cause downregulation of their respective receptors, while most receptor antagonists temporarily upregulate their respective receptors. The disequilibrium caused by these changes often causes withdrawal when the long-term use of a drug is discontinued. However, the use of certain receptor antagonists may also damage receptors faster than they upregulate (internalization of receptors due to antagonism).\n\nUpregulation and downregulation can also happen as a response to toxins or hormones. An example of upregulation in pregnancy is hormones that cause cells in the uterus to become more sensitive to oxytocin.\n\nElevated levels of the hormone insulin in the blood trigger downregulation of the associated receptors. When insulin binds to its receptors on the surface of a cell, the hormone receptor complex undergoes endocytosis and is subsequently attacked by intracellular lysosomal enzymes. The internalization of the insulin molecules provides a pathway for degradation of the hormone as well as for regulation of the number of sites that are available for binding on the cell surface. At high plasma concentrations, the number of surface receptors for insulin is gradually reduced by the accelerated rate of receptor internalization and degradation brought about by increased hormonal binding. The rate of synthesis of new receptors within the endoplasmic reticulum and their insertion in the plasma membrane do not keep pace with their rate of destruction. Over time, this self-induced loss of target cell receptors for insulin reduces the target cell's sensitivity to the elevated hormone concentration.\n\nThis process is illustrated by the insulin receptor sites on target cells in a person with type 2 diabetes. Due to the elevated levels of blood glucose in an overweight individual, the β-cells (islets of Langerhans) in the pancreas must release more insulin than normal to meet the demand and return the blood to homeostatic levels. The near-constant increase in blood insulin levels results from an effort to match the increase in blood glucose, which will cause receptor sites on the liver cells to downregulate and decrease the number of receptors for insulin, increasing the subject’s resistance by decreasing sensitivity to this hormone. There is also a hepatic decrease in sensitivity to insulin. This can be seen in the continuing gluconeogenesis in the liver even when blood glucose levels are elevated. This is the more common process of insulin resistance, which leads to adult-onset diabetes.\n\nAnother example can be seen in diabetes insipidus, in which the kidneys become insensitive to arginine vasopressin.\n\n\n", "id": "1197980", "title": "Downregulation and upregulation"}
{"url": "https://en.wikipedia.org/wiki?curid=52431039", "text": "List of signalling pathways\n\nIn cell biology, there are several signalling pathways. Cell signalling is part of the molecular biology system that controls and coordinates the actions of cells.\n", "id": "52431039", "title": "List of signalling pathways"}
{"url": "https://en.wikipedia.org/wiki?curid=52432771", "text": "Loading control\n\nA loading control is a protein used as a control in a Western blotting experiment. Typically, loading controls are proteins with high and ubiquitous expression, such as beta-actin or GADPH. They are used to make sure that the protein has been loaded equally across all wells.\n", "id": "52432771", "title": "Loading control"}
{"url": "https://en.wikipedia.org/wiki?curid=52702499", "text": "Mitochondrial unfolded protein response\n\nThe mitochondrial unfolded protein response (UPR) is a cellular stress response related to the mitochondria. The UPR results from unfolded or misfolded proteins in mitochondria beyond the capacity of chaperone proteins to handle them. The UPR can occur either in the mitochondrial matrix or in the mitochondrial inner membrane. In the UPR, the mitochondrion will either upregulate chaperone proteins or invoke proteases to degrade proteins that fail to fold properly. UPR causes the sirtuin SIRT3 to activate antioxidant enzymes and mitophagy.\n\nMitochondrial electron transport chain mutations that extend the life span of Caenorhabditis elegans (nematode worms) also activate the UPR. Activation of the UPR in nematode worms by increasing NAD+ by supplementation with nicotinamide or nicotinamide riboside has been shown to extend lifespan. Nicotinamide riboside supplementation in mice has also been shown to activate the UPR.\n\n", "id": "52702499", "title": "Mitochondrial unfolded protein response"}
{"url": "https://en.wikipedia.org/wiki?curid=12383", "text": "Genetic engineering\n\nGenetic engineering, also called genetic modification, is the direct manipulation of an organism's genes using biotechnology. It is a set of technologies used to change the genetic makeup of cells, including the transfer of genes within and across species boundaries to produce improved or novel organisms. New DNA is obtained by either isolating and copying the genetic material of interest using recombinant DNA methods or by artificially synthesising the DNA. A construct is usually created and used to insert this DNA into the host organism. The first recombinant DNA molecule was made by Paul Berg in 1972 by combining DNA from the monkey virus SV40 with the lambda virus. As well as inserting genes, the process can be used to remove, or \"knock out\", genes. The new DNA can be inserted randomly, or targeted to a specific part of the genome.\n\nAn organism that is generated through genetic engineering is considered to be genetically modified (GM) and the resulting entity is a genetically modified organism (GMO). The first GMO was a bacterium generated by Herbert Boyer and Stanley Cohen in 1973. Rudolf Jaenisch created the first GM animal when he inserted foreign DNA into a mouse in 1974. The first company to focus on genetic engineering, Genentech, was founded in 1976 and started the production of human proteins. Genetically engineered human insulin was produced in 1978 and insulin-producing bacteria were commercialised in 1982. Genetically modified food has been sold since 1994, with the release of the Flavr Savr tomato. The Flavr Savr was engineered to have a longer shelf life, but most current GM crops are modified to increase resistance to insects and herbicides. GloFish, the first GMO designed as a pet, was sold in the United States in December 2003. In 2016 salmon modified with a growth hormone were sold.\n\nGenetic engineering has been applied in numerous fields including research, medicine, industrial biotechnology and agriculture. In research GMOs are used to study gene function and expression through loss of function, gain of function, tracking and expression experiments. By knocking out genes responsible for certain conditions it is possible to create animal model organisms of human diseases. As well as producing hormones, vaccines and other drugs genetic engineering has the potential to cure genetic diseases through gene therapy. The same techniques that are used to produce drugs can also have industrial applications such as producing enzymes for laundry detergent, cheeses and other products.\n\nThe rise of commercialised genetically modified crops has provided economic benefit to farmers in many different countries, but has also been the source of most of the controversy surrounding the technology. This has been present since its early use, the first field trials were destroyed by anti-GM activists. Although there is a scientific consensus that currently available food derived from GM crops poses no greater risk to human health than conventional food, GM food safety is a leading concern with critics. Gene flow, impact on non-target organisms, control of the food supply and intellectual property rights have also been raised as potential issues. These concerns have led to the development of a regulatory framework, which started in 1975. It has led to an international treaty, the Cartagena Protocol on Biosafety, that was adopted in 2000. Individual countries have developed their own regulatory systems regarding GMOs, with the most marked differences occurring between the USA and Europe.\n\nGenetic engineering is a process that alters the genetic make-up of an organism by either removing or introducing DNA. Unlike traditionally animal and plant breeding, which involves doing multiple crosses and then selecting for the organism with the desired phenotype, genetic engineering takes the gene directly from one organism and inserts it in the other. This is much faster, can be used to insert any genes from any organism (even ones from different domains) and prevents other undesirable genes from also being added.\n\nGenetic engineering could potentially fix severe genetic disorders in humans by replacing the defective gene with a functioning one. It is an important tool in research that allows the function of specific genes to be studied. Drugs, vaccines and other products have been harvested from organisms engineered to produce them. Crops have been developed that aid food security by increasing yield, nutritional value and tolerance to environmental stresses.\n\nThe DNA can be introduced directly into the host organism or into a cell that is then fused or hybridised with the host. This relies on recombinant nucleic acid techniques to form new combinations of heritable genetic material followed by the incorporation of that material either indirectly through a vector system or directly through micro-injection, macro-injection or micro-encapsulation.\n\nGenetic engineering does not normally include traditional breeding, in vitro fertilisation, induction of polyploidy, mutagenesis and cell fusion techniques that do not use recombinant nucleic acids or a genetically modified organism in the process. However, some broad definitions of genetic engineering include selective breeding. Cloning and stem cell research, although not considered genetic engineering, are closely related and genetic engineering can be used within them. Synthetic biology is an emerging discipline that takes genetic engineering a step further by introducing artificially synthesised material into an organism.\n\nPlants, animals or micro organisms that have been changed through genetic engineering are termed genetically modified organisms or GMOs. If genetic material from another species is added to the host, the resulting organism is called transgenic. If genetic material from the same species or a species that can naturally breed with the host is used the resulting organism is called cisgenic. If genetic engineering is used to remove genetic material from the target organism the resulting organism is termed a knockout organism. In Europe genetic modification is synonymous with genetic engineering while within the United States of America and Canada genetic modification can also be used to refer to more conventional breeding methods.\n\nHumans have altered the genomes of species for thousands of years through selective breeding, or artificial selection as contrasted with natural selection, and more recently through mutagenesis. Genetic engineering as the direct manipulation of DNA by humans outside breeding and mutations has only existed since the 1970s. The term \"genetic engineering\" was first coined by Jack Williamson in his science fiction novel \"Dragon's Island\", published in 1951 – one year before DNA's role in heredity was confirmed by Alfred Hershey and Martha Chase, and two years before James Watson and Francis Crick showed that the DNA molecule has a double-helix structure – though the general concept of direct genetic manipulation was explored in rudimentary form in Stanley G. Weinbaum's 1936 science fiction story \"Proteus Island\".\n\nIn 1972, Paul Berg created the first recombinant DNA molecules by combining DNA from the monkey virus SV40 with that of the lambda virus. In 1973 Herbert Boyer and Stanley Cohen created the first transgenic organism by inserting antibiotic resistance genes into the plasmid of an \"Escherichia coli\" bacterium. A year later Rudolf Jaenisch created a transgenic mouse by introducing foreign DNA into its embryo, making it the world’s first transgenic animal. These achievements led to concerns in the scientific community about potential risks from genetic engineering, which were first discussed in depth at the Asilomar Conference in 1975. One of the main recommendations from this meeting was that government oversight of recombinant DNA research should be established until the technology was deemed safe.\n\nIn 1976 Genentech, the first genetic engineering company, was founded by Herbert Boyer and Robert Swanson and a year later the company produced a human protein (somatostatin) in \"E.coli\". Genentech announced the production of genetically engineered human insulin in 1978. In 1980, the U.S. Supreme Court in the \"Diamond v. Chakrabarty\" case ruled that genetically altered life could be patented. The insulin produced by bacteria was approved for release by the Food and Drug Administration (FDA) in 1982.\n\nIn 1983, a biotech company, Advanced Genetic Sciences (AGS) applied for U.S. government authorisation to perform field tests with the ice-minus strain of \"Pseudomonas syringae\" to protect crops from frost, but environmental groups and protestors delayed the field tests for four years with legal challenges. In 1987, the ice-minus strain of \"P. syringae\" became the first genetically modified organism (GMO) to be released into the environment when a strawberry field and a potato field in California were sprayed with it. Both test fields were attacked by activist groups the night before the tests occurred: \"The world's first trial site attracted the world's first field trasher\".\n\nThe first field trials of genetically engineered plants occurred in France and the USA in 1986, tobacco plants were engineered to be resistant to herbicides. The People’s Republic of China was the first country to commercialise transgenic plants, introducing a virus-resistant tobacco in 1992. In 1994 Calgene attained approval to commercially release the first genetically modified food, the Flavr Savr, a tomato engineered to have a longer shelf life. In 1994, the European Union approved tobacco engineered to be resistant to the herbicide bromoxynil, making it the first genetically engineered crop commercialised in Europe. In 1995, Bt Potato was approved safe by the Environmental Protection Agency, after having been approved by the FDA, making it the first pesticide producing crop to be approved in the USA. In 2009 11 transgenic crops were grown commercially in 25 countries, the largest of which by area grown were the USA, Brazil, Argentina, India, Canada, China, Paraguay and South Africa.\n\nIn 2010, scientists at the J. Craig Venter Institute created the first synthetic genome and inserted it into an empty bacterial cell. The resulting bacterium, named Mycoplasma laboratorium, could replicate and produce proteins. Four years later this was taken a step further when bacterium was developed that replicated a plasmid containing a unique base pair, creating the first organism engineered to use an expanded genetic alphabet. In 2012, Jennifer Doudna and Emmanuelle Charpentier collaborated to develop the CRISPR/Cas9 system, a technique which can be used to easily and specifically alter the genome of almost any organism.\n\nCreating a GMO is a multi-step process. Genetic engineers must first choose what gene they wish to insert into the organism. This is driven by what the aim is for the resultant organism and is built on earlier research. Genetic screens can be carried out to determine potential genes and further tests then used to identify the best candidates. The development of microarrays, transcriptomes and genome sequencing has made it much easier to find suitable genes. Luck also plays its part; the round-up ready gene was discovered after scientists noticed a bacterium thriving in the presence of the herbicide.\n\nThe next step is to isolate the candidate gene. The cell containing the gene is opened and the DNA is purified. The gene is separated by using restriction enzymes to cut the DNA into fragments or polymerase chain reaction (PCR) to amplify up the gene segment. These segments can then be extracted through gel electrophoresis. If the chosen gene or the donor organism's genome has been well studied it may already be accessible from a genetic library. If the DNA sequence is known, but no copies of the gene are available, it can also be artificially synthesised. Once isolated the gene is ligated into a plasmid that is then inserted into a bacterium. The plasmid is replicated when the bacteria divide, ensuring unlimited copies of the gene are available.\n\nBefore the gene is inserted into the target organism it must be combined with other genetic elements. These include a promoter and terminator region, which initiate and end transcription. A selectable marker gene is added, which in most cases confers antibiotic resistance, so researchers can easily determine which cells have been successfully transformed. The gene can also be modified at this stage for better expression or effectiveness. These manipulations are carried out using recombinant DNA techniques, such as restriction digests, ligations and molecular cloning.\n\nThere are a number of techniques available for inserting the gene into the host genome. Some bacteria can naturally take up foreign DNA. This ability can be induced in other bacteria via stress (e.g. thermal or electric shock), which increases the cell membrane's permeability to DNA; up-taken DNA can either integrate with the genome or exist as extrachromosomal DNA. DNA is generally inserted into animal cells using microinjection, where it can be injected through the cell's nuclear envelope directly into the nucleus, or through the use of viral vectors.\n\nIn plants the DNA is often inserted using \"Agrobacterium\"-mediated recombination, taking advantage of the \"Agrobacterium\"s T-DNA sequence that allows natural insertion of genetic material into plant cells. Other methods include biolistics, where particles of gold or tungsten are coated with DNA and then shot into young plant cells, and electroporation, which involves using an electric shock to make the cell membrane permeable to plasmid DNA. Due to the damage caused to the cells and DNA the transformation efficiency of biolistics and electroporation is lower than agrobacterial transformation and microinjection.\n\nAs only a single cell is transformed with genetic material, the organism must be regenerated from that single cell. In plants this is accomplished through the use of tissue culture. In animals it is necessary to ensure that the inserted DNA is present in the embryonic stem cells. Bacteria consist of a single cell and reproduce clonally so regeneration is not necessary. Selectable markers are used to easily differentiate transformed from untransformed cells. These markers are usually present in the transgenic organism, although a number of strategies have been developed that can remove the selectable marker from the mature transgenic plant.\n\nFurther testing using PCR, Southern hybridization, and DNA sequencing is conducted to confirm that an organism contains the new gene. These tests can also confirm the chromosomal location and copy number of the inserted gene. The presence of the gene does not guarantee it will be expressed at appropriate levels in the target tissue so methods that look for and measure the gene products (RNA and protein) are also used. These include northern hybridisation, quantitative RT-PCR, Western blot, immunofluorescence, ELISA and phenotypic analysis.\n\nThe new genetic material can be inserted randomly within the host genome or targeted to a specific location. The technique of gene targeting uses homologous recombination to make desired changes to a specific endogenous gene. This tends to occur at a relatively low frequency in plants and animals and generally requires the use of selectable markers. The frequency of gene targeting can be greatly enhanced through genome editing. Genome editing uses artificially engineered nucleases that create specific double-stranded breaks at desired locations in the genome, and use the cell’s endogenous mechanisms to repair the induced break by the natural processes of homologous recombination and nonhomologous end-joining. There are four families of engineered nucleases: meganucleases, zinc finger nucleases, transcription activator-like effector nucleases (TALENs), and the Cas9-guideRNA system (adapted from CRISPR). TALEN and CRISPR are the two most commonly used and each has its own advantages. TALENs have greater target specificity, while CRISPR is easier to design and more efficient. In addition to enhancing gene targeting, engineered nucleases can be used to introduce mutations at endogenous genes that generate a gene knockout.\n\nGenetic engineering has applications in medicine, research, industry and agriculture and can be used on a wide range of plants, animals and micro organisms. Bacteria, the first organisms to be genetically modified, can have plasmid DNA inserted containing new genes that code for medicines or enzymes that process food and other substrates. Plants have been modified for insect protection, herbicide resistance, virus resistance, enhanced nutrition, tolerance to environmental pressures and the production of edible vaccines. Most commercialised GMOs are insect resistant or herbicide tolerant crop plants. Genetically modified animals have been used for research, model animals and the production of agricultural or pharmaceutical products. The genetically modified animals include animals with genes knocked out, increased susceptibility to disease, hormones for extra growth and the ability to express proteins in their milk.\n\nGenetic engineering has many applications to medicine that include the manufacturing of drugs, creation of model animals that mimic human conditions and gene therapy. One of the earliest uses of genetic engineering was to mass-produce human insulin in bacteria. This application has now been applied to, human growth hormones, follicle stimulating hormones (for treating infertility), human albumin, monoclonal antibodies, antihemophilic factors, vaccines and many other drugs. Mouse hybridomas, cells fused together to create monoclonal antibodies, have been adapted through genetic engineering to create human monoclonal antibodies. In 2017, genetic engineering of chimeric antigen receptors on a patient's own T-cells was approved by the U.S. FDA as a treatment for the cancer acute lymphoblastic leukemia. Genetically engineered viruses are being developed that can still confer immunity, but lack the infectious sequences.\n\nGenetic engineering is also used to create animal models of human diseases. Genetically modified mice are the most common genetically engineered animal model. They have been used to study and model cancer (the oncomouse), obesity, heart disease, diabetes, arthritis, substance abuse, anxiety, aging and Parkinson disease. Potential cures can be tested against these mouse models. Also genetically modified pigs have been bred with the aim of increasing the success of pig to human organ transplantation.\n\nGene therapy is the genetic engineering of humans, generally by replacing defective genes with effective ones. Clinical research using somatic gene therapy has been conducted with several diseases, including X-linked SCID, chronic lymphocytic leukemia (CLL), and Parkinson's disease. In 2012, Alipogene tiparvovec became the first gene therapy treatment to be approved for clinical use. In 2015 a virus was used to insert a healthy gene into the skin cells of a boy suffering from a rare skin disease, epidermolysis bullosa, in order to grow, and then graft healthy skin onto 80 percent of the boy's body which was affected by the illness. Germline gene therapy would result in any change being inheritable, which has raised concerns within the scientific community. In 2015, CRISPR was used to edit the DNA of non-viable human embryos, leading scientists of major world academies to called for a moratorium on inheritable human genome edits. There are also concerns that the technology could be used not just for treatment, but for enhancement, modification or alteration of a human beings' appearance, adaptability, intelligence, character or behavior. The distinction between cure and enhancement can also be difficult to establish.\n\nResearchers are altering the genome of pigs to induce the growth of human organs to be used in transplants. Scientists are creating \"gene drives\", changing the genomes of mosquitoes to make them immune to malaria, and then spreading the genetically altered mosquitoes throughout the mosquito population in the hopes of eliminating the disease.\n\nGenetic engineering is an important tool for natural scientists. Genes and other genetic information from a wide range of organisms can be inserted into bacteria for storage and modification, creating genetically modified bacteria in the process. Bacteria are cheap, easy to grow, clonal, multiply quickly, relatively easy to transform and can be stored at -80 °C almost indefinitely. Once a gene is isolated it can be stored inside the bacteria providing an unlimited supply for research.\n\nOrganisms are genetically engineered to discover the functions of certain genes. This could be the effect on the phenotype of the organism, where the gene is expressed or what other genes it interacts with. These experiments generally involve loss of function, gain of function, tracking and expression.\n\n\nOrganisms can have their cells transformed with a gene coding for a useful protein, such as an enzyme, so that they will overexpress the desired protein. Mass quantities of the protein can then be manufactured by growing the transformed organism in bioreactor equipment using industrial fermentation, and then purifying the protein. Some genes do not work well in bacteria, so yeast, insect cells or mammalians cells can also be used. These techniques are used to produce medicines such as insulin, human growth hormone, and vaccines, supplements such as tryptophan, aid in the production of food (chymosin in cheese making) and fuels. Other applications with genetically engineered bacteria could involve making them perform tasks outside their natural cycle, such as making biofuels, cleaning up oil spills, carbon and other toxic waste and detecting arsenic in drinking water. Certain genetically modified microbes can also be used in biomining and bioremediation, due to their ability to extract heavy metals from their environment and incorporate them into compounds that are more easily recoverable.\n\nIn materials science, a genetically modified virus has been used in a research laboratory as a scaffold for assembling a more environmentally friendly lithium-ion battery. Bacteria have also been engineered to function as sensors by expressing a fluorescent protein under certain environmental conditions.\n\nOne of the best-known and controversial applications of genetic engineering is the creation and use of genetically modified crops or genetically modified livestock to produce genetically modified food. Crops have been developed to increase production, increase tolerance to abiotic stresses, alter the composition of the food, or to produce novel products.\n\nThe first crops to be realised commercially on a large scale provided protection from insect pests or tolerance to herbicides. Fungal and virus resistant crops have also being developed or are in development. This make the insect and weed management of crops easier and can indirectly increase crop yield. GM crops that directly improve yield by accelerating growth or making the plant more hardy (by improving salt, cold or drought tolerance) are also under development. In 2016 Salmon have been genetically modified with growth hormones to reach normal adult size much faster.\n\nGMOs have been developed that modify the quality of produce by increasing the nutritional value or providing more industrially useful qualities or quantities. The Amflora potato produces a more industrially useful blend of starches. Soybeans and canola have been genetically modified to produce more healthy oils. The first commercialised GM food was a tomato that had delayed ripening, increasing its shelf life.\n\nPlants and animals have been engineered to produce materials they do not normally make. Pharming uses crops and animals as bioreactors to produce vaccines, drug intermediates, or the drugs themselves; the useful product is purified from the harvest and then used in the standard pharmaceutical production process. Cows and goats have been engineered to express drugs and other proteins in their milk, and in 2009 the FDA approved a drug produced in goat milk.\n\nGenetic engineering has potential applications in conservation and natural area management. Gene transfer through viral vectors has been proposed as a means of controlling invasive species as well as vaccinating threatened fauna from disease. Transgenic trees have been suggested as a way to confer resistance to pathogens in wild populations. With the increasing risks of maladaptation in organisms as a result of climate change and other perturbations, facilitated adaptation through gene tweaking could be one solution to reducing extinction risks. Applications of genetic engineering in conservation are thus far mostly theoretical and have yet to be put into practice.\n\nGenetic engineering is also being used to create microbial art. Some bacteria have been genetically engineered to create black and white photographs. Novelty items such as lavender-colored carnations, blue roses, and glowing fish have also been produced through genetic engineering.\n\nThe regulation of genetic engineering concerns the approaches taken by governments to assess and manage the risks associated with the development and release of GMOs. The development of a regulatory framework began in 1975, at Asilomar, California. The Asilomar meeting recommended a set of voluntary guidelines regarding the use of recombinant technology. As the technology improved USA established a committee at the Office of Science and Technology, which assigned regulatory approval of GM plants to the USDA, FDA and EPA. The Cartagena Protocol on Biosafety, an international treaty that governs the transfer, handling, and use of GMOs, was adopted on 29 January 2000. One hundred and fifty-seven countries are members of the Protocol and many use it as a reference point for their own regulations.\n\nThe legal and regulatory status of GM foods varies by country, with some nations banning or restricting them, and others permitting them with widely differing degrees of regulation. Some countries allow the import of GM food with authorisation, but either do not allow its cultivation (Russia, Norway, Israel) or have provisions for cultivation, but no GM products are yet produced (Japan, South Korea). Most countries that do not allow for GMO cultivation do permit research. Some of the most marked differences occurring between the USA and Europe. The US policy focuses on the product (not the process), only looks at verifiable scientific risks and uses the concept of substantial equivalence. The European Union by contrast has possibly the most stringent GMO regulations in the world. All GMOs, along with irradiated food, are considered \"new food\" and subject to extensive, case-by-case, science-based food evaluation by the European Food Safety Authority. The criteria for authorisation fall in four broad categories: \"safety,\" \"freedom of choice,\" \"labelling,\" and \"traceability.\" The level of regulation in other countries that cultivate GMOs lie in between Europe and the United States.\nOne of the key issues concerning regulators is whether GM products should be labeled. The European Commission says that mandatory labeling and traceability are needed to allow for informed choice, avoid potential false advertising and facilitate the withdrawal of products if adverse effects on health or the environment are discovered. The American Medical Association and the American Association for the Advancement of Science say that absent scientific evidence of harm even voluntary labeling is misleading and will falsely alarm consumers\". Labeling of GMO products in the marketplace is required in 64 countries. Labeling can be mandatory up to a threshold GM content level (which varies between countries) or voluntary. In Canada and the USA labeling of GM food is voluntary, while in Europe all food (including processed food) or feed which contains greater than 0.9% of approved GMOs must be labelled.\n\nCritics have objected to the use of genetic engineering on several grounds, that include ethical, ecological and economic concerns. Many of these concerns involve GM crops and whether food produced from them is safe, whether it should be labeled and what impact growing them will have on the environment. These controversies have led to litigation, international trade disputes, and protests, and to restrictive regulation of commercial products in some countries.\n\nAccusations that scientists are \"playing God\" and other religious issues have been ascribed to the technology from the beginning. Other ethical issues raised include the patenting of life, the use of intellectual property rights, the level of labeling on products, control of the food supply and the objectivity of the regulatory process. Although doubts have been raised, economically most studies have found growing GM crops to be beneficial to farmers.\n\nGene flow between GM crops and compatible plants, along with increased use of selective herbicides, can increase the risk of \"superweeds\" developing. Other environmental concerns involve potential impacts on non-target organisms, including soil microbes, and an increase in secondary and resistant insect pests. Many of the environmental impacts regarding GM crops may take many years to be understood are also evident in conventional agriculture practices. With the commercialisation of genetically modified fish there are concerns over what the environmental consequences will be if they escape.\n\nThere are three main concerns over the safety of genetically modified food: whether they may provoke an allergic reaction; whether the genes could transfer from the food into human cells; and whether the genes not approved for human consumption could outcross to other crops. There is a scientific consensus that currently available food derived from GM crops poses no greater risk to human health than conventional food, but that each GM food needs to be tested on a case-by-case basis before introduction. Nonetheless, members of the public are much less likely than scientists to perceive GM foods as safe.\n\n\n\n", "id": "12383", "title": "Genetic engineering"}
{"url": "https://en.wikipedia.org/wiki?curid=12582", "text": "Gel electrophoresis\n\nGel electrophoresis is a method for separation and analysis of macromolecules (DNA, RNA and proteins) and their fragments, based on their size and charge. It is used in clinical chemistry to separate proteins by charge and/or size (IEF agarose, essentially size independent) and in biochemistry and molecular biology to separate a mixed population of DNA and RNA fragments by length, to estimate the size of DNA and RNA fragments or to separate proteins by charge.\n\nNucleic acid molecules are separated by applying an electric field to move the negatively charged molecules through a matrix of agarose or other substances. Shorter molecules move faster and migrate farther than longer ones because shorter molecules migrate more easily through the pores of the gel. This phenomenon is called sieving. Proteins are separated by charge in agarose because the pores of the gel are too large to sieve proteins. Gel electrophoresis can also be used for separation of nanoparticles.\n\nGel electrophoresis uses a gel as an anticonvective medium and/or sieving medium during electrophoresis, the movement of a charged particle in an electrical field. Gels suppress the thermal convection caused by application of the electric field, and can also act as a sieving medium, retarding the passage of molecules; gels can also simply serve to maintain the finished separation, so that a post electrophoresis stain can be applied. DNA Gel electrophoresis is usually performed for analytical purposes, often after amplification of DNA via polymerase chain reaction (PCR), but may be used as a preparative technique prior to use of other methods such as mass spectrometry, RFLP, PCR, cloning, DNA sequencing, or Southern blotting for further characterization.\n\nIn simple terms, electrophoresis is a process which enables the sorting of molecules based on size. Using an electric field, molecules (such as DNA) can be made to move through a gel made of agarose or polyacrylamide. The electric field consists of a negative charge at one end which pushes the molecules through the gel, and a positive charge at the other end that pulls the molecules through the gel. The molecules being sorted are dispensed into a well in the gel material. The gel is placed in an electrophoresis chamber, which is then connected to a power source. When the electric current is applied, the larger molecules move more slowly through the gel while the smaller molecules move faster. The different sized molecules form distinct bands on the gel.\n\nThe term \"gel\" in this instance refers to the matrix used to contain, then separate the target molecules. In most cases, the gel is a crosslinked polymer whose composition and porosity is chosen based on the specific weight and composition of the target to be analyzed. When separating proteins or small nucleic acids (DNA, RNA, or oligonucleotides) the gel is usually composed of different concentrations of acrylamide and a cross-linker, producing different sized mesh networks of polyacrylamide. When separating larger nucleic acids (greater than a few hundred bases), the preferred matrix is purified agarose. In both cases, the gel forms a solid, yet porous matrix. Acrylamide, in contrast to polyacrylamide, is a neurotoxin and must be handled using appropriate safety precautions to avoid poisoning. Agarose is composed of long unbranched chains of uncharged carbohydrate without cross links resulting in a gel with large pores allowing for the separation of macromolecules and macromolecular complexes.\n\nElectrophoresis refers to the electromotive force (EMF) that is used to move the molecules through the gel matrix. By placing the molecules in wells in the gel and applying an electric field, the molecules will move through the matrix at different rates, determined largely by their mass when the charge-to-mass ratio (Z) of all species is uniform. However, when charges are not all uniform then, the electrical field generated by the electrophoresis procedure will affect the species that have different charges and therefore will attract the species according to their charges being the opposite. Species that are positively charged will migrate towards the cathode which is negatively charged (because this is an electrolytic rather than galvanic cell). If the species are negatively charged they will migrate towards the positively charged anode.\n\nIf several samples have been loaded into adjacent wells in the gel, they will run parallel in individual lanes. Depending on the number of different molecules, each lane shows separation of the components from the original mixture as one or more distinct bands, one band per component. Incomplete separation of the components can lead to overlapping bands, or to indistinguishable smears representing multiple unresolved components. Bands in different lanes that end up at the same distance from the top contain molecules that passed through the gel with the same speed, which usually means they are approximately the same size. There are molecular weight size markers available that contain a mixture of molecules of known sizes. If such a marker was run on one lane in the gel parallel to the unknown samples, the bands observed can be compared to those of the unknown in order to determine their size. The distance a band travels is approximately inversely proportional to the logarithm of the size of the molecule.\n\nThere are limits to electrophoretic techniques. Since passing current through a gel causes heating, gels may melt during electrophoresis. Electrophoresis is performed in buffer solutions to reduce pH changes due to the electric field, which is important because the charge of DNA and RNA depends on pH, but running for too long can exhaust the buffering capacity of the solution. There are also limitations in determining the molecular weight by SDS-PAGE, especially if you are trying to find the MW of an unknown protein. There are certain biological variables that are difficult or impossible to minimize and can affect the electrophoretic migration. Such factors include protein structure, post-translational modifications, and amino acid composition. For example, tropomyosin is an acidic protein that migrates abnormally on SDS-PAGE gels. This is because the acidic residues are repelled by the negatively charged SDS, leading to an inaccurate mass-to-charge ratio and migration. Further, different preparations of genetic material may not migrate consistently with each other, for morphological or other reasons.\n\nThe types of gel most typically used are agarose and polyacrylamide gels. Each type of gel is well-suited to different types and sizes of analyte. Polyacrylamide gels are usually used for proteins, and have very high resolving power for small fragments of DNA (5-500 bp). Agarose gels on the other hand have lower resolving power for DNA but have greater range of separation, and are therefore used for DNA fragments of usually 50-20,000 bp in size, but resolution of over 6 Mb is possible with pulsed field gel electrophoresis (PFGE). Polyacrylamide gels are run in a vertical configuration while agarose gels are typically run horizontally in a submarine mode. They also differ in their casting methodology, as agarose sets thermally, while polyacrylamide forms in a chemical polymerization reaction.\n\nAgarose gels are made from the natural polysaccharide polymers extracted from seaweed.\nAgarose gels are easily cast and handled compared to other matrices, because the gel setting is a physical rather than chemical change. Samples are also easily recovered. After the experiment is finished, the resulting gel can be stored in a plastic bag in a refrigerator.\n\nAgarose gels do not have a uniform pore size, but are optimal for electrophoresis of proteins that are larger than 200 kDa. Agarose gel electrophoresis can also be used for the separation of DNA fragments ranging from 50 base pair to several megabases (millions of bases), the largest of which require specialized apparatus. The distance between DNA bands of different lengths is influenced by the percent agarose in the gel, with higher percentages requiring longer run times, sometimes days. Instead high percentage agarose gels should be run with a pulsed field electrophoresis (PFE), or field inversion electrophoresis.\n\n\"Most agarose gels are made with between 0.7% (good separation or resolution of large 5–10kb DNA fragments) and 2% (good resolution for small 0.2–1kb fragments) agarose dissolved in electrophoresis buffer. Up to 3% can be used for separating very tiny fragments but a vertical polyacrylamide gel is more appropriate in this case. Low percentage gels are very weak and may break when you try to lift them. High percentage gels are often brittle and do not set evenly. 1% gels are common for many applications.\"\n\nPolyacrylamide gel electrophoresis (PAGE) is used for separating proteins ranging in size from 5 to 2,000 kDa due to the uniform pore size provided by the polyacrylamide gel. Pore size is controlled by modulating the concentrations of acrylamide and bis-acrylamide powder used in creating a gel. Care must be used when creating this type of gel, as acrylamide is a potent neurotoxin in its liquid and powdered forms.\n\nTraditional DNA sequencing techniques such as Maxam-Gilbert or Sanger methods used polyacrylamide gels to separate DNA fragments differing by a single base-pair in length so the sequence could be read. Most modern DNA separation methods now use agarose gels, except for particularly small DNA fragments. It is currently most often used in the field of immunology and protein analysis, often used to separate different proteins or isoforms of the same protein into separate bands. These can be transferred onto a nitrocellulose or PVDF membrane to be probed with antibodies and corresponding markers, such as in a western blot.\n\nTypically resolving gels are made in 6%, 8%, 10%, 12% or 15%. Stacking gel (5%) is poured on top of the resolving gel and a gel comb (which forms the wells and defines the lanes where proteins, sample buffer and ladders will be placed) is inserted. The percentage chosen depends on the size of the protein that one wishes to identify or probe in the sample. The smaller the known weight, the higher the percentage that should be used. Changes on the buffer system of the gel can help to further resolve proteins of very small sizes.\n\nPartially hydrolysed potato starch makes for another non-toxic medium for protein electrophoresis. The gels are slightly more opaque than acrylamide or agarose. Non-denatured proteins can be separated according to charge and size. They are visualised using Napthal Black or Amido Black staining. Typical starch gel concentrations are 5% to 10%.\n\nDenaturing gels are run under conditions that disrupt the natural structure of the analyte, causing it to unfold into a linear chain. Thus, the mobility of each macromolecule depends only on its linear length and its mass-to-charge ratio. Thus, the secondary, tertiary, and quaternary levels of biomolecular structure are disrupted, leaving only the primary structure to be analyzed.\n\nNucleic acids are often denatured by including urea in the buffer, while proteins are denatured using sodium dodecyl sulfate, usually as part of the SDS-PAGE process. For full denaturation of proteins, it is also necessary to reduce the covalent disulfide bonds that stabilize their tertiary and quaternary structure, a method called reducing PAGE. Reducing conditions are usually maintained by the addition of beta-mercaptoethanol or dithiothreitol. For general analysis of protein samples, reducing PAGE is the most common form of protein electrophoresis.\n\nDenaturing conditions are necessary for proper estimation of molecular weight of RNA. RNA is able to form more intramolecular interactions than DNA which may result in change of its electrophoretic mobility. Urea, DMSO and glyoxal are the most often used denaturing agents to disrupt RNA structure. Originally, highly toxic methylmercury hydroxide was often used in denaturing RNA electrophoresis, but it may be method of choice for some samples.\n\nDenaturing gel electrophoresis is used in the DNA and RNA banding pattern-based methods temperature gradient gel electrophoresis (TGGE) and denaturing gradient gel electrophoresis (DGGE).\n\nNative gels are run in non-denaturing conditions, so that the analyte's natural structure is maintained. This allows the physical size of the folded or assembled complex to affect the mobility, allowing for analysis of all four levels of the biomolecular structure. For biological samples, detergents are used only to the extent that they are necessary to lyse lipid membranes in the cell. Complexes remain—for the most part—associated and folded as they would be in the cell. One downside, however, is that complexes may not separate cleanly or predictably, as it is difficult to predict how the molecule's shape and size will affect its mobility. Addressing and solving this problem is a major aim of quantitative native PAGE.\n\nUnlike denaturing methods, native gel electrophoresis does not use a charged denaturing agent. The molecules being separated (usually proteins or nucleic acids) therefore differ not only in molecular mass and intrinsic charge, but also the cross-sectional area, and thus experience different electrophoretic forces dependent on the shape of the overall structure. For proteins, since they remain in the native state they may be visualised not only by general protein staining reagents but also by specific enzyme-linked staining.\n\nA specific experiment example of an application of native gel electrophoresis is to check for enzymatic activity to verify the presence of the enzyme in the sample during protein purification. For example, for the protein alkaline phosphatase, the staining solution is a mixture of 4-chloro-2-2methylbenzenediazonium salt with 3-phospho-2-naphthoic acid-2’-4’-dimethyl aniline in Tris buffer. This stain is commercially sold as kit for staining gels. If the protein is present, the mechanism of the reaction takes place in the following order: it starts with the de-phosphorylation of 3-phospho-2-naphthoic acid-2’-4’-dimethyl aniline by alkaline phosphatase (water is needed for the reaction). The phosphate group is released and replaced by an alcohol group from water. The electrophile 4- chloro-2-2 methylbenzenediazonium (Fast Red TR Diazonium salt) displaces the alcohol group forming the final product Red Azo dye. As its name implies, this is the final visible-red product of the reaction. In undergraduate academic experimentation of protein purification, the gel is usually ran next to commercial purified samples in order to visualize the results and make confusions of whether or not purification was successful.\n\nNative gel electrophoresis is typically used in proteomics and metallomics. However, native PAGE is also used to scan genes (DNA) for unknown mutations as in Single-strand conformation polymorphism.\n\nBuffers in gel electrophoresis are used to provide ions that carry a current and to maintain the pH at a relatively constant value.\nThese buffers have plenty of ions in them, which is necessary for the passage of electricity through them. Something like distilled water or benzene contains few ions, which is not ideal for the use in electrophoresis. There are a number of buffers used for electrophoresis. The most common being, for nucleic acids Tris/Acetate/EDTA (TAE), Tris/Borate/EDTA (TBE). Many other buffers have been proposed, e.g. lithium borate, which is almost never used, based on Pubmed citations (LB), iso electric histidine, pK matched goods buffers, etc.; in most cases the purported rationale is lower current (less heat) and or matched ion mobilities, which leads to longer buffer life. Borate is problematic; Borate can polymerize, and/or interact with cis diols such as those found in RNA. TAE has the lowest buffering capacity but provides the best resolution for larger DNA. This means a lower voltage and more time, but a better product. LB is relatively new and is ineffective in resolving fragments larger than 5 kbp; However, with its low conductivity, a much higher voltage could be used (up to 35 V/cm), which means a shorter analysis time for routine electrophoresis. As low as one base pair size difference could be resolved in 3% agarose gel with an extremely low conductivity medium (1 mM Lithium borate).\n\nMost SDS-PAGE protein separations are performed using a \"discontinuous\" (or DISC) buffer system that significantly enhances the sharpness of the bands within the gel. During electrophoresis in a discontinuous gel system, an ion gradient is formed in the early stage of electrophoresis that causes all of the proteins to focus into a single sharp band in a process called isotachophoresis. Separation of the proteins by size is achieved in the lower, \"resolving\" region of the gel. The resolving gel typically has a much smaller pore size, which leads to a sieving effect that now determines the electrophoretic mobility of the proteins.\n\nAfter the electrophoresis is complete, the molecules in the gel can be stained to make them visible. DNA may be visualized using ethidium bromide which, when intercalated into DNA, fluoresce under ultraviolet light, while protein may be visualised using silver stain or Coomassie Brilliant Blue dye. Other methods may also be used to visualize the separation of the mixture's components on the gel. If the molecules to be separated contain radioactivity, for example in a DNA sequencing gel, an autoradiogram can be recorded of the gel. Photographs can be taken of gels, often using a Gel Doc system.\n\nAfter separation, an additional separation method may then be used, such as isoelectric focusing or SDS-PAGE. The gel will then be physically cut, and the protein complexes extracted from each portion separately. Each extract may then be analysed, such as by peptide mass fingerprinting or de novo peptide sequencing after in-gel digestion. This can provide a great deal of information about the identities of the proteins in a complex.\n\n\nGel electrophoresis is used in forensics, molecular biology, genetics, microbiology and biochemistry. The results can be analyzed quantitatively by visualizing the gel with UV light and a gel imaging device. The image is recorded with a computer operated camera, and the intensity of the band or spot of interest is measured and compared against standard or markers loaded on the same gel. The measurement and analysis are mostly done with specialized software.\n\nDepending on the type of analysis being performed, other techniques are often implemented in conjunction with the results of gel electrophoresis, providing a wide range of field-specific applications.\n\nIn the case of nucleic acids, the direction of migration, from negative to positive electrodes, is due to the naturally occurring negative charge carried by their sugar-phosphate backbone.\n\nDouble-stranded DNA fragments naturally behave as long rods, so their migration through the gel is relative to their size or, for cyclic fragments, their radius of gyration. Circular DNA such as plasmids, however, may show multiple bands, the speed of migration may depend on whether it is relaxed or supercoiled. Single-stranded DNA or RNA tend to fold up into molecules with complex shapes and migrate through the gel in a complicated manner based on their tertiary structure. Therefore, agents that disrupt the hydrogen bonds, such as sodium hydroxide or formamide, are used to denature the nucleic acids and cause them to behave as long rods again.\n\nGel electrophoresis of large DNA or RNA is usually done by agarose gel electrophoresis. See the \"Chain termination method\" page for an example of a polyacrylamide DNA sequencing gel. Characterization through ligand interaction of nucleic acids or fragments may be performed by mobility shift affinity electrophoresis.\n\nElectrophoresis of RNA samples can be used to check for genomic DNA contamination and also for RNA degradation. RNA from eukaryotic organisms shows distinct bands of 28s and 18s rRNA, the 28s band being approximately twice as intense as the 18s band. Degraded RNA has less sharply defined bands, has a smeared appearance, and intensity ratio is less than 2:1.\n\nProteins, unlike nucleic acids, can have varying charges and complex shapes, therefore they may not migrate into the polyacrylamide gel at similar rates, or at all, when placing a negative to positive EMF on the sample. Proteins therefore, are usually denatured in the presence of a detergent such as sodium dodecyl sulfate (SDS) that coats the proteins with a negative charge. Generally, the amount of SDS bound is relative to the size of the protein (usually 1.4g SDS per gram of protein), so that the resulting denatured proteins have an overall negative charge, and all the proteins have a similar charge-to-mass ratio. Since denatured proteins act like long rods instead of having a complex tertiary shape, the rate at which the resulting SDS coated proteins migrate in the gel is relative only to its size and not its charge or shape.\n\nProteins are usually analyzed by sodium dodecyl sulfate polyacrylamide gel electrophoresis (SDS-PAGE), by native gel electrophoresis, by preparative gel electrophoresis (QPNC-PAGE), or by 2-D electrophoresis.\n\nCharacterization through ligand interaction may be performed by electroblotting or by affinity electrophoresis in agarose or by capillary electrophoresis as for estimation of binding constants and determination of structural features like glycan content through lectin binding.\n\n\nA 1959 book on electrophoresis by Milan Bier cites references from the 1800s. However, Oliver Smithies made significant contributions. Bier states: \"The method of Smithies ... is finding wide application because of its unique separatory power.\" Taken in context, Bier clearly implies that Smithies' method is an improvement.\n\n", "id": "12582", "title": "Gel electrophoresis"}
{"url": "https://en.wikipedia.org/wiki?curid=52832272", "text": "Mitochondria associated membranes (MAM)\n\nMitochondria-associated ER membranes (MAM) is a mechanism which results from communication between endoplasmic reticulum (ER) and mitochondria, this linkage consist of some proteins and a region on ER containing lipid biosynthetic enzyme connected reversibly to mitochondria.\n\nIn mammalian cells, formation of these linkage sites are important for some cellular events including:\n\nMitochondria associated membranes are involved in the transport of calcium from the ER to mitochondria. This interaction is important for rapid uptake of calcium by mitochondria through Voltage dependent anion channels (VDACs), which are located at the outer mitochondrial membrane (OMM). This transport is regulated with chaperones and regulatory proteins which control the formation of the ER–mitochondria junction. Transfer of calcium from ER to mitochondria depends on high concentration of calcium macrodomes in the intermembrane space, and mitochondrial calcium uniporter (MCU) accumulates of calcium into the mitochondrial matrix for electrochemical gradient.\n\nTransport of phosphatidylserine into mitochondria from the ER for decarboxylation to phosphatidylethanolamine through the ER-mitochondria lipid which transform phosphatidic acid (PA) into phosphatidylserine (PS) by phosphatidylserine synthases 1 and 2 (PSS1, PSS2) in the ER and then transfers PS to mitochondria, where phosphatidylserine decarboxylase (PSD) transform into phosphatidylethanolamine (PE). PE which is synthesized at mitochondria goes back to ER where phosphatidylethanolamine methyltransferase 2 (PEMT2) synthesizes PC (phosphatidylcholine).\n\nThe formation of autophagosomes through the coordination of ATG (autophagy-related) proteins and the vesicular trafficking by MAM.\n\nThese contact sites have been associated with the delicate balance between life and death of the cell.\nIsolation membranes are the initial step to form auto-phagosomes. These closed membranes are double membrane-bond, with lysosomes inside it. The main function of these membrane is degradation, as role in cellular homeostasis. However, the origin of them has remained unclear. \nMaybe it is the plasma membrane, the endoplasmic reticulum (ER) and the mitochondria. But the ER- mitochondria contact site have markers, the auto-phagosome marker ATG14, and the auto-phagosome-formation marker ATG5, until the formation of auto-phagosome is complete. Whereas, the absent of ATG14 puncta, it is caused by the breakdown of the ER–mitochondria contact site \nThe oxidative stress and the beginning of endoplasmic reticulum (ER) stress occur together; the ER stress have a key sensor enriched at the mitochondria-associated ER membranes (MAMs). This key is PERK (RNA-dependent protein kinase (PKR)-like ER kinase), PERK contributes to apoptosis twofold by sustaining the levels of pro-apoptotic C/EBP homologous protein (CHOP). \nA tight ER–mitochondria contact site is integral to the mechanisms controlling cellular apoptosis and to inter-organelle Ca2 + signals. The mitochondria-associated ER membranes (MAMs), play role in cell death modulation. Mitochondrial outer membrane permeabilization (MOMP), is a reason of the higher matrix Ca2 + levels, which is acts as a trigger for apoptosis. MOMP is the process before apoptosis, which is accompanied to permeability of the inner membrane of the mitochondria (IMM). \nPermeability transition pore (PTP) opening induces mitochondrial swelling and outer membrane of the mitochondria (OMM) rupture. Moreover, PTP opening induce releasing of caspase-activating factors and apoptosis. Caspase-activating factors induced by cytochrome C to bind to the IP3R, this will result in higher Ca2 + transfer from the ER to the mitochondria, amplifying the apoptotic signal.\n\nOngoing research has provided evidence for the impact associated with dysfunctional MAM’s. Alterations in MAMs function whether up regulation or down regulation are associated with many human disorders.\n\nMAMS play an important role in Ca+2 Homeostasis, phospholipid and cholesterol metabolism. Research has associated the alteration of these functions of MAMs in AD. Mitochindrial associated membranes associated with Alzheimer's disease have been reported to have an up-regulation of lipids synthesized in the MAMs juxtaposition and an up regulation of protein complexes present in the contact region between the ER and mitochondria. Research has suggested that the sites of MAM are the primary sites of activity for γ-secretase activity and amyloid precursor protein (APP) localization along with the presenilin 1 (PS1), presenilin 2 (PS2) proteins. γ-secretase functions in the cleavage of the beta- APP protein. Patients diagnosed with Alzheimer’s disease have presented results that indicated the accumulation of amyloid beta peptide in the brain which in turn leads to the amyloid cascade suggestion. Also up increased connectivity between the ER and the mitochondria at MAM sites has been observed in human patients diagnosed with familial AD (FAD) by increase of the contact sites. These individuals showed mutations in the PS1, PS2 and APP proteins at the MAM sites. This increased connectivity also caused an abnormality in Ca+2 signaling between neurons. Also with regard to the role in MAMs in phospholipid metabolism, patients diagnosed with AD have been reported to show alterations in levels of Phosphatedylserine and phostphatedylethanolamine in the ER and mitochondria respectively, this leads to the intracellular tangles containing hyperphosphorylated forms of the microtubule‐associated protein tau within tissues.\n\nOne of the causes of Parkinson’s disease is mutations in genes encoding for different proteins that are localized at the MAM sites. Mutations in the genes that encode the proteins Parkin, PINK1, alpha-Synuclein (α-Syn) or the protein deglycase DJ-1 have been linked to this disease through research. However, further research is still being considered in order to determine the direct correlations of these genes to Parkinson’s disease. In normal conditions, these genes are believed to be responsible for the cells ability to degrade mitochondria that has been rendered nonfunctional in a process known as mitophagy. However, mutations in the Parkin and pink1 genes have been associated with the cells becoming incapable of degrading faulty mitochondria. The proteins alpha-Synuclein (α-Syn) and DJ-1 have been shown to promote MAM function interaction between the ER and the mitochondria. The wild-type gene that codes for α-Syn promotes the physical junction between ER and mitochondria by binding to the lipid raft regions of the MAM. However, the mutant form of this gene has a low affinity to the lipid raft regions, thereby diminishing the contact between the ER and mitochondria and causing accumulation of α-Syn in Lewy bodies which is a major characteristic of PD. Further research on PD association with alterations in MAM is still being developed.\n\n", "id": "52832272", "title": "Mitochondria associated membranes (MAM)"}
{"url": "https://en.wikipedia.org/wiki?curid=31001884", "text": "Transcription activator-like effector nuclease\n\nTranscription activator-like effector nucleases (TALEN) are restriction enzymes that can be engineered to cut specific sequences of DNA. They are made by fusing a TAL effector DNA-binding domain to a DNA cleavage domain (a nuclease which cuts DNA strands). Transcription activator-like effectors (TALEs) can be engineered to bind to practically any desired DNA sequence, so when combined with a nuclease, DNA can be cut at specific locations. The restriction enzymes can be introduced into cells, for use in gene editing or for genome editing \"in situ\", a technique known as genome editing with engineered nucleases. Alongside zinc finger nucleases and CRISPR/Cas9, TALEN is a prominent tool in the field of genome editing.\n\nTAL effectors are proteins that are secreted by \"Xanthomonas\" bacteria via their type III secretion system when they infect plants. The DNA binding domain contains a repeated highly conserved 33–34 amino acid sequence with divergent 12th and 13th amino acids. These two positions, referred to as the Repeat Variable Diresidue (RVD), are highly variable and show a strong correlation with specific nucleotide recognition. This straightforward relationship between amino acid sequence and DNA recognition has allowed for the engineering of specific DNA-binding domains by selecting a combination of repeat segments containing the appropriate RVDs. Notably, slight changes in the RVD and the incorporation of \"nonconventional\" RVD sequences can improve targeting specificity.\n\nThe non-specific DNA cleavage domain from the end of the FokI endonuclease can be used to construct hybrid nucleases that are active in a yeast assay. These reagents are also active in plant cells and in animal cells. Initial TALEN studies used the wild-type FokI cleavage domain, but some subsequent TALEN studies also used FokI cleavage domain variants with mutations designed to improve cleavage specificity and cleavage activity. The FokI domain functions as a dimer, requiring two constructs with unique DNA binding domains for sites in the target genome with proper orientation and spacing. Both the number of amino acid residues between the TALE DNA binding domain and the FokI cleavage domain and the number of bases between the two individual TALEN binding sites appear to be important parameters for achieving high levels of activity.\n\nThe simple relationship between amino acid sequence and DNA recognition of the TALE binding domain allows for the efficient engineering of proteins. In this case, artificial gene synthesis is problematic because of improper annealing of the repetitive sequence found in the TALE binding domain. One solution to this is to use a publicly available software program (DNAWorks) to calculate oligonucleotides suitable for assembly in a two step PCR oligonucleotide assembly followed by whole gene amplification. A number of modular assembly schemes for generating engineered TALE constructs have also been reported. Both methods offer a systematic approach to engineering DNA binding domains that is conceptually similar to the modular assembly method for generating zinc finger DNA recognition domains.\n\nOnce the TALEN constructs have been assembled, they are inserted into plasmids; the target cells are then transfected with the plasmids, and the gene products are expressed and enter the nucleus to access the genome. Alternatively, TALEN constructs can be delivered to the cells as mRNAs, which removes the possibility of genomic integration of the TALEN-expressing protein. Using an mRNA vector can also dramatically increase the level of homology directed repair (HDR) and the success of introgression during gene editing.\n\nTALEN can be used to edit genomes by inducing double-strand breaks (DSB), which cells respond to with repair mechanisms.\n\nNon-homologous end joining (NHEJ) directly ligates DNA from either side of a double-strand break where there is very little or no sequence overlap for annealing. This repair mechanism induces errors in the genome via indels (insertion or deletion), or chromosomal rearrangement; any such errors may render the gene products coded at that location non-functional. Because this activity can vary depending on the species, cell type, target gene, and nuclease used, it should be monitored when designing new systems. A simple heteroduplex cleavage assay can be run which detects any difference between two alleles amplified by PCR. Cleavage products can be visualized on simple agarose gels or slab gel systems.\n\nAlternatively, DNA can be introduced into a genome through NHEJ in the presence of exogenous double-stranded DNA fragments.\n\nHomology directed repair can also introduce foreign DNA at the DSB as the transfected double-stranded sequences are used as templates for the repair enzymes.\n\nTALEN has been used to efficiently modify plant genomes, creating economically important food crops with favorable nutritional qualities. They have also been harnessed to develop tools for the production of biofuels. In addition, it has been used to engineer stably modified human embryonic stem cell and induced pluripotent stem cell (IPSCs) clones and human erythroid cell lines, to generate knockout \"C. elegans\", knockout rats, knockout mice, and knockout zebrafish. Moreover, the method can be used to generate knockin organisms. Wu et al.obtained a Sp110 knockin cattle using Talen nickases to induce increased resistance of tuberculosis. This approach has also been used to generate knockin rats by TALEN mRNA microinjection in one-cell embryos.\n\nTALEN has also been utilized experimentally to correct the genetic errors that underlie disease. For example, it has been used \"in vitro\" to correct the genetic defects that cause disorders such as sickle cell disease, xeroderma pigmentosum, and epidermolysis bullosa. Recently, it was shown that TALEN can be used as tools to harness the immune system to fight cancers; TALEN-mediated targeting can generate T cells that are resistant to chemotherapeutic drugs and show anti-tumor activity.\n\nIn theory, the genome-wide specificity of engineered TALEN fusions allows for correction of errors at individual genetic loci via homology-directed repair from a correct exogenous template. In reality, however, the \"in situ\" application of TALEN is currently limited by the lack of an efficient delivery mechanism, unknown immunogenic factors, and uncertainty in the specificity of TALEN binding.\n\nAnother emerging application of TALEN is its ability to combine with other genome engineering tools, such as meganucleases. The DNA binding region of a TAL effector can be combined with the cleavage domain of a meganuclease to create a hybrid architecture combining the ease of engineering and highly specific DNA binding activity of a TAL effector with the low site frequency and specificity of a meganuclease.\n\nIn comparison to other genome editing techniques TALEN falls in the middle in terms of difficulty and cost. Unlike ZFNs, TALEN recognizes single nucleotides. It's far more straightforward to engineer interactions between TALEN DNA binding domains and their target nucleotides than it is to create interactions with ZNFs and their target nucleotide triplets. On the other hand, CRISPR relies on ribonucleotide complex formation instead of protein/DNA recognition. gRNAs can target nearly any sequence in the genome and they can be cheaply produced, thus making CRISPR more efficient and less expensive than both TALEN and ZFN. TALEN is ultimately 200 times more expensive than CRISPR and takes several months more to perform.\n\nThe off-target activity of an active nuclease may lead to unwanted double-strand breaks and may consequently yield chromosomal rearrangements and/or cell death. Studies have been carried out to compare the relative nuclease-associated toxicity of available technologies. Based on these studies and the maximal theoretical distance between DNA binding and nuclease activity, TALEN constructs are believed to have the greatest precision of the currently available technologies.\n\n\n", "id": "31001884", "title": "Transcription activator-like effector nuclease"}
{"url": "https://en.wikipedia.org/wiki?curid=6476735", "text": "Zinc finger nuclease\n\nZinc-finger nucleases (ZFNs) are artificial restriction enzymes generated by fusing a zinc finger DNA-binding domain to a DNA-cleavage domain. Zinc finger domains can be engineered to target specific desired DNA sequences and this enables zinc-finger nucleases to target unique sequences within complex genomes. By taking advantage of endogenous DNA repair machinery, these reagents can be used to precisely alter the genomes of higher organisms. Alongside CRISPR/Cas9 and TALEN, ZFN is a prominent tool in the field of genome editing.\n\nThe DNA-binding domains of individual ZFNs typically contain between three and six individual zinc finger repeats and can each recognize between 9 and 18 basepairs. If the zinc finger domains perfectly recognize a 3 basepair DNA sequence to generate a 3-finger array that can recognize a 9 basepair target site. Other procedures can utilize either 1-finger or 2-finger modules to generate zinc-finger arrays with six or more individual zinc fingers. The main drawback with this procedure is the specificities of individual zinc fingers can overlap and can depend on the context of the surrounding zinc fingers and DNA. Without methods to account for this \"context dependence\", the standard modular assembly procedure often fails unless it is used to recognize sequences of the form (GNN).\n\nNumerous selection methods have been used to generate zinc-finger arrays capable of targeting desired sequences. Initial selection efforts utilized phage display to select proteins that bound a given DNA target from a large pool of partially randomized zinc-finger arrays. More recent efforts have utilized yeast one-hybrid systems, bacterial one-hybrid and two-hybrid systems, and mammalian cells. A promising new method to select novel zinc-finger arrays utilizes a bacterial two-hybrid system and has been dubbed \"OPEN\" by its creators. This system combines pre-selected pools of individual zinc fingers that were each selected to bind a given triplet and then utilizes a second round of selection to obtain 3-finger arrays capable of binding a desired 9-bp sequence. This system was developed by the Zinc-Finger Consortium as an alternative to commercial sources of engineered zinc-finger arrays.\n\nThe non-specific cleavage domain from the type IIs restriction endonuclease FokI is typically used as the cleavage domain in ZFNs. \nThis cleavage domain must dimerize in order to cleave DNA \nand thus a pair of ZFNs are required to target non-palindromic DNA sites. Standard ZFNs fuse the cleavage domain to the C-terminus of each zinc finger domain. To let the two cleavage domains dimerize and cleave DNA, the two individual ZFNs must bind opposite strands of DNA with their C-termini a certain distance apart. The most commonly used linker sequences between the zinc finger domain and the cleavage domain requires the 5' edge of each binding site to be separated by 5 to 7 bp.\n\nSeveral different protein engineering techniques have been employed to improve both the activity and specificity of the nuclease domain used in ZFNs. Directed evolution has been employed to generate a FokI variant with enhanced cleavage activity that the authors dubbed \"Sharkey\". Structure-based design has also been employed to improve the cleavage specificity of FokI by modifying the dimerization interface so that only the intended heterodimeric species are active.\n\nZinc finger nucleases are useful to manipulate the genomes of many plants and animals including arabidopsis, tobacco, soybean, corn, \"Drosophila melanogaster\", \"C. elegans\", \"Platynereis dumerilii\", sea urchin, \nsilkworm, \nzebrafish, frogs, mice, rats, rabbits, pigs, cattle, and \nvarious types of mammalian cells. Zinc finger nucleases have also been used in a mouse model of haemophilia and a clinical trial found CD4+ human T-cells with the CCR5 gene disrupted by zinc finger nucleases to be safe as a potential treatment for HIV/AIDS. ZFNs are also used to create a new generation of genetic disease models called isogenic human disease models.\n\nZFNs can be used to disable dominant mutations in heterozygous individuals by producing double-strand breaks (DSBs) in the DNA (see Genetic recombination) in the mutant allele, which will, in the absence of a homologous template, be repaired by non-homologous end-joining (NHEJ). NHEJ repairs DSBs by joining the two ends together and usually produces no mutations, provided that the cut is clean and uncomplicated. In some instances, however, the repair is imperfect, resulting in deletion or insertion of base-pairs, producing frame-shift and preventing the production of the harmful protein. Multiple pairs of ZFNs can also be used to completely remove entire large segments of genomic sequence.\nTo monitor the editing activity, a PCR of the target area amplifies both alleles and, if one contains an insertion, deletion, or mutation, it results in a heteroduplex single-strand bubble that cleavage assays can easily detect.\nZFNs have also been used to modify disease-causing alleles in triplet repeat disorders. Expanded CAG/CTG repeat tracts are the genetic basis for more than a dozen inherited neurological disorders including Huntington’s disease, myotonic dystrophy, and several spinocerebellar ataxias. It has been demonstrated in human cells that ZFNs can direct double-strand breaks (DSBs) to CAG repeats and shrink the repeat from long pathological lengths to short, less toxic lengths.\n\nRecently, a group of researchers have successfully applied the ZFN technology to genetically modify the gol pigment gene and the ntl gene in zebrafish embryo. Specific zinc-finger motifs were engineered to recognize distinct DNA sequences. The ZFN-encoding mRNA was injected into one-cell embryos and a high percentage of animals carried the desired mutations and phenotypes. Their research work demonstrated that ZFNs can specifically and efficiently create heritable mutant alleles at loci of interest in the germ line, and ZFN-induced alleles can be propagated in subsequent generations.\n\nSimilar research of using ZFNs to create specific mutations in zebrafish embryo has also been carried out by other research groups. The kdr gene in zebra fish encodes for the vascular endothelial growth factor-2 receptor. Mutagenic lesions at this target site was induced using ZFN technique by a group of researchers in US. They suggested that the ZFN technique allows straightforward generation of a targeted allelic series of mutants; it does not rely on the existence of species-specific embryonic stem cell lines and is applicable to other vertebrates, especially those whose embryos are easily available; finally, it is also feasible to achieve targeted knock-ins in zebrafish, therefore it is possible to create human disease models that are heretofore inaccessible.\n\nZFNs are also used to rewrite the sequence of an allele by invoking the homologous recombination (HR) machinery to repair the DSB using the supplied DNA fragment as a template. The HR machinery searches for homology between the damaged chromosome and the extra-chromosomal fragment and copies the sequence of the fragment between the two broken ends of the chromosome, regardless of whether the fragment contains the original sequence. If the subject is homozygous for the target allele, the efficiency of the technique is reduced since the undamaged copy of the allele may be used as a template for repair instead of the supplied fragment.\n\nThe success of gene therapy depends on the efficient insertion of therapeutic genes at the appropriate chromosomal target sites within the human genome, without causing cell injury, oncogenic mutations or an immune response. The construction of plasmid vectors is simple and straightforward. Custom-designed ZFNs that combine the non-specific cleavage domain (N) of \"Fok\"I endonuclease with zinc-finger proteins (ZFPs) offer a general way to deliver a site-specific DSB to the genome, and stimulate local homologous recombination by several orders of magnitude. This makes targeted gene correction or genome editing a viable option in human cells. Since ZFN-encoding plasmids could be used to transiently express ZFNs to target a DSB to a specific gene locus in human cells, they offer an excellent way for targeted delivery of the therapeutic genes to a pre-selected chromosomal site. The ZFN-encoding plasmid-based approach has the potential to circumvent all the problems associated with the viral delivery of therapeutic genes. The first therapeutic applications of ZFNs are likely to involve \"ex vivo\" therapy using a patients own stem cells. After editing the stem cell genome, the cells could be expanded in culture and reinserted into the patient to produce differentiated cells with corrected functions. Initial targets likely include the causes of monogenic diseases, such as the IL2Rγ gene and the b-globin gene for gene correction and CCR5 gene for mutagenesis and disablement.\n\nIf the zinc finger domains are not specific enough for their target site or they do not target a unique site within the genome of interest, off-target cleavage may occur. Such off-target cleavage may lead to the production of enough double-strand breaks to overwhelm the repair machinery and, as a consequence, yield chromosomal rearrangements and/or cell death. Off-target cleavage events may also promote random integration of donor DNA.\nTwo separate methods have been demonstrated to decrease off-target cleavage for 3-finger ZFNs that target two adjacent 9-basepair sites.\nOther groups use ZFNs with 4, 5 or 6 zinc fingers that target longer and presumably rarer sites and such ZFNs could theoretically yield less off-target activity. A comparison of a pair of 3-finger ZFNs and a pair of 4-finger ZFNs detected off-target cleavage in human cells at 31 loci for the 3-finger ZFNs and at 9 loci for the 4-finger ZFNs. Whole genome sequencing of \"C. elegans\" modified with a pair of 5-finger ZFNs found only the intended modification and a deletion at a site \"unrelated to the ZFN site\" indicating this pair of ZFNs was capable of targeting a unique site in the \"C. elegans\" genome.\n\nAs with many foreign proteins inserted into the human body, there is a risk of an immunological response against the therapeutic agent and the cells in which it is active. Since the protein must be expressed only transiently, however, the time over which a response may develop is short.\nLiu et al. respectively target ZFNickases to the endogenous b-casein(CSN2) locus stimulates lysostaphin and human lysozyme gene addition by homology-directed repair and derive secrete lysostaphin cows.\n\nThe ability to precisely manipulate the genomes of plants, animals and insects has numerous applications in basic research, agriculture, and human therapeutics. Using ZFNs to modify endogenous genes has traditionally been a difficult task due mainly to the challenge of generating zinc finger domains that target the desired sequence with sufficient specificity. Improved methods of engineering zinc finger domains and the availability of ZFNs from a commercial supplier now put this technology in the hands of increasing numbers of researchers. Several groups are also developing other types of engineered nucleases including engineered homing endonucleases\nTAL effector nucleases (TALENs) are particularly interesting because TAL effectors appear to be very simple to engineer\n\nand TALENs can be used to target endogenous loci in human cells. But to date no one has reported the isolation of clonal cell lines or transgenic organisms using such reagents. One type of ZFN, known as SB-728-T, has been tested for potential application in the treatment of HIV.\n\nZinc-finger nickases (ZFNickases) are created by inactivating the catalytic activity of one ZFN monomer in the ZFN dimer required for double-strand cleavage. ZFNickases demonstrate strand-specific nicking activity \"in vitro\" and thus provide for highly specific single-strand breaks in DNA. These SSBs undergo the same cellular mechanisms for DNA that ZFNs exploit, but they show a significantly reduced frequency of mutagenic NHEJ repairs at their target nicking site. This reduction provides a bias for HR-mediated gene modifications. ZFNickases can induce targeted HR in cultured human and livestock cells, although at lower levels than corresponding ZFNs from which they were derived because nicks can be repaired without genetic alteration. A major limitation of ZFN-mediated gene modifications is the competition between NHEJ and HR repair pathways. Regardless of the presence of a DNA donor construct, both repair mechanisms can be activated following DSBs induced by ZFNs. Thus, ZFNickases is the first plausible attempt at engineering a method to favor the HR method of DNA repair as opposed to the error-prone NHEJ repair. By reducing NHEJ repairs, ZFNickases can thereby reduce the spectrum of unwanted off-target alterations. The ease by which ZFNickases can be derive from ZFNs provides a great platform for further studies regarding the optimization of ZFNickases and possibly increasing their levels of targeted HR while still maintain their reduced NHEJ frequency.\n\nSince antiretroviral therapy requires a lifelong treatment regimen, research to find more permanent cures for HIV infection is currently underway. It is possible to synthesize zinc finger nucleotides with zinc finger components that selectively (almost selectively) bind to specific portions of DNA. Conceptually, targeting and editing could focus on host cellular co-receptors for HIV or on proviral HIV DNA.\n\nIt has also been observed that 20% of the Caucasian population possess a mutation, called CCR5-Δ32 (frequency of 0.0808 for homozygous allele), that prevents the CCR5 chemokine receptor protein, which is the main means of viral access into the cell, from being expressed on the surface of their CD4 T-cells. Individuals who are homozygous for this mutation are immune to HIV strains that use the CCR5 receptor to access the cell, while those that are heterozygous for this mutation have been found to reduce plasma viral load and delay progression of AIDS. By combining these facts, researchers have proposed a novel method of treatment for HIV. This method attempts to treat the infection by disrupting the CCR5 gene, such as introducing the CCR5-Δ32 mutation using a recombinant adenoviral vector or forcing DNA repair by nonhomologous end joining, which is prone to error and results in a non-functional gene. As a consequence, resulting in the expression of nonfunctional CCR5 co-receptors on CD4 T cells, providing immunity against infection.\n\nThe zinc finger nucleases that have been synthesized for this treatment are manufactured by combining FokI Type II restriction endonucleases with engineered zinc fingers. The number of zinc fingers attached to the endonuclease controls the specificity of the ZFN since they are engineered to preferentially bind to specific base sequences in DNA. Each ZFN is made up of multiple zinc fingers and one nuclease enzyme.\n\nA recent and unique application of ZFN-technology to treat HIV has emerged whose focus is to target not the host genome, but rather proviral HIV DNA, for mutagenesis. The authors of this work have drawn their inspiration from the innate defense mechanism against bacteria-infecting-viruses called bacteriophages, present amongst those bacteria endowed with restriction modification (R-M) systems. These bacteria secrete a restriction enzyme (REase) that recognizes and repetitively cleaves around palindromic sequences within the xenogenic DNAs of the bacteriophages or simply phages, until the same is disabled. Further support for this approach resides in the fact that, the human genome comprises in large part remnants of retroviral genomes that have been inactivated by several mechanisms, some of whose action resembles that of ZFN. It should not be surprising, therefore, that the initial work leading to the application of ZFN technology in this manner revolved around and involved the isolation and testing of HIV/SIV targeting bacteria-derived REases, whose non-specificity (due to their short recognition sequences) unfortunately, rendered them toxic to the host genome. The latter-potential host-genome toxicity posed by the raw bacteria-derived REases limited their application to \"ex-vivo\" modalities for HIV prevention, namely synthetic or live microbicides. Subsequently, however, the unique specificity offered by ZFNs was quickly recognized and harnessed, paving way for a novel strategy for attacking HIV \"in-vivo\" (through target mutagenesis of proviral HIV DNA) that is similar to the manner by which bacteria equipped with R-M systems do, to disable the foreign DNAs of in-coming phage-genomes. Because latent proviral HIV DNA resident in resting memory CD4 cells forms the major barrier to the eradication of HIV by highly active antiviral therapy (HAART), it is speculated that this approach may offer a 'functional cure\" for HIV. Both \"ex-vivo\" (manipulation of stem or autologous T cell precursors) and \"in-vivo\" delivery platforms are being explored. It is also hoped that, when applied to non-HIV infected persons, this strategy could offer a genomic vaccine against HIV and other viruses. Similar work is ongoing for high-risk HPVs (with the intent of reversing cervical neoplasia) as well as with HSV-2 (with the goal of achieving a complete cure for genital herpes) \n\nThe FokI catalytic domain must dimerize to cleave the DNA at the targeted site, and requires there to be two adjacent zinc finger nucleases (see picture), which independently bind to a specific codon at the correct orientation and spacing. As a result, the two binding events from the two zinc finger nuclease enables specific DNA targeting. Specificity of genome editing is important for the zinc finger nuclease to be a successful application. The consequence of off-targeting cleavage can lead to a decrease in efficiency of the on-target modification in addition to other unwanted changes.\n\nThe exact constitution of the ZFNs that are to be used to treat HIV is still unknown. The binding of ZFNs for the alteration of the Zif268 genelink, however, has been well-studied and is outlined below to illustrate the mechanism by which the zinc finger domain of ZFNs bind to DNA.\n\nThe amino terminus of the alpha helix portion of zinc fingers targets the major grooves of the DNA helix and binds near the CCR5 gene positioning FokI in a suitable location for DNA cleavage.\n\nZinc fingers are repeated structural protein motifs with DNA recognition function that fit in the major grooves of DNA. Three zinc fingers are positioned in a semi-circular or C-shaped arrangement. Each zinc finger is made up of anti-parallel beta sheets and an alpha helix, held together by a zinc ion and hydrophobic residues.\n\nThe zinc atom is constrained in a tetrahedral conformation through the coordination of Cys3, Cys6, His19, and His23 and Zinc – Sulfur bond distance of 2.30 +/- 0.05 Angstroms and Zinc – Nitrogen bond distances of 2.0 +/- 0.05 Angstroms.\n\nEach zinc finger has an arginine (arg) amino acid protruding from the alpha helix, which forms a hydrogen bond with Nitrogen 7 and Oxygen 6 of the guanine (gua) that is located at the 3’ end of the binding site. The arg-gua bond is stabilized by aspartic acid from a 2nd residue, which positions the long chain of arginine through a hydrogen bond salt bridge interaction.\n\nIn residue 3 of the 2nd (i.e., middle) zinc finger, histidine49 forms a hydrogen bond with a co-planar guanine in base pair 6. The stacking of Histidine against Thymine in base pair 5 limits the conformational ability of Histidine49 leading to increased specificity for the histidine-guanine hydrogen bond.\n\nAt the 6th residue, fingers 1 and 3 have arginine donating a pair of charged hydrogen bonds to Nitrogen 7 and Oxygen 6 of guanine at the 5’ end enhancing the site recognition sequence of zinc fingers.\n\nContacts with DNA backbone\n\nThe histidine coordinated to the zinc atom, which is also the seventh residue in the alpha helix of the zinc fingers, coordinates the Zinc ion through its Nε and hydrogen bonds with phosphodiester oxygen through Nδ on the primary DNA strand.\n\nIn addition to histidine, a conserved arginine on the second beta strand of the zinc fingers makes contact with the phosphodiester oxygen on the DNA strand.\n\nAlso serine 75 on the third finger hydrogen bonds to the phosphate between base pairs 7 and 8, as the only backbone contact with the secondary strand of DNA.\n\nIt has been discovered that FokI has no intrinsic specificity in its cleavage of DNA and that the zinc finger recognition domain confers selectivity to zinc finger nucleases.\n\nSpecificity is provided by dimerization, which decreases the probability of off-site cleavage. Each set of zinc fingers is specific to a nucleotide sequence on either side of the targeted gene 5-7 bp separation between nuclease components.\n\nThe dimerization of two ZFNs is required to produce the necessary double-strand break within the CCR5 gene because the interaction between the FokI enzyme and DNA is weak. This break is repaired by the natural repair mechanisms of the cell, specifically non-homologous end joining.\n\nIntroducing genome alterations depends upon either of the two natural repair mechanisms of a cell: non-homologous end joining (NHEJ) and homology-directed repair (HDR). Repair through NHEJ comes about by the ligation of the end of the broken strands and, upon the occurrence of an error, can produce small insertions and deletions. HDR, on the other hand, uses a homologous DNA strand to repair—and gene making use of this repair mechanism and providing the desired nucleotide sequence allows for gene insertion or modification.\n\nIn the absence of a homologous nucleotide base sequence that can be used by a homologous recombination mechanism, the main DSB repair pathway in mammals is through non-homologous end joining (NHEJ). NHEJ, although capable of restoring a damaged gene, is error-prone. DSB are, therefore, introduced into the gene until an error in its repair occurs at which point ZFNs are no longer able to bind and dimerize and the mutation is complete. To accelerate this process, exonucleases can be introduced to digest the ends of the strands generated at DSBs.\n\nIncreasing the number of zinc fingers increases the specificity by increasing the number of base pairs that the ZFN can bind to. However too many zinc fingers can lead to off-target binding and thus offsite cleavage. This is due to an increased likelihood of zinc fingers binding to parts of the genome outside of the gene of interest.\n\nCurrent ZFN treatments focus on the CCR5 gene as no known side effects result from altering CCR5. There are strains of HIV that are able to use CXCR4 to enter the host cell, bypassing CCR5 altogether. The same gene editing technology has been applied to CXCR4 alone and in combination with CCR5 \n\nSeveral issues exist with this experimental treatment. One issue lies in ensuring that the desired repair mechanism is the one that is used to repair the DSB following gene addition. Another issue with the disruption of the CCR5 gene is that CXCR4-specific or dual-tropic strains are still able to access the cell. This method can prevent the progression of HIV infection.\n\nTo employ the ZFNs in clinical settings the following criteria must be met:\n\ni) High specificity of DNA-binding – Correlates with better performance and less toxicity of ZFNs. Engineered ZFNs take into account positional and context-dependent effects of zinc fingers to increase specificity.\n\nii) Enable allosteric activation of FokI once bound to DNA in order for it to produce only the required DSB.\n\niii) To deliver two different zinc finger nuclease subunits and donor DNA to the cell, the vectors that are used need to be improved to decrease the risk of mutagenesis. These include adeno-associated virus vectors, integrase-deficient lentiviral vectors and adenovirus type 5 vectors.\n\niv) Transient expression of ZFNs is preferred over permanent expression of these proteins to avoid ‘off-target’ effects.\n\nv) During gene targeting, genotoxicity associated with high expression of ZFNs might lead to cell apoptosis and thus needs to be thoroughly verified in vitro and in vivo transformation assays.\n\nThe cells in which the mutations are induced ex vivo are filtered out from lymphocytes by apheresis to produce analogous lentiviral engineered CD4 T-cells. These are re-infused into the body as a single dose of 1 X 10 gene modified analogous CD4 T-cells. A viral vector is used to deliver the ZFNs that induce the desired mutation into the cells. Conditions that promote this process are carefully monitored ensuring the production of CCR5 strain HIV-resistant T cells.\n\nThe Berlin Patient\n\nTimothy Ray Brown, who underwent a bone marrow transplant in 2007 to treat leukemia, had HIV simultaneously. Soon after the operation the HIV dropped to undetectable levels. This is a result of the bone marrow donor being homozygous for the CCR5-Δ32 mutation. This new mutation conferred a resistance to HIV in the recipient, eventually leading to an almost complete disappearance of HIV particles in his body. After nearly 2 years without antiretroviral drug therapy, HIV could still not be detected in any of his tissues. Though this method has been effective at reducing the level of infection, the risks associated with bone marrow transplants outweighs its potential value as a treatment for HIV.\n\n\n\n", "id": "6476735", "title": "Zinc finger nuclease"}
{"url": "https://en.wikipedia.org/wiki?curid=52873758", "text": "Polysome Profiling\n\nPolysome profiling is a technique in molecular biology that is used to study the association of mRNAs with ribosomes. It is important to note that this technique is different than ribosome profiling. Both techniques have been reviewed and both are used in analysis of the translatome, but the data they generate are at very different levels of specificity. When employed by experts, the technique is remarkably reproducible: the 3 profiles in the first image are from 3 different experiments.\n\nThe procedure begins by making a cell lysate of the cells of interest. This lysate contains polysomes, monosomes (composed of one ribosome residing on an mRNA), the small (40S in eukaryotes) and large (60S in eukaryotes) ribosomal subunits, \"free\" mRNA and a host of other soluble cellular components.\n\nThe procedure continues by making a continuous sucrose gradient of continuously-variable density in a centrifuge tube. At the concentrations used (15-45% in the example), sucrose does not disrupt the association of ribosomes and mRNA. The 15% portion of the gradient is at the top of the tube, while the 45% portion is at the bottom because of their different density.\n\nA specific amount (as measured by optical density) of the lysate is then layered gently on top of the gradient in the tube. The lysate, even though it contains a large amount of soluble material, is much less dense than 15% sucrose, and so it can be kept as a separate layer at the top of the tube if this is done gently.\n\nIn order to separate the components of the lysate, the preparation is subjected to centrifugation. This accelerates the components of the lysate with many times the force of gravity and thus propels them through the gradient based upon how \"big\" the individual components are. The small (40S) subunits travel less far into the gradient than the large (60S) subunits. The 80S ribsomes on an mRNA travel further (note that the contribution of the size of the mRNA to the distance traveled is not significant). Polysomes composed of 2 ribosomes travel further, polysomes with 3 ribsomes travel further still, and on and on. The \"size\" of the components is designated by S, the svedberg unit. Note that one S = 10 seconds, and that the concept of \"big\" is actually an oversimplification.\n\nAfter centrifugation, the contents of the tube are collected as fractions from the top (smaller, slower traveling) to bottom (bigger, faster traveling) and the optical density of the fractions is determined. The first fractions removed have a large amount of relatively small molecules, such as tRNAs, individual proteins, etc.\n\nIt is possible to use this technique to study the overall degree of translation in cells (for examples), but it can be used much more specifically to study individual proteins and their mRNAs. As an example shown in the lower portion of the figure, a protein that composes part of the small subunit can first be detected in the 40S fraction, then nearly disappears from the 60S fraction (the separations on these gradients are not absolute), then reappears in the 80S and polysome fractions. This indicates that there is at most very little of the protein found in the cell that is not part of the small subunit. In contrast, in the upper row of the immunoblot figure, a soluble protein appears in the soluble fractions and associated with ribosomes and polysomes. The particular protein is a chaperone protein, which (in brief) helps to fold the nascent peptide as it is being extruded from the ribosome. As other work in the paper showed, there is a direct association of the chaperone with the ribosome.\n\nThe technique can also be used to study the degree of translation of a particular mRNA In these experiments, 5' and 3' sequences of an mRNA were investigated for their effects on amount of mRNA produced and how well the mRNAs were translated. As shown, not all mRNA isoforms are translated with the same efficiency \"even though\" their coding sequences are the same.\n", "id": "52873758", "title": "Polysome Profiling"}
{"url": "https://en.wikipedia.org/wiki?curid=51039804", "text": "Mycofactocin\n\nMycofactocin is a ribosomally synthesized and post-translationally modified peptide, or RiPP. It was discovered in a bioinformatics study in 2011. The name \"mycofactocin\" is derived from three words, the genus name \"Mycobacterium\" (across which it is nearly universal), \"cofactor\" because its presence in a genome predicts the co-occurrence of certain families of enzymes as if it is a cofactor they require, and \"bacteriocin\" because a radical SAM enzyme critical to its biosynthesis, MftC, is closely related to the key enzyme for the biosynthesis of subtilosin A, a bacteriocin, from its precursor peptide. Mycofactocin is thought to play a role in redox pathways involving nicotinoproteins, enzymes with non-exchangeable bound nicotinamide adenine dinucleotide (NAD). This notion comes largely from comparative genomics work that highlighted the many parallels between mycofactocin and pyrroloquinoline quinone (PQQ). In both cases, maturation of the RiPP requires post-translational modification of a precursor peptide by a radical SAM enzyme, the system appears in very similar form in large numbers of species, the product appears to be used within the cell rather than exported, and several families of enzymes occur exclusively in bacteria with those systems. The number of putatively mycofactocin-dependent oxidoreductases encoded by a single genome can be quite large: at least 19 for \"Rhodococcus jostii\" RHA1, and 26 for the short chain dehydrogenase/reductase (SDR) family alone in \"Mycobacterium avium.\"\n\nThe mycofactocin biosynthesis pathway is one of the most abundant of any RiPP system in the collection of bacterial genomes sequenced to date. However, its species distribution is heavily skewed towards the Actinobacteria, including Mycobacterium tuberculosis, which is the causative agent of tuberculosis and therefore the number one killer among bacterial pathogens of humans. The system is virtually absent from the normal human microbiome, although common in soil bacteria.\n\nThe biosynthesis of mycofactocin from its precursor peptide MftA begins with decarboxylation of the C-terminal tyrosine residue by the radical SAM enzyme MftC, with help from the precursor-binding protein MftB. Next, the creatininase homolog MftE releases the C-terminal dipeptide, VY* (valine-tyrosine, where * indicates that the tyrosine was previously modified). The biosynthesis may continue with additional modifications to VY* that are not yet characterized; the mature form of mycofactocin is not yet known.\n", "id": "51039804", "title": "Mycofactocin"}
{"url": "https://en.wikipedia.org/wiki?curid=53236762", "text": "Epitranscriptomic sequencing\n\nIn epitranscriptomic sequencing, most methods focus on either (1) enrichment and purification of the modified RNA molecules before running on the RNA sequencer, or (2) improving or modifying bioinformatics analysis pipelines to call the modification peaks. Most methods have been adapted and optimized for mRNA molecules, except for modified bisulfite sequencing for profiling 5-methylcytidine which was optimized for tRNAs and rRNAs.\n\nThere are six major classes of chemical modifications found in RNA molecules: N-methyladenosine, N6,2'-O-dimethyladenosine, 5-methylcytidine, 5-hydroxylmethylcytidine, inosine, and pseudouridine. Various sequencing methods have been developed to profile each type of modification. The scale, resolution, sensitivity, and limitations associated with each method and the corresponding bioinformatics tools used will be discussed.\n\nMethylation of adenosine does not affect its ability to base-pair with thymidine or uracil, so N-methyladenosine (mA) cannot be detected using standard sequencing or hybridization methods. This modification is marked by the methylation of the adenosine base at the nitrogen-6 position. It is abundantly found in polyA+ mRNA; also found in tRNA, rRNA, snRNA, and long ncRNA.\n\nIn 2012, the first two methods for m6A sequencing came out that enabled transcriptome-wide profile of m6A in mammalian cells. These two techniques, called m6A-seq and MeRIP-seq (m6A-specific methylated RNA immunoprecipitation), are also the first methods to allow for any type of RNA modification sequencing. These methods were able to detect 10,000 m6A peaks in the mammalian transcriptome; the peaks were found to be enriched in 3’UTR regions, near STOP codons, and within long exons.\n\nThe two methods were optimized to detect methylation peaks in poly(A)+ mRNA, but the protocol could be adapted to profile any type of RNA. Collected RNA sample is fragmented into ~100-nucleotide-long oligonucleotides using a fragmentation buffer, immunoprecipitation with purified anti-m6A antibody, elution and collection of antibody-tagged RNA molecules. The immunoprecipitation procedure in MeRIP-Seq is able to produce >130fold enrichment of m6A sequences. Random primed cDNA library generation was performed, followed by adaptor ligation and Illumina sequencing. Since the RNA strands are randomly chopped up, the m6A site should, in principle, lie somewhere in the center of the regions to which sequence reads align. At extremes, the region would be roughly 200nt wide (100nt up- and downstream of the m6A site).\n\nWhen the first nucleotide of a transcript is an adenosine, in addition to the ribose 2’-O-methylation, this base can be further methylated at the N6 position.\nm6A-seq was confirmed to be able to detect m6Am peaks at transcription start sites. Adapter ligation at both ends of RNA fragment results in reads tending to pileup at the 5’ terminus of the transcript. Schwartz et al. (2015) leveraged this knowledge to detect mTSS sites by picking out sites with a high ratio of the size of pileups in the IP samples compared to input sample. As confirmation, >80% of the highly enriched pileup sites contained adenosine.\n\nThe resolution of these methods is 100-200nt, which was the range of the fragment size. \nThese two methods had several drawbacks: (1) required substantial input material, (2) low resolution which made pinpointing the actual site with the m6A mark difficult, and (3) cannot directly assess false positives.\n\nEspecially in MeRIP-Seq, the bioinformatics tools that are currently available are only able to call 1 site per ~100-200nt wide peak, so a substantial portion of clustered m6As (~64nt between each individual site within a cluster) are missed. Each cluster can contain up to 15 m6A residues.\n\nIn 2013, a modified version of m6A-seq based on the previous two methods m6A-seq and MeRIP-seq came out which aimed to increase resolution, and demonstrated this in the yeast transcriptome. They achieved this by decreasing fragment size and employing a ligation-based strand-specific library preparation protocol capturing both ends of the fragmented RNA, ensuring that the methylated position is within the sequenced fragment. By additionally referencing the m6A consensus motif and eliminating false positive m6A peaks using negative control samples, the m6A profiling in yeast was able to be done at single-base resolution.\n\nUV-induced RNA-antibody crosslinking was added on top of m6A-seq to produce PA-m6A-seq (photo-crosslinking-assisted m6A-seq) which increases resolution up to ~23nt. First, 4-thiourodine (4SU) is incorporated into the RNA by adding 4SU in growth media, some incorporation sites presumably near m6A location. Immunoprecipitation is then performed on full-length RNA using m6A-specific antibody [36]. UV light at 365 nm is then shined onto RNA to activate the crosslinking to the antibody with 4SU. Crosslinked RNA was isolated via competition elution and fragmented further to ~25-30nt; proteinase K was used to dissociate the covalent bond between crosslinking site and antibody. Peptide fragments that remain after antibody removal from RNA cause the base to be read as a C as opposed to a T during reverse transcription, effectively inducing a point mutation at the 4SU crosslinking site. The short fragments are subjected to library construction and Illumina sequencing, followed by finding the consensus methylation sequence.\nThe presence of the T to C mutation helps increase the signal to noise ratio of methylation site detection as well as providing greater resolution to the methylation sequence.\nOne shortcoming of this method is that m6A sites that did not incorporate 4SU can’t be detected.\nAnother caveat is that position of 4SU incorporation can vary relative to any single m6A residue, so it still remains challenging to precisely locate m6A site using the T to C mutation.\n\nm6A-CLIP (crosslinking immunoprecipitation) and miCLIP (m6A individual-nucleotide-resolution crosslinking and immunoprecipitation) are UV-based sequencing techniques. These two methods activate crosslinking at 254 nm, fragments RNA molecules before immunoprecipitation with antibody, and do not depend on the incorporation of photoactivatable ribonucleosides - the antibody directly crosslinks with a base close (very predictable location) to the m6A site. These UV-based strategies uses antibodies that induces consistent and predictable mutational and truncation patterns in the cDNA strand during reverse-transcription that could be leveraged to more precisely locate the m6A site.\n\nIn m6A-CLIP and miCLIP, RNA is fragmented to ~20-80nt first, then the 254 nm UV-induced covalent RNA/m6A antibody complex was formed in the fragments containing m6A. The antibody was removed with proteinase K before reverse-transcription, library construction and sequencing. Remnants of peptides at the crosslinking site on the RNA after antibody removal, leads to insertions, truncations, and C to T mutations during reverse transcription to cDNA, especially at the +1 position to the m6A site (5’ to the m6A site) in the sequence reads. \nPositive sites seen using m6A-CLIP and miCLIP had high percent of matches with those detected using SCARLET, which has higher local resolution around a specific site, (see below), implicating m6A-CLIP and miCLIP has high spatial resolution and low false discovery rate. \nmiCLIP has been used to detect m6Am by looking at crosslinking-induced truncation sites at the 5’UTR. While both m6A-CLIP and miCLIP reply on UV induced mutations, m6A-CLIP further takes advantage that m6A alone could induce cDNA truncation during reverse transcription (MITS, m6A-induced truncation sites), permitting the single-nucleotide mapping for much more m6A sites. The precise location of tens of thousands of m6A sites in human and mouse mRNAs by m6A-CLIP reveals that m6A is enriched at last exon but not around stop codon.\n\nAlthough m6A sites could be profiled at high resolution using UV-based methods, the stoichiometry of m6A sites - the methylation status or the ratio m6A+ to m6A- for each individual site within a type of RNA - is still unknown. SCARLET (2013) and m6A-LAIC-seq (2016) allows for the quantitation of stoichiometry at a specific locus and transcriptome-wide, respectively.\n\nBioinformatics methods used to analyze m6A peaks do not make any prior assumptions about the sequence motifs within which m6A sites are usually found, and take into consideration all possible motifs. Therefore, it is less likely to miss sites.\n\nSCARLET (site-specific cleavage and radioactive-labeling followed by ligation-assisted extraction and thin-layer chromatography) is used determining the fraction of RNA in a sample that carries a methylated adenine at a specific site. One can start with total RNA without having to enrich for the target RNA molecule. Therefore, it is an especially suitable method for quantifying methylation status in low abundance RNAs such as tRNAs. However, it is not suitable or practical for large-scale location of m6A sites.\n\nThe procedure begins with a chimeric DNA oligonucleotide annealing to the target RNA around the candidate modification site. The chimeric ssDNA has 2’OMe/2’H modifications and is complementary to the target sequence. The chimeric oligonucleotide serves as a guide to allow RNase H to cleave the RNA strand precisely at the 5’-end of the candidate site. The cut site is then radiolabeled with phosphorus-32 and splint-ligated to a 116nt ssDNA oligonucleotide using DNA ligase. RNase T1/A is introduced to the sample to digest all RNA, except for the RNA molecules with the 116-mers DNA attached. This radiolabeled product is then isolated and digested by nuclease to generate a mixture of modified and unmodified adenosines (5’P-m6A and 5’-P-A) which is separated using thin layer chromatography. The relative proportions of the two groups can be determined using UV absorption levels.\n\nm6A-LAIC-seq (m6A-level and isoform-characterization sequencing) is a high-throughput approach to quantify methylation status on a whole-transcriptome scale. Full-length RNA samples are used in this method. RNAs are first subjected to immunoprecipitation with an anti-m6A antibody. Excess antibody is added to the mixture to ensure all m6A-containing RNAs are pulled down. The mixture is separated into eluate (m6A+ RNAs) and supernatant (m6A- RNAs) pools. External RNA Controls Consortium (ERCC) spike ins are added to the eluate and supernatant, as well as an independent control arm consisting of just ERCC spike in. After antibody cleavage in the eluate pool, each of the three mixtures are sequenced on a next generation sequencing platform. The m6A levels per site or gene could be quantified by the ERCC-normalized RNA abundances in different pools. Since full-length RNA is used, it is possible to directly compare alternatively spliced isoforms between the m6A+ and m6A- fractions as well as comparing isoform abundance within the m6A+ portion.\n\nDespite the advances in m6A-sequencing, several challenges still remain: (1) A method has yet to be developed that characterizes the stoichiometry between different sites in the same transcript; (2) Analysis results are heavily dependent on the bioinformatics algorithm used to call the peaks; (3) Current methods all use m6A-specific antibodies to tag m6A sites, but it has been reported that the antibodies contain intrinsic bias for RNA sequences.\n\nN6,2'-O-dimethyladenosine, abundant in polyA+ mRNAs, occurs at the first nucleotide after the 5’ cap, when an additional methyl group is added to a 2ʹ-O-methyladenosine residue at the ‘capped’ 5ʹ end of mRNA.\n\nSince m6Am can be recognized by anti-m6A antibodies at transcription start sites, the methods used for m6A profiling can be and were adapted for m6Am profiling, namely m6A-seq, and miCLIP (see m6A-seq and miCLIP descriptions above).\n\n5-methylcytidine, m5C, is abundantly found in mRNA and ncRNAs, especially tRNA and rRNAs. In tRNAs, this modification stabilizes the secondary structure and influences anticodon stem-loop conformation. In rRNAs, m5C affects translational fidelity.\n\nTwo principles have been used to develop m5C sequencing methods. The first one is antibody-based approach (bisuphite sequencing and m5C-RIP), similar to m6C sequencing. The second is detecting targets of m5C RNA methyltransferases by covalently linking the enzyme to its target, and then using IP specific to the target enzyme to enrich for RNA molecules containing the mark (Aza-IP and miCLIP).\n\nModified bisulfite sequencing was optimized for rRNA, tRNA, and miRNA molecules from Drosophila.\nBisulfite treatment has been most widely used to detect dm5C (DNA m5C). The treatment essentially converts a cytosine to a uridine, but methylated cytosines would be unchanged by the treatment.\nPrevious attempts to develop m5C sequencing protocols using bisulfite treatment were not able to effectively address the problem of the harsh treatment of RNA which causes significant degradation of the molecules. Specifically, bisulfite deamination treatment (high pH) of RNA is detrimental to the stability of phosphodiester bonds. As a result, it is difficult to pre-enrich RNA molecules or to obtain enough PCR product of the correct size for deep sequencing.\n\nA modified version of bisulfite sequencing was developed by Schaefer et al. (2009) which decreased the temperature at which bisulfite treatment of RNA from 95 °C to 60 °C. The rationale behind the modification was that since RNA, unlike DNA, is not double-stranded, but rather, consists of regions of single-strandedness, double-stranded stem structures and loops, it could be possible to unwind RNA at a much lower temperature. Indeed, RNA could be treated for 180 minutes at 60C without significant loss of PCR amplicons of the expected size. Deamination rates were determined to be 99% at 180min of treatment.\n\nAfter bisulfite treatment of fragmented RNA, reverse transcription is performed, followed by PCR amplification of the cDNA products, and finally deep sequencing was done using the Roche 454 platform.\n\nSince the developers of the method used the Roche platform, they also used GS Amplicon Variant Analyzer (Roche) for analyzing deep sequencing data to quantify sequence-specific cytosine content.\nHowever, recent papers have suggested that the method have several flaws: (1) Incomplete conversion of regular cytosines in double-stranded regions of RNA; (2) areas containing other modifications that resulted in bisulfite-treatment resistance; and (3) sites containing potential false-positives due to (1) and (2) In addition, it is possible the sequencing depth is still not high enough to correctly detect all methylated sites.\n\nAza-IP 5-azacytidine-mediated RNA immunoprecipitation has been optimized on and used for detecting targets of methyltransferases, particularly NSUN2 and DNMT2 — the two main enzymes responsible for laying down the m5C mark.\n\nFirst, the cell is made to overexpress an epitope-tagged m5C-RNA methytransferase derivative so that the antibody used later on for immunoprecipitation could recognize the enzyme. Second, 5-aza-C is introduced to the cells so that it could be incorporated into nascent RNA in place of cytosine. Normally, the methyltransferases are released (i.e. covalent bond between cytosine and methyltransferase is broken) following methylation of the residue. For 5-aza-C, due to a nitrogen substitution in the C5 position of cytosine, the RNA methytransferase enzyme remains covalently bound to the target RNA molecule at the C6 position.\n\nThird, the cell is lysed and the m5C-RNA methyltransferase of interest is immunoprecipitated along with the RNA molecules that are covalently linked to the protein. The IP step enabled >200-fold enrichment of RNA targets, which were mainly tRNAs. The enriched molecules were then fragmented and purified. cDNA library is then constructed and sequencing is performed.\n\nAn important additional feature is that RNA methyltransferase covalent linkage to the C5 of m-aza-C induces rearrangement and ring opening. This ring opening results in preferential pairing with cytosine and is therefore read as guanosine during sequencing. This C to G transversion allows for base resolution detection of m5C sites. \nOne caveat is that m5C sites not replaced by 5-azacytosine will be missed.\n\nmiCLIP (Methylation induced crosslinking immunoprecipitation) was used to detect NSUN2 targets, which were found to be mostly non-coding RNAs such as tRNA. An induced mutation of C271A in NSUN2 inhibits release of enzyme from RNA target. This mutation was over-expressed in the cells of interest, and the mutated NSUN2 was also tagged with the Myc epitope. The covalently linked RNA-protein complexes are isolated via immunoprecipitation for a Myc-specific antibody. These complexes are confirmed and detected by radiolabeling with phosphorus-32. The RNA is then extracted from the complex, reverse-transcribed, amplified with PCR, and sequenced using next-generation platforms.\n\nBoth miCLIP and Aza-IP, though limited by specific targeting of enzymes, can allow for the detection of low-abundance methylated RNA without deep sequencing.\n\nInosine is created enzymatically when an adenosine residue is modified.\n\nSince the chemical makeup of inosine is a deaminated adenosine, this is one of few methylation alterations that has an accompanying alteration in base pairing, which can be capitalised on. The original adenosine nucleotide will pair with a thymine, whereas the methylated inosine will pair with a cytosine. cDNA sequences obtained by rtPCR can therefore be compared to the corresponding genomic sequences; in sites where A residues are repeatedly interpreted as G, a methylation event can be assumed. At high enough accuracy, it is feasible that the quantity of mRNA molecules in the population that have been methylated can be calculated as a percentage. This method potentially has single-nucleotide resolution. In fact, the abundance of RNA-seq data that is now publicly available can be leveraged to investigate G (in cDNA) versus A (in genome). One particular pipeline, called RNA and DNA differences (RDD), claims to excludes false positives, but only 56.8% of its A-to-I sites were found to be valid by ICE-seq(see below).\n\nThe background noise caused by single nucleotide polymorphisms (SNPs), somatic mutations, pseudogenes and sequencing errors reduce the reliability of the signal, especially in a single-cell context.\n\nThe first method to detect A-to-I RNA modifications, developed in 1997, was inosine-specific cleavage. RNA samples are treated with glyoxal and borate to specifically modify all G bases, and subsequently enzymatically digested to by RNase T1, which cleaves after I sites. The amplification of these fragments then allows analysis of cleavage sites and inference of A-to-I modification.\n. It was used to prove the position of inosine at specific sites rather than identify novel sites or transcriptome-wide profiles.\n\nThe existence of two A-to-I modifications in relatively close proximity, which is common in Alu elements, means the downstream mod is less likely to be detected since the cDNA synthesis will be truncated at a prior nucleotide. The throughput is low, and the initial method required specific primers; the protocol is complicated and labour-intensive.\n\nInosine chemical erasing (ICE) refer to a process in which acrylonitrile is reacted with inosine to form N1-cyanoethylinosine (ce1I). This serves to stall reverse transcriptase and lead to truncated cDNA molecules. This was combined with deep-sequencing in a developed method called ICE-seq. Computational methods for automated analysis of the data are available, the main premise being the comparison of treated and untreated samples to identify truncated transcripts and thus infer an inosine modification by read count, with a step to reduce false positives by comparison to online database dbSNP.\n\nThe original ICE protocol involved an RT-PCR amplification step and therefore required primers and knowledge of the location or regions to be investigated, alongside a maximum cDNA length of 300–500bp.\nThe ICE-seq method is complicated, along with being labour-, reagent- and time-intensive. One protocol from 2015 took 22 days. This shares a limitation with inosine-specific cleavage, in that if there are two A-to-I modifications in relatively close proximity, the downstream mod is less likely to be detected since the cDNA synthesis will be truncated at a prior nucleotide.\nBoth ICE and ICE-seq suffer from a lack of sensitivity to infrequently edited locations: it becomes difficult to distinguish a modification with a frequency of <10% from a false positive. An increase in read depth and quality can increase sensitivity, but also then suffer from further amplification bias.\n\nThe modification of A to I is effected by adenosine deaminases that act on RNA (ADARs), of which in mice there are three. The knockdown of these in the cell, therefore, and the subsequent cell–cell comparison of ADAR+ and ADAR- RNA content would be anticipated to provide a basis for A-to-I modification profiling. However, there are further functions of ADAR enzymes within the cell — for example, they have further roles in RNA processing, and in miRNA biogenesis — which would also be likely to change the landscape of cellular mRNA.\n\nThe high instance of side effects rule out ADAR knockdown as a categorical A-to-I detection method. Moreover, since ADAR knockout results in embryonic lethality, its utility is restricted to cultured cells.\n\nPseudouridine, or Ψ, the overall most abundant post-translational RNA modification, is created when a uridine base is isomerised. In eukaryotes, this can occur by either of two distinct mechanisms; it is sometimes referred to as the ‘fifth RNA nucleotide’. It is incorporated into stable non-coding RNAs such as tRNA, rRNA, and snRNA, with roles in ribosomal ligand binding and translational fidelity in tRNA, and in fine-tuning branching events and splicing events in snRNAs. Pseudouridine has one more hydrogen bond donor from an imino group and a more stable C–C bond, since a C-glycosidic linkage has replaced the N-glycosidic linkage found in its counterpart (regular uridine). As neither of these changes affect its base-pairing properties, both will have the same output when directly sequenced; therefore methods for its detection involve prior biochemical modification.\n\nThere are multiple pseudouridine detection methods beginning with the addition of N-cyclohexyl-N′-b-(4-methylmorpholinium) ethylcarbodiimide metho-p-toluene-sulfonate (CMCT; also known as CMC), since its reaction with pseudouridine produces CMC-Ψ. CMC-Ψ causes reverse transcriptase to stall one nucleotide in the 3’ direction. These methods have single-nucleotide resolution.\nIn an optimisation step, azido-CMC can confer the ability to add biotinylation; subsequent biotin pulldown will enrich Ψ-containing transcripts, allowing identification of even low-abundance transcripts.\n\nAs with other procedures predicated on biochemical alteration followed by sequencing, the development of high-throughput sequencing has removed the limitations requiring prior knowledge of sites of interest and primer design. The method causes a lot of RNA degradation, so it is necessary to start with a large amount of sample, or use effective normalisation techniques to account for amplification biases. One final limitation is that, for CMC labelling of pseudouridine to be specific, it is not complete, and therefore nor is it quantitative. A new reactant that could achieve a higher sensitivity with specificity would be beneficial.\n\nCytidine residues, modified once to m5C (discussed above), can be further modified: either oxidised once for 5-hydroxylmethylcytidine (hm5C), or oxidised twice for 5-formylcytidine (f5C). Arising from the oxidative processing of m5C enacted in mammals by ten-eleven translocation (TET) family enzymes, hm5C is known to occur in all three kingdoms and to have roles in regulation. While 5-hydroxymethylcytidine (hm5dC) is known to be found in DNA in a widespread manner, hm5C is also found in organisms for which no hm5dC has been detected, indicating it is a separate process with distinct regulatory stipulations. To observe the \"in vivo\" addition of methyl groups to cytosine RNA residues followed by oxidative processing, mice can be fed on a diet incorporating particular isotopes and these be traced by LC-MS/MS analysis. Since the metabolic pathway from nutritional intake to nucleotide incorporation is known to progress from dietary methionine --> S-adenosylmethionine (SAM) --> methyl group on RNA base, the labelling of dietary methionine with C and D means these will end up in hm5C residues that have been altered since the addition of these into the diet. In contrast to m5C, a large quantity of hm5C modifications have been recorded within coding sequences.\n\nhMeRIP-seq is an immunoprecipitation method, in which RNA–protein complexes are crosslinked for stability, and antibodies specific to hm5C are added. Using this method, over 3,000 hm5C peaks have been called in \"Drosophila melanogaster\" S2 cells.\n\nDespite two distinct base-resolution methods being available for hm5dC, there are no base-resolution methods for detection of hm5C.\n", "id": "53236762", "title": "Epitranscriptomic sequencing"}
{"url": "https://en.wikipedia.org/wiki?curid=53480349", "text": "Genetic Literacy Project\n\nThe stated purpose of the Genetic Literacy Project (GLP) is to promote public awareness and discussion of genetics, biotechnology, evolution and science literacy. It was founded by science journalist Jon Entine, who is its executive director. The staff produces articles focusing on human genetics as well as on food and farming issues, including genetic engineering, the use and impact of crop protection chemicals and pollinator health. It also aggregates articles from various published sources.The GLP staff have been quoted on GMO, Biotechnology, and Eugenics in a number of publications and websites.\n\nThe staff cover topics on genetically modified organisms (GMO) in agriculture and Epigenetics, the expression of genes in humans and animals in the context of their environment (GLP has a companion project, the Epigenetics Literacy Project, launched in 2016). The staff also produces articles on human and animal genetics topics such as gene splicing, CRISPR, government regulation, bioethics, use of stem cells, transhumanism, nanotechnology and synthetic biology. The GLP's articles and staff are quoted and interviewed in a number of publications and websites.\n\nThe GLP is a non-partisan non-profit organization founded in 2011 and funded by donations from non-profit foundations and individual donors. It operated initially as an independent organization within the non-profit Statistical Assessment Service, which was based at George Mason University Virginia, U.S.A. STATS provided accounting services for the GLP before it dissolved in 2015. The GLP became its own 501c3 under the name Science Literacy Project in 2015. The SLP oversees the GLP and the Epigenetics Literacy Project, founded in 2015. It's banner logo says \"Science not Ideology\" in reference to the gulf between scientific consensus and public perception. \"A Pew Research Center poll in January found 88 percent of scientists believed GMOs to be “generally safe” versus 37 percent of U.S. adults. That gap was the widest among 13 questions asked by Pew, surpassing divides on climate change and evolution.\"\n\n2015-2016 Fiscal Year Donations to the Genetic Literacy Project\nJohn Templeton Foundation Epigenetics Literacy Project: $151,985\nSearle Freedom Trust, GLP: $150,000\nWinkler Family Foundation, GENeS Project, $50,000\nAcademics Review Charitable Association, (pass through support for University of California-Davis Biotech Literacy Bootcamp from BIO, UC-Davis and USDA): $5,000\nIndividual donations: $9,647.12 \n\nThe US Right to Know, a group that obtains and publishes source materials and communications, raised concerns after the GLP ran a series of articles in 2014 supportive of crop biotechnology after the scientists had been encouraged to do so by Monsanto. The scientists were not paid for their articles and the GLP had control of the writing and editing process.\nGLP has taken positions against labeling GMO foods. GMO labeling has widespread public support despite the fact that the National Academy of Sciences recently released a report summarizing years of research on genetically engineered crops. The report concluded that there was “no substantiated evidence of a difference in risks to human health between currently commercialized genetically engineered (GE) crops and conventionally bred crops, nor did it find conclusive cause-and-effect evidence of environmental problems from the GE crops.” \n\nFacebook PageNewsletter\n\n", "id": "53480349", "title": "Genetic Literacy Project"}
{"url": "https://en.wikipedia.org/wiki?curid=53493192", "text": "GLAD-PCR assay\n\nGlal hydrolysis and Ligation Adapter Dependent PCR assay (GLAD-PCR assay) is the novel method to determine R(5mC)GY sites produced in the course of \"de novo\" DNA methylation with DNMTЗA and DNMTЗB DNA methyltransferases. GLAD-PCR assay do not require bisulfite treatment of the DNA.\n\nMethod was specially designed to determine methylation of RCGY site of interest in human and mammalian genomes in excess of corresponding unmethylated sites. This is a typical situation for DNA preparations from clinical samples of blood and tissues.\nGLAD-PCR assay is based on the new type of enzymes - site-specific methyl-directed DNA-endonucleases (MD DNA endonucleases). These enzymes are very similar to restriction enzymes in biochemical properties and cleave DNA completely, but act in opposite way: they cleave only methylated DNA and do not cleave unmethylated DNA at all. Mammalian DNA-methyltransferases DNMT1, DNMT3a and DNMT3b catalyze a reaction of DNA methylation.\nIt is well known that hypermethylation of CpG-islands in regulatory regions of promoter and/or first exon in a variety of genes often occurs at early stages of sporadic carcinogenesis. This leads to downregulation of the genes expression in tumor cells, whereas in a healthy tissue the corresponding genes remain to be active. Thus, the detection of such epigenetic biomarkers is one of the most promising diagnostic and prognostic tools\nStudy of DNMT3a and DNMT3b substrate specificity has shown that both enzymes predominantly recognize RCGY site and modify internal CG-dinucleotide to form 5’-R(5mC)GY-3’/3’-YG(5mC) R-5’ sequence. One of new enzymes GlaI recognizes and cleaves site R(5mC)GY. Due to this unique substrate specificity, GlaI is a convenient tool for identification of \"de novo\" methylated sites in the human and mammalian DNA.GLAD-PCR assay includes 3 simple steps: \nAssay is performed in one tube, takes about 2–3 hours and determines even several copies of DNA with R(5mC)GY site of interest.\n", "id": "53493192", "title": "GLAD-PCR assay"}
{"url": "https://en.wikipedia.org/wiki?curid=52953124", "text": "Nucleosome remodeling factor\n\nNucleosome Remodeling Factor (NURF) is an ATP-dependent chromatin remodeling complex first discovered in \"Drosophila melanogaster\" (fruit fly) that catalyzes nucleosome sliding in order to regulate gene transcription. It contains an ISWI ATPase, making it part of the ISWI family of chromatin remodeling complexes. NURF is highly conserved among eukaryotes and is involved in transcriptional regulation of developmental genes.\n\nNURF was first purified from the model organism \"Drosophila melanogaster\" by Toshio Tsukiyama and Carl Wu in 1995. Tsukiyama and Wu described NURF’s chromatin remodeling activity on the hsp70 promoter. It was later discovered that NURF regulates transcription in this manner for hundreds of genes. A human ortholog of NURF, called hNURF, was isolated in 2003.\n\nThe NURF complex in \"Drosophila\" contains four subunits: NURF301, NURF140, NURF55, and NURF38. NURF140 is an ISWI ATPase, distinguishable by its HAND, SANT, and SLIDE domains. The NURF complex in \"Homo sapiens\" has three subunits, BPTF, SNF2L, and pRBAP46/48, homologous to NURF301, NURF140, and NURF55, respectively. There is no human homolog for NURF38.\n\nNURF interacts with chromatin by binding to modified histones or interacting with various transcription factors. NURF catalyzes nucleosome sliding in either direction on DNA without any apparent modifications to the histone octamer itself. NURF is essential for the expression of homeotic genes. The ISWI ATPase specifically recognizes intact N-terminal histone tails. In \"Drosophila\", NURF interacts with the transcription factor GAGA to remodel chromatin at the hsp70 promoter, and null mutations in the Nurf301 subunit prevent larval metamorphosis. Other NURF mutants cause the development of melanotic tumors from larval blood cells. In humans, hNURF is involved in neuronal development and has been shown to enhance neurite outgrowth in vitro.\n", "id": "52953124", "title": "Nucleosome remodeling factor"}
{"url": "https://en.wikipedia.org/wiki?curid=53767303", "text": "Pseudo-response regulator\n\nPseudo-response regulator (PRR) refers to a group of genes that are important in the plant circadian oscillator. There are four primary PRR proteins (PRR9, PRR7, PRR5 and TOC1/PRR1) that perform the majority of interactions with other proteins within the circadian oscillator, and another (PRR3) that has limited function. These genes are all paralogs of each other, and all repress the transcription of Circadian Clock Associated 1 (CCA1) and Late Elongated Hypocotyl (LHY) at various times throughout the day. The expression of PRR9, PRR7, PRR5 and TOC1/PRR1 peak around morning, mid-day, afternoon and evening, respectively. As a group, these genes are one part of the three-part repressilator system that governs the biological clock in plants.\n\nMultiple labs identified the PRR genes as parts of the circadian clock in the 1990s. In 2000, Akinori Matsushika, Seiya Makino, Masaya Kojima, and Takeshi Mizuno were the first to understand PRR genes as pseudo-response repressor genes rather than as response regulator (ARR) genes. The factor that distinguishes PRR from ARR genes is the lack of a phospho-accepting aspartate site that characterizes ARR proteins. Though their research that discovered PRR genes was primarily hailed during the early 2000s as informing the scientific community about the function of TOC1 (named APRR1 by the Mizuno lab), an additional pseudo-response regulator in the \"Arabidopsis thaliana\" biological clock, the information about PRR genes that Matsushika and his team found deepened scientific understanding of circadian clocks in plants and led other researchers to hypothesize about the purpose of the PRR genes. Though current research has identified TOC1, PRR3, PRR5, PRR7, and PRR9 as of importance to the \"A. thaliana\" circadian clock mechanism, Matsushika et al. first categorized PRR genes into two subgroups (APRR1 and APRR2, the A stands for Arabidopsis) due to two differing amino acid structures. The negative feedback loops including \"PRR\" genes, proposed by Mizuno, were incorporated into a complex repressilator circuit by Andrew Millar’s lab in 2012. The conception of the plant biological clock as made up of interacting negative feedback loops is unique in comparison to mammal and fungal circadian clocks which contain autoregulatory negative feedback loops with positive and negative elements (see \"Transcriptional and non-transcriptional control on the Circadian clock page).\n\nPRR3, PRR5, PRR7 and PRR9 participate in the repressilator of a negative autoregulatory feedback loop that synchronizes to environmental inputs. The repressilator has a morning, evening, and night loop that are regulated in part by the pseudo-response regulator proteins' interactions with CCA1 and LHY. CCA1 and LHY exhibit peak binding to PRR9, PRR7, and PRR5 in the morning, evening, and night, respectively.\n\nWhen phosphorylated by an unknown kinase, PRR5 and PRR3 proteins demonstrate increased binding to TIMING OF CAB2 EXPRESSION 1 ( TOC1). This interaction stabilizes both TOC1 and PRR5 and prevents their degradation by the F-box protein ZEITLUPE (ZTL). Through this mechanism, PRR5 is indirectly activated by light, as ZTL is inhibited by light. Additionally, PRR5 contributes to the transcriptional repression of the genes encoding the single MYB transcription factors CCA1 and LHY.\n\nTwo single MYB transcription factors, CCA1 and LHY, activate expression of \"PRR7\" and \"PRR9\". In turn, PRR7 and PRR9 repress \"CCA1\" and \"LHY\" through the binding of their promoters. This interaction forms the morning loop of the repressilator of the biological clock in \"A. thaliana\". Chromatin immunoprecipitation demonstrates that LUX binds to the \"PRR9\" promoter to repress it. Additionally, ELF3 has been shown to activate \"PRR9\" and repress \"CCA1\" and \"LHY\". PRR9 is also activated by alternative RNA splicing. When PRMT5 (a methylation factor) is prevented from methylating intron 2 of PRR9, a frameshift resulting in premature truncation occurs.\n\nPRR7 and PRR9 also play a role in the entrainment of \"A. thaliana\" to a temperature cycle. Double-mutant plants with inactivated \"PRR7\" and \"PRR9\" exhibit extreme period lengthening at high temperatures but show no change in period at low temperatures. However, the inactivation of \"CCA1\" and \"LHY\" in the \"PRR7/PRR9\" loss-of-function mutants shows no change in period at high temperatures—this suggests that \"PRR7\" and \"PRR9\" are acting by overcompensation.\n\nIn \"A. thaliana\", the main feedback loop is proposed to involve a transcriptional regulation between several proteins. The three main components of this loop are TOC1 (also known as PRR1), CCA1 and LHY. Each individual component peaks in transcriptions at different times of day. PRR 9, 7 and 5 each significantly reduce the transcription levels of CCA1 and LHY. In the opposite manner, PRR 9 and 7 slightly increase the transcription levels of TOC1. The Constans (CO) is also indirectly regulated by the PRR proteins as well by setting up the molecular mechanism to dictate the photosensitive period in the afternoon. PRRs are also known to stabilize CO at certain times of day to mediate its accumulation. This results in the regulation of early flowering in shorter photoperiods, making light sensitivity and control of flowering time important functions of the PRR class.\n\nPPR3, PRR5, PRR7, and PRR9 are all paralogs of each other. They have similar structure, and all repress the transcription of CCA1 and LHY. Additionally, they are all characterized by their lack of a phospho-accepting aspartate site. These genes are also paralogs to TOC1, which is alternatively called PRR1.\n\nSeveral pseudo-response regulators have been found in \"Selaginella,\" but their function has not yet been explored.\n\nAs PRR is a family of genes, several rounds mutant screening have been performed to identify each possible phenotype.\n\nIn regards to rhythmicity of the clock in a free running setting PRR9 and PRR5 are associated with longer and shorter periods respectively. For each gene, the double mutant with PRR7 exacerbates observed trends in rhythmicity. The triple mutant renders the plant arrhythmic.\n\nIn terms of flowering time in long day conditions, all mutants made the observed flowering late, with PRR7 significantly more late in comparison to the other mutants. All double mutants with PRR7 saw much later flowering time than the PRR5/PRR9 mutant.\n\nWith regard to light sensitivity, particularly in red light which is associated with hypocotyl lengthening, all PRR mutants were observed to be hypo-sensitive with PRR9 showing to be less sensitive. All the double mutants were equal in hyposensitivity as the PRR5 or PRR7 mutants; the triple mutant is extremely hypo-sensitive.\n\nRecent research has showed that expression of clock genes show tissue-specificity. Learning about how, when, and why specific tissues show certain peaks in clock genes like PRR can reveal more about the subtle nuances of each gene within the repressilator.\n\nFew investigations into the circadian oscillator mechanisms in species other than \"A. thaliana\" have taken place; learning which genes are responsible for clock functions in other species will give more insight into the similarities and differences in clocks across plant species.\n\nThe mechanistic details of each step in the plant biological clock repressilator system have yet to be fully understood. An understanding of these will give knowledge of clock function and, across species, increase understanding of the ecological and evolutionary functions of circadian oscillators.\n\nAdditionally, identifying direct targets of PRR5, PRR7 and PRR9 that are not CCA1 and LHY will provide information about the molecular links from the PRRs to output genes like the flowering pathway and metabolism in mitochondria, which are CCA1-independent.\n\n", "id": "53767303", "title": "Pseudo-response regulator"}
{"url": "https://en.wikipedia.org/wiki?curid=1690338", "text": "Fluorescence in situ hybridization\n\nFluorescent \"in situ\" hybridization (FISH) is a molecular cytogenetic technique that uses fluorescent probes that bind to only those parts of the chromosome with a high degree of sequence complementarity. It was developed by biomedical researchers in the early 1980s and is used to detect and localize the presence or absence of specific DNA sequences on chromosomes. Fluorescence microscopy can be used to find out where the fluorescent probe is bound to the chromosomes. FISH is often used for finding specific features in DNA for use in genetic counseling, medicine, and species identification. FISH can also be used to detect and localize specific RNA targets (mRNA, lncRNA and miRNA) in cells, circulating tumor cells, and tissue samples. In this context, it can help define the spatial-temporal patterns of gene expression within cells and tissues.\n\nRNA probes can be designed for any gene or any sequence within a gene for visualization of mRNA, lncRNA and miRNA in tissues and cells. FISH is used by examining the cellular reproduction cycle, specifically interphase of the nuclei for any chromosomal abnormalities. FISH allows the analysis of a large series of archival cases much easier to identify the pinpointed chromosome by creating a probe with an artificial chromosomal foundation that will attract similar chromosomes. The hybridization signals for each probe when a nucleic abnormality is detected. Each probe for the detection of mRNA and lncRNA is composed of 20 oligonucleotide pairs, each pair covering a space of 40–50 bp. For miRNA detection, the probes use proprietary chemistry for specific detection of miRNA and cover the entire miRNA sequence.\n\nProbes are often derived from fragments of DNA that were isolated, purified, and amplified for use in the Human Genome Project. The size of the human genome is so large, compared to the length that could be sequenced directly, that it was necessary to divide the genome into fragments. (In the eventual analysis, these fragments were put into order by digesting a copy of each fragment into still smaller fragments using sequence-specific endonucleases, measuring the size of each small fragment using size-exclusion chromatography, and using that information to determine where the large fragments overlapped one another.) To preserve the fragments with their individual DNA sequences, the fragments were added into a system of continually replicating bacteria populations. Clonal populations of bacteria, each population maintaining a single artificial chromosome, are stored in various laboratories around the world. The artificial chromosomes (BAC) can be grown, extracted, and labeled, in any lab containing a library. Genomic libraries are often named after the institution in which they were developed. An example being the RPCI-11 library, which is named after the Roswell Park Cancer Institute in Buffalo NY. These fragments are on the order of 100 thousand base-pairs, and are the basis for most FISH probes.\n\nCells, circulating tumor cells (CTCs), or formalin-fixed paraffin-embedded (FFPE) or frozen tissue sections are fixed, then permeabilized to allow target accessibility. FISH has also been successfully done on unfixed cells. A target-specific probe, composed of 20 oligonucleotide pairs, hybridizes to the target RNA(s). Separate but compatible signal amplification systems enable the multiplex assay (up to two targets per assay). Signal amplification is achieved via series of sequential hybridization steps. At the end of the assay the tissue samples are visualized under a fluorescence microscope.\n\nFirst, a probe is constructed. The probe must be large enough to hybridize specifically with its target but not so large as to impede the hybridization process. The probe is tagged directly with fluorophores, with targets for antibodies or with biotin. Tagging can be done in various ways, such as nick translation, or PCR using tagged nucleotides.\n\nThen, an interphase or metaphase chromosome preparation is produced. The chromosomes are firmly attached to a substrate, usually glass. Repetitive DNA sequences must be blocked by adding short fragments of DNA to the sample. The probe is then applied to the chromosome DNA and incubated for approximately 12 hours while hybridizing. Several wash steps remove all unhybridized or partially hybridized probes. The results are then visualized and quantified using a microscope that is capable of exciting the dye and recording images.\n\nIf the fluorescent signal is weak, amplification of the signal may be necessary in order to exceed the detection threshold of the microscope. Fluorescent signal strength depends on many factors such as probe labeling efficiency, the type of probe, and the type of dye. Fluorescently tagged antibodies or streptavidin are bound to the dye molecule. These secondary components are selected so that they have a strong signal.\n\nFISH is a very general technique. The differences between the various FISH techniques are usually due to variations in the sequence and labeling of the probes; and how they are used in combination. Probes are divided into two generic categories: cellular and acellular. In fluorescent \"in situ\" hybridization refers to the cellular placement of the probe.\n\nProbe size is important because longer probes hybridize less specifically than shorter probes, so that short strands of DNA or RNA (often 10–25 nucleotides) which are complementary to a given target sequence are often used to locate a target. The overlap defines the resolution of detectable features. For example, if the goal of an experiment is to detect the breakpoint of a translocation, then the overlap of the probes — the degree to which one DNA sequence is contained in the adjacent probes — defines the minimum window in which the breakpoint may be detected.\n\nThe mixture of probe sequences determines the type of feature the probe can detect. Probes that hybridize along an entire chromosome are used to count the number of a certain chromosome, show translocations, or identify extra-chromosomal fragments of chromatin. This is often called \"whole-chromosome painting.\" If every possible probe is used, every chromosome, (the whole genome) would be marked fluorescently, which would not be particularly useful for determining features of individual sequences. However, it is possible to create a mixture of smaller probes that are specific to a particular region (locus) of DNA; these mixtures are used to detect deletion mutations. When combined with a specific color, a locus-specific probe mixture is used to detect very specific translocations. Special locus-specific probe mixtures are often used to count chromosomes, by binding to the centromeric regions of chromosomes, which are distinctive enough to identify each chromosome (with the exception of Chromosome 13, 14, 21, 22.)\n\nA variety of other techniques use mixtures of differently colored probes. A range of colors in mixtures of fluorescent dyes can be detected, so each human chromosome can be identified by a characteristic color using whole-chromosome probe mixtures and a variety of ratios of colors. Although there are more chromosomes than easily distinguishable fluorescent dye colors, ratios of probe mixtures can be used to create \"secondary\" colors. Similar to comparative genomic hybridization, the probe mixture for the secondary colors is created by mixing the correct ratio of two sets of differently colored probes for the same chromosome. This technique is sometimes called M-FISH.\n\nThe same physics that make a variety of colors possible for M-FISH can be used for the detection of translocations. That is, colors that are adjacent appear to overlap; a secondary color is observed. Some assays are designed so that the secondary color will be present or absent in cases of interest. An example is the detection of BCR/ABL translocations, where the secondary color indicates disease. This variation is often called double-fusion FISH or D-FISH. In the opposite situation—where the absence of the secondary color is pathological—is illustrated by an assay used to investigate translocations where only one of the breakpoints is known or constant. Locus-specific probes are made for one side of the breakpoint and the other intact chromosome. In normal cells, the secondary color is observed, but only the primary colors are observed when the translocation occurs. This technique is sometimes called \"break-apart FISH\".\n\nSingle-molecule RNA FISH, also known as Stellaris® RNA FISH, is a method of detecting and quantifying mRNA and other long RNA molecules in a thin layer of tissue sample. Targets can be reliably imaged through the application of multiple short singly labeled oligonucleotide probes. The binding of up to 48 fluorescent labeled oligos to a single molecule of mRNA provides sufficient fluorescence to accurately detect and localize each target mRNA in a wide-field fluorescent microscopy image. Probes not binding to the intended sequence do not achieve sufficient localized fluorescence to be distinguished from background.\n\nSingle-molecule RNA FISH assays can be performed in simplex or multiplex, and can be used as a follow-up experiment to quantitative PCR, or imaged simultaneously with a fluorescent antibody assay. The technology has potential applications in cancer diagnosis, neuroscience, gene expression analysis, and companion diagnostics.\n\nIn an alternative technique to interphase or metaphase preparations, fiber FISH, interphase chromosomes are attached to a slide in such a way that they are stretched out in a straight line, rather than being tightly coiled, as in conventional FISH, or adopting a chromosome territory conformation, as in interphase FISH. This is accomplished by applying mechanical shear along the length of the slide, either to cells that have been fixed to the slide and then lysed, or to a solution of purified DNA. A technique known as chromosome combing is increasingly used for this purpose. The extended conformation of the chromosomes allows dramatically higher resolution – even down to a few kilobases. The preparation of fiber FISH samples, although conceptually simple, is a rather skilled art, and only specialized laboratories use the technique routinely. [Reference needed]\n\nQ-FISH combines FISH with PNAs and computer software to quantify fluorescence intensity. This technique is used routinely in telomere length research.\n\nFlow-FISH uses flow cytometry to perform FISH automatically using per-cell fluorescence measurements.\n\nMicrofluidics-assisted FISH (MA-FISH) uses a microfluidic flow to increase DNA hybridization efficiency, decreasing expensive FISH probe consumption and reduce the hybridization time. MA-FISH is applied for detecting the \"HER2\" gene in breast cancer tissues.\n\nOften parents of children with a developmental disability want to know more about their child's conditions before choosing to have another child. These concerns can be addressed by analysis of the parents' and child's DNA. In cases where the child's developmental disability is not understood, the cause of it can potentially be determined using FISH and cytogenetic techniques. Examples of diseases that are diagnosed using FISH include Prader-Willi syndrome, Angelman syndrome, 22q13 deletion syndrome, chronic myelogenous leukemia, acute lymphoblastic leukemia, Cri-du-chat, Velocardiofacial syndrome, and Down syndrome. FISH on sperm cells is indicated for men with an abnormal somatic or meiotic karyotype as well as those with oligozoospermia, since approximately 50% of oligozoospermic men have an increased rate of sperm chromosome abnormalities. The analysis of chromosomes 21, X, and Y is enough to identify oligozoospermic individuals at risk.\n\nIn medicine, FISH can be used to form a diagnosis, to evaluate prognosis, or to evaluate remission of a disease, such as cancer. Treatment can then be specifically tailored. A traditional exam involving metaphase chromosome analysis is often unable to identify features that distinguish one disease from another, due to subtle chromosomal features; FISH can elucidate these differences. FISH can also be used to detect diseased cells more easily than standard Cytogenetic methods, which require dividing cells and requires labor and time-intensive manual preparation and analysis of the slides by a technologist. FISH, on the other hand, does not require living cells and can be quantified automatically, a computer counts the fluorescent dots present. However, a trained technologist is required to distinguish subtle differences in banding patterns on bent and twisted metaphase chromosomes. FISH can be incorporated into Lab-on-a-chip microfluidic device. This technology is still in a developmental stage but, like other lab on a chip methods, it may lead to more portable diagnostic techniques.\n\nFISH is often used in clinical studies. If a patient is infected with a suspected pathogen, bacteria, from the patient's tissues or fluids, are typically grown on agar to determine the identity of the pathogen. Many bacteria, however, even well-known species, do not grow well under laboratory conditions. FISH can be used to detect directly the presence of the suspect on small samples of patient's tissue.\n\nFISH can also be used to compare the genomes of two biological species, to deduce evolutionary relationships. A similar hybridization technique is called a zoo blot. Bacterial FISH probes are often primers for the 16s rRNA region.\n\nFISH is widely used in the field of microbial ecology, to identify microorganisms. Biofilms, for example, are composed of complex (often) multi-species bacterial organizations. Preparing DNA probes for one species and performing FISH with this probe allows one to visualize the distribution of this specific species within the biofilm. Preparing probes (in two different colors) for two species allows to visualize/study co-localization of these two species in the biofilm, and can be useful in determining the fine architecture of the biofilm.\n\nComparative genomic hybridization can be described as a method that uses FISH in a parallel manner with the comparison of the hybridization strength to recall any major disruptions in the duplication process of the DNA sequences in the genome of the nucleus.\n\nVirtual karyotyping is another cost-effective, clinically available alternative to FISH panels using thousands to millions of probes on a single array to detect copy number changes, genome-wide, at unprecedented resolution. Currently, this type of analysis will only detect gains and losses of chromosomal material and will not detect balanced rearrangements, such as translocations and inversions which are hallmark aberrations seen in many types of leukemia and lymphoma.\n\nSpectral karyotyping is an image of colored chromosomes. Spectral karyotyping involves FISH using multiple forms of many types of probes with the result to see each chromosome labeled through its metaphase stage. This type of karyotyping is used specifically when seeking out chromosome arrangements.\n\n\n\n", "id": "1690338", "title": "Fluorescence in situ hybridization"}
{"url": "https://en.wikipedia.org/wiki?curid=54112223", "text": "Transcriptomics technologies\n\nTranscriptomics technologies are the techniques used to study an organism’s transcriptome, the sum of all of its RNA transcripts. The information content of an organism is recorded in the DNA of its genome and expressed through transcription. Here, mRNA serves as a transient intermediary molecule in the information network, whilst non-coding RNAs perform additional diverse functions. A transcriptome captures a snapshot in time of the total transcripts present in a cell.\n\nThe first attempts to study the whole transcriptome began in the early 1990s, and technological advances since the late 1990s have made transcriptomics a widespread discipline. Transcriptomics has been defined by repeated technological innovations that transform the field. There are two key contemporary techniques in the field: microarrays, which quantify a set of predetermined sequences, and RNA-Seq, which uses high-throughput sequencing to capture all sequences.\n\nMeasuring the expression of an organism’s genes in different tissues, conditions, or time points gives information on how genes are regulated and reveal details of an organism’s biology. It can also help to infer the functions of previously unannotated genes. Transcriptomic analysis has enabled the study of how gene expression changes in different organisms and has been instrumental in the understanding of human disease. An analysis of gene expression in its entirety allows detection of broad coordinated trends which cannot be discerned by more targeted assays.\n\nTranscriptomics has been characterised by the development of new techniques which have redefined what is possible every decade or so and render previous technologies obsolete. The first attempt at capturing a partial human transcriptome was published in 1991 and reported 609 mRNA sequences from the human brain. In 2008, two human transcriptomes, composed of millions of transcript-derived sequences covering 16,000 genes, were published and, by 2015, transcriptomes had been published for hundreds of individuals. Transcriptomes of different disease states, tissues or even single cells are now routinely generated. This explosion in transcriptomics has been driven by the rapid development of new technologies with improved sensitivity and economy.\n\nStudies of individual transcripts were being performed several decades before any transcriptomics approaches were available. Libraries of silkmoth mRNA transcripts were collected and converted to complementary DNA (cDNA) for storage using reverse transcriptase in the late 1970s. In the 1980s, low-throughput sequencing using the Sanger method was used to sequence random transcripts, producing Expressed Sequence Tags (ESTs). The Sanger method of sequencing was predominant until the advent of high-throughput methods such as sequencing by synthesis (Solexa/Illumina). ESTs came to prominence during the 1990s as an efficient method to determine the gene content of an organism without sequencing the entire genome. Amounts of individual transcripts were quantified using Northern blotting, nylon membrane arrays, and later Reverse Transcriptase quantitative PCR (RT-qPCR) methods, but these methods are laborious and can only capture a tiny subsection of a transcriptome. Consequently, the manner in which a transcriptome as a whole is expressed and regulated remained unknown until higher-throughput techniques were developed.\n\nThe word “Transcriptome” was first used in the 1990s. In 1995, one of the earliest sequencing-based transcriptomic methods was developed, Serial Analysis of Gene Expression (SAGE), which worked by Sanger sequencing of concatenated random transcript fragments. Transcripts were quantified by matching the fragments to known genes. A variant of SAGE using high-throughput sequencing techniques, called digital gene expression analysis, was also briefly used. However, these methods were largely overtaken by high throughput sequencing of entire transcripts, which provided additional information on transcript structure e.g. splice variants.\n\nThe dominant contemporary techniques, microarrays and RNA-Seq, were developed in the mid-1990s and 2000s. Microarrays that measure the abundances of a defined set of transcripts via their hybridisation to an array of complementary probes were first published in 1995. Microarray technology allowed the assay of 1000s of transcripts simultaneously, at a greatly reduced cost per gene and labour saving. Both spotted oligonucleotide arrays and Affymetrix high-density arrays were the method of choice for transcriptional profiling until the late 2000s. Over this period, a range of microarrays were produced to cover known genes in model or economically important organisms. Advances in design and manufacture of arrays improved the specificity of probes and allowed more genes to be tested on a single array. Advances in fluorescence detection increased the sensitivity and measurement accuracy for low abundance transcripts.\n\nRNA-Seq refers to the sequencing of transcript cDNAs, where abundance is derived from the number of counts from each transcript. The technique has therefore been heavily influenced by the development of high-throughput sequencing technologies. Massively Parallel Signature Sequencing (MPSS) was an early example based on generating 16-20 bp sequences via a complex series of hybridisations, and was used in 2004 to validate the expression of ten thousand genes in \"Arabidopsis thaliana\". The earliest RNA-Seq work was published in 2006 with one hundred thousand transcripts sequenced using the 454 technology. This was sufficient coverage to quantify relative transcript abundance. RNA-Seq began to increase in popularity after 2008 when new Solexa/Illumina technologies allowed one billion transcript sequences to be recorded. This yield now allows us to quantify and compare human transcriptomes.\n\nGenerating data on RNA transcripts can be achieved via either of two main principles: sequencing of individual transcripts (ESTs, or RNA-Seq) or hybridisation of transcripts to an ordered array of nucleotide probes (microarrays).\n\nAll transcriptomic methods require RNA to first be isolated from the experimental organism before transcripts can be recorded. Although biological systems are incredibly diverse, RNA extraction techniques are broadly similar and involve: mechanical disruption of cells or tissues, disruption of RNase with chaotropic salts, disruption of macromolecules and nucleotide complexes, separation of RNA from undesired biomolecules including DNA, and concentration of the RNA via precipitation from solution or elution from a solid matrix. Isolated RNA may additionally be treated with DNase to digest any traces of DNA. It is necessary to enrich messenger RNA as total RNA extracts are typically 98% ribosomal RNA. Enrichment for transcripts can be performed by poly-A affinity methods or by depletion of ribosomal RNA using sequence-specific probes. Degraded RNA may affect downstream results, for example, mRNA enrichment from degraded samples will result in the depletion of 5’ mRNA ends and uneven signal across the length of a transcript. Snap-freezing of tissue prior to RNA isolation is typical, and care is taken to reduce exposure to RNase enzymes once isolation is complete.\n\nAn expressed sequence tag (EST) is a short nucleotide sequence generated from a single RNA transcript. RNA is first copied as complementary DNA (cDNA) by a reverse transcriptase enzyme before the resultant cDNA is sequenced. The Sanger method of sequencing was predominant until the advent of high-throughput methods such as sequencing by synthesis (Solexa/Illumina). Because ESTs can be collected without prior knowledge of the organism from which they come, they can be made from mixtures of organisms or environmental samples. Although higher-throughput methods are now used, EST libraries commonly provided sequence information for early microarray designs, for example, a barley GeneChip was designed from 350,000 previously sequenced ESTs.\n\nSerial Analysis of Gene Expression (SAGE) was a development of EST methodology to increase the throughput of the tags generated and allow some quantitation of transcript abundance. cDNA is generated from the RNA but is then digested into 11 bp ‘tag’ fragments using restriction enzymes that cut DNA at a specific sequence, and 11 base pairs along from that sequence. These cDNA tags are then joined head-to-tail into long strands (>500 bp) and sequenced using low-throughput, but long read length methods such as Sanger sequencing. The sequences are then divided back into their original 11 bp tags using computer software in a process called deconvolution. If a reference genome is available, these tags may be matched to their corresponding gene in the genome. If a reference genome is unavailable, the tags can be directly used as diagnostic markers if found to be differentially expressed in a disease state.\n\nThe Cap Analysis of Gene Expression (CAGE) method is a variant of SAGE that sequences tags from the 5’ end of an mRNA transcript only. Therefore, the transcriptional start site of genes can be identified when the tags are aligned to a reference genome. Identifying gene start sites is of use for promoter analysis and for the cloning of full-length cDNAs.\n\nSAGE and CAGE methods produce information on more genes than was possible when sequencing single ESTs, but sample preparation and data analysis are typically more labour-intensive.\n\nMicroarrays consist of short nucleotide oligomers, known as \"probes\", which are typically arrayed in a grid on glass slide. Transcript abundance is determined by hybridisation of fluorescently labelled transcripts to these probes. The fluorescence intensity at each probe location on the array indicates the transcript abundance for that probe sequence.\n\nMicroarrays require some genomic knowledge from the organism of interest, for example, in the form of an annotated genome sequence, or a library of ESTs that can be used to generate the probes for the array.\n\nMicroarrays for transcriptomics typically fall into one of two broad categories: low-density spotted arrays or high-density short probe arrays. Transcript abundance may be recorded using single- or dual-channel detection of fluorescent tags on probes.\n\nSpotted low-density arrays typically feature picolitre drops of a range of purified cDNAs arrayed on the surface of a glass slide. The probes are longer than those of high-density arrays and typically lack the transcript resolution of high-density arrays. Spotted arrays use different fluorophores for test and control samples, and the ratio of fluorescence is used to calculate a relative measure of abundance. High-density arrays use single channel detection, and each sample is hybridised and detected individually. High-density arrays were popularised by the Affymetrix GeneChip array, where each transcript is quantified by several short 25-mer probes that together assay one gene.\n\nNimbleGen arrays were a high-density array produced by a maskless-photochemistry method, which permitted flexible manufacture of arrays in small or large numbers. These arrays had 100,000s of 45 to 85-mer probes and were hybridised with a one-colour labelled sample for expression analysis. Some designs incorporated up to 12 independent arrays per slide.\n\nRNA-Seq refers to the combination of a high-throughput sequencing methodology with computational methods to capture and quantify transcripts present in an RNA extract. The nucleotide sequences generated are typically around 100 bp in length, but can range from 30 bp to over 10,000 bp, depending on the sequencing method used. RNA-Seq leverages deep sampling of the transcriptome with many short fragments from a transcriptome to allow computational reconstruction of the original RNA transcript by aligning reads to a reference genome or to each other (de novo assembly). The typical dynamic range of 5 orders of magnitude for RNA-Seq is a key advantage over microarray transcriptomes. In addition, input RNA amounts are much lower for RNA-Seq (nanogram quantity) compared to microarrays (microgram quantity), which allowed finer examination of cellular structures, down to the single-cell level when combined with linear amplification of cDNA. Theoretically, there is no upper limit of quantification in RNA-Seq, and background signal is very low for 100 bp reads in non-repetitive regions.\n\nRNA-Seq may be used to identify genes within a genome, or identify which genes are active at a particular point in time, and read counts can be used to accurately model the relative gene expression level. RNA-Seq methodology has constantly improved, primarily through the development of DNA sequencing technologies to increase throughput, accuracy, and read length. Since the first descriptions in 2006 and 2008, RNA-Seq has been rapidly adopted and overtook microarrays as the dominant transcriptomics technique in 2015.\n\nThe quest for transcriptome data at the level of individual cells has driven advances in RNA-Seq library preparation methods, resulting in dramatic advances in sensitivity. Single-cell transcriptomes are now well described and have even been extended to \"in situ\" RNA-Seq where transcriptomes of individual cells are directly interrogated in fixed tissues.\n\nRNA-Seq was established in concert with the rapid development of a range of high-throughput DNA sequencing technologies. However, before the extracted RNA transcripts are sequenced, several key processing steps are performed. Methods differ in the use of transcript enrichment, fragmentation, amplification, single or paired-end sequencing, and whether to preserve strand information.\n\nThe sensitivity of an RNA-Seq experiment can be increased by enriching classes of RNA that are of interest and depleting known abundant RNAs. The mRNA molecules can be separated using oligonucleotides probes which bind their poly-A tails. Alternatively, ribo-depletion can be used to specifically remove abundant but uninformative ribosomal RNAs (rRNAs) by hybridisation to probes tailored to the taxon's specific rRNA sequences (e.g. mammal rRNA, plant rRNA). However, ribo-depletion can also introduce some bias via non-specific depletion of off-target transcripts. Small RNAs such as micro RNAs, can be purified based on their size by gel electrophoresis and extraction.\n\nSince mRNAs are longer than the read-lengths of typical high-throughput sequencing methods, transcripts are usually fragmented prior to sequencing. The fragmentation method is a key aspect of sequencing library construction. It may incorporate chemical hydrolysis, nebulisation, or sonication of RNA, or utilise simultaneous fragmentation and tagging of cDNA by transposase enzymes.\n\nDuring preparation for sequencing, cDNA copies of transcripts may be amplified by PCR to enrich for fragments that contain the expected 5’ and 3’ adapter sequences. Amplification is also used to allow sequencing of very low input amounts of RNA, down to as little as 50 pg, in extreme applications. Spike-in controls can be used to provide quality control assessment of library preparation and sequencing, in terms of GC-content, fragment length, as well as the bias due to fragment position within a transcript. Unique molecular identifiers (UMIs) are short random sequences that are used to individually tag sequence fragments during library preparation, so that every tagged fragment is unique. UMIs provide an absolute scale for quantification and the opportunity to correct for subsequent amplification bias introduced during library construction, and accurately estimate the initial sample size. UMIs are particularly well suited to single-cell RNA-Seq transcriptomics, where the amount of input RNA is restricted and extended amplification of the sample is required.\n\nOnce the transcript molecules have been prepared, they can be sequenced in just one direction (single-end) or both directions (paired-end). A single-end sequence is usually quicker to produce, cheaper than paired-end sequencing and sufficient for quantification of gene expression levels. Paired-end sequencing produces more robust alignments/assemblies, which is beneficial for gene annotation and transcript isoform discovery. Strand-specific RNA-Seq methods preserve the strand information of a sequenced transcript. Without strand information, reads can be aligned to a gene locus, but do not inform in which direction the gene is transcribed. Stranded-RNA-Seq is useful for deciphering transcription for genes that overlap in different directions, and to make more robust gene predictions in non-model organisms.\n\nCurrently, RNA-Seq relies on copying of RNA molecules into cDNA molecules prior to sequencing, hence the subsequent platforms are the same for transcriptomic and genomic data. Consequently, the development of DNA sequencing technologies has been a defining feature of RNA-Seq. Direct sequencing of RNA using nanopore sequencing represents a current state-of-the-art RNA-Seq technique in its infancy (in pre-release beta testing as of 2016). However, nanopore sequencing of RNA can detect modified bases that would be otherwise masked when sequencing cDNA and also eliminates amplification steps that can otherwise introduce bias.\n\nThe sensitivity and accuracy of an RNA-Seq experiment are dependent on the number of reads obtained from each sample. A large number of reads are needed to ensure sufficient coverage of the transcriptome, enabling detection of low abundance transcripts. Experimental design is further complicated by sequencing technologies with a limited output range, the variable efficiency of sequence creation, and variable sequence quality. Added to those considerations is that every species has a different number of genes and therefore requires a tailored sequence yield for an effective transcriptome. Early studies determined suitable thresholds empirically, but as the technology matured, suitable coverage is predicted computationally by transcriptome saturation. Somewhat counter-intuitively, the most effective way to improve detection of differential expression in low expression genes is to add more biological replicates, rather than adding more reads. The current benchmarks recommended by the Encyclopedia of DNA Elements (ENCODE) Project are for 70-fold exome coverage for standard RNA-Seq and up to 500-fold exome coverage to detect rare transcripts and isoforms.\n\nTranscriptomics methods are highly parallel and require significant computation to produce meaningful data for both microarray and RNA-Seq experiments. Microarray data is recorded as high-resolution images, requiring feature detection and spectral analysis. Microarray raw image files are each about 750 MB in size, while the processed intensities are around 60 MB in size. Multiple short probes matching a single transcript can reveal details about the intron-exon structure, requiring statistical models to determine the authenticity of the resulting signal. RNA-Seq studies produce billions of short DNA sequences, which must be aligned to reference genomes composed of millions to billions of base pairs. \"De novo\" assembly of reads within a dataset requires the construction of highly complex sequence graphs. RNA-Seq operations are highly repetitious and benefit from parallelised computation but modern algorithms mean consumer computing hardware is sufficient for simple transcriptomics experiments that do not require \"de novo\" assembly of reads. A human transcriptome could be accurately captured using RNA-Seq with 30 million 100 bp sequences per sample. This example would require approximately 1.8 gigabytes of disk space per sample when stored in a compressed fastq format. Processed count data for each gene would be much smaller, equivalent to processed microarray intensities. Sequence data may be stored in public repositories, such as the Sequence Read Archive (SRA). RNA-Seq datasets can be uploaded via the Gene Expression Omnibus.\n\nMicroarray image processing must correctly identify the regular grid of features within an image and independently quantify the fluorescence intensity for each feature. Image artefacts must be additionally identified and removed from the overall analysis. Fluorescence intensities directly indicate the abundance of each sequence, since the sequence of each probe on the array is already known.\n\nThe first steps of RNA-seq also include similar image processing, however, conversion of images to sequence data is typically handled automatically by the instrument software. The Illumina sequencing-by-synthesis method results in a random or ordered array of clusters distributed over the surface of a flow cell. The flow cell is imaged up to four times during each sequencing cycle, with tens to hundreds of cycles in total. Flow cell clusters are analogous to microarray spots and must be correctly identified during the early stages of the sequencing process. In Roche’s pyrosequencing method, the intensity of emitted light determines the number of consecutive nucleotides in a homopolymer repeat. There are many variants on these methods, each with a different error profile for the resulting data.\n\nRNA-Seq experiments generate a large volume of raw sequence reads, which have to be processed to yield useful information. Data analysis usually requires a combination of bioinformatics software tools (see also List of RNA-Seq bioinformatics tools) that vary according to the experimental design and goals. The process can be broken down into four stages: quality control, alignment, quantification, and differential expression. Most popular RNA-Seq programs are run from a command-line interface, either in a Unix environment or within the R/Bioconductor statistical environment.\n\nSequence reads are not perfect, so the accuracy of each base in the sequence needs to be estimated for downstream analyses. Raw data is examined for: high quality scores for base calls, GC content matches the expected distribution, the over representation of particular short sequence motifs (k-mers), and an unexpectedly high read duplication rate. Several software options exist for sequence quality analysis, including FastQC and FaQCs. Abnormalities identified may be removed by trimming, or tagged for special treatment during later processes.\n\nIn order to link sequence read abundance to expression of a particular gene, transcript sequences are aligned to a reference genome, or \"de novo\" aligned to one another if no reference is available. The key challenges for alignment software include sufficient speed to permit billions of short sequences to be aligned in a meaningful timeframe, flexibility to recognise and deal with intron splicing of eukaryotic mRNA, and correct assignment of reads that map to multiple locations. Software advances have greatly addressed these issues, and increases in sequencing read length are further reducing multimapping reads. A list of currently available high-throughput sequence aligners is maintained by the EBI.\n\nAlignment of primary transcript mRNA sequences derived from eukaryotes to a reference genome requires specialised handling of intron sequences, which are absent from mature mRNA. Short read aligners perform an additional round of alignments specifically designed to identify splice junctions, informed by canonical splice site sequences and known intron splice site information. Identification of intron splice junctions prevents reads being misaligned across splice junctions or erroneously discarded, allowing more reads to be aligned to the reference genome and improving the accuracy of gene expression estimates. Since gene regulation may occur at the mRNA isoform level, splice-aware alignments also permit detection of isoform abundance changes that would otherwise be lost in a bulked analysis.\n\n\"De novo\" assembly can be used to align reads to one another to construct full-length transcript sequences without use of a reference genome. Challenges particular to \"de novo\" assembly include larger computational requirements compared to a reference-based transcriptome, additional validation of gene variants or fragments, additional annotation of assembled transcripts. The first metrics used to describe transcriptome assemblies, such as N50, have been shown to be misleading and subsequently improved evaluation methods are now available. Annotation-based metrics are better assessments of assembly completeness, such as contig reciprocal best hit count. Once assembled \"de novo\", the assembly can be used as a reference for subsequent sequence alignment methods and quantitative gene expression analysis.\n\nQuantification of sequence alignments may be performed at the gene, exon, or transcript level. Typical outputs include a table of reads counts for each feature supplied to the software, for example for genes in a general feature format file. Gene and exon read counts may be calculated quite easily using HTSeq, for example. Quantitation at the transcript level is more complicated and requires probabilistic methods to estimate transcript isoform abundance from short read information, for example, using cufflinks software. Reads that align equally well to multiple locations must be identified and either removed, aligned to one of the possible locations, or aligned to the most probable location.\n\nSome quantification methods can circumvent the need for an exact alignment of a read to a reference sequence all together. The kallisto method combines pseudoalignment and quantification into a single step that runs 2 orders of magnitude faster than comparable methods such as tophat/cufflinks, with less computational burden.\n\nOnce quantitative counts of each transcript are available, differential gene expression is measured by normalising, modelling, and statistically analysing the data. Most read a table of genes and read counts as their input, but some, such as cuffdiff, will accept binary alignment map format read alignments as input. The final outputs of these analyses are gene lists with associated pair-wise tests for differential expression between treatments and the probability estimates of those differences.\n\nTranscriptomic analyses may be validated using an independent technique, for example, quantitative PCR (qPCR), which is recognisable and statistically assessable. Gene expression is measured against defined standards both for the gene of interest and control genes. The measurement by qPCR is similar to that obtained by RNA-Seq wherein a value can be calculated for the concentration of a target region in a given sample. qPCR is, however, restricted to amplicons smaller than 300 bp, usually toward the 3’ end of the coding region, avoiding the 3’UTR. If validation of transcript isoforms is required, an inspection of RNA-Seq read alignments should indicate where qPCR primers might be placed for maximum discrimination. The measurement of multiple control genes along with the genes of interest produces a stable reference within a biological context. qPCR validation of RNA-Seq data has generally shown that different RNA-Seq methods are highly correlated.\n\nFunctional validation of key genes is an important consideration for post transcriptome planning. Observed gene expression patterns may be functionally linked to a phenotype by an independent knock-down/rescue study in the organism of interest.\n\nTranscriptomic strategies have seen broad application across diverse areas of biomedical research, including disease diagnosis and profiling. RNA-Seq approaches have allowed for the large-scale identification of transcriptional start sites, uncovered alternative promoter usage and novel splicing alterations. These regulatory elements are important in human disease, and therefore, defining such variants is crucial to the interpretation of disease-association studies. RNA-Seq can also identify disease-associated single nucleotide polymorphisms (SNP), allele-specific expression and gene fusions contributing to our understanding of disease causal variants.\n\nRetrotransposons are transposable elements which proliferate within eukaryotic genomes through a process involving reverse transcription. RNA-Seq can provide information about the transcription of endogenous retrotransposons that may influence the transcription of neighboring genes by various epigenetic mechanisms that lead to disease. Similarly, the potential for using RNA-Seq to understand immune-related disease is expanding rapidly due to the ability to dissect immune cell populations and to sequence T cell and B cell receptor repertoires from patients.\n\nRNA-Seq of human pathogens has become an established method for quantifying gene expression changes, identifying novel virulence factors, predicting antibiotic resistance and unveiling host-pathogen immune interactions. A primary aim of this technology is to develop optimised infection control measures and targeted individualised treatment.\n\nTranscriptomic analysis has predominantly focused on either the host or the pathogen. Dual RNA-Seq has recently been applied to simultaneously profile RNA expression in both the pathogen and host throughout the infection process. This technique enables the study of the dynamic response and interspecies gene regulatory networks in both interaction partners from initial contact through to invasion and the final persistence of the pathogen or clearance by the host immune system.\n\nTranscriptomics allows identification of genes and pathways that respond to and counteract biotic and abiotic environmental stresses. The non-targeted nature of transcriptomics allows the identification of novel transcriptional networks in complex systems. For example, comparative analysis of a range of chickpea lines at different developmental stages identified distinct transcriptional profiles associated with drought and salinity stresses, including identifying the role of transcript isoforms of AP2-EREBP. Investigation of gene expression during biofilm formation by the fungal pathogen \"Candida albicans\" revealed a co-regulated set of genes critical for biofilm establishment and maintenance.\n\nTranscriptomic profiling also provides crucial information on mechanisms of drug resistance. Analysis of over 1000 \"Plasmodium falciparum\" isolates identified that upregulation of the unfolded protein response and slower progression through the early stages of the asexual intraerythrocytic developmental cycle were associated with artemisinin resistance in isolates from Southeast Asia.\n\nAll transcriptomic techniques have been particularly useful in identifying the functions of genes and identifying those responsible for particular phenotypes. Transcriptomics of \"Arabidopsis\" ecotypes that hyperaccumulate metals correlated genes involved in metal uptake, tolerance and homeostasis with the phenotype. Integration of RNA-Seq datasets across different tissues has been used to improve annotation of gene functions in commercially important organisms (e.g. cucumber) or threatened species (e.g. koala).\n\nAssembly of RNA-Seq reads is not dependent on a reference genome and so ideal for gene expression studies of non-model organisms with non-existing or poorly developed genomic resources. For example, a database of SNPs used in Douglas fir breeding programs was created by \"de novo\" transcriptome analysis, in the absence of a sequenced genome. Similarly, genes that function in the development of cardiac, muscle and nervous tissue in lobster were identified by comparing the transcriptomes of the various tissue types, without use of a genome sequence. RNA-Seq can also be used to identify previously unknown protein coding regions in existing sequenced genomes.\n\nTranscriptomics is most commonly applied to the mRNA content of the cell. However, the same techniques are equally applicable to non-coding RNAs that are not translated into a protein, but instead, have direct functions (e.g. roles in protein translation, DNA replication, RNA splicing and Transcriptional regulation). Many of these ncRNAs affect disease states, including cancer, cardiovascular and neurological diseases.\n\nTranscriptomics studies generate large amounts of data that has potential applications far beyond the original aims of an experiment. As such, raw or processed data may be deposited in public databases to ensure their utility for the broader scientific community. For example, as of 2016, the Gene Expression Omnibus contained millions of experiments.\n\n", "id": "54112223", "title": "Transcriptomics technologies"}
{"url": "https://en.wikipedia.org/wiki?curid=54202739", "text": "Amphipathic lipid packing sensor motifs\n\nAmphipathic Lipid Packing Sensor (ALPS) motifs were first identified in 2007 in ARFGAP1 and have been reviewed.\nThe curving of a phospholipid bilayer, for example into a liposome, causes disturbances to the packing of the lipids on the side of the bilayer that has the larger surface area (the outside of a liposome for example). The less \"ordered\" or \"looser\" packing of the lipids is recognized by ALPS motifs.\n\nALPS motifs are 20 to 40 amino acid long portions of proteins that have important collections of types of amino acid residues. Bulky hydrophobic amino acid residues, such as Phenylalanine, Leucine, and Tryptophan are present every 3 or 4 positions, with many polar amino acid residues such as Glycine, Serine and Threonine between. The ALPS forms an alpha helix when associated with the bilayer, such that the hydrophobic residues associate with the lipids and the polar residues associate with the aqueous cytoplasm.\n", "id": "54202739", "title": "Amphipathic lipid packing sensor motifs"}
{"url": "https://en.wikipedia.org/wiki?curid=54236356", "text": "Molecular phenotyping\n\nMolecular phenotyping describes the technique of quantifying pathway reporter genes, \"i.e.\" pre-selected genes that are modulated specifically by metabolic and signaling pathways, in order to infer activity of these pathways.\nIn most cases, molecular phenotyping quantifies changes of pathway reporter gene expression to characterize modulation of pathway activities induced by perturbations such as therapeutic agents or stress in a cellular system \"in vitro\". In such contexts, measurements at early time points are often more informative than later observations because they capture the primary response to the perturbation by the cellular system. Integrated with quantified changes of phenotype induced by the perturbation, molecular phenotyping can identify pathways that contribute to the phenotypic changes.\n\nCurrently molecular phenotyping uses RNA sequencing and mRNA expression to infer pathway activities. Other technologies and readouts such as mass spectrometry and protein abundance or phosphorylation levels can be potentially used as well.\n\nCurrent data suggest that by quantifying pathway reporter gene expression, molecular phenotyping is able to cluster compounds based on pathway profiles and dissect associations between pathway activities and disease phenotypes simultaneously. Furthermore, molecular phenotyping can be applicable to compounds with a range of binding specificities and is able to triage false positives derived from high-content screening assays. Furthermore, molecular phenotyping allows integration of data derived from \"in vitro\" and \"in vivo\" models as well as patient data into the drug discovery process.\n", "id": "54236356", "title": "Molecular phenotyping"}
{"url": "https://en.wikipedia.org/wiki?curid=3954", "text": "Biochemistry\n\nBiochemistry, sometimes called biological chemistry, is the study of chemical processes within and relating to living organisms. By controlling information flow through biochemical signaling and the flow of chemical energy through metabolism, biochemical processes give rise to the complexity of life. Over the last decades of the 20th century, biochemistry has become so successful at explaining living processes that now almost all areas of the life sciences from botany to medicine to genetics are engaged in biochemical research. Today, the main focus of pure biochemistry is on understanding how biological molecules give rise to the processes that occur within living cells, which in turn relates greatly to the study and understanding of tissues, organs, and whole organisms—that is, all of biology.\n\nBiochemistry is closely related to molecular biology, the study of the molecular mechanisms by which genetic information encoded in DNA is able to result in the processes of life. Depending on the exact definition of the terms used, molecular biology can be thought of as a branch of biochemistry, or biochemistry as a tool with which to investigate and study molecular biology.\n\nMuch of biochemistry deals with the structures, functions and interactions of biological macromolecules, such as proteins, nucleic acids, carbohydrates and lipids, which provide the structure of cells and perform many of the functions associated with life. The chemistry of the cell also depends on the reactions of smaller molecules and ions. These can be inorganic, for example water and metal ions, or organic, for example the amino acids, which are used to synthesize proteins. The mechanisms by which cells harness energy from their environment via chemical reactions are known as metabolism. The findings of biochemistry are applied primarily in medicine, nutrition, and agriculture. In medicine, biochemists investigate the causes and cures of diseases. In nutrition, they study how to maintain health wellness and study the effects of nutritional deficiencies. In agriculture, biochemists investigate soil and fertilizers, and try to discover ways to improve crop cultivation, crop storage and pest control.\n\nAt its broadest definition, biochemistry can be seen as a study of the components and composition of living things and how they come together to become life, in this sense the history of biochemistry may therefore go back as far as the ancient Greeks. However, biochemistry as a specific scientific discipline has its beginning sometime in the 19th century, or a little earlier, depending on which aspect of biochemistry is being focused on. Some argued that the beginning of biochemistry may have been the discovery of the first enzyme, diastase (today called amylase), in 1833 by Anselme Payen, while others considered Eduard Buchner's first demonstration of a complex biochemical process alcoholic fermentation in cell-free extracts in 1897 to be the birth of biochemistry. Some might also point as its beginning to the influential 1842 work by Justus von Liebig, \"Animal chemistry, or, Organic chemistry in its applications to physiology and pathology\", which presented a chemical theory of metabolism, or even earlier to the 18th century studies on fermentation and respiration by Antoine Lavoisier. Many other pioneers in the field who helped to uncover the layers of complexity of biochemistry have been proclaimed founders of modern biochemistry, for example Emil Fischer for his work on the chemistry of proteins, and F. Gowland Hopkins on enzymes and the dynamic nature of biochemistry.\n\nThe term \"biochemistry\" itself is derived from a combination of biology and chemistry. In 1877, Felix Hoppe-Seyler used the term (\"biochemie\" in German) as a synonym for physiological chemistry in the foreword to the first issue of \"Zeitschrift für Physiologische Chemie\" (Journal of Physiological Chemistry) where he argued for the setting up of institutes dedicated to this field of study. The German chemist Carl Neuberg however is often cited to have coined the word in 1903, while some credited it to Franz Hofmeister.\nIt was once generally believed that life and its materials had some essential property or substance (often referred to as the \"vital principle\") distinct from any found in non-living matter, and it was thought that only living beings could produce the molecules of life. Then, in 1828, Friedrich Wöhler published a paper on the synthesis of urea, proving that organic compounds can be created artificially. Since then, biochemistry has advanced, especially since the mid-20th century, with the development of new techniques such as chromatography, X-ray diffraction, dual polarisation interferometry, NMR spectroscopy, radioisotopic labeling, electron microscopy, and molecular dynamics simulations. These techniques allowed for the discovery and detailed analysis of many molecules and metabolic pathways of the cell, such as glycolysis and the Krebs cycle (citric acid cycle), and led to an understanding of biochemistry on a molecular level.\n\nAnother significant historic event in biochemistry is the discovery of the gene and its role in the transfer of information in the cell. This part of biochemistry is often called molecular biology. In the 1950s, James D. Watson, Francis Crick, Rosalind Franklin, and Maurice Wilkins were instrumental in solving DNA structure and suggesting its relationship with genetic transfer of information. In 1958, George Beadle and Edward Tatum received the Nobel Prize for work in fungi showing that one gene produces one enzyme. In 1988, Colin Pitchfork was the first person convicted of murder with DNA evidence, which led to the growth of forensic science. More recently, Andrew Z. Fire and Craig C. Mello received the 2006 Nobel Prize for discovering the role of RNA interference (RNAi), in the silencing of gene expression.\n\nAround two dozen of the 92 naturally occurring chemical elements are essential to various kinds of biological life. Most rare elements on Earth are not needed by life (exceptions being selenium and iodine), while a few common ones (aluminum and titanium) are not used. Most organisms share element needs, but there are a few differences between plants and animals. For example, ocean algae use bromine, but land plants and animals seem to need none. All animals require sodium, but some plants do not. Plants need boron and silicon, but animals may not (or may need ultra-small amounts).\n\nJust six elements—carbon, hydrogen, nitrogen, oxygen, calcium, and phosphorus—make up almost 99% of the mass of living cells, including those in the human body (see composition of the human body for a complete list). In addition to the six major elements that compose most of the human body, humans require smaller amounts of possibly 18 more.\n\nThe four main classes of molecules in biochemistry (often called biomolecules) are carbohydrates, lipids, proteins, and nucleic acids. Many biological molecules are polymers: in this terminology, monomers are relatively small micromolecules that are linked together to create large macromolecules known as polymers. When monomers are linked together to synthesize a biological polymer, they undergo a process called dehydration synthesis. Different macromolecules can assemble in larger complexes, often needed for biological activity.\n\nThe function of carbohydrates includes energy storage and providing structure. Sugars are carbohydrates, but not all carbohydrates are sugars. There are more carbohydrates on Earth than any other known type of biomolecule; they are used to store energy and genetic information, as well as play important roles in cell to cell interactions and communications.\n\nThe simplest type of carbohydrate is a monosaccharide, which among other properties contains carbon, hydrogen, and oxygen, mostly in a ratio of 1:2:1 (generalized formula CHO, where \"n\" is at least 3). Glucose (CHO) is one of the most important carbohydrates; others include fructose (CHO), the sugar commonly associated with the sweet taste of fruits, and deoxyribose (CHO). A monosaccharide can switch between acyclic (open-chain) form and a cyclic form. The open-chain form can be turned into a ring of carbon atoms bridged by an oxygen atom created from the carbonyl group of one end and the hydroxyl group of another. The cyclic molecule has an hemiacetal or hemiketal group, depending on whether the linear form was an aldose or a ketose.\n\nIn these cyclic forms, the ring usually has 5 or 6 atoms. These forms are called furanoses and pyranoses, respectively — by analogy with furan and pyran, the simplest compounds with the same carbon-oxygen ring (although they lack the double bonds of these two molecules). For example, the aldohexose glucose may form a hemiacetal linkage between the hydroxyl on carbon 1 and the oxygen on carbon 4, yielding a molecule with a 5-membered ring, called glucofuranose. The same reaction can take place between carbons 1 and 5 to form a molecule with a 6-membered ring, called glucopyranose. Cyclic forms with a 7-atom ring called heptoses are rare.\n\nTwo monosaccharides can be joined together by a glycosidic or ether bond into a \"disaccharide\" through a dehydration reaction during which a molecule of water is released. The reverse reaction in which the glycosidic bond of a disaccharide is broken into two monosaccharides is termed \"hydrolysis\". The best-known disaccharide is sucrose or ordinary sugar, which consists of a glucose molecule and a fructose molecule joined together. Another important disaccharide is lactose found in milk, consisting of a glucose molecule and a galactose molecule. Lactose may be hydrolysed by lactase, and deficiency in this enzyme results in lactose intolerance.\n\nWhen a few (around three to six) monosaccharides are joined, it is called an \"oligosaccharide\" (\"oligo-\" meaning \"few\"). These molecules tend to be used as markers and signals, as well as having some other uses. Many monosaccharides joined together make a polysaccharide. They can be joined together in one long linear chain, or they may be branched. Two of the most common polysaccharides are cellulose and glycogen, both consisting of repeating glucose monomers. Examples are \"cellulose\" which is an important structural component of plant's cell walls, and \"glycogen\", used as a form of energy storage in animals.\n\nSugar can be characterized by having reducing or non-reducing ends. A reducing end of a carbohydrate is a carbon atom that can be in equilibrium with the open-chain aldehyde (aldose) or keto form (ketose). If the joining of monomers takes place at such a carbon atom, the free hydroxy group of the pyranose or furanose form is exchanged with an OH-side-chain of another sugar, yielding a full acetal. This prevents opening of the chain to the aldehyde or keto form and renders the modified residue non-reducing. Lactose contains a reducing end at its glucose moiety, whereas the galactose moiety forms a full acetal with the C4-OH group of glucose. Saccharose does not have a reducing end because of full acetal formation between the aldehyde carbon of glucose (C1) and the keto carbon of fructose (C2).\n\nLipids comprises a diverse range of molecules and to some extent is a catchall for relatively water-insoluble or nonpolar compounds of biological origin, including waxes, fatty acids, fatty-acid derived phospholipids, sphingolipids, glycolipids, and terpenoids (e.g., retinoids and steroids). Some lipids are linear aliphatic molecules, while others have ring structures. Some are aromatic, while others are not. Some are flexible, while others are rigid.\n\nLipids are usually made from one molecule of glycerol combined with other molecules. In triglycerides, the main group of bulk lipids, there is one molecule of glycerol and three fatty acids. Fatty acids are considered the monomer in that case, and may be saturated (no double bonds in the carbon chain) or unsaturated (one or more double bonds in the carbon chain).\n\nMost lipids have some polar character in addition to being largely nonpolar. In general, the bulk of their structure is nonpolar or hydrophobic (\"water-fearing\"), meaning that it does not interact well with polar solvents like water. Another part of their structure is polar or hydrophilic (\"water-loving\") and will tend to associate with polar solvents like water. This makes them amphiphilic molecules (having both hydrophobic and hydrophilic portions). In the case of cholesterol, the polar group is a mere -OH (hydroxyl or alcohol). In the case of phospholipids, the polar groups are considerably larger and more polar, as described below.\n\nLipids are an integral part of our daily diet. Most oils and milk products that we use for cooking and eating like butter, cheese, ghee etc., are composed of fats. Vegetable oils are rich in various polyunsaturated fatty acids (PUFA). Lipid-containing foods undergo digestion within the body and are broken into fatty acids and glycerol, which are the final degradation products of fats and lipids. Lipids, especially phospholipids, are also used in various pharmaceutical products, either as co-solubilisers (e.g., in parenteral infusions) or else as drug carrier components (e.g., in a liposome or transfersome).\n\nProteins are very large molecules – macro-biopolymers – made from monomers called amino acids. An amino acid consists of a carbon atom attached to an amino group, —NH, a carboxylic acid group, —COOH (although these exist as —NH and —COO under physiologic conditions), a simple hydrogen atom, and a side chain commonly denoted as \"—R\". The side chain \"R\" is different for each amino acid of which there are 20 standard ones. It is this \"R\" group that made each amino acid different, and the properties of the side-chains greatly influence the overall three-dimensional conformation of a protein. Some amino acids have functions by themselves or in a modified form; for instance, glutamate functions as an important neurotransmitter. Amino acids can be joined via a peptide bond. In this dehydration synthesis, a water molecule is removed and the peptide bond connects the nitrogen of one amino acid's amino group to the carbon of the other's carboxylic acid group. The resulting molecule is called a \"dipeptide\", and short stretches of amino acids (usually, fewer than thirty) are called \"peptides\" or polypeptides. Longer stretches merit the title \"proteins\". As an example, the important blood serum protein albumin contains 585 amino acid residues.\n\nProteins can have structural and/or functional roles. For instance, movements of the proteins actin and myosin ultimately are responsible for the contraction of skeletal muscle. One property many proteins have is that they specifically bind to a certain molecule or class of molecules—they may be \"extremely\" selective in what they bind. Antibodies are an example of proteins that attach to one specific type of molecule. In fact, the enzyme-linked immunosorbent assay (ELISA), which uses antibodies, is one of the most sensitive tests modern medicine uses to detect various biomolecules. Probably the most important proteins, however, are the enzymes. Virtually every reaction in a living cell requires an enzyme to lower the activation energy of the reaction. These molecules recognize specific reactant molecules called \"substrates\"; they then catalyze the reaction between them. By lowering the activation energy, the enzyme speeds up that reaction by a rate of 10 or more; a reaction that would normally take over 3,000 years to complete spontaneously might take less than a second with an enzyme. The enzyme itself is not used up in the process, and is free to catalyze the same reaction with a new set of substrates. Using various modifiers, the activity of the enzyme can be regulated, enabling control of the biochemistry of the cell as a whole.\n\nThe structure of proteins is traditionally described in a hierarchy of four levels. The primary structure of a protein simply consists of its linear sequence of amino acids; for instance, \"alanine-glycine-tryptophan-serine-glutamate-asparagine-glycine-lysine-…\". Secondary structure is concerned with local morphology (morphology being the study of structure). Some combinations of amino acids will tend to curl up in a coil called an α-helix or into a sheet called a β-sheet; some α-helixes can be seen in the hemoglobin schematic above. Tertiary structure is the entire three-dimensional shape of the protein. This shape is determined by the sequence of amino acids. In fact, a single change can change the entire structure. The alpha chain of hemoglobin contains 146 amino acid residues; substitution of the glutamate residue at position 6 with a valine residue changes the behavior of hemoglobin so much that it results in sickle-cell disease. Finally, quaternary structure is concerned with the structure of a protein with multiple peptide subunits, like hemoglobin with its four subunits. Not all proteins have more than one subunit.\n\nIngested proteins are usually broken up into single amino acids or dipeptides in the small intestine, and then absorbed. They can then be joined to make new proteins. Intermediate products of glycolysis, the citric acid cycle, and the pentose phosphate pathway can be used to make all twenty amino acids, and most bacteria and plants possess all the necessary enzymes to synthesize them. Humans and other mammals, however, can synthesize only half of them. They cannot synthesize isoleucine, leucine, lysine, methionine, phenylalanine, threonine, tryptophan, and valine. These are the essential amino acids, since it is essential to ingest them. Mammals do possess the enzymes to synthesize alanine, asparagine, aspartate, cysteine, glutamate, glutamine, glycine, proline, serine, and tyrosine, the nonessential amino acids. While they can synthesize arginine and histidine, they cannot produce it in sufficient amounts for young, growing animals, and so these are often considered essential amino acids.\n\nIf the amino group is removed from an amino acid, it leaves behind a carbon skeleton called an α-keto acid. Enzymes called transaminases can easily transfer the amino group from one amino acid (making it an α-keto acid) to another α-keto acid (making it an amino acid). This is important in the biosynthesis of amino acids, as for many of the pathways, intermediates from other biochemical pathways are converted to the α-keto acid skeleton, and then an amino group is added, often via transamination. The amino acids may then be linked together to make a protein.\n\nA similar process is used to break down proteins. It is first hydrolyzed into its component amino acids. Free ammonia (NH), existing as the ammonium ion (NH) in blood, is toxic to life forms. A suitable method for excreting it must therefore exist. Different tactics have evolved in different animals, depending on the animals' needs. Unicellular organisms simply release the ammonia into the environment. Likewise, bony fish can release the ammonia into the water where it is quickly diluted. In general, mammals convert the ammonia into urea, via the urea cycle.\n\nIn order to determine whether two proteins are related, or in other words to decide whether they are homologous or not, scientists use sequence-comparison methods. Methods like sequence alignments and structural alignments are powerful tools that help scientists identify homologies between related molecules. The relevance of finding homologies among proteins goes beyond forming an evolutionary pattern of protein families. By finding how similar two protein sequences are, we acquire knowledge about their structure and therefore their function.\n\nNucleic acids, so called because of their prevalence in cellular nuclei, is the generic name of the family of biopolymers. They are complex, high-molecular-weight biochemical macromolecules that can convey genetic information in all living cells and viruses. The monomers are called nucleotides, and each consists of three components: a nitrogenous heterocyclic base (either a purine or a pyrimidine), a pentose sugar, and a phosphate group.\n\nThe most common nucleic acids are deoxyribonucleic acid (DNA) and ribonucleic acid (RNA). The phosphate group and the sugar of each nucleotide bond with each other to form the backbone of the nucleic acid, while the sequence of nitrogenous bases stores the information. The most common nitrogenous bases are adenine, cytosine, guanine, thymine, and uracil. The nitrogenous bases of each strand of a nucleic acid will form hydrogen bonds with certain other nitrogenous bases in a complementary strand of nucleic acid (similar to a zipper). Adenine binds with thymine and uracil; thymine binds only with adenine; and cytosine and guanine can bind only with one another.\n\nAside from the genetic material of the cell, nucleic acids often play a role as second messengers, as well as forming the base molecule for adenosine triphosphate (ATP), the primary energy-carrier molecule found in all living organisms. Also, the nitrogenous bases possible in the two nucleic acids are different: adenine, cytosine, and guanine occur in both RNA and DNA, while thymine occurs only in DNA and uracil occurs in RNA.\n\nGlucose is the major energy source in most life forms. For instance, polysaccharides are broken down into their monomers (glycogen phosphorylase removes glucose residues from glycogen). Disaccharides like lactose or sucrose are cleaved into their two component monosaccharides.\n\nGlucose is mainly metabolized by a very important ten-step pathway called glycolysis, the net result of which is to break down one molecule of glucose into two molecules of pyruvate. This also produces a net two molecules of ATP, the energy currency of cells, along with two reducing equivalents of converting NAD (nicotinamide adenine dinucleotide: oxidised form) to NADH (nicotinamide adenine dinucleotide: reduced form). This does not require oxygen; if no oxygen is available (or the cell cannot use oxygen), the NAD is restored by converting the pyruvate to lactate (lactic acid) (e.g., in humans) or to ethanol plus carbon dioxide (e.g., in yeast). Other monosaccharides like galactose and fructose can be converted into intermediates of the glycolytic pathway.\n\nIn aerobic cells with sufficient oxygen, as in most human cells, the pyruvate is further metabolized. It is irreversibly converted to acetyl-CoA, giving off one carbon atom as the waste product carbon dioxide, generating another reducing equivalent as NADH. The two molecules acetyl-CoA (from one molecule of glucose) then enter the citric acid cycle, producing two more molecules of ATP, six more NADH molecules and two reduced (ubi)quinones (via FADH as enzyme-bound cofactor), and releasing the remaining carbon atoms as carbon dioxide. The produced NADH and quinol molecules then feed into the enzyme complexes of the respiratory chain, an electron transport system transferring the electrons ultimately to oxygen and conserving the released energy in the form of a proton gradient over a membrane (inner mitochondrial membrane in eukaryotes). Thus, oxygen is reduced to water and the original electron acceptors NAD and quinone are regenerated. This is why humans breathe in oxygen and breathe out carbon dioxide. The energy released from transferring the electrons from high-energy states in NADH and quinol is conserved first as proton gradient and converted to ATP via ATP synthase. This generates an additional \"28\" molecules of ATP (24 from the 8 NADH + 4 from the 2 quinols), totaling to 32 molecules of ATP conserved per degraded glucose (two from glycolysis + two from the citrate cycle). It is clear that using oxygen to completely oxidize glucose provides an organism with far more energy than any oxygen-independent metabolic feature, and this is thought to be the reason why complex life appeared only after Earth's atmosphere accumulated large amounts of oxygen.\n\nIn vertebrates, vigorously contracting skeletal muscles (during weightlifting or sprinting, for example) do not receive enough oxygen to meet the energy demand, and so they shift to anaerobic metabolism, converting glucose to lactate. The liver regenerates the glucose, using a process called gluconeogenesis. This process is not quite the opposite of glycolysis, and actually requires three times the amount of energy gained from glycolysis (six molecules of ATP are used, compared to the two gained in glycolysis). Analogous to the above reactions, the glucose produced can then undergo glycolysis in tissues that need energy, be stored as glycogen (or starch in plants), or be converted to other monosaccharides or joined into di- or oligosaccharides. The combined pathways of glycolysis during exercise, lactate's crossing via the bloodstream to the liver, subsequent gluconeogenesis and release of glucose into the bloodstream is called the Cori cycle.\n\nResearchers in biochemistry use specific techniques native to biochemistry, but increasingly combine these with techniques and ideas developed in the fields of genetics, molecular biology and biophysics. There has never been a hard-line among these disciplines in terms of content and technique. Today, the terms \"molecular biology\" and \"biochemistry\" are nearly interchangeable. The following figure is a schematic that depicts one possible view of the relationship between the fields:\n\n\n\na. Fructose is not the only sugar found in fruits. Glucose and sucrose are also found in varying quantities in various fruits, and indeed sometimes exceed the fructose present. For example, 32% of the edible portion of date is glucose, compared with 23.70% fructose and 8.20% sucrose. However, peaches contain more sucrose (6.66%) than they do fructose (0.93%) or glucose (1.47%).\n\n\n\n", "id": "3954", "title": "Biochemistry"}
{"url": "https://en.wikipedia.org/wiki?curid=41069188", "text": "Discovery and development of phosphodiesterase 5 inhibitors\n\nPhosphodiesterases (PDEs) are a superfamily of enzymes. This superfamily is further classified into 11 families, PDE1 - PDE11, on the basis of regulatory properties, amino acid sequences, substrate specificities, pharmacological properties and tissue distribution. Their function is to degrade intracellular second messengers such as cyclic adenine monophosphate (cAMP) and cyclic guanosine monophosphate (cGMP) which leads to several biological processes like effect on intracellular calcium level by the Ca pathway.\n\nPhosphodiesterase 5 (PDE5) is widely expressed in several tissues in the body for example brain, lung, kidney, urinary bladder, smooth muscle and platelets. It is possible to prevent cGMP hydrolysis by inhibiting PDE5 and therefore treat diseases associated with low cGMP levels, because of this, PDE5 is an ideal target for the development of inhibitors.\n\nThe three major PDE5 inhibitors are sildenafil, tadalafil and vardenafil.\n\nThe human genome contains at least 21 genes involved in determining the intracellular levels of cAMP and cGMP by the expression of phosphodiesterase proteins or PDE’s. These PDE’s are grouped into at least 11 functional subfamiles, named PDE1-PDE11. PDEs are enzymes that hydrolyze cyclic adenosine 3,5-monophosphate (cAMP) and cyclic guanosine 3,5-monophospahate (cGMP), which are intracellular second messengers, into AMP and GMP. These second messengers control many physiological processes.\nThe cAMP is formed from ATP by the enzyme adenylyl cyclase and cGMP is formed from GTP by the enzyme guanylyl cyclase which are either membrane bound or soluble in the cytosol. When soluble it functions as a receptor for nitric oxide (NO) (see figure 1).\nFormation of cGMP initiates several reactions in the body including influence on cGMP ion channels, cGMP binding proteins and protein kinase G (PKG). The effect on PKG reduces levels of calcium leading to relaxation of smooth muscles (see figure 2). \nThe PDE5 enzyme is specific for cGMP which means it only hydrolyzes cGMP but not cAMP. The selectivity is mediated through an intricate network of hydrogen bonding which is favorable for cGMP but unfavorable for cAMP in PDE5.\nBy inhibition of PDE5 enzyme the cGMP concentration will be raised and can therefore increase the relaxation of smooth muscles. PDE5 has only one subtype, PDE5A, of which there are 4 isoforms in humans called PDE5A1-4. The difference in PDE5A1-3 isoforms is only in the 5´ end of the mRNA and corresponding N-terminal of the protein. \n\nIn humans the distribution of PDE5A1 and PDE5A2 isoforms is the same and can be found in the brain, lung tissue, heart, liver, kidneys, bladder, prostate, urethra, penis, uterus and skeletal muscles. PDE5A2 is more common than PDE5A1. PDE5A3 is not as widespread as the other two isoforms, and is only found in smooth muscle tissues, it is found in the heart, bladder, prostate, urethra, penis and uterus, Exact distribution of PDE5A4 isoform was not found in the literature. PDE5 enzyme in humans has also been reported in platelets, gastrointestinal epithelial cells, Purkinje cells of cerebellum, corpus cavernosum, pancreas, placenta and colon, clitoral corpus cavernosum as well as vaginal smooth muscle and epithelium.\n\nPDE enzymes are composed of 3 functional domains: an N-terminal cyclin fold domain, a linker helical domain and a C-terminal helical bundle domain (see figure 3). The active site is a deep pocket at the junction of the 3 subdomains and is lined with highly conserved residues between isotypes of PDE. The pocket is approximately 15 Å deep and the opening is approximately 20 by 10 Å. The volume of the active site has been calculated to be between 875 and 927 Å. The active site of PDE5 has been described as subdivided into 3 main regions based on its crystal structure in complex with sildenafil: \nJeon \"et al.\" also describe a fourth pocket called the H pocket which is hydrophobic and accommodates the ethoxyphenyl group of sildenafil\nThe 3 PDE5 inhibitors already on the market, sildenafil, tadalafil and vardenafil, occupy part of the active site, mainly around the Q pocket and sometimes the M pocket as well and all 3 interact with the active site in 3 important manners:\nIt has also been described that the hydrophobic interaction with the Q1 and Q2 pockets are important for inhibitor potency and differences between isotypes of PDE in the Q2 pocket can be exploited for selectivity between isotypes.\n\nDrugs that inhibit PDE5, sildenafil, tadalafil and vardenafil, have been used as treatment for erectile dysfunction. These inhibitors increase the cGMP, smooth muscle relaxation and consequently cause penis erection during sexual stimulation.\n\nPulmonary hypertension is the result of upregulation of PDE5 gene expression, causing vasoconstriction in the lung. PDE5 inhibitors are used as potent pulmonary vasodilators reducing Pulmonary hypertension and inhibiting vascular remodelling. Long-term treatment with a PDE5 inhibitor has been shown to enhance natriuretic peptide-cGMP pathway, downregulate Ca signaling pathway and alter vascular tone in pulmonary arteries in rat models.\n\nAdding PDE5 inhibitors to SSRI drugs (e.g. paroxetine) for the treatment of premature ejaculation could result in better ejaculatory control according to recent studies. Possible mechanism is based on nitric oxide (NO)/cGMP transduction system as a central and peripheral mediator of inhibitory non-adrenergic, non-cholinergic nitrergic neurotransmission in the urogenital system.\n\nPDE5 is expressed in clitoral corpus cavernosum and in vaginal smooth muscle and epithelium. Therefore, it is possible that PDE5 inhibitors could affect female sexual arousal disorder but further research is needed. Increased levels of cGMP have been shown to occur in human-cultured vaginal smooth muscle cells treated with a PDE5 inhibitor suggesting involvement of the NO/cGMP axis in the female sexual response.\n\nThe similarity of many PDE5 inhibitors to the structure of many of the analogs of caffeine that are also suggests that in the future, it may be possible to design an PDE5 inhibitor that, like caffeine, is also an adenosine antagonist.\n\nSildenafil has been shown to be effective in treating severe Raynaud's phenomenon associated with systemic sclerosis and digital ulceration. When given sildenafil for 4 weeks subjects had reduced mean frequency and duration of Raynaud attacks and a significantly lowered mean Raynaud’s condition score. The capillary blood flow velocity also increased in each individual patient and the mean capillary flow velocity of all patients increased significantly. These results came without significant reductions of the systemic blood pressure.\n\nSildenafil has shown promise in the treatment of congestive cardiac failure. A study showed that effective treatment of pulmonary arterial hypertension with sildenafil improved functional capacity and reduced right ventricular mass in patients. The effects on right ventricular remodeling were significantly greater in comparison with the non-selective endothelia receptor antagonist bosentan.\n\nSildenafil has been shown to improve endothelial function in diabetes and congestive heart failure., It has also been shown to reduce aortic pressure through vasodilation, reduced arterial stiffness and wave reflection and could be used in the management of systemic hypertension.\n\nSildenafil has been shown to significantly improve neurovascular coupling without affecting overall cerebral blood flow by increasing brain levels of cGMP, evoking neurogenesis and reducing neurological deficits in rats 2 or 24 hours after stroke. This data suggest that PDE5 inhibitors may have a role in promoting recovery from stroke.,\n\nPDE5 is an enzyme that was first purified in 1980 from a rats lung. PDE5 converts intracellular cGMP to the nucleotide GMP. Many tissues contain PDE5, such as lungs, kidneys, brain, platelets, liver, prostate, urethra, bladder and smooth muscles. Because of the localization of PDE5 in the smooth muscle tissue, inhibitors were developed for the treatment of erectile dysfunction along with pulmonary hypertension.\n\nSildenafil was initially introduced for clinical trial in 1989. It was the result of extensive research on chemical agents targeting PDE5 that could be effective in treatment of coronary heart disease. Sildenafil did not prove effective for coronary heart disease but an interesting side effect was discovered, a penile erection. That side effect soon became the main field of investigation. The inhibitor is highly selective for the PDE5 family.\n\nSildenafil is a prototype of PDE5 inhibitors that Pfizer launched as Viagra. It was approved by the Food and Drug Administration (FDA) in 1998 as the first oral medicine for erectile dysfunction. Later, in the year 2005, it was approved for the treatment of pulmonary arterial hypertension. Vardenafil and tadalafil were discovered in 1990. These drugs came out of research programs focusing on finding PDE5 inhibitors for the treatment of cardiovascular diseases and erectile dysfunction.The two PDE5 inhibitors soon became treatments for these conditions.\n\nTadalafil is the most versatile inhibitor and has the longest half-life, 17,5 hours. This allows for a longer therapeutic window and is therefore often a more convenient drug than others with a shorter therapeutic window. Tadalafil is more bioavailable (80%) than sildenafil (40%) and vardenafil (15%) but it has a slow absorption, or about 2 hours compared to 50 minutes of sildenfil. Vardenafil is most known for its potency.\n\nBecause of severe adverse effects and patients dissatisfaction with current therapy choices other inhibitors have recently been approved for clinical use. These inhibitors are udenfil, avanafil lodenafil and mirodenafil.\n\nPenile erection is a hemodynamic event in the smooth muscle of corpus cavernous. PDE5 is the main cGMP hydrolysing enzyme found in penile corpus cavernous. Erection is triggered by release of the neurotransmitter nitric oxide (NO) from non-adrenergic and non-cholinergic neurons from nerve ending in the penis as well as from endothelial cells. NO activates soluble guanylyl cyclase in smooth muscle cells in the penis which results in increased production of 3'-5'-cyclic guanosine monophosphate from guanosine-5'-triphosphate (GTP). Cyclic GMP binds to the cGMP-dependent protein kinase (PKG1) which phosphorylates several proteins that results in decreased intracellular calcium. Lower intracellular calcium leads to smooth muscle relaxation and ultimately penile erection. This pathway is demonstrated in .\n\nPDE5 degrades cGMP and therefore inhibits erection. As demonstrated in , inhibition of PDE5 reduces degradation of cGMP and leads to penile erection.\nBecause of this action PDE5 inhibitors have been developed for the treatment of penile erectile dysfunction.\n\nThe PDE5 enzyme has a molecular mass of 200 kDa and its active state is a homodimer. PDE5 consists of monomers and each contains two major functional domains: the regulatory domain (R domain) which is located in the N-terminal portion of the protein and the catalytic domain (C domain) located in the more C-terminal portion of the protein.\n\nThe R domain contains specific allosteric cGMP binding site that controls the enzymes function. This specific binding site consists of subdomain GAF (cGMP-specific cGMP-stimulated PDE, adenylate cyclase, and FhlA) which is located in the N-terminal section of the specific proteins. The allosteric binding site GAF consists of GAFa and GAFb where GAFa has a higher binding affinity. The importance and functional role of the two homologous binding sites are unknown.\n\nConformational change occurs when cGMP binds to the allosteric site that exposes serine and permits phosphorylation. The results for the phosphorylation of serine leads to increased cGMP hydrolysis at the catalytic domain. The affinity of the catalytic domain for cGMP increases and further increases the PDE5 catalytic domain activity.\nThrough the C domain, intracellular cGMP is degraded rapidly by PDE5 which minimizes the activity of cGMP on its PKG1 substrate by cleaving the cyclic phosphate part of cGMP to GMP. GMP is an inactive molecule with no second messenger activity.\n\nPhosphorylation of a single serine by PKG1 and the allosteric cGMP binding site activates the PDE5 catalytic activity and the result is a negative feedback regulation of cGMP/NO/PKG1 signalling. cGMP therefore interacts with both allosteric and catalytic domain of the PDE5 enzyme and PDE5 inhibitors compete with cGMP for binding at the catalytic domain resulting in higher cGMP levels. PDE5 domains are demonstrated in .\n\nThe PDE5 inhibitors sildenafil, vardenafil and tadalafil are competitive and reversible inhibitors of cGMP hydrolysis by the catalytic side of PDE5. The structures of vardenafil and sildenafil are similar, they both contain similar structured purine ring of cGMP that contributes their features to act as a competitive inhibitor of PDE5. The difference of the molecular structures is the reason for interaction with the catalytic site of PDE5 and improves the affinity of these compounds compared with cGMP selectivity.\n\nThe pharmacophore model of PDE5 usually consists of one hydrogen bond acceptor, one hydrophobic aliphatic carbon chain and two aromatic rings. Small hydrophobic pocket and H-loop of PDE5 enzyme are important for binding affinity of PDE5 inhibitors. As well as positional and conformational changes are observed upon inhibitor binding in many cases.\n\nThe active site of PDE5 is located at a helical bundle domain at the center of C domain (catalytic domain). The substrate pocket is composed of four subsites: M site (metal-binding site), Q pocket (core pocket), H pocket (hydrophobic pocket) and L region (lid region) as demonstrated in figure 3. The Q pocket accommodates the pyrazolopyrimidinone group of sildenafil. That suggest that other chemicals similar to guanidine groups of cGMP can also bind at this region. The amino acids residues, Gln817, Phe820, Val782 and Tyr612, are lined in the Q pocket, they are highly conserved in all PDEs. The amide moiety of the pyrazolopyrimidinone group forms a bidentate hydrogen bond with the ɣ-amide group of Gln817. 3D structure of sildenafil is demonstrated in figure 4.\n\nNo serious side effects have occurred in clinical trials although serious adverse effects have been recognized. For those who are taking nitrates parallel PDE5 inhibitors systemic hypotension may occur and therefore patients should not take nitrates with PDE5 inhibitors. Hearing inpairment is one risk factor for those who are using PDE5 inhibitors and it has been reported for all three available drugs on the market. This problem may be due to high level effect cGMP on cochlear hair cells. \nIt has been reported that PDE5 inhibitors (sildenafil & vardenafil) cause moderate-severe visual disturbances likely due to PDE6 inhibition, but recent large trial and case review found no increase in ocular risk in patient taking sildenafil.\n\nThese side effects can be attributed to the limited selectivity of PDE5 inhibitors against other PDE isozyme such as PDE1 and PDE6. That is why it is important to improve selectivity of PDE5 inhibitors that potentially would lead to fewer side effects. Vardenafil and Tadalafil have demonstrated reduced adverse effects probably due to improved selectivity for PDE5.\n\nSeveral reports are about approaches to improve PDE5 inhibitors, where as chemical groups have been switched out to increase potency and selectivity, which should potentially lead to drugs with fewer side effects.\n\nSildenafil, the first PDE5 inhibitor, was discovered through rational drug design programme. The compound was potent and selective over PDE5 but was lacking preferable pharmacological properties.\n\nStructure-activity relationship (SAR) is demonstrated in figure 5, figure 6 and figure 7. Figure 5 demonstrates the three main groups of sildenafil, R1, R2 and R3. R1 is the pyrazolopyrimidinone ring, R2 the ethoxyphenyl ring and R3 is the methylpiperazine ring. R1 group is responsible for the binding of the drug to its active binding site of PDE5.\nSolubility is one of the pharmacological properties that was increased. A group was substituted for the hydrogen atom as demonstrated in figure 6. The sulfonamide group was chosen to lower lipophilicity and increase solubility as seen in figure 7.\nSolubility was further increased by placing a methyl group at R positions as demonstrated in figure 7. Other phosphodiesterase-5 inhibitors were developed from the structure in figure 7.\nAlthough PDE5 inhibitors main use has been for erectile dysfunction there has been a great interest in PDE5 inhibitors as a promising new therapeutic agents for treatment of other diseases, such as Alzheimer's disease. Elevation of cGMP levels through inhibition of PDE5 provides a way of improving memory and learning.\nPDE5 has also been considered as a potential therapeutic agent for parasitic disease such as African sleeping sickness. Strategic changes were made to the structure of sildenafil so the molecule could project into a parasite-specific pocket (the p-pocket). Similar approach has been used to design therapeutic agents \"Plasmodium falciparum\".\n\n", "id": "41069188", "title": "Discovery and development of phosphodiesterase 5 inhibitors"}
{"url": "https://en.wikipedia.org/wiki?curid=54375950", "text": "The Resilience Project\n\nThe Resilience Project is a project, undertaken by the Icahn Institute for Genomics at Mount Sinai in collaboration with Sage Bionetworks.\n\nThe project seeks to identify genetic mutations that confer protection to people that have known genetic defects (which causes severe disorders with most people). Big data is used to find these genetic mutations by process of elimination.\n\nThis approach may seem weird, since the gene that is known to cause a genetic disorder could also be dealt with (head on) by just using overwriting the genetic code of this faulty gene with \"good code\" using gene therapy.\n\nHowever, there is never just one version of \"good code\" (even people that do not have a disorder, the gene that is otherwise known to cause the defect can be present with different code). So rather than having to deal with these problems, Stephen Friend decided to use a workaround method (which consists of the approach noted above).\n\nInitially, the diseases the project looked at were 170 severe, Mendelian, disorders. However, the genetic data gathered from 600 000 people was not enough(only resilient individuals of 8 of the targeted diseases were found). The list of diseases it know look at is the following::\n\nDNA sequences from 589,306 people were used, obtained from 23andMe, Beijing Genomics Institute, Broad Institute and others.\n\nCritics have argued that the researchers could not contact any of people to positively ensure that they were indeed healthy, despite having the disease mutation. Human geneticist Daniel MacArthur of the Broad Institute in Cambridge, Massachusetts still regards the study as “important as a proof-of-principle”.\n\nIn response to this criticism, Friend and Schadt have modified their Resilience Project by inviting new volunteers who agree to be recontacted to participate through a website\n\n", "id": "54375950", "title": "The Resilience Project"}
{"url": "https://en.wikipedia.org/wiki?curid=23647", "text": "Polymerase chain reaction\n\nPolymerase chain reaction (PCR) is a technique used in molecular biology to amplify a single copy or a few copies of a segment of DNA across several orders of magnitude, generating thousands to millions of copies of a particular DNA sequence. Developed in 1983 by Kary Mullis, who was an employee of the Cetus Corporation and also, the winner of Nobel Prize in Chemistry in 1993, it is an easy, cheap, and reliable way to repeatedly replicate a focused segment of DNA, a concept which is applicable to numerous fields in modern biology and related sciences. PCR is probably the most widely used technique in molecular biology. This technique is used in biomedical research, criminal forensics, and molecular archaeology. \n\nPCR is now a common and often indispensable technique used in clinical and research laboratories for a broad variety of applications. These include DNA cloning for sequencing, gene cloning and manipulation, gene mutagenesis; construction of DNA-based phylogenies, or functional analysis of genes; diagnosis and monitoring of hereditary diseases; amplification of ancient DNA; analysis of genetic fingerprints for DNA profiling (for example, in forensic science and parentage testing); and detection of pathogens in nucleic acid tests for the diagnosis of infectious diseases. In 1993, Mullis was awarded the Nobel Prize in Chemistry along with Michael Smith for his work on PCR. \n\nThe vast majority of PCR methods rely on thermal cycling, which involves exposing the reactants to cycles of repeated heating and cooling, permitting different temperature-dependent reactions—specifically, DNA melting and enzyme-driven DNA replication—to quickly proceed many times in sequence. Primers (short DNA fragments) containing sequences complementary to the target region, along with a DNA polymerase (e.g. Taq polymerase), after which the method is named, enable selective and repeated amplification. As PCR progresses, the DNA generated is itself used as a template for replication, setting in motion a chain reaction in which the original DNA template is exponentially amplified. The simplicity of the basic principle underlying PCR means it can be extensively modified to perform a wide array of genetic manipulations. PCR is not generally considered to be a recombinant DNA method, as it does not involve cutting and pasting DNA, only amplification of existing sequences.\n\nAlmost all PCR applications employ a heat-stable DNA polymerase, such as Taq polymerase, an enzyme originally isolated from the thermophilic bacterium \"Thermus aquaticus\". If heat-susceptible DNA polymerase is used, it will denature every cycle at the denaturation step. Before the use of Taq polymerase, DNA polymerase had to be manually added every cycle, which was a tedious and costly process. This DNA polymerase enzymatically assembles a new DNA strand from free nucleotides, the building blocks of DNA, by using single-stranded DNA as a template and DNA oligonucleotides (the primers mentioned above) to initiate DNA synthesis.\n\nIn the first step, the two strands of the DNA double helix are physically separated at a high temperature in a process called DNA melting. In the second step, the temperature is lowered and the two DNA strands become templates for DNA polymerase to selectively amplify the target DNA. The selectivity of PCR results from the use of primers that are complementary to sequence around the DNA region targeted for amplification under specific thermal cycling conditions.\n\nThe PCR, like recombinant DNA technology, has had an enormous impact in both basic and diagnostic aspects of molecular biology because it can produce large amounts of a specific DNA fragment from small amounts of a complex template. Recombinant DNA techniques create molecular clones by conferring on a specific sequence the ability to replicate by inserting it into a vector and introducing the vector into a host cell. PCR represents a form of “\"in vitro\" cloning” that can generate, as well as modify, DNA fragments of defined length and sequence in a simple automated reaction. In addition to its many applications in basic molecular biological research, PCR promises to play a critical role in the identification of medically important sequences as well as an important diagnostic one in their detection.\n\nPCR amplifies a specific region of a DNA strand (the DNA target). Most PCR methods amplify DNA fragments of between 0.1 and 10 kilo base pairs (kbp), although some techniques allow for amplification of fragments up to 40 kbp in size. The amount of amplified product is determined by the available substrates in the reaction, which become limiting as the reaction progresses.\n\nA basic PCR set-up requires several components and reagents, including:\n\nThe reaction is commonly carried out in a volume of 10–200 μl in small reaction tubes (0.2–0.5 ml volumes) in a thermal cycler. The thermal cycler heats and cools the reaction tubes to achieve the temperatures required at each step of the reaction (see below). Many modern thermal cyclers make use of the Peltier effect, which permits both heating and cooling of the block holding the PCR tubes simply by reversing the electric current. Thin-walled reaction tubes permit favorable thermal conductivity to allow for rapid thermal equilibration. Most thermal cyclers have heated lids to prevent condensation at the top of the reaction tube. Older thermal cyclers lacking a heated lid require a layer of oil on top of the reaction mixture or a ball of wax inside the tube.\n\nTypically, PCR consists of a series of 20–40 repeated temperature changes, called cycles, with each cycle commonly consisting of two or three discrete temperature steps (see figure below). The cycling is often preceded by a single temperature step at a very high temperature (>), and followed by one hold at the end for final product extension or brief storage. The temperatures used and the length of time they are applied in each cycle depend on a variety of parameters, including the enzyme used for DNA synthesis, the concentration of bivalent ions and dNTPs in the reaction, and the melting temperature (\"Tm\") of the primers. The individual steps common to most PCR methods are as follows:\n\n\n\n\nTo check whether the PCR successfully generated the anticipated DNA target region (also sometimes referred to as the amplimer or amplicon), agarose gel electrophoresis may be employed for size separation of the PCR products. The size(s) of PCR products is determined by comparison with a DNA ladder, a molecular weight marker which contains DNA fragments of known size run on the gel alongside the PCR products.\nAs with other chemical reactions, the reaction rate and efficiency of PCR are affected by limiting factors. Thus, the entire PCR process can further be divided into three stages based on reaction progress:\n\nIn practice, PCR can fail for various reasons, in part due to its sensitivity to contamination causing amplification of spurious DNA products. Because of this, a number of techniques and procedures have been developed for optimizing PCR conditions. Contamination with extraneous DNA is addressed with lab protocols and procedures that separate pre-PCR mixtures from potential DNA contaminants. This usually involves spatial separation of PCR-setup areas from areas for analysis or purification of PCR products, use of disposable plasticware, and thoroughly cleaning the work surface between reaction setups. Primer-design techniques are important in improving PCR product yield and in avoiding the formation of spurious products, and the usage of alternate buffer components or polymerase enzymes can help with amplification of long or otherwise problematic regions of DNA. Addition of reagents, such as formamide, in buffer systems may increase the specificity and yield of PCR. Computer simulations of theoretical PCR results (Electronic PCR) may be performed to assist in primer design.\n\nPCR allows isolation of DNA fragments from genomic DNA by selective amplification of a specific region of DNA. This use of PCR augments many ways, such as generating hybridization probes for Southern or northern hybridization and DNA cloning, which require larger amounts of DNA, representing a specific DNA region. PCR supplies these techniques with high amounts of pure DNA, enabling analysis of DNA samples even from very small amounts of starting material.\n\nOther applications of PCR include DNA sequencing to determine unknown PCR-amplified sequences in which one of the amplification primers may be used in Sanger sequencing, isolation of a DNA sequence to expedite recombinant DNA technologies involving the insertion of a DNA sequence into a plasmid, phage, or cosmid (depending on size) or the genetic material of another organism. Bacterial colonies \"(such as E. coli)\" can be rapidly screened by PCR for correct DNA vector constructs. PCR may also be used for genetic fingerprinting; a forensic technique used to identify a person or organism by comparing experimental DNAs through different PCR-based methods.\n\nSome PCR 'fingerprints' methods have high discriminative power and can be used to identify genetic relationships between individuals, such as parent-child or between siblings, and are used in paternity testing (Fig. 4). This technique may also be used to determine evolutionary relationships among organisms when certain molecular clocks are used (i.e., the 16S rRNA and recA genes of microorganisms).\n\nBecause PCR amplifies the regions of DNA that it targets, PCR can be used to analyze extremely small amounts of sample. This is often critical for forensic analysis, when only a trace amount of DNA is available as evidence. PCR may also be used in the analysis of ancient DNA that is tens of thousands of years old. These PCR-based techniques have been successfully used on animals, such as a forty-thousand-year-old mammoth, and also on human DNA, in applications ranging from the analysis of Egyptian mummies to the identification of a Russian tsar and the body of English king Richard III.\n\nQuantitative PCR (qPCR) methods allow the estimation of the amount of a given sequence present in a sample—a technique often applied to quantitatively determine levels of gene expression. Quantitative PCR is an established tool for DNA quantification that measures the accumulation of DNA product after each round of PCR amplification.\n\nqPCR allows the quantification and detection of a specific DNA sequence in real time since it measures concentration while the synthesis process is taking place. There are two methods for simultaneous detection and quantification. The first method consists of using fluorescent dyes that are retained nonspecifically in between the double strands. The second method involves probes that code for specific sequences and are fluorescently labeled. Detection of DNA using these methods can only be seen after the hybridization of probes with its complementary DNA takes place. An interesting technique combination is real-time PCR and reverse transcription (RT-qPCR). This sophisticated technique allows for the quantification of a small quantity of RNA. Through this combined technique, mRNA is converted to cDNA, which is further quantified using qPCR. This technique lowers the possibility of error at the end point of PCR, increasing chances for detection of genes associated with genetic diseases such as cancer. Laboratories use RT-qPCR for the purpose of sensitively measuring gene regulation.\n\nAfter the completion of sequencing of the first genome in 2000, the Human Genome Project, PCR has been applied to a large number of medical procedures:\n\n\nPCR allows for rapid and highly specific diagnosis of infectious diseases, including those caused by bacteria or viruses. PCR also permits identification of non-cultivatable or slow-growing microorganisms such as mycobacteria, anaerobic bacteria, or viruses from tissue culture assays and animal models. The basis for PCR diagnostic applications in microbiology is the detection of infectious agents and the discrimination of non-pathogenic from pathogenic strains by virtue of specific genes.\n\nCharacterization and detection of infectious disease organisms have been revolutionized by PCR in the following ways:\n\n\nThe development of PCR-based genetic (or DNA) fingerprinting protocols has seen widespread application in forensics:\n\n\nPCR has been applied to many areas of research in molecular genetics:\n\n\nPCR has a number of advantages. It is fairly simple to understand and to use, and produces results rapidly. The technique is highly sensitive with the potential to produce millions to billions of copies of a specific product for sequencing, cloning, and analysis. qRT-PCR shares the same advantages as the PCR, with an added advantage of quantification of the synthesized product. Therefore, it has its uses to analyze alterations of gene expression levels in tumors, microbes, or other disease states.\n\nPCR is a very powerful and practical research tool. The sequencing of unknown etiologies of many diseases are being figured out by the PCR. The technique can help identify the sequence of previously unknown viruses related to those already known and thus give us a better understanding of the disease itself. If the procedure can be further simplified and sensitive non radiometric detection systems can be developed, the PCR will assume a prominent place in the clinical laboratory for years to come.\n\nOne major limitation of PCR is that prior information about the target sequence is necessary in order to generate the primers that will allow its selective amplification.<ref name=\"10.1038/jid.2013.1\"></ref> This means that, typically, PCR users must know the precise sequence(s) upstream of the target region on each of the two single-stranded templates in order to ensure that the DNA polymerase properly binds to the primer-template hybrids and subsequently generates the entire target region during DNA synthesis.\n\nLike all enzymes, DNA polymerases are also prone to error, which in turn causes mutations in the PCR fragments that are generated.\n\nAnother limitation of PCR is that even the smallest amount of contaminating DNA can be amplified, resulting in misleading or ambiguous results. To minimize the chance of contamination, investigators should reserve separate rooms for reagent preparation, the PCR, and analysis of product. Reagents should be dispensed into single-use aliquots. Pipetters with disposable plungers and extra-long pipette tips should be routinely used.\n\n\n\nA 1971 paper in the \"Journal of Molecular Biology\" by and co-workers in the laboratory of H. Gobind Khorana first described a method using an enzymatic assay to replicate a short DNA template with primers \"in vitro\". However, this early manifestation of the basic PCR principle did not receive much attention at the time, and the invention of the polymerase chain reaction in 1983 is generally credited to Kary Mullis.\n\nWhen Mullis developed the PCR in 1983, he was working in Emeryville, California for Cetus Corporation, one of the first biotechnology companies. There, he was responsible for synthesizing short chains of DNA. Mullis has written that he conceived of PCR while cruising along the Pacific Coast Highway one night in his car. He was playing in his mind with a new way of analyzing changes (mutations) in DNA when he realized that he had instead invented a method of amplifying any DNA region through repeated cycles of duplication driven by DNA polymerase. In \"Scientific American\", Mullis summarized the procedure: \"Beginning with a single molecule of the genetic material DNA, the PCR can generate 100 billion similar molecules in an afternoon. The reaction is easy to execute. It requires no more than a test tube, a few simple reagents, and a source of heat.\" In 1988, DNA fingerprinting first become used for paternity testing in 1988.\n\nMullis was awarded the Nobel Prize in Chemistry in 1993 for his invention, seven years after he and his colleagues at Cetus first put his proposal to practice. However, some controversies have remained about the intellectual and practical contributions of other scientists to Mullis' work, and whether he had been the sole inventor of the PCR principle (see below).\n\nAt the core of the PCR method is the use of a suitable DNA polymerase able to withstand the high temperatures of > required for separation of the two DNA strands in the DNA double helix after each replication cycle. The DNA polymerases initially employed for in vitro experiments presaging PCR were unable to withstand these high temperatures. So the early procedures for DNA replication were very inefficient and time-consuming, and required large amounts of DNA polymerase and continuous handling throughout the process.\n\nThe discovery in 1976 of Taq polymerase — a DNA polymerase purified from the thermophilic bacterium, \"Thermus aquaticus\", which naturally lives in hot () environments such as hot springs — paved the way for dramatic improvements of the PCR method. The DNA polymerase isolated from \"T. aquaticus\" is stable at high temperatures remaining active even after DNA denaturation, thus obviating the need to add new DNA polymerase after each cycle. This allowed an automated thermocycler-based process for DNA amplification.\n\nThe PCR technique was patented by Kary Mullis and assigned to Cetus Corporation, where Mullis worked when he invented the technique in 1983. The \"Taq\" polymerase enzyme was also covered by patents. There have been several high-profile lawsuits related to the technique, including an unsuccessful lawsuit brought by DuPont. The pharmaceutical company Hoffmann-La Roche purchased the rights to the patents in 1992 and currently holds those that are still protected.\n\nA related patent battle over the Taq polymerase enzyme is still ongoing in several jurisdictions around the world between Roche and Promega. The legal arguments have extended beyond the lives of the original PCR and Taq polymerase patents, which expired on March 28, 2005.\n\n\n", "id": "23647", "title": "Polymerase chain reaction"}
{"url": "https://en.wikipedia.org/wiki?curid=55178557", "text": "Milk fat globule membrane\n\nMilk fat globule membrane (MFGM) is a complex and unique structure composed primarily of lipids and proteins that surrounds milk fat globule secreted from the milk producing cells of humans and other mammals. It is a source of multiple bioactive compounds, including phospholipids, glycolipids, glycoproteins, and carbohydrates that have important functional roles within the brain and gut.\n\nPreclinical studies have demonstrated effects of MFGM-derived bioactive components on brain structure and function, intestinal development, and immune defense. Similarly, pediatric clinical trials have reported beneficial effects on cognitive and immune outcomes. In populations ranging from premature infants to preschool-age children, dietary supplementation with MFGM or its components has been associated with improvements in cognition and behavior, gut and oral bacterial composition, fever incidence, and infectious outcomes including diarrhea and otitis media.\n\nMFGM may also play a role in supporting cardiovascular health by modulating cholesterol and fat uptake. Clinical trials in adult populations have shown that MFGM could positively affect markers associated with cardiovascular disease including lowering serum cholesterol and triacylglycerol levels as well as blood pressure.\n\nMilk lipids are secreted in a unique manner by lactocytes, which are specialized epithelial cells within the alveoli of the lactating mammary gland.\n\nThe process takes place in multiple stages. First, fat synthesized within the endoplasmic reticulum accumulates in droplets between the inner and outer phospholipid monolayers of the endoplasmic reticulum membrane. As these droplets increase in size, the two monolayers separate further and eventually pinch off. This leads to the surrounding of the droplet in a phospholipid monolayer that allows it to disperse within the aqueous cytoplasm. In the next stage, lipid droplets then migrate to the apical surface of the cell, where plasma membrane subsequently envelops the droplet and extrudes together with it. It fully encases the fat droplet in an additional bilayer of phospholipids. The milk fat globule thus released into the glandular lumen, measuring 3-6 μm in average diameter, is surrounded by a phospholipid trilayer containing associated proteins, carbohydrates, and lipids derived primarily from the membrane of the secreting lactocyte. This trilayer is collectively known as MFGM.\n\nThis secretion process occurs in all types of mammalian milk, including human and bovine. However, it is distinct from the lipid secretion mechanism used by all other non-mammary cells. That makes MFGM unique to milk and it is not present in non-dairy food products.\n\nMFGM is a structurally complex bioactive milk component, found in human milk as well as the milk of other mammalian species. The MFGM in human milk contains many bioactive components with diverse functions and has been linked to cognitive and health benefits to infants. Some compositional differences are reported to exist between species, but bovine MFGM, the best-studied non-human source, generally contains a lipid and protein composition, which is similar to that of human MFGM.\n\nThe content of MFGM in dairy products varies depending on the processing involved. During dairy processing such as churning or decreaming, the MFGM is disrupted and preferentially distributed into aqueous phases such as buttermilk, butter serum, or certain type of whey. Thus they can be a good source of MFGM for addition into food products.\n\nFor example, infant formulas traditionally were lacking the MFGM because this fraction is lost during regular dairy processing. However, more recent advances in technology have facilitated the separation of MFGM from the fat globule, allowing bovine MFGM to be added in concentrated form. The MFGM fraction is now commercially available and can be added to infant formula or other nutritional products.\n\nThe milk fat globule is surrounded by a phospholipid trilayer containing associated proteins, carbohydrates, and lipids derived primarily from the membrane of the secreting mammary epithelial cell (lactocyte). This trilayer is collectively known as MFGM. While MFGM only makes up an estimated 2% to 6% of the total milk fat globule, it is an especially rich phospholipid source, accounting for the majority of total milk phospholipids. In contrast, the inner core of the milk fat globule is composed predominantly of triacylglycerols.\n\nThe MFGM structure is complex and comprises a variety of phospholipids, glycolipids, proteins, and glycoproteins, along with cholesterol and other lipids. Specific lipids and proteins are localized to different layers of the membrane, with carbohydrate chains of glycoproteins and glycolipids directed toward the outer surface of the milk fat globule; the lipid-to-protein weight ratio in MFGM is approximately 1:1.\n\nHowever, the nutritional significance of these components is defined not only by their structure or macronutrient category, but also by the physiological role that each nutrient serves. As a quantitatively minor presence within milk, MFGM likely contributes little to energy production, but its constituents may confer structural and functional benefits. Many of these nutrients are known to play important functional roles within the gut, brain, and elsewhere in the body; the functions of other components are still being elucidated.\n\nThe lipid component of MFGM is rich in phospholipids, glycosphingolipids, and cholesterol. Phospholipids make up approximately 30% of the total lipid weight of MFGM, the three most prominent being sphingomyelin (SM), phosphatidylcholine (PC), and phosphatidylethanolamine (PE), which together represent up to 85% of total phospholipids. Phospholipids and sphingolipids play central roles in cerebral neurogenesis and migration during fetal development, as well as promoting neuronal growth, differentiation, and synaptogenesis during the first year of life. Other important polar lipids present in the membrane include the glycerophospholipids phosphatidylserine (PS) and phosphatidylinositol (PI), as well as gangliosides (GG), which are sphingolipids containing sialic acid and an oligosaccharide side chain. Each of these lipid classes is known to play functional roles within the body, including the support of gut, immune, and central nervous system development.\n\nBesides the polar lipids, the outer layer of MFGM contains a number of glycosylated and non-glycosylated proteins. Proteomic analysis has revealed at least 191 different known proteins in human MFGM, and comparable numbers in bovine milk protein concentrates. While quantitatively these only represent 1% to 2% of total milk protein content, MFGM proteins are of significant interest because many are known to have bioactive and potentially beneficial properties; almost half of identified proteins have membrane/protein trafficking or cell signaling functions. The glycosylated proteins, including mucins (MUC-1, MUC-4, MUC-15), butyrophilin, lactadherin, and CD36, have been suggested to enhance triacylglyceride digestion efficiency. Furthermore, lactadherin and MUC-1, in addition to the non-glycosylated protein xanthine oxidase, have been shown or suggested in preclinical studies to possess antimicrobial properties.\n\nResearch has indicated that MFGM, or components thereof, may potentially play roles in brain development and cognitive function, immunity and gut health, and cardiovascular health.\n\nMFGM lipid components such as sphingomyelin and gangliosides are highly concentrated in the brain and support synaptogenesis and myelination. In the central nervous system, sphingomyelin is a key component of the myelin sheath, which insulates axons and supports efficient transmission of nerve impulses. During myelination, nerve axons are wrapped with multiple layers of cell membrane by oligodendrocyte glial cells, a process that accounts for a large portion of brain growth during late gestation and the first two years of life, but which can also continue up to 5–10 years of age. Meanwhile, gangliosides are concentrated within the brain’s gray matter and constitute approximately 6% to 10% of the total human brain lipid mass. Additionally, gangliosides are enriched at the synaptic membrane of neurons, and are functionally involved in neurotransmission and synapse formation. Brain ganglioside accretion occurs at an accelerated rate in the early years of life, coinciding with the most active period of myelination, axonal outgrowth, and synaptogenesis.\nAlongside the growth of brain size, total brain ganglioside concentration also increases 3-fold from early fetal development to 5 years of age.\n\nA number of preclinical studies have been conducted using MFGM and combinations of MFGM-derived components. Liu et al. (2014) studied brain development and spatial learning and memory in neonatal piglets.\nPiglets that were fed with a formula containing milk phospholipids and gangliosides to mimic levels in human milk made choices more rapidly and with fewer errors in a spatial T-maze cognitive test compared to controls, implying improved spatial learning. Similarly, Vickers et al. (2009) demonstrated that administration of complex milk lipids to rats from postnatal day 10 through adulthood (day 80) led to significant improvements in learning and memory tasks compared to control animals. Conversely, a study of complex milk lipid supplementation to pregnant mice did not have an effect on cognitive tasks in their offspring.\n\nSeveral studies of diets supplemented with MFGM and its components, including gangliosides and sphingomyelin, have aimed to address measures of cognitive development in pediatric populations. In some of the studies, MFGM supplementation to infant formula was shown to narrow the gap in cognitive development between breastfed and formula-fed infants.\n\nTanaka et al. (2013) studied the neurobehavioral effects of feeding formula supplemented with sphingomyelin-enriched phospholipid in 24 very low birth weight preterm infants (birth weight <1500 g).\nIn this double-blind RCT, the preterm infants were fed either control formula containing phospholipids derived from egg yolk lecithin with sphingomyelin at 13% of total phospholipid or a supplemented formula with milk-derived phospholipids containing 20% sphingomyelin. Infants fed the supplemented formula had significantly higher percentages of sphingomyelin in total plasma phospholipids after 4, 6, and 8 weeks of feeding compared to those fed the control formula. The infants fed the supplemented formula also showed improvements across multiple developmental measures at 18 months, with significantly better scores on the Behavior Rating Scale of the Bayley Scales of Infant Development II (BSID-II), the Fagan test (novelty preference rate), the latency of visual evoked potentials (VEP), and sustained attention test than in the control group.\n\nGurnida et al. (2012) assessed the cognitive effects of formula supplemented with a ganglioside-enriched, MFGM-derived complex milk lipid in term infants. In this double-blind RCT, healthy infants (2–8 weeks of age) were fed until 6 months of age, either control infant formula (n=30), or a supplemented infant formula (n=29) with added complex milk lipids to increase ganglioside concentration to approximately 11-12 μg/mL to be within the human milk range. A breastfed reference group (n=32) was also included. Results showed that serum ganglioside levels in the supplemented group were significantly higher compared to the control group at 6 months, but did not significantly differ from levels in the breastfed group. The cognitive outcomes measured using the Griffiths Mental Development Scale showed that the supplemented group had significantly increased scores for Hand and Eye Coordination, Performance, and Total Score (General Quotient) at 6 months compared to the control group, and there were no significant differences in cognitive performance compared to the breastfed reference group.\n\nTimby et al. (2014) also assessed the potential impact of MFGM supplementation on cognitive development in term infants. In this double-blind RCT, term infants (<2 months old) were fed until 6 months of age either a control formula (n=64) or an MFGM-supplemented formula (n=71). A breastfed reference group (n=70) was also included. Cognitive assessment done using the BSID-III at 12 months of age showed that the MFGM-fed infants exhibited significantly higher mean cognitive scores than the control group (105.8 vs 101.8; P<0.008), and not significantly different from the breastfed reference group. In contrast, there were no significant differences in motor domain scores between the three groups, and both experimental and control formula groups scored lower than the reference group in the verbal domain.\n\nVeereman-Wauters et al. (2012) assessed the potential behavioral benefits of MFGM supplementation in young children. In this double-blind RCT, healthy preschool children (2.5 to 6 years of age) consumed for 4 months, either a control formula (n=97) providing 60 mg/day of endogenous phospholipid, or an MFGM-supplemented formula (n=85) providing a total of 500 mg/day of dairy-derived phospholipids. At the end of the trial, parents and teachers completed the Achenbach System of Empirically Based Assessment (ASEBA), a validated questionnaire considered to be a gold standard for assessing emotion and behavior in preschool children. Significant differences in internal, external, and total behavioral problem scores were observed in favor of the supplemented formula group, as reported by parents (but not by teachers).\n\nMFGM bioactive protein components, including the glycoproteins lactadherin, MUC-1, and butyrophilin, have been shown in preclinical studies to affect immune response. These components influence the immune system by several mechanisms, including interference with microbe adhesion to intestinal epithelia, bacteriocidal action, support of beneficial microbiota, and modulation of other parts of the immune system.\n\nMFGM phospholipid components such as phosphatidylcholine are a key constituent of the intestinal mucus barrier, and therefore may contribute to intestinal defense against invasive pathogens. Sphingolipids, including sphingomyelin, are present in the apical membrane of the gut epithelia, and are also important for maintaining membrane structure, modulating growth factor receptors, and serving competitive binding inhibitors for microorganisms, microbial toxins, and viruses. Gangliosides are also present in intestinal mucosa and may possibly contribute to improved gut microflora and antibacterial defense.\n\nMFGM may be capable of modulating immune function in the gut through distinct but potentially complementary mechanisms. Glycosylated proteins (MUC-1, MUC-15, butyrophilin, and lactadherin) and glycosylated sphingolipids from MFGM may promote the development of healthy gut microbiota by favoring beneficial Bifidobacterium species. Another key to the immunomodulatory function of MFGM may be that its structure is similar to that of the intestinal cell membrane, allowing human milk glycans (including those on glycoproteins and glycolipids) to competitively inhibit the binding of pathogens (bacteria, viruses, even toxins) to host cells.\n\nA number of preclinical studies have demonstrated inhibitory effects of MFGM against several pathogens. Both whole bovine MFGM and its extracted lipid components were found to exhibit dose-dependent inhibition of rotavirus infectivity in vitro. Antibacterial effects of MFGM have included decreased gastric colonization and inflammation after H. pylori infection in mice; inhibition of shiga toxin gene expression by E. coli O157:H7; and decreased colonization and translocation of L. monocytogenes. Mice that were fed prophylactically with bovine whey glycoprotein fraction, including MFGM proteins, did not develop diarrhea after exposure to rotavirus.\n\nThe previously described study by Timby et al. (2015) also assessed the effects of MFGM supplementation in term infants on the risk of infectious diseases and other disease symptoms. In particular, the cumulative incidence of acute otitis media was analyzed between the two randomized feeding groups (control formula or MFGM- supplemented formula to 6 months of age), and compared to a breastfed reference group. The MFGM-supplemented group experienced a significant reduction in episodes of acute otitis media up to 6 months of age compared with infants fed control formula (1% vs 9%; P=0.034); with no significant difference in otitis media incidence compared to the breastfed group (0%). In addition, a significantly lower incidence and longitudinal prevalence of antipyretic drug use was seen in the MFGM-supplemented group (25%) compared with the control formula group (43%). Timby et al. (2017) further showed that the MFGM supplementation influenced the infants’ oral microbiota; the authors noted that, Moraxella catarrhalis, a common bacterial cause of acute otitis media, was less prevalent in infants fed the MFGM-supplemented formula than in those fed control formula.\n\nZavaleta et al. (2011) evaluated the effects of an MFGM-enriched complementary food on health outcomes in term infants 6 to 11 months of age in Peru. In this double-blind RCT, 499 primarily breast-fed infants were fed for 6 months with a daily milk-based complementary food that included either whey protein concentrate enriched in MFGM, or an equal amount of additional protein from skim milk (control). Results showed that the group with the MFGM-supplemented diet had a significantly lower prevalence of diarrhea during the study compared to the control group (3.84% vs 4.37%; P<0.05), as well as a significant reduction (46%) in episodes of bloody diarrhea compared to the control group (P=0.025).\n\nThe previously described study by Veereman-Wauters et al. (2012) in preschool-age children (2.5 to 6 years old) also reported the effect of MFGM-supplemented formula consumption on health outcomes. Children receiving the MFGM-supplemented formula reported a significant reduction in the number of days with fever, and particularly the number of short febrile episodes (<3 days), compared to the control group.\n\nDietary guidelines generally recommend limiting full-fat dairy products. This recommendation has been based on traditional hypothesis that dietary saturated fatty acids, such as those derived from milk fat, have serum LDL cholesterol raising effects. Subsequently, although not demonstrated in randomized controlled trials, serum LDL cholesterol has been associated with cardiovascular disease (CVD) risk based on observational evidence. A review of observational studies has suggested that the association between milk fat intake and serum cholesterol measures could vary depending on the type of dairy products. Differential effects of various dairy foods on plasma lipids might be partly dependent on the presence of MFGM.\nMFGM lipid components may play a role in supporting cardiovascular health by modulating cholesterol and fat uptake.\n\nMFGM lipid components such as sphingolipids are involved in the intestinal uptake of cholesterol. Studies in adult rodents have shown that milk sphingomyelin could lower the intestinal absorption of cholesterol in a dose-dependent manner. Intestinal cholesterol absorption in adult rodents consuming a high fat diet was limited by sphingomyelin supplementation. Milk sphingomyelin and other phospholipids with high affinity for cholesterol could limit the micellar solubility of intestinal cholesterol, thereby limiting the cholesterol uptake by the enterocyte. Dietary sphingolipids have been shown to dose-dependently lower plasma cholesterol and triacylglycerol in adult rodents fed with Western-type diet and protect the liver from fat- and cholesterol-induced steatosis. Dietary sphingolipids also lowers hepatic cholesterol and triglyceride levels in adult rodents partly by modulating hepatic gene expression.\n\nSeveral clinical studies have shown that MFGM could positively affect circulating lipids. A single-blind RCT in overweight adults has shown that the effects of milk fat on plasma lipids were modulated by the MFGM content; compared to butter oil (control diet), consumption of whipping cream (MFGM diet) for 8 weeks did not impair the lipoprotein profile. Another double-blind RCT in overweight and obese adults has also shown that MFGM attenuated the negative effects of a high-saturated fats meal by reducing postprandial cholesterol, inflammatory markers and insulin response. A double-blind RCT in normal healthy adults has indicated that one month consumption of buttermilk rich in MFGM led to reduction in serum cholesterol and triacylglycerol levels as well as blood pressure.\n\nInterestingly, MFGM supplementation in infancy is hypothesized to have programming effects that may influence circulating lipid levels later in life. Breastfed infants are known to have a higher total serum cholesterol and LDL cholesterol than formula-fed infants in infancy, but lower levels in adulthood. A clinical study in infants has suggested that MFGM supplementation could narrow the gap between breastfed and formula-fed infants with regard to serum lipid status. Specifically, as compared with a control formula, infants receiving MFGM-supplemented formula had higher total serum cholesterol until 6 months of age, similar to breastfed infants. The LDL:HDL ratio did not differ between the formula-fed groups and was significantly higher in the breastfed reference group as compared with both formula-fed groups.\n", "id": "55178557", "title": "Milk fat globule membrane"}
{"url": "https://en.wikipedia.org/wiki?curid=2146034", "text": "CRISPR\n\nCRISPR () is a family of DNA sequences in bacteria. The sequences contain snippets of DNA from viruses that have attacked the bacterium. These snippets are used by the bacterium to detect and destroy DNA from similar viruses during subsequent attacks. These sequences play a key role in a bacterial defence system, and form the basis of a technology known as CRISPR/Cas9 that effectively and specifically changes genes within organisms.\n\nThe CRISPR/Cas system is a prokaryotic immune system that confers resistance to foreign genetic elements such as those present within plasmids and phages that provides a form of acquired immunity. RNA harboring the spacer sequence helps Cas (CRISPR-associated) proteins recognize and cut exogenous DNA. Other RNA-guided Cas proteins cut foreign RNA. CRISPRs are found in approximately 40% of sequenced bacterial genomes and 90% of sequenced archaea.\n\nCRISPR is an abbreviation of Clustered Regularly Interspaced Short Palindromic Repeats. The name was minted at a time when the origin and use of the interspacing subsequences were not known. At that time the CRISPRs were described as segments of prokaryotic DNA containing short, repetitive base sequences. In a palindromic repeat, the sequence of nucleotides is the same in both directions. Each repetition is followed by short segments of spacer DNA from previous exposures to foreign DNA (e.g., a virus or plasmid). Small clusters of \"cas\" (CRISPR-associated system) genes are located next to CRISPR sequences.\n\nA simple version of the CRISPR/Cas system, CRISPR/Cas9, has been modified to edit genomes. By delivering the Cas9 nuclease complexed with a synthetic guide RNA (gRNA) into a cell, the cell's genome can be cut at a desired location, allowing existing genes to be removed and/or new ones added. The Cas9-gRNA complex corresponds with the CAS III crRNA complex in the above diagram.\n\nCRISPR/Cas genome editing techniques have many potential applications, including medicine and crop seed enhancement. The use of CRISPR/Cas9-gRNA complex for genome editing was the AAAS's choice for breakthrough of the year in 2015. Bioethical concerns have been raised about the prospect of using CRISPR for germline editing.\n\nThe discovery of clustered DNA repeats began independently in three parts of the world. One of the first discoveries was in 1987 at Osaka University in Japan. Researcher Yoshizumi Ishino and colleagues published their findings on the sequence of a gene called \"iap\" and its relation to E. coli. Technological advances in the 1990s allowed them to continue their research and speed up their sequencing with a technique called metagenomics. They were able to collect seawater or soil samples and sequence the DNA in the sample.\n\nThe first description of what would later be called CRISPR was from Osaka University researcher Yoshizumi Ishino in 1987, who accidentally cloned part of a CRISPR together with the \"iap\" gene, the target of interest. The organization of the repeats was unusual because repeated sequences are typically arranged consecutively along DNA. The function of the interrupted clustered repeats was not known at the time.\n\nIn 1993 researchers of \"Mycobacterium tuberculosis\" in the Netherlands published two articles about a cluster of interrupted direct repeats (DR) in this bacterium. These researchers recognized the diversity of the DR-intervening sequences among different strains of \"M. tuberculosis\" and used this property to design a typing method that was named \"spoligotyping\", which is still in use today.\n\nAt the same time, repeats were observed in the archaeal organisms of \"Haloferax\" and \"Haloarcula\" species, and their function was studied by Francisco Mojica at the University of Alicante in Spain. Although his hypothesis turned out to be wrong, Mojica surmised at the time that the clustered repeats had a role in correctly segregating replicated DNA into daughter cells during cell division because plasmids and chromosomes with identical repeat arrays could not coexist in \"Haloferax volcanii\". Transcription of the interrupted repeats was also noted for the first time. By 2000, Mojica's group had identified interrupted repeats in 20 species of microbes. In 2001, Mojica and Ruud Jansen, who was searching for additional interrupted repeats, proposed the acronym CRISPR (Clustered Regularly Interspaced Short Palindromic Repeats) to alleviate the confusion stemming from the numerous acronyms used to describe the sequences in the scientific literature.\n\nA major addition to the understanding of CRISPR came with Jansen's observation that the prokaryote repeat cluster was accompanied by a set of homologous genes that make up CRISPR-associated systems or \"cas\" genes. Four \"cas\" genes (\"cas\" 1 to 4) were initially recognized. The Cas proteins showed helicase and nuclease motifs, suggesting a role in the dynamic structure of the CRISPR loci. In this publication the acronym CRISPR was coined as the universal name of this pattern. However, the CRISPR function remained enigmatic.\nIn 2005, three independent research groups showed that some CRISPR spacers are derived from phage DNA and extrachromosomal DNA such as plasmids. In effect, the spacers are fragments of DNA gathered from viruses that previously tried to attack the cell. The source of the spacers was a sign that the CRISPR/\"cas\" system could have a role in adaptive immunity in bacteria. All three studies proposing this idea were initially rejected by high-profile journals, but eventually appeared in other journals.\n\nThe first publication proposing a role of CRISPR-Cas in microbial immunity, by Mojica's group, predicted a role for the RNA transcript of spacers on target recognition in a mechanism that could be analogous to the RNA interference system used by eukaryotic cells. Therefore, as Ian Wilmut became world-famous for being the scientist who cloned Dolly, Koonin and colleagues extended this RNA interference hypothesis by proposing mechanisms of action for the different CRISPR-Cas subtypes according to the predicted function of their proteins. Others hypothesized that CRISPR sequences directed Cas enzymes to degrade viral DNA.\n\nExperimental work by several groups revealed the basic mechanisms of CRISPR-Cas immunity. In 2007 the first experimental evidence that CRISPR was an adaptive immune system was published. A CRISPR region in \"Streptococcus thermophilus\" acquired spacers from the DNA of an infecting bacteriophage. The researchers manipulated the resistance of \"S. thermophilus\" to phage by adding and deleting spacers whose sequence matched those found in the tested phages. In 2008, Brouns and colleagues identified a complex of Cas protein that in \"E. coli\" cut the CRISPR RNA within the repeats into spacer-containing RNA molecules, which remained bound to the protein complex. That year Marraffini and Sontheimer showed that a CRISPR sequence of \"S. epidermidis\" targeted DNA and not RNA to prevent conjugation. This finding was at odds with the proposed RNA-interference-like mechanism of CRISPR-Cas immunity, although a CRISPR-Cas system that targets foreign RNA was later found in \"Pyrococcus furiosus\". A 2010 study showed that CRISPR-Cas cuts both strands of phage and plasmid DNA in \"S. thermophilus\".\n\nResearchers studied a simpler CRISPR system from \"Streptococcus pyogenes\" that relies on the protein Cas9. The Cas9 endonuclease is a four-component system that includes two small RNA molecules named CRISPR RNA (crRNA) and trans-activating CRISPR RNA (tracrRNA). Jennifer Doudna and Emmanuelle Charpentier re-engineered the Cas9 endonuclease into a more manageable two-component system by fusing the two RNA molecules into a \"single-guide RNA\" that, when combined with Cas9, could find and cut the DNA target specified by the guide RNA. By manipulating the nucleotide sequence of the guide RNA, the artificial Cas9 system could be programmed to target any DNA sequence for cleavage. Another group of collaborators comprising Šikšnys together with Gasiūnas, Barrangou and Horvath showed that Cas9 from the \"S. thermophilus\" CRISPR system can also be reprogrammed to target a site of their choosing by changing the sequence of its crRNA. These advances fueled efforts to edit genomes with the modified CRISPR-Cas9 system.\n\nFeng Zhang's and George Church's groups simultaneously described genome editing in human cell cultures using CRISPR-Cas9 for the first time. It has since been used in a wide range of organisms, including baker's yeast (\"Saccharomyces cerevisiae\"), zebrafish (\"D. rerio\"), fruit flies (\"Drosophila melanogaster\"), nematodes (\"C. elegans\"), plants, mice, monkeys and human embryos.\n\nCRISPR has been modified to make programmable transcription factors that allow scientists to target and activate or silence specific genes.\n\nThe CRIPSR/Cas9 system has shown to make effective gene edits in Human tripronuclear zygotes first described in a 2015 paper by Chinese scientists P. Liang and Y. Xu. The system made a successful cleavage of mutant Beta-Hemoglobin (HBB) in 28 out of 54 embryos. 4 out of the 28 embryos were successfully recombined using a donor template given by the scientists. The scientists showed that during DNA recombination of the cleaved strand, the homologous endogenous sequence HBD competes with the exogenous donor template. DNA repair in human embryos is much more complicated and particular than in derived stem cells.\n\nIn 2015, the nuclease Cpf1 was discovered in the CRISPR/Cpf1 system of the bacterium \"Francisella novicida\". Cpf1 showed several key differences from Cas9 including: causing a 'staggered' cut in double stranded DNA as opposed to the 'blunt' cut produced by Cas9, relying on a 'T rich' PAM (providing alternate targeting sites to Cas9) and requiring only a CRISPR RNA (crRNA) for successful targeting. By contrast Cas9 requires both crRNA and a transactivating crRNA (tracrRNA). \n\nThese differences may give Cpf1 some advantages over Cas9. For example, Cpf1's small crRNAs are ideal for multiplexed genome editing, as more of them can be packaged in one vector than can Cas9's sgRNAs. As well, the sticky 5' overhangs left by Cpf1 can be used for DNA assembly that is much more target-specific than traditional Restriction Enzyme cloning. Finally, Cpf1 cleaves DNA 18-23 bp downstream from the PAM site. This means there is no disruption to the recognition sequence after repair, and so Cpf1 enables multiple rounds of DNA cleavage. By contrast, since Cas9 cuts only 3 bp upstream of the PAM site, the NHEJ pathway results in indel mutations which destroy the recognition sequence, thereby preventing further rounds of cutting. In theory, repeated rounds of DNA cleavage should cause an increased opportunity for the desired genomic editing to occur.\n\nIn the early 2000s, researchers developed zinc finger nucleases, synthetic proteins whose DNA-binding domains enable them to create double-stranded breaks in DNA at specific points. In 2010, synthetic nucleases called transcription activator-like effector nucleases (TALENs) provided an easier way to target a double-stranded break to a specific location on the DNA strand. Both zinc finger nucleases and TALENs require the creation of a custom protein for each targeted DNA sequence, which is a more difficult and time-consuming process than that for guide RNAs. CRISPRs are much easier to design because the process requires making only a short RNA sequence.\n\nThe CRISPR array comprises an AT-rich leader sequence followed by short repeats that are separated by unique spacers. CRISPR repeats typically range in size from 28 to 37 base pairs (bps), though there can be as few as 23 bp and as many as 55 bp. Some show dyad symmetry, implying the formation of a secondary structure such as a stem-loop ('hairpin') in the RNA, while others are predicted to be unstructured. The size of spacers in different CRISPR arrays is typically 32 to 38 bp (range 21 to 72 bp). New spacers can appear rapidly as part of the immune response to phage infection. There are usually fewer than 50 units of the repeat-spacer sequence in a CRISPR array.\n\nSmall clusters of \"cas\" genes are often located next to CRISPR repeat-spacer arrays. Collectively there are 93 \"cas\" genes that are grouped into 35 families based on sequence similarity of the encoded proteins. 11 of the 35 families form the \"cas\" core, which includes the protein families Cas1 through Cas9. A complete CRISPR-Cas locus has at least one gene belonging to the \"cas\" core.\n\nCRISPR-Cas systems fall into two classes. Class 1 systems use a complex of multiple Cas proteins to degrade foreign nucleic acids. Class 2 systems use a single large Cas protein for the same purpose. Class 1 is divided into types I, III, and IV; class 2 is divided into types II, V, and VI. The 6 system types are divided into 19 subtypes. Each type and most subtypes are characterized by a \"signature gene\" found almost exclusively in the category. Classification is also based on the complement of \"cas\" genes that are present. Most CRISPR-Cas systems have a Cas1 protein. The phylogeny of Cas1 proteins generally agrees with the classification system. Many organisms contain multiple CRISPR-Cas systems suggesting that they are compatible and may share components. The sporadic distribution of the CRISPR/Cas subtypes suggests that the CRISPR/Cas system is subject to horizontal gene transfer during microbial evolution.\n\nCRISPR-Cas immunity is a natural process of bacteria and archaea. CRISPR-Cas prevents bacteriophage infection, conjugation and natural transformation by degrading foreign nucleic acids that enter the cell.\n\nWhen a microbe is invaded by a virus, the first stage of the immune response is to capture viral DNA and insert it into a CRISPR locus in the form of a spacer. Cas1 and Cas2 are found in all three types of CRISPR-Cas immune systems, which indicates that they are involved in spacer acquisition. Mutation studies confirmed this hypothesis, showing that removal of cas1 or cas2 stopped spacer acquisition, without affecting CRISPR immune response.\n\nMultiple Cas1 proteins have been characterised and their structures resolved. Cas1 proteins have diverse amino acid sequences. However, their crystal structures are similar and all purified Cas1 proteins are metal-dependent nucleases/integrases that bind to DNA in a sequence-independent manner. Representative Cas2 proteins have been characterised and possess either (single strand) ssRNA- or (double strand) dsDNA- specific endoribonuclease activity.\n\nIn the I-E system of \"E. coli\" Cas1 and Cas2 form a complex where a Cas2 dimer bridges two Cas1 dimers. In this complex Cas2 performs a non-enzymatic scaffolding role, binding double-stranded fragments of invading DNA, while Cas1 binds the single-stranded flanks of the DNA and catalyses their integration into CRISPR arrays. New spacers are always added at the beginning of the CRISPR next to the leader sequence creating a chronological record of viral infections. In \"E. Coli\" a histone like protein called integration host factor (IHF), which binds to the leader sequence, is responsible for the accuracy of this integration.\n\nBioinformatic analysis of regions of phage genomes that were excised as spacers (termed protospacers) revealed that they were not randomly selected but instead were found adjacent to short (3 – 5 bp) DNA sequences termed protospacer adjacent motifs (PAM). Analysis of CRISPR-Cas systems showed PAMs to be important for type I and type II, but not type III systems during acquisition. In type I and type II systems, protospacers are excised at positions adjacent to a PAM sequence, with the other end of the spacer cut using a ruler mechanism, thus maintaining the regularity of the spacer size in the CRISPR array. The conservation of the PAM sequence differs between CRISPR-Cas systems and appears to be evolutionarily linked to Cas1 and the leader sequence.\n\nNew spacers are added to a CRISPR array in a directional manner, occurring preferentially, but not exclusively, adjacent to the leader sequence. Analysis of the type I-E system from \"E. coli\" demonstrated that the first direct repeat adjacent to the leader sequence, is copied, with the newly acquired spacer inserted between the first and second direct repeats.\n\nThe PAM sequence appears to be important during spacer insertion in type I-E systems. That sequence contains a strongly conserved final nucleotide (nt) adjacent to the first nt of the protospacer. This nt becomes the final base in the first direct repeat. This suggests that the spacer acquisition machinery generates single-stranded overhangs in the second-to-last position of the direct repeat and in the PAM during spacer insertion. However, not all CRISPR-Cas systems appear to share this mechanism as PAMs in other organisms do not show the same level of conservation in the final position. It is likely that in those systems, a blunt end is generated at the very end of the direct repeat and the protospacer during acquisition.\n\nAnalysis of \"Sulfolobus solfataricus\" CRISPRs revealed further complexities to the canonical model of spacer insertion, as one of its six CRISPR loci inserted new spacers randomly throughout its CRISPR array, as opposed to inserting closest to the leader sequence.\n\nMultiple CRISPRs contain many spacers to the same phage. The mechanism that causes this phenomenon was discovered in the type I-E system of \"E. coli\". A significant enhancement in spacer acquisition was detected where spacers already target the phage, even mismatches to the protospacer. This ‘priming’ requires the Cas proteins involved in both acquisition and interference to interact with each other. Newly acquired spacers that result from the priming mechanism are always found on the same strand as the priming spacer. This observation led to the hypothesis that the acquisition machinery slides along the foreign DNA after priming to find a new protospacer.\n\nCRISPR-RNA (crRNA), which later guides the Cas nuclease to the target during the interference step, must be generated from the CRISPR sequence. The crRNA is initially transcribed as part of a single long transcript encompassing much of the CRISPR array. This transcript is then cleaved by Cas proteins to form crRNAs. The mechanism to produce crRNAs differs among CRISPR/Cas systems. In type I-E and type I-F systems, the proteins Cas6e and Cas6f respectively, recognise stem-loops created by the pairing of identical repeats that flank the crRNA. These Cas proteins cleave the longer transcript at the edge of the paired region, leaving a single crRNA along with a small remnant of the paired repeat region.\n\nType III systems also use Cas6, however their repeats do not produce stem-loops. Cleavage instead occurs by the longer transcript wrapping around the Cas6 to allow cleavage just upstream of the repeat sequence.\n\nType II systems lack the Cas6 gene and instead utilize RNaseIII for cleavage. Functional type II systems encode an extra small RNA that is complementary to the repeat sequence, known as a trans-activating crRNA (tracrRNA). Transcription of the tracrRNA and the primary CRISPR transcript results in base pairing and the formation of dsRNA at the repeat sequence, which is subsequently targeted by RNaseIII to produce crRNAs. Unlike the other two systems the crRNA does not contain the full spacer, which is instead truncated at one end.\n\nCrRNAs associate with Cas proteins to form ribonucleotide complexes that recognize foreign nucleic acids. CrRNAs show no preference between the coding and non-coding strands, which is indicative of an RNA-guided DNA-targeting system. The type I-E complex (commonly referred to as Cascade) requires five Cas proteins bound to a single crRNA.\n\nDuring the interference stage in type I systems the PAM sequence is recognized on the crRNA-complementary strand and is required along with crRNA annealing. In type I systems correct base pairing between the crRNA and the protospacer signals a conformational change in Cascade that recruits Cas3 for DNA degradation.\n\nType II systems rely on a single multifunctional protein, Cas9, for the interference step. Cas9 requires both the crRNA and the tracrRNA to function and cleaves DNA using its dual HNH and RuvC/RNaseH-like endonuclease domains. Basepairing between the PAM and the phage genome is required in type II systems. However, the PAM is recognized on the same strand as the crRNA (the opposite strand to type I systems).\n\nType III systems, like type I require six or seven Cas proteins binding to crRNAs. The type III systems analysed from \"S. solfataricus\" and \"P. furiosus\" both target the mRNA of phages rather than phage DNA genome, which may make these systems uniquely capable of targeting RNA-based phage genomes.\n\nThe mechanism for distinguishing self from foreign DNA during interference is built into the crRNAs and is therefore likely common to all three systems. Throughout the distinctive maturation process of each major type, all crRNAs contain a spacer sequence and some portion of the repeat at one or both ends. It is the partial repeat sequence that prevents the CRISPR-Cas system from targeting the chromosome as base pairing beyond the spacer sequence signals self and prevents DNA cleavage. RNA-guided CRISPR enzymes are classified as type V restriction enzymes.\n\nA bioinformatic study has suggested that CRISPRs are evolutionarily conserved and cluster into related types. Many show signs of a conserved secondary structure.\n\nCRISPR/Cas can immunize bacteria against certain phages and thus halt transmission. For this reason, Koonin described CRISPR/Cas as a Lamarckian inheritance mechanism. However, this was disputed by a critic who noted, \"We should remember [Lamarck] for the good he contributed to science, not for things that resemble his theory only superficially. Indeed, thinking of CRISPR and other phenomena as Lamarckian only obscures the simple and elegant way evolution really works\".\n\nAnalysis of CRISPR sequences revealed coevolution of host and viral genomes. Cas9 proteins are highly enriched in pathogenic and commensal bacteria. CRISPR/Cas-mediated gene regulation may contribute to the regulation of endogenous bacterial genes, particularly during interaction with eukaryotic hosts. For example, \"Francisella novicida\" uses a unique, small, CRISPR/Cas-associated RNA (scaRNA) to repress an endogenous transcript encoding a bacterial lipoprotein that is critical for \"F. novicida\" to dampen host response and promote virulence.\n\nThe basic model of CRISPR evolution is newly incorporated spacers driving phages to mutate their genomes to avoid the bacterial immune response, creating diversity in both the phage and host populations. To fight off a phage infection, the sequence of the CRISPR spacer must correspond perfectly to the sequence of the target phage gene. Phages can continue to infect their hosts given point mutations in the spacer. Similar stringency is required in PAM or the bacterial strain remains phage sensitive.\n\nA study of 124 \"S. thermophilus\" strains showed that 26% of all spacers were unique and that different CRISPR loci showed different rates of spacer acquisition. Some CRISPR loci evolve more rapidly than others, which allowed the strains' phylogenetic relationships to be determined. A comparative genomic analysis showed that \"E. coli\" and \"S. enterica\" evolve much more slowly than \"S. thermophilus\". The latter's strains that diverged 250 thousand years ago still contained the same spacer complement.\n\nMetagenomic analysis of two acid mine drainage biofilms showed that one of the analyzed CRISPRs contained extensive deletions and spacer additions versus the other biofilm, suggesting a higher phage activity/prevalence in one community than the other. In the oral cavity, a temporal study determined that 7-22% of spacers were shared over 17 months within an individual while less than 2% were shared across individuals.\n\nFrom the same environment a single strain was tracked using PCR primers specific to its CRISPR system. Broad-level results of spacer presence/absence showed significant diversity. However, this CRISPR added 3 spacers over 17 months, suggesting that even in an environment with significant CRISPR diversity some loci evolve slowly.\n\nCRISPRs were analysed from the metagenomes produced for the human microbiome project. Although most were body-site specific, some within a body site are widely shared among individuals. One of these loci originated from streptococcal species and contained ~15,000 spacers, 50% of which were unique. Similar to the targeted studies of the oral cavity, some showed little evolution over time.\n\nCRISPR evolution was studied in chemostats using \"S. thermophilus\" to directly examine spacer acquisition rates. In one week, \"S. thermophilus\" strains acquired up to three spacers when challenged with a single phage. During the same interval the phage developed single nucleotide polymorphisms that became fixed in the population, suggesting that targeting had prevented phage replication absent these mutations.\n\nAnother \"S. thermophilus\" experiment showed that phages can infect and replicate in hosts that have only one targeting spacer. Yet another showed that sensitive hosts can exist in environments with high phage titres. The chemostat and observational studies suggest many nuances to CRISPR and phage (co)evolution.\n\nCRISPRs are widely distributed among bacteria and archaea and show some sequence similarities. Their most notable characteristic is their repeating spacers and direct repeats. This characteristic makes CRISPRs easily identifiable in long sequences of DNA, since the number of repeats decreases the likelihood of a false positive match. Three programs used for CRISPR repeat identification search for regularly interspaced repeats in long sequences: CRT, PILER-CR and CRISPRfinder.\n\nAnalysis of CRISPRs in metagenomic data is more challenging, as CRISPR loci do not typically assemble, due to their repetitive nature or through strain variation, which confuses assembly algorithms. Where many reference genomes are available, polymerase chain reaction (PCR) can be used to amplify CRISPR arrays and analyse spacer content. However, this approach yields information only for specifically targeted CRISPRs and for organisms with sufficient representation in public databases to design reliable polymerase chain reaction (PCR) primers.\n\nThe alternative is to extract and reconstruct CRISPR arrays from shotgun metagenomic data. This is computationally more difficult, particularly with second generation sequencing technologies (e.g. 454, Illumina), as the short read lengths prevent more than two or three repeat units appearing in a single read. CRISPR identification in raw reads has been achieved using purely \"de novo\" identification or by using direct repeat sequences in partially assembled CRISPR arrays from contigs (overlapping DNA segments that together represent a consensus region of DNA) and direct repeat sequences from published genomes as a hook for identifying direct repeats in individual reads.\n\nAnother way for bacteria to defend against phage infection is by having chromosomal islands. A subtype of chromosomal islands called phage-inducible chromosomal island (PICI) is excised from a bacterial chromosome upon phage infection and can inhibit phage replication. The mechanisms that induce PICI excision and how PICI inhibits phage replication are not well understood. One study showed that lytic ICP1 phage, which specifically targets \"Vibrio cholerae\" serogroup O1, has acquired a CRISPR/Cas system that targets a \"V. cholera\" PICI-like element. The system has 2 CRISPR loci and 9 Cas genes. It seems to be homologous to the 1-F system found in \"Yersinia pestis\". Moreover, like the bacterial CRISPR/Cas system, ICP1 CRISPR/Cas can acquire new sequences, which allows phage and host to co-evolve.\n\nBy the end of 2014 some 1000 research papers had been published that mentioned CRISPR. The technology had been used to functionally inactivate genes in human cell lines and cells, to study \"Candida albicans\", to modify yeasts used to make biofuels and to genetically modify crop strains. CRISPR can also be used to change mosquitos so they cannot transmit diseases such as malaria.\n\nCRISPR-based re-evaluations of claims for gene-disease relationships have led to the discovery of potentially important anomalies.\nCRISPR/Cas9 genome editing is carried out with a Type II CRISPR system. When utilized for genome editing, this system includes Cas9, crRNA, tracrRNA along with an optional section of DNA repair template that is utilized in either non-homologous end joining (NHEJ) or homology directed repair (HDR).\n\nCRISPR/Cas9 often employs a plasmid to transfect the target cells. The main components of this plasmid are displayed in the image and listed in the table. The crRNA needs to be designed for each application as this is the sequence that Cas9 uses to identify and directly bind to the cell's DNA. The crRNA must bind only where editing is desired. The repair template is designed for each application, as it must overlap with the sequences on either side of the cut and code for the insertion sequence.\n\nMultiple crRNAs and the tracrRNA can be packaged together to form a single-guide RNA (sgRNA). This sgRNA can be joined together with the Cas9 gene and made into a plasmid in order to be transfected into cells.\n\nCRISPR/Cas9 offers a high degree of fidelity and relatively simple construction. It depends on two factors for its specificity: the target sequence and the PAM. The target sequence is 20 bases long as part of each CRISPR locus in the crRNA array. A typical crRNA array has multiple unique target sequences. Cas9 proteins select the correct location on the host's genome by utilizing the sequence to bond with base pairs on the host DNA. The sequence is not part of the Cas9 protein and as a result is customizable and can be independently synthesized.\n\nThe PAM sequence on the host genome is recognized by Cas9. Cas9 cannot be easily modified to recognize a different PAM sequence. However this is not too limiting as it is a short sequence and nonspecific (e.g. the SpCas9 PAM sequence is 5'-NGG-3' and in the human genome occurs roughly every 8 to 12 base pairs).\n\nOnce these have been assembled into a plasmid and transfected into cells the Cas9 protein with the help of the crRNA finds the correct sequence in the host cell's DNA and – depending on the Cas9 variant – creates a single or double strand break in the DNA.\n\nProperly spaced single strand breaks in the host DNA can trigger homology directed repair, which is less error prone than the non-homologous end joining that typically follows a double strand break. Providing a DNA repair template allows for the insertion of a specific DNA sequence at an exact location within the genome. The repair template should extend 40 to 90 base pairs beyond the Cas9 induced DNA break. The goal is for the cell's HDR process to utilize the provided repair template and thereby incorporate the new sequence into the genome. Once incorporated, this new sequence is now part of the cell's genetic material and passes into its daughter cells.\n\nMany online tools are available to aid in designing effective sgRNA sequences.\n\nScientists can use viral or non-viral systems for delivery of the Cas9 and sgRNA into target cells. Electroporation of DNA, RNA or ribonucleocomplexes is the most common and cheapest system. This technique was used to edit CXCR4 and PD-1, knocking in new sequences to replace specific genetic \"letters\" in these proteins. The group was then able to sort the cells, using cell surface markers, to help identify successfully edited cells. Deep sequencing of a target site confirmed that knock-in genome modifications had occurred with up to ∼20% efficiency, which accounted for up to approximately one-third of total editing events. However, hard-to-transfect cells (stem cells, neurons, hematopoietic cells, etc.) require more efficient delivery systems such as those based on lentivirus (LVs), adenovirus (AdV) and adeno-associated virus (AAV).\n\nCRISPRs have been used to cut five to 62 genes at once: pig cells have been engineered to inactivate all 62 Porcine Endogenous Retroviruses in the pig genome, which eliminated transinfection from the pig to human cells in culture. CRISPR's low cost compared to alternatives is widely seen as revolutionary.\n\nSelective engineered redirection of the CRISPR/Cas system was first demonstrated in 2012 in:\n\n\nSeveral variants of CRISPR/Cas9 allow gene activation or genome editing with an external trigger such as light or small molecules. These include photoactivatable CRISPR systems developed by fusing light-responsive protein partners with an activator domain and a dCas9 for gene activation, or fusing similar light responsive domains with two constructs of split-Cas9, or by incorporating caged unnatural amino acids into Cas9, or by modifying the guide RNAs with photocleavable complements for genome editing.\n\nMethods to control genome editing with small molecules include an allosteric Cas9, with no detectable background editing, that will activate binding and cleavage upon the addition of 4-hydroxytamoxifen (4-HT), 4-HT responsive intein-linked Cas9s or a Cas9 that is 4-HT responsive when fused to four ERT2 domains. Intein-inducible split-Cas9 allows dimerization of Cas9 fragments and Rapamycin-inducible split-Cas9 system developed by fusing two constructs of split Cas9 with FRB and FKBP fragments. Furthermore, other studies have shown to induce transcription of Cas9 with a small molecule, doxycyline. Small molecules can also be used to improve Homology Directed Repair (HDR), often by inhibiting the Non-Homologous End Joining (NHEJ) pathway. These systems allow conditional control of CRISPR activity for improved precision, efficiency and spatiotemporal control.\n\nIn 2017, researchers successfully used CRISPR-Cas9 as a treatment in a mouse model of human genetic deafness, by genetically editing the DNA in some cells in the ears of live mice.\n\nUsing \"dead\" versions of Cas9 (dCas9) eliminates CRISPR's DNA-cutting ability, while preserving its ability to target desirable sequences. Multiple groups added various regulatory factors to dCas9s, enabling them to turn almost any gene on or off or adjust its level of activity. Like RNAi, CRISPR interference (CRISPRi) turns off genes in a reversible fashion by targeting, but not cutting a site. The targeted site is methylated, epigenetically modifying the gene. This modification inhibits transcription. Conversely, CRISPR-mediated activation (CRISPRa) promotes gene transcription. Cas9 is an effective way of targeting and silencing specific genes at the DNA level. In bacteria, the presence of Cas9 alone is enough to block transcription. For mammalian applications, a section of protein is added. Its guide RNA targets regulatory DNA sequences called promoters that immediately precede the target gene.\n\nCas9 was used to carry synthetic transcription factors that activated specific human genes. The technique achieved a strong effect by targeting multiple CRISPR constructs to slightly different locations on the gene's promoter.\n\nIn 2016 researchers demonstrated that CRISPR from an ordinary mouth bacterium could be used to edit RNA. The researchers searched databases containing hundreds of millions of genetic sequences for those that resembled Crispr genes. They considered the fusobacteria \"Leptotrichia shahii\". It had a group of genes that resembled CRISPR genes, but with important differences. When the researchers equipped other bacteria with these genes, which they called C2c2, they found that the organisms gained a novel defense.\n\nMany viruses encode their genetic information in RNA rather than DNA that they repurpose to make new viruses. HIV and poliovirus are such viruses. Bacteria with C2c2 make molecules that can dismember RNA, destroying the virus. Tailoring these genes opened any RNA molecule to editing.\n\nCRISPR simplifies creation of animals for research that mimic disease or show what happens when a gene is knocked down or mutated. CRISPR may be used at the germline level to create animals where the gene is changed everywhere, or it may be targeted at non-germline cells.\n\nCRISPR can be utilized to create human cellular models of disease. For instance, applied to human pluripotent stem cells CRISPR introduced targeted mutations in genes relevant to polycystic kidney disease (PKD) and focal segmental glomerulosclerosis (FSGS). These CRISPR-modified pluripotent stem cells were subsequently grown into human kidney organoids that exhibited disease-specific phenotypes. Kidney organoids from stem cells with PKD mutations formed large, translucent cyst structures from kidney tubules. The cysts were capable of reaching macroscopic dimensions, up to one centimeter in diameter. Kidney organoids with mutations in a gene linked to FSGS developed junctional defects between podocytes, the filtering cells affected in that disease. This was traced to the inability of podocytes ability to form microvilli between adjacent cells. Importantly, these disease phenotypes were absent in control organoids of identical genetic background, but lacking the CRISPR modifications.\n\nA similar approach was taken to model long QT syndrome in cardiomyocytes derived from pluripotent stem cells. These CRISPR-generated cellular models, with isogenic controls, provide a new way to study human disease and test drugs.\n\nGene drives may provide a powerful tool to restore balance of ecosystems by eliminating invasive species. Concerns regarding efficacy, unintended consequences in the target species as well as non-target species have been raised particularly in the potential for accidental release from laboratories into the wild. Scientists have proposed several safeguards for ensuring the containment of experimental gene drives including molecular, reproductive, and ecological. Many recommend that immunization and reversal drives be developed in tandem with gene drives in order to overwrite their effects if necessary. There remains consensus that long-term effects must be studied more thoroughly particularly in the potential for ecological disruption that cannot be corrected with reversal drives.\n\nCRISPR/Cas-based \"RNA-guided nucleases\" can be used to target virulence factors, genes encoding antibiotic resistance and other medically relevant sequences of interest. This technology thus represents a novel form of antimicrobial therapy and a strategy by which to manipulate bacterial populations. Recent studies suggested a correlation between the interfering of the CRISPR/Cas locus and acquisition of antibiotic resistance This system provides protection of bacteria against invading foreign DNA, such as transposons, bacteriophages and plasmids. This system was shown to be a strong selective pressure for the acquisition of antibiotic resistance and virulence factor in bacterial pathogens. Some of the affected genes are tied to human diseases, including those involved in muscle differentiation, cancer, inflammation and fetal hemoglobin.\n\nResearch suggests that CRISPR is an effective way to limit replication of multiple herpesviruses. It was able to eradicate viral DNA in the case of Epstein-Barr virus (EBV). Anti-herpesvirus CRISPRs have promising applications such as removing cancer-causing EBV from tumor cells, helping rid donated organs for immunocompromised patients of viral invaders, or preventing cold sore outbreaks and recurrent eye infections by blocking HSV-1 reactivation. As of August 2016, these were awaiting testing. CRISPR is being applied to develop tissue-based treatments for cancer and other diseases.\n\nCRISPR may revive the concept of transplanting animal organs into people. Retroviruses present in animal genomes could harm transplant recipients. In 2015 a team eliminated 62 copies of a retrovirus's DNA from the pig genome in a kidney epithelial cell. Researchers recently demonstrated the ability to birth live pig specimens after removing these retroviruses from their genome using CRISPR for the first time.\n\nCRISPR may have applications in tissue engineering and regenerative medicine, such as by creating human blood vessels that lack expression of MHC class II proteins, which often cause transplant rejection.\n\nAs of 2016 CRISPR had been studied in animal models and cancer cell lines, to learn if it can be used to repair or thwart mutated genes that cause cancer.\n\nThe first clinical trial involving CRISPR started in 2016. It involved removing immune cells from people with lung cancer, using CRISPR to edit out the gene expressed PD-1, then administrating the altered cells back to the same person. 20 other trials were under way or nearly ready, mostly in China, as of 2017.\n\nIn 2016 the United States Food and Drug Administration (FDA) approved a clinical trial in which CRISPR would be used to alter T cells extracted from people with different kinds of cancer and then administer those engineered T cells back to the same people.\n\nIn 2015, multiple studies attempted to systematically disable each individual human gene, in an attempt to identify which genes were essential to human biology. Between 1,600 and 1,800 genes passed this test—of the 20,000 or so known human genes. Such genes are more strongly activated, and unlikely to carry disabling mutations. They are more likely to have indispensable counterparts in other species. They build proteins that unite to form larger collaborative complexes. The studies also catalogued the essential genes in four cancer-cell lines and identified genes that are expendable in healthy cells, but crucial in specific tumor types and drugs that could target these rogue genes.\n\nThe specific functions of some 18 percent of the essential genes are unidentified. In one 2015 targeting experiment, disabling individual genes in groups of cells attempted to identify those involved in resistance to a melanoma drug. Each such gene manipulation is itself a separate \"drug\", potentially opening the entire genome to CRISPR-based regulation.\n\nIn 2016-2017, a CRISPR/Cas-based approach to genetically engineering adult rodent brains \"in vivo\" was successfully demonstrated.\n\nUnenriched sequencing libraries often have abundant undesired sequences. Cas9 can specifically deplete the undesired sequences with double strand breakage with up to 99% efficiency and without significant off-target effects as seen with restriction enzymes. Treatment with Cas9 can deplete abundant rRNA while increasing pathogen sensitivity in RNA-seq libraries.\n\nAs of December 2014, patent rights to CRISPR were contested. Several companies formed to develop related drugs and research tools. As companies ramp up financing, doubts as to whether CRISPR can be quickly monetized were raised. In February 2017 the US Patent Office ruled on a patent interference case brought by University of California with respect to patents issued to the Broad Institute, and found that the Broad patents, with claims covering the application of CRISPR/cas9 in eukaryotic cells, were distinct from the inventions claimed by University of California.\nShortly after, University of California filed an appeal of this ruling.\n\nAs of November 2013, SAGE Labs (part of Horizon Discovery group) had exclusive rights from one of those companies to produce and sell genetically engineered rats and non-exclusive rights for mouse and rabbit models. , Thermo Fisher Scientific had licensed intellectual property from ToolGen to develop CRISPR reagent kits.\n\nIn March 2017, the European Patent Office (EPO) announced its intention to allow claims to Max-Planck Institute in Berlin, University of California, and University of Vienna, and in August 2017, the EPO announced its intention to allow CRISPR claims in a patent application that MilliporeSigma had filed. As of August 2017 the patent situation in Europe was complex, with MilliporeSigma, ToolGen, Vilnius University, and Harvard contending for claims, along with University of California and Broad.\n\nAt least four labs in the US, labs in China and the UK, and a US biotechnology company called Ovascience announced plans or ongoing research to apply CRISPR to human embryos. Scientists, including a CRISPR co-inventor, urged a worldwide moratorium on applying CRISPR to the human germline, especially for clinical use. They said \"scientists should avoid even attempting, in lax jurisdictions, germline genome modification for clinical application in humans\" until the full implications \"are discussed among scientific and governmental organizations\". These scientists support basic research on CRISPR and do not see CRISPR as developed enough for any clinical use in making heritable changes to humans.\n\nIn April 2015, Chinese scientists reported results of an attempt to alter the DNA of non-viable human embryos using CRISPR to correct a mutation that causes beta thalassemia, a lethal heritable disorder. The study had previously been rejected by both \"Nature\" and \"Science\" in part because of ethical concerns. The experiments resulted in changing only some genes, and had off-target effects on other genes. The researchers stated that CRISPR is not ready for clinical application in reproductive medicine. In April 2016 Chinese scientists were reported to have made a second unsuccessful attempt to alter the DNA of non-viable human embryos using CRISPR - this time to alter the CCR5 gene to make the embryo HIV resistant.\n\nIn December 2015, an International Summit on Human Gene Editing took place in Washington under the guidance of David Baltimore. Members of national scientific academies of America, Britain and China discussed the ethics of germline modification. They agreed to support basic and clinical research under appropriate legal and ethical guidelines. A specific distinction was made between somatic cells, where the effects of edits are limited to a single individual, versus germline cells, where genome changes could be inherited by future generations. Heritable modifications could have unintended and far-reaching consequences for human evolution, genetically (e.g. gene/environment interactions) and culturally (e.g. Social Darwinism). Altering of gametocytes and embryos to generate inheritable changes in humans was defined to be irresponsible. The group agreed to initiate an international forum to address such concerns and harmonize regulations across countries.\n\nPolicy regulations for the CRISPR/cas9 system vary around the globe. In February 2016, British scientists were given permission by regulators to genetically modify human embryos by using CRISPR-Cas9 and related techniques. However, researchers were forbidden from implanting the embryos and the embryos were to be destroyed after seven days.\n\nThe US has an elaborate, interdepartmental regulatory system to evaluate new genetically modified foods and crops. For example, the Agriculture Risk Protection Act of 2000 gives the USDA the authority to oversee the detection, control, eradication, suppression, prevention, or retardation of the spread of plant pests or noxious weeds to protect the agriculture, environment and economy of the US. The act regulates any genetically modified organism that utilizes the genome of a predefined 'plant pest' or any plant not previously categorized. In 2015, Yang successfully deactivated 16 specific genes in the white button mushroom. Since he had not added any foreign DNA to his organism, the mushroom could not be regulated under by the USDA under Section 340.2. Yang's white button mushroom was the first organism genetically modified with the Crispr/cas9 protein system to pass US regulation. In 2016, the USDA sponsored a committee to consider future regulatory policy for upcoming genetic modification techniques. With the help of the US National Academies of Sciences, Engineering and Medicine, special interests groups met on April 15 to contemplate the possible advancements in genetic engineering within the next 5 years and potential policy regulations that would need to come into play. With the emergence of rogue genetic engineers employing the technology, the FDA has begun issuing new regulations.\n\nIn China, where social conditions sharply contrast both the USA and England, genetic diseases carry a heavy stigma, individuals with mental and physical disabilities do not get much federal or public support and religiously there are no barriers against the use of genetic modifications to change the genotypes of their people. This leaves China with far fewer policy barriers and an advantage over the use of the technology. Time will tell what direction they choose to take, one thing is for certain, China has many policies to consider.\n\nIn 2012 and 2013, CRISPR was a runner-up in \"Science Magazine\"'s Breakthrough of the Year award. In 2015, it was the winner of that award. CRISPR was named as one of \"MIT Technology Review\"s 10 breakthrough technologies in 2014 and 2016. In 2016, Jennifer Doudna, Emmanuel Charpentier, along with Rudolph Barrangou, Philippe Horvath, and Feng Zhang won the Gairdner International award. In 2017, Jennifer Doudna and Emmanuel Charpentier were awarded the Japan Prize for their revolutionary invention of CRISPR-Cas9 in Tokyo, Japan.\n\n", "id": "2146034", "title": "CRISPR"}
{"url": "https://en.wikipedia.org/wiki?curid=6910", "text": "Cloning\n\nIn biology, cloning is the process of producing similar populations of genetically identical individuals that occurs in nature when organisms such as bacteria, insects,plants or animals reproduce asexually. Cloning in biotechnology refers to processes used to create copies of DNA fragments (molecular cloning), cells (cell cloning), or organisms (organism cloning). The term also refers to the production of multiple copies of a product such as digital media or software.\n\nThe term clone, invented by J. B. S. Haldane, is derived from the Ancient Greek word κλών \"klōn\", \"twig\", referring to the process whereby a new plant can be created from a twig. In horticulture, the spelling \"clon\" was used until the twentieth century; the final \"e\" came into use to indicate the vowel is a \"long o\" instead of a \"short o\". Since the term entered the popular lexicon in a more general context, the spelling \"clone\" has been used exclusively.\n\nIn botany, the term lusus was traditionally used.\n\nCloning is a natural form of reproduction that has allowed life forms to spread for more than 50 thousand years. It is the reproduction method used by plants, fungi, and bacteria, and is also the way that clonal colonies reproduce themselves. Examples of these organisms include blueberry plants, hazel trees, the Pando trees, the Kentucky coffeetree, \"Myrica\"s, and the American sweetgum.\n\nMolecular cloning refers to the process of making multiple molecules. Cloning is commonly used to amplify DNA fragments containing whole genes, but it can also be used to amplify any DNA sequence such as promoters, non-coding sequences and randomly fragmented DNA. It is used in a wide array of biological experiments and practical applications ranging from genetic fingerprinting to large scale protein production. Occasionally, the term cloning is misleadingly used to refer to the identification of the chromosomal location of a gene associated with a particular phenotype of interest, such as in positional cloning. In practice, localization of the gene to a chromosome or genomic region does not necessarily enable one to isolate or amplify the relevant genomic sequence. To amplify any DNA sequence in a living organism, that sequence must be linked to an origin of replication, which is a sequence of DNA capable of directing the propagation of itself and any linked sequence. However, a number of other features are needed, and a variety of specialised cloning vectors (small piece of DNA into which a foreign DNA fragment can be inserted) exist that allow protein production, affinity tagging, single stranded RNA or DNA production and a host of other molecular biology tools.\n\nCloning of any DNA fragment essentially involves four steps\n\nAlthough these steps are invariable among cloning procedures a number of alternative routes can be selected; these are summarized as a \"cloning strategy\".\n\nInitially, the DNA of interest needs to be isolated to provide a DNA segment of suitable size. Subsequently, a ligation procedure is used where the amplified fragment is inserted into a vector (piece of DNA). The vector (which is frequently circular) is linearised using restriction enzymes, and incubated with the fragment of interest under appropriate conditions with an enzyme called DNA ligase. Following ligation the vector with the insert of interest is transfected into cells. A number of alternative techniques are available, such as chemical sensitivation of cells, electroporation, optical injection and biolistics. Finally, the transfected cells are cultured. As the aforementioned procedures are of particularly low efficiency, there is a need to identify the cells that have been successfully transfected with the vector construct containing the desired insertion sequence in the required orientation. Modern cloning vectors include selectable antibiotic resistance markers, which allow only cells in which the vector has been transfected, to grow. Additionally, the cloning vectors may contain colour selection markers, which provide blue/white screening (alpha-factor complementation) on X-gal medium. Nevertheless, these selection steps do not absolutely guarantee that the DNA insert is present in the cells obtained. Further investigation of the resulting colonies must be required to confirm that cloning was successful. This may be accomplished by means of PCR, restriction fragment analysis and/or DNA sequencing.\n\nCloning a cell means to derive a population of cells from a single cell. In the case of unicellular organisms such as bacteria and yeast, this process is remarkably simple and essentially only requires the inoculation of the appropriate medium. However, in the case of cell cultures from multi-cellular organisms, cell cloning is an arduous task as these cells will not readily grow in standard media.\n\nA useful tissue culture technique used to clone distinct lineages of cell lines involves the use of cloning rings (cylinders). In this technique a single-cell suspension of cells that have been exposed to a mutagenic agent or drug used to drive selection is plated at high dilution to create isolated colonies, each arising from a single and potentially clonal distinct cell. At an early growth stage when colonies consist of only a few cells, sterile polystyrene rings (cloning rings), which have been dipped in grease, are placed over an individual colony and a small amount of trypsin is added. Cloned cells are collected from inside the ring and transferred to a new vessel for further growth.\n\nSomatic-cell nuclear transfer, known as SCNT, can also be used to create embryos for research or therapeutic purposes. The most likely purpose for this is to produce embryos for use in stem cell research. This process is also called \"research cloning\" or \"therapeutic cloning.\" The goal is not to create cloned human beings (called \"reproductive cloning\"), but rather to harvest stem cells that can be used to study human development and to potentially treat disease. While a clonal human blastocyst has been created, stem cell lines are yet to be isolated from a clonal source.\n\nTherapeutic cloning is achieved by creating embryonic stem cells in the hopes of treating diseases such as diabetes and Alzheimer's. The process begins by removing the nucleus (containing the DNA) from an egg cell and inserting a nucleus from the adult cell to be cloned. In the case of someone with Alzheimer's disease, the nucleus from a skin cell of that patient is placed into an empty egg. The reprogrammed cell begins to develop into an embryo because the egg reacts with the transferred nucleus. The embryo will become genetically identical to the patient. The embryo will then form a blastocyst which has the potential to form/become any cell in the body.\n\nThe reason why SCNT is used for cloning is because somatic cells can be easily acquired and cultured in the lab. This process can either add or delete specific genomes of farm animals. A key point to remember is that cloning is achieved when the oocyte maintains its normal functions and instead of using sperm and egg genomes to replicate, the oocyte is inserted into the donor’s somatic cell nucleus. The oocyte will react on the somatic cell nucleus, the same way it would on sperm cells.\n\nThe process of cloning a particular farm animal using SCNT is relatively the same for all animals. The first step is to collect the somatic cells from the animal that will be cloned. The somatic cells could be used immediately or stored in the laboratory for later use. The hardest part of SCNT is removing maternal DNA from an oocyte at metaphase II. Once this has been done, the somatic nucleus can be inserted into an egg cytoplasm. This creates a one-cell embryo. The grouped somatic cell and egg cytoplasm are then introduced to an electrical current. This energy will hopefully allow the cloned embryo to begin development. The successfully developed embryos are then placed in surrogate recipients, such as a cow or sheep in the case of farm animals.\n\nSCNT is seen as a good method for producing agriculture animals for food consumption. It successfully cloned sheep, cattle, goats, and pigs. Another benefit is SCNT is seen as a solution to clone endangered species that are on the verge of going extinct. However, stresses placed on both the egg cell and the introduced nucleus can be enormous, which led to a high loss in resulting cells in early research. For example, the cloned sheep Dolly was born after 277 eggs were used for SCNT, which created 29 viable embryos. Only three of these embryos survived until birth, and only one survived to adulthood. As the procedure could not be automated, and had to be performed manually under a microscope, SCNT was very resource intensive. The biochemistry involved in reprogramming the differentiated somatic cell nucleus and activating the recipient egg was also far from being well understood. However, by 2014 researchers were reporting cloning success rates of seven to eight out of ten and in 2016, a Korean Company Sooam Biotech was reported to be producing 500 cloned embryos per day.\n\nIn SCNT, not all of the donor cell's genetic information is transferred, as the donor cell's mitochondria that contain their own mitochondrial DNA are left behind. The resulting hybrid cells retain those mitochondrial structures which originally belonged to the egg. As a consequence, clones such as Dolly that are born from SCNT are not perfect copies of the donor of the nucleus.\n\nOrganism cloning (also called reproductive cloning) refers to the procedure of creating a new multicellular organism, genetically identical to another. In essence this form of cloning is an asexual method of reproduction, where fertilization or inter-gamete contact does not take place. Asexual reproduction is a naturally occurring phenomenon in many species, including most plants (see vegetative reproduction) and some insects. Scientists have made some major achievements with cloning, including the asexual reproduction of sheep and cows. There is a lot of ethical debate over whether or not cloning should be used. However, cloning, or asexual propagation, has been common practice in the horticultural world for hundreds of years.\n\nThe term \"clone\" is used in horticulture to refer to descendants of a single plant which were produced by vegetative reproduction or apomixis. Many horticultural plant cultivars are clones, having been derived from a single individual, multiplied by some process other than sexual reproduction. As an example, some European cultivars of grapes represent clones that have been propagated for over two millennia. Other examples are potato and banana. Grafting can be regarded as cloning, since all the shoots and branches coming from the graft are genetically a clone of a single individual, but this particular kind of cloning has not come under ethical scrutiny and is generally treated as an entirely different kind of operation.\n\nMany trees, shrubs, vines, ferns and other herbaceous perennials form clonal colonies naturally. Parts of an individual plant may become detached by fragmentation and grow on to become separate clonal individuals. A common example is in the vegetative reproduction of moss and liverwort gametophyte clones by means of gemmae. Some vascular plants e.g. dandelion and certain viviparous grasses also form seeds asexually, termed apomixis, resulting in clonal populations of genetically identical individuals.\n\nClonal derivation exists in nature in some animal species and is referred to as parthenogenesis (reproduction of an organism by itself without a mate). This is an asexual form of reproduction that is only found in females of some insects, crustaceans, nematodes, fish (for example the hammerhead shark), the Komodo dragon and lizards. The growth and development occurs without fertilization by a male. In plants, parthenogenesis means the development of an embryo from an unfertilized egg cell, and is a component process of apomixis. In species that use the XY sex-determination system, the offspring will always be female. An example is the little fire ant (\"Wasmannia auropunctata\"), which is native to Central and South America but has spread throughout many tropical environments.\n\nArtificial cloning of organisms may also be called \"reproductive cloning\".\n\nHans Spemann, a German embryologist was awarded a Nobel Prize in Physiology or Medicine in 1935 for his discovery of the effect now known as embryonic induction, exercised by various parts of the embryo, that directs the development of groups of cells into particular tissues and organs. In 1928 he and his student, Hilde Mangold, were the first to perform somatic-cell nuclear transfer using amphibian embryos – one of the first steps towards cloning.\n\nReproductive cloning generally uses \"somatic cell nuclear transfer\" (SCNT) to create animals that are genetically identical. This process entails the transfer of a nucleus from a donor adult cell (somatic cell) to an egg from which the nucleus has been removed, or to a cell from a blastocyst from which the nucleus has been removed. If the egg begins to divide normally it is transferred into the uterus of the surrogate mother. Such clones are not strictly identical since the somatic cells may contain mutations in their nuclear DNA. Additionally, the mitochondria in the cytoplasm also contains DNA and during SCNT this mitochondrial DNA is wholly from the cytoplasmic donor's egg, thus the mitochondrial genome is not the same as that of the nucleus donor cell from which it was produced. This may have important implications for cross-species nuclear transfer in which nuclear-mitochondrial incompatibilities may lead to death.\n\nArtificial \"embryo splitting\" or \"embryo twinning\", a technique that creates monozygotic twins from a single embryo, is not considered in the same fashion as other methods of cloning. During that procedure, a donor embryo is split in two distinct embryos, that can then be transferred via embryo transfer. It is optimally performed at the 6- to 8-cell stage, where it can be used as an expansion of IVF to increase the number of available embryos. If both embryos are successful, it gives rise to monozygotic (identical) twins.\n\nDolly, a Finn-Dorset ewe, was the first mammal to have been successfully cloned from an adult somatic cell. Dolly was formed by taking a cell from the udder of her 6-year old biological mother. Dolly's embryo was created by taking the cell and inserting it into a sheep ovum. It took 434 attempts before an embryo was successful. The embryo was then placed inside a female sheep that went through a normal pregnancy. She was cloned at the Roslin Institute in Scotland by British scientists Sir Ian Wilmut and Keith Campbell and lived there from her birth in 1996 until her death in 2003 when she was six. She was born on 5 July 1996 but not announced to the world until 22 February 1997. Her stuffed remains were placed at Edinburgh's Royal Museum, part of the National Museums of Scotland.\n\nDolly was publicly significant because the effort showed that genetic material from a specific adult cell, programmed to express only a distinct subset of its genes, can be reprogrammed to grow an entirely new organism. Before this demonstration, it had been shown by John Gurdon that nuclei from differentiated cells could give rise to an entire organism after transplantation into an enucleated egg. However, this concept was not yet demonstrated in a mammalian system.\n\nThe first mammalian cloning (resulting in Dolly the sheep) had a success rate of 29 embryos per 277 fertilized eggs, which produced three lambs at birth, one of which lived. In a bovine experiment involving 70 cloned calves, one-third of the calves died young. The first successfully cloned horse, Prometea, took 814 attempts. Notably, although the first clones were frogs, no adult cloned frog has yet been produced from a somatic adult nucleus donor cell.\n\nThere were early claims that Dolly the sheep had pathologies resembling accelerated aging. Scientists speculated that Dolly's death in 2003 was related to the shortening of telomeres, DNA-protein complexes that protect the end of linear chromosomes. However, other researchers, including Ian Wilmut who led the team that successfully cloned Dolly, argue that Dolly's early death due to respiratory infection was unrelated to deficiencies with the cloning process. This idea that the nuclei have not irreversibly aged was shown in 2013 to be true for mice.\n\nDolly was named after performer Dolly Parton because the cells cloned to make her were from a mammary gland cell, and Parton is known for her ample cleavage.\n\nThe modern cloning techniques involving nuclear transfer have been successfully performed on several species. Notable experiments include:\n\nHuman cloning is the creation of a genetically identical copy of a human. The term is generally used to refer to artificial human cloning, which is the reproduction of human cells and tissues. It does not refer to the natural conception and delivery of identical twins. The possibility of human cloning has raised controversies. These ethical concerns have prompted several nations to pass legislature regarding human cloning and its legality.\n\nTwo commonly discussed types of theoretical human cloning are \"therapeutic cloning\" and \"reproductive cloning\". Therapeutic cloning would involve cloning cells from a human for use in medicine and transplants, and is an active area of research, but is not in medical practice anywhere in the world, as of 2014. Two common methods of therapeutic cloning that are being researched are somatic-cell nuclear transfer and, more recently, pluripotent stem cell induction. Reproductive cloning would involve making an entire cloned human, instead of just specific cells or tissues.\n\nThere are a variety of ethical positions regarding the possibilities of cloning, especially human cloning. While many of these views are religious in origin, the questions raised by cloning are faced by secular perspectives as well. Perspectives on human cloning are theoretical, as human therapeutic and reproductive cloning are not commercially used; animals are currently cloned in laboratories and in livestock production.\n\nAdvocates support development of therapeutic cloning in order to generate tissues and whole organs to treat patients who otherwise cannot obtain transplants, to avoid the need for immunosuppressive drugs, and to stave off the effects of aging. Advocates for reproductive cloning believe that parents who cannot otherwise procreate should have access to the technology.\n\nOpponents of cloning have concerns that technology is not yet developed enough to be safe and that it could be prone to abuse (leading to the generation of humans from whom organs and tissues would be harvested), as well as concerns about how cloned individuals could integrate with families and with society at large.\n\nReligious groups are divided, with some opposing the technology as usurping \"God's place\" and, to the extent embryos are used, destroying a human life; others support therapeutic cloning's potential life-saving benefits.\n\nCloning of animals is opposed by animal-groups due to the number of cloned animals that suffer from malformations before they die, and while food from cloned animals has been approved by the US FDA, its use is opposed by groups concerned about food safety.\n\nCloning, or more precisely, the reconstruction of functional DNA from extinct species has, for decades, been a dream. Possible implications of this were dramatized in the 1984 novel \"Carnosaur\" and the 1990 novel \"Jurassic Park\". The best current cloning techniques have an average success rate of 9.4 percent (and as high as 25 percent) when working with familiar species such as mice, while cloning wild animals is usually less than 1 percent successful. Several tissue banks have come into existence, including the \"Frozen Zoo\" at the San Diego Zoo, to store frozen tissue from the world's rarest and most endangered species.\n\nIn 2001, a cow named Bessie gave birth to a cloned Asian gaur, an endangered species, but the calf died after two days. In 2003, a banteng was successfully cloned, followed by three African wildcats from a thawed frozen embryo. These successes provided hope that similar techniques (using surrogate mothers of another species) might be used to clone extinct species. Anticipating this possibility, tissue samples from the last \"bucardo\" (Pyrenean ibex) were frozen in liquid nitrogen immediately after it died in 2000. Researchers are also considering cloning endangered species such as the giant panda and cheetah.\n\nIn 2002, geneticists at the Australian Museum announced that they had replicated DNA of the thylacine (Tasmanian tiger), at the time extinct for about 65 years, using polymerase chain reaction. However, on 15 February 2005 the museum announced that it was stopping the project after tests showed the specimens' DNA had been too badly degraded by the (ethanol) preservative. On 15 May 2005 it was announced that the thylacine project would be revived, with new participation from researchers in New South Wales and Victoria.\n\nIn January 2009, for the first time, an extinct animal, the Pyrenean ibex mentioned above was cloned, at the Centre of Food Technology and Research of Aragon, using the preserved frozen cell nucleus of the skin samples from 2001 and domestic goat egg-cells. The ibex died shortly after birth due to physical defects in its lungs.\n\nOne of the most anticipated targets for cloning was once the woolly mammoth, but attempts to extract DNA from frozen mammoths have been unsuccessful, though a joint Russo-Japanese team is currently working toward this goal. In January 2011, it was reported by Yomiuri Shimbun that a team of scientists headed by Akira Iritani of Kyoto University had built upon research by Dr. Wakayama, saying that they will extract DNA from a mammoth carcass that had been preserved in a Russian laboratory and insert it into the egg cells of an African elephant in hopes of producing a mammoth embryo. The researchers said they hoped to produce a baby mammoth within six years. It was noted, however that the result, if possible, would be an elephant-mammoth hybrid rather than a true mammoth. Another problem is the survival of the reconstructed mammoth: ruminants rely on a symbiosis with specific microbiota in their stomachs for digestion.\n\nScientists at the University of Newcastle and University of New South Wales announced in March 2013 that the very recently extinct gastric-brooding frog would be the subject of a cloning attempt to resurrect the species.\n\nMany such \"de-extinction\" projects are described in the Long Now Foundation's Revive and Restore Project.\n\nAfter an eight-year project involving the use of a pioneering cloning technique, Japanese researchers created 25 generations of healthy cloned mice with normal lifespans, demonstrating that clones are not intrinsically shorter-lived than naturally born animals. Other sources have noted that the offspring of clones tend to be healthier than the original clones and indistinguishable from animals produced naturally.\n\nIn a detailed study released in 2016 and less detailed studies by others suggest that once cloned animals get past the first month or two of life they are generally healthy. However, early pregnancy loss and neonatal losses are still greater with cloning than natural conception or assisted reproduction (IVF). Current research endeavors are attempting to overcome this problem.\n\nDiscussion of cloning in the popular media often presents the subject negatively. In an article in the 8 November 1993 article of \"Time\", cloning was portrayed in a negative way, modifying Michelangelo's \"Creation of Adam\" to depict Adam with five identical hands. \"Newsweek\"'s 10 March 1997 issue also critiqued the ethics of human cloning, and included a graphic depicting identical babies in beakers.\n\nThe concept of cloning has featured a wide variety of science fiction works. An early fictional depiction of cloning is Bokanovsky's Process which features in Aldous Huxley's 1931 dystopian novel \"Brave New World\". The process is applied to fertilized human eggs \"in vitro\", causing them to split into identical genetic copies of the original. Following renewed interest in cloning in the 1950s, the subject was explored further in works such as Poul Anderson's 1953 story \"UN-Man\", which describes a technology called \"exogenesis\", and Gordon Rattray Taylor's book \"The Biological Time Bomb\", which popularised the term \"cloning\" in 1963.\n\nCloning is a recurring theme in a number of contemporary science fiction films, ranging from action films such as \"Jurassic Park\" (1993), \"Alien Resurrection\" (1997), \"The 6th Day\" (2000), \"Resident Evil\" (2002), \"\" (2002) and \"The Island\" (2005), to comedies such as Woody Allen's 1973 film \"Sleeper\".\n\nThe process of cloning is represented in different ways in fiction. Many works depict the artificial creation of humans by a method of growing cells from a tissue or DNA sample; the process may instantaneous, or take place through a slow process of growing human embryos in artificial wombs. Science fiction films such as \"The Matrix\" and \"Star Wars: Episode II – Attack of the Clones\" have featured scenes of human foetuses being cultured on an industrial scale in mechanical tanks. In the long-running British television series \"Doctor Who\", the Fourth Doctor and his companion Leela were cloned in a matter of seconds from DNA samples (\"The Invisible Enemy\", 1977) and then — in an apparent homage to the 1966 film \"Fantastic Voyage\" — shrunk to microscopic size in order to enter the Doctor's body to combat an alien virus. The clones in this story are short-lived, and can only survive a matter of minutes before they expire.\n\nCloning humans from body parts is also a common theme in science fiction. Cloning features strongly among the science fiction conventions parodied in Woody Allen's \"Sleeper\", the plot of which centres around an attempt to clone an assassinated dictator from his disembodied nose. In the 2008 \"Doctor Who\" story \"Journey's End\", a duplicate version of the Tenth Doctor spontaneously grows from his severed hand, which had been cut off in a sword fight during an earlier episode.\n\nScience fiction has used cloning, most commonly and specifically human cloning, due to the fact that it brings up controversial questions of identity. \"A Number\" is a 2002 play by English playwright Caryl Churchill which addresses the subject of human cloning and identity, especially nature and nurture. The story, set in the near future, is structured around the conflict between a father (Salter) and his sons (Bernard 1, Bernard 2, and Michael Black) – two of whom are clones of the first one. \"A Number\" was adapted by Caryl Churchill for television, in a co-production between the BBC and HBO Films.\n\nIn 2012, a Japanese television series named \"Bunshin\" was created. The story's main character, Mariko, is a woman studying child welfare in Hokkaido. She grew up always doubtful about the love from her mother, who looked nothing like her and who died nine years before. One day, she finds some of her mother's belongings at a relative's house, and heads to Tokyo to seek out the truth behind her birth. She later discovered that she was a clone.\n\nIn the 2013 television series \"Orphan Black\", cloning is used as a scientific study on the behavioral adaptation of the clones. In a similar vein, the book \"The Double\" by Nobel Prize winner José Saramago explores the emotional experience of a man who discovers that he is a clone.\n\nCloning has been used in fiction as a way of recreating historical figures. In the 1976 Ira Levin novel \"The Boys from Brazil\" and its 1978 film adaptation, Josef Mengele uses cloning to create copies of Adolf Hitler.\n\nIn Michael Chrichton's 1990 novel \"Jurassic Park\", which spawned a series of \"Jurassic Park\" feature films, a bioengineering company develops a technique to resurrect extinct species of dinosaurs by creating cloned creatures using DNA extracted from fossils. The cloned dinosaurs are used to populate the eponymous Jurassic Park wildlife park for the entertainment of visitors. The scheme goes disastrously wrong when the dinosaurs escape their enclosures. Despite being selectively cloned as females to prevent them from breeding, the dinosaurs develop the ability to reproduce through parthenogenesis.\n\nThe use of cloning for military purposes has also been explored in several works. In \"Doctor Who\", an alien race of armour-clad, warlike beings called Sontarans was introduced in the 1973 serial \"The Time Warrior\". Sontarans are depicted as squat, bald creatures who have been genetically engineered for combat. Their weak spot is a \"probic vent\", a small socket at the back of their neck which is associated with the cloning process. The concept of cloned soldiers being bred for combat was revisited in \"The Doctor's Daughter\" (2008), when the Doctor's DNA is used to create a female warrior called Jenny.\n\nThe 1977 film \"Star Wars\" was set against the backdrop of a historical conflict called the Clone Wars. The events of this war were not fully explored until the prequel films \"\" (2002) and \"\" (2005), which depict a space war waged by a massive army of heavily armoured clone troopers that leads to the foundation of the Galactic Empire. Cloned soldiers are \"manufactured\" on an industrial scale, genetically conditioned for obedience and combat effectiveness. It is also revealed that the popular character Boba Fett originated as a clone of Jango Fett, a mercenary who served as the genetic template for the clone troopers.\n\nA recurring sub-theme of cloning fiction is the use of clones as a supply of organs for transplantation. The 2005 Kazuo Ishiguro novel \"Never Let Me Go\" and the 2010 film adaption are set in an alternate history in which cloned humans are created for the sole purpose of providing organ donations to naturally born humans, despite the fact that they are fully sentient and self-aware. The 2005 film \"The Island\" revolves around a similar plot, with the exception that the clones are unaware of the reason for their existence. In Raymond Han's 2017 novel, The Mind Clones Trilogy, a dictator who suffered a terminal illness sought to implant his mind clone into his son's mind so that he could continue to rule the country. In another part of the trilogy, usurpers plotted to replace members of the Chinese Politburo Standing Committee using look-alike human clones.\n\nThe exploitation of human clones for dangerous and undesirable work was examined in the 2009 British science fiction film \"Moon\". In the futuristic novel \"Cloud Atlas\" and subsequent film, one of the story lines focuses on a genetically-engineered fabricant clone named Sonmi~451 who is one of millions raised in an artificial \"wombtank,\" destined to serve from birth. She is one of thousands of clones created for manual and emotional labor; Sonmi herself works as a server in a restaurant. She later discovers that the sole source of food for clones, called 'Soap', is manufactured from the clones themselves.\n\n\n", "id": "6910", "title": "Cloning"}
{"url": "https://en.wikipedia.org/wiki?curid=3768056", "text": "SnRNP\n\nsnRNPs (pronounced \"snurps\"), or small nuclear ribonucleo proteins, are RNA-protein complexes that combine with unmodified pre-mRNA and various other proteins to form a spliceosome, a large RNA-protein molecular complex upon which splicing of pre-mRNA occurs. The action of snRNPs is essential to the removal of introns from pre-mRNA, a critical aspect of post-transcriptional modification of RNA, occurring only in the nucleus of eukaryotic cells.\nAdditionally, \"U7 snRNP\" is not involved in splicing at all, as U7 snRNP is responsible for processing the 3′ stem-loop of histone pre-mRNA.\nThe two essential components of snRNPs are protein molecules and RNA. The RNA found within each snRNP particle is known as \"small nuclear RNA\", or snRNA, and is usually about 150 nucleotides in length. The snRNA component of the snRNP gives specificity to individual introns by \"recognizing\" the sequences of critical splicing signals at the 5' and 3' ends and branch site of introns. The snRNA in snRNPs is similar to ribosomal RNA in that it directly incorporates both an enzymatic and a structural role.\n\nSnRNPs were discovered by Michael R. Lerner and Joan A. Steitz.\nThomas R. Cech and Sidney Altman also played a role in the discovery, winning the Nobel Prize for Chemistry in 1989 for their independent discoveries that RNA can act as a catalyst in cell development.\n\nAt least five different kinds of snRNPs join the spliceosome to participate in splicing. They can be visualized by gel electrophoresis and are known individually as: U1, U2, U4, U5, and U6. Their snRNA components are known, respectively, as: U1 snRNA, U2 snRNA, U4 snRNA, U5 snRNA, and U6 snRNA.\n\nIn the mid-1990s, it was discovered that a variant class of snRNPs exists to help in the splicing of a class of introns found only in metazoans, with highly conserved 5' splice sites and branch sites. This variant class of snRNPs includes: U11 snRNA, U12 snRNA, U4atac snRNA, and U6atac snRNA. While different, they perform the same functions as do U1, U2, U4, and U6, respectively.\n\nAdditionally, U7 snRNP is made of U7 small nuclear RNA and associated proteins and is involved in the processing of the 3′ stem-loop of histone pre-mRNA.\n\nSmall nuclear ribonucleoproteins (snRNPs) assemble in a tightly orchestrated and regulated process that involves both the cell nucleus and cytoplasm.\n\nThe RNA polymerase II transcribes U1, U2, U4, U5 and the less abundant U11, U12 and U4atac (snRNAs) acquire a m7G-cap which serves as an export signal. Nuclear export is mediated by CRM1.\n\nThe Sm proteins are synthesized in the cytoplasm by ribosomes translating Sm messenger RNA, just like any other protein. These are stored in the cytoplasm in the form of three partially assembled rings complexes all associated with the pICln protein. They are a 6S pentamer complex of SmD1,SmD2, SmF, SmE and SmG with pICln, a 2-4S complex of SmB, possibly with SmD3 and pICln and the 20S methylosome, which is a large complex of SmD3, SmB, SmD1, pICln and the arginine methyltransferase-5 (PRMT5) protein. SmD3, SmB and SmD1 undergo post-translational modification in the methylosome. These three Sm proteins have repeated arginine-glycine motifs in the C-terminal ends of SmD1, SmD3 and SmB, and the arginine side chains are symmetrically dimethylated to ω-N, N-dimethyl-arginine. It has been suggested that pICln, which occurs in all three precursor complexes but is absent in the mature snRNPs, acts as a specialized chaperone, preventing premature assembly of Sm proteins.\n\nThe snRNAs (U1, U2, U4, U5, and the less abundant U11, U12 and U4atac) quickly interact with the SMN (survival of motor neuron protein); encoded by \"SMN1\" gene) and Gemins 2-8 (Gem-associated proteins: GEMIN2, GEMIN3, GEMIN4, GEMIN5, GEMIN6, GEMIN7, GEMIN8) forming the SMN complex. It is here that the snRNA binds to the SmD1-SmD2-SmF-SmE-SmG pentamer, followed by addition of the SmD3-SmB dimer to complete the Sm ring around the so-called Sm site of the snRNA. This Sm site is a conserved sequence of nucleotides in these snRNAs, typically AUUUGUGG (where A, U and G represent the nucleosides adenosine, uridine and guanosine, respectively). After assembly of the Sm ring around the snRNA, the 5' terminal nucleoside (already modified to a 7-methylguanosine cap) is hyper-methylated to 2,2,7-trimethylguanosine and the other (3') end of the snRNA is trimmed. This modification, and the presence of a complete Sm ring, is recognized by the snurportin 1 protein.\n\nThe completed core snRNP-snurportin 1 complex is transported into the nucleus via the protein importin β. Inside the nucleus, the core snRNPs appear in the Cajal bodies, where final assembly of the snRNPs take place. This consists of additional proteins and other modifications specific to the particular snRNP (U1, U2, U4, U5). The biogenesis of the U6 snRNP occurs in the nucleus, although large amounts of free U6 are found in the cytoplasm. The LSm ring may assemble first, and then associate with the U6 snRNA.\n\nThe snRNPs are very long-lived, but are assumed to be eventually disassembled and degraded. Little is known about the degradation process.\n\nDefective function of the survival of motor neuron (SMN) protein in snRNP biogenesis, caused by a genetic defect in the \"SMN1\" gene which codes for SMN, may account for the motor neuron pathology observed in the genetic disorder spinal muscular atrophy.\n\nSeveral human and yeast snRNP structures were determined by the cryo-electron microscopy and successive single particle analysis.\n\nRecently, the human U1 snRNP core structure was determined by X-ray crystallography (3CW1, 3PGW), followed by a structure of the U4 core snRNP (2Y9A), which yielded first insights into atomic contacts, especially the binding mode of the Sm proteins to the Sm site. The structure of U6 UsnRNA was solved in complex with a specific protein Prp24 (4N0T), as well as a structure of its 3'-Nucleotides bound to the special Lsm2-8 protein ring (4M7A). The PDB codes for the respective structures are mentioned in parenthesis.\nThe structures determined by single particle electron microscopy analysis are: human U1 snRNP\n\n, human U11/U12 di-snRNP\n\nhuman U5 snRNP, U4/U6 di-snRNP, U4/U6∙U5 tri-snRNP\nThe further progress determining the structures and functions of snRNPs and spliceosomes continues.\nAutoantibodies may be produced against the body's own snRNPs, most notably the anti-Sm antibodies targeted against the Sm protein type of snRNP specifically in systemic lupus erythematosus (SLE).\n\n", "id": "3768056", "title": "SnRNP"}
{"url": "https://en.wikipedia.org/wiki?curid=55912224", "text": "PDE7B\n\nPDE7B is a mammalian gene that encodes a 3'5'-cyclic nucleotide phosphodiesterase (PDE) that converts 3'5'-cyclic adenosine monophosphate (cAMP) to 5'AMP as part of cyclic nucleotide signaling pathways . There are 21 PDE genes in mammals that are pharmacologically-grouped into 11 families based on their biochemical characteristics and sequence conservation. The PDE7 family is composed of PDEs encoded by two genes, PDE7A and PDE7B. These PDEs are highly specific for cAMP relative to cGMP.\n", "id": "55912224", "title": "PDE7B"}
{"url": "https://en.wikipedia.org/wiki?curid=49577229", "text": "43S preinitiation complex\n\nThe 43S preinitiation complex (43S PIC) is a ribonucleoprotein complex that exists during an early step of eukaryotic translation initiation. The 43S PIC contains the small ribosomal subunit (40S) bound by the initiation factors eIF1, eIF1A, eIF3, and the eIF2-Met-tRNA-GTP ternary complex (eIF2-TC).\n\nThe 43S is an important intermediate complex during cap-dependent translation initiation. In the canonical model of translation initiation, the 43S PIC is pre-formed as a stable complex and recruited to the Five-prime cap of eukaryotic messenger RNAs (mRNAs) by the eIF4F complex. The 43S PIC then \"scans\" in the 5' --> 3' direction along the mRNA in an ATP-dependent fashion (via eIF4A and/or other RNA helicases such as Ded1/DDX3 and DHX29) to locate the start codon. Start codon recognition occurs through base-pairing between the Met-tRNA and AUG in the ribosomal P-site and a number of associated changes, and is followed by joining of the large 60S ribosomal subunit to form the 80S ribosome.\n\nDue to its size and complexity, the 43S PIC has eluded high resolution structural characterization. However, combined approaches including cryo-EM, cross-linking, and the structural characterization of individual components, has led to models for the complex organization.\n\n", "id": "49577229", "title": "43S preinitiation complex"}
{"url": "https://en.wikipedia.org/wiki?curid=30876044", "text": "Plant breeding\n\nPlant breeding is the art and science of changing the traits of plants in order to produce desired characteristics. It has been used to improve the quality of nutrition in products for humans and animals. . Plant breeding can be accomplished through many different techniques ranging from simply selecting plants with desirable characteristics for propagation, to methods that make use of knowledge of genetics and chromosomes, to more complex molecular techniques (see cultigen and cultivar). Genes in a plant are what determine what type of qualitative or quantitative traits it will have.The main purpose plant breeders is have is so they can create a specific outcome of plants and potentially new plant varieties.\n\nPlant breeding has been practiced for thousands of years, since near the beginning of human civilization. It is practiced worldwide by individuals such as gardeners and farmers, or by professional plant breeders employed by organizations such as government institutions, universities, crop-specific industry associations or research centers.\n\nInternational development nation agencies believe that breeding new crops is important for ensuring food security by developing new varieties that are higher-yielding, disease resistant, drought-resistant or regionally adapted to different environments and growing conditions.\n\nPlant breeding started with sedentary agriculture and particularly the domestication of the first agricultural plants, a practice which is estimated to date back 9,000 to 11,000 years. Initially early farmers simply selected food plants with particular desirable characteristics, and employed these as progenitors for subsequent generations, resulting in an accumulation of valuable traits over time.\n\nGregor Mendel's experiments with plant hybridization led to his establishing laws of inheritance. Once this work became well known, it formed the basis of the new science of genetics, which stimulated research by many plant scientists dedicated to improving crop production through plant breeding.\n\nModern plant breeding is applied genetics, but its scientific basis is broader, covering molecular biology, cytology, systematics, physiology, pathology, entomology, chemistry, and statistics (biometrics). It has also developed its own technology.\n\nOne major technique of plant breeding is selection, the process of selectively propagating plants with desirable characteristics and eliminating or \"culling\" those with less desirable characteristics.\n\nAnother technique is the deliberate interbreeding (crossing) of closely or distantly related individuals to produce new crop varieties or lines with desirable properties. Plants are crossbred to introduce traits/genes from one variety or line into a new genetic background. For example, a mildew-resistant pea may be crossed with a high-yielding but susceptible pea, the goal of the cross being to introduce mildew resistance without losing the high-yield characteristics. Progeny from the cross would then be crossed with the high-yielding parent to ensure that the progeny were most like the high-yielding parent, (backcrossing). The progeny from that cross would then be tested for yield (selection, as described above) and mildew resistance and high-yielding resistant plants would be further developed. Plants may also be crossed with themselves to produce inbred varieties for breeding. Pollinators may be excluded through the use of pollination bags.\n\nClassical breeding relies largely on homologous recombination between chromosomes to generate genetic diversity. The classical plant breeder may also make use of a number of \"in vitro\" techniques such as protoplast fusion, embryo rescue or mutagenesis (see below) to generate diversity and produce hybrid plants that would not exist in nature.\n\nTraits that breeders have tried to incorporate into crop plants include:\n\nSuccessful commercial plant breeding concerns were founded from the late 19th century. Gartons Agricultural Plant Breeders in England was established in the 1890s by John Garton, who was one of the first to commercialize new varieties of agricultural crops created through cross-pollination. The firm's first introduction was Abundance Oat, one of the first agricultural grain varieties bred from a \"controlled\" cross, introduced to commerce in 1892.\n\nIn the early 20th century, plant breeders realized that Mendel's findings on the non-random nature of inheritance could be applied to seedling populations produced through deliberate pollinations to predict the frequencies of different types. Wheat hybrids were bred to increase the crop production of Italy during the so-called \"Battle for Grain\" (1925–1940). Heterosis was explained by George Harrison Shull. It describes the tendency of the progeny of a specific cross to outperform both parents. The detection of the usefulness of heterosis for plant breeding has led to the development of inbred lines that reveal a heterotic yield advantage when they are crossed. Maize was the first species where heterosis was widely used to produce hybrids.\n\nStatistical methods were also developed to analyze gene action and distinguish heritable variation from variation caused by environment. In 1933 another important breeding technique, cytoplasmic male sterility (CMS), developed in maize, was described by Marcus Morton Rhoades. CMS is a maternally inherited trait that makes the plant produce sterile pollen. This enables the production of hybrids without the need for labor-intensive detasseling.\n\nThese early breeding techniques resulted in large yield increase in the United States in the early 20th century. Similar yield increases were not produced elsewhere until after World War II, the Green Revolution increased crop production in the developing world in the 1960s.\n\nFollowing World War II a number of techniques were developed that allowed plant breeders to hybridize distantly related species, and artificially induce genetic diversity.\n\nWhen distantly related species are crossed, plant breeders make use of a number of plant tissue culture techniques to produce progeny from otherwise fruitless mating. Interspecific and intergeneric hybrids are produced from a cross of related species or genera that do not normally sexually reproduce with each other. These crosses are referred to as \"Wide crosses\". For example, the cereal triticale is a wheat and rye hybrid. The cells in the plants derived from the first generation created from the cross contained an uneven number of chromosomes and as result was sterile. The cell division inhibitor colchicine was used to double the number of chromosomes in the cell and thus allow the production of a fertile line.\n\nFailure to produce a hybrid may be due to pre- or post-fertilization incompatibility. If fertilization is possible between two species or genera, the hybrid embryo may abort before maturation. If this does occur the embryo resulting from an interspecific or intergeneric cross can sometimes be rescued and cultured to produce a whole plant. Such a method is referred to as Embryo Rescue. This technique has been used to produce new rice for Africa, an interspecific cross of Asian rice \"(Oryza sativa)\" and African rice \"(Oryza glaberrima)\".\n\nHybrids may also be produced by a technique called protoplast fusion. In this case protoplasts are fused, usually in an electric field. Viable recombinants can be regenerated in culture.\n\nChemical mutagens like EMS and DMS, radiation and transposons are used to generate mutants with desirable traits to be bred with other cultivars – a process known as \"Mutation Breeding\". Classical plant breeders also generate genetic diversity within a species by exploiting a process called somaclonal variation, which occurs in plants produced from tissue culture, particularly plants derived from callus. Induced polyploidy, and the addition or removal of chromosomes using a technique called chromosome engineering may also be used.\nWhen a desirable trait has been bred into a species, a number of crosses to the favored parent are made to make the new plant as similar to the favored parent as possible. Returning to the example of the mildew resistant pea being crossed with a high-yielding but susceptible pea, to make the mildew resistant progeny of the cross most like the high-yielding parent, the progeny will be crossed back to that parent for several generations (See backcrossing ). This process removes most of the genetic contribution of the mildew resistant parent. Classical breeding is therefore a cyclical process.\n\nWith classical breeding techniques, the breeder does not know exactly what genes have been introduced to the new cultivars. Some scientists therefore argue that plants produced by classical breeding methods should undergo the same safety testing regime as genetically modified plants. There have been instances where plants bred using classical techniques have been unsuitable for human consumption, for example the poison solanine was unintentionally increased to unacceptable levels in certain varieties of potato through plant breeding. New potato varieties are often screened for solanine levels before reaching the marketplace.\n\nModern plant breeding may use techniques of molecular biology to select, or in the case of genetic modification, to insert, desirable traits into plants. Application of biotechnology or molecular biology is also known as molecular breeding.\n\nSometimes many different genes can influence a desirable trait in plant breeding. The use of tools such as molecular markers or DNA fingerprinting can map thousands of genes. This allows plant breeders to screen large populations of plants for those that possess the trait of interest. The screening is based on the presence or absence of a certain gene as determined by laboratory procedures, rather than on the visual identification of the expressed trait in the plant. The purpose of marker assisted selection, or plant genomes analysis, is to identify the location and function (phenotype) of various genes within the genome. If all of the genes are identified it leads to Genome sequence. All plants have varying sizes and lengths of genomes with genes that code for different proteins, but many are also the same. If a gene's location and function is identified in one plant species, a very similar gene likely can also be found in a similar location in another species genome.\n\nHomozygous plants with desirable traits can be produced from heterozygous starting plants, if a haploid cell with the alleles for those traits can be produced, and then used to make a doubled haploid. The doubled haploid will be homozygous for the desired traits. Furthermore, two different homozygous plants created in that way can be used to produce a generation of F1 hybrid plants which have the advantages of heterozygosity and a greater range of possible traits. Thus, an individual heterozygous plant chosen for its desirable characteristics can be converted into a heterozygous variety (F1 hybrid) without the necessity of vegetative reproduction but as the result of the cross of two homozygous/doubled haploid lines derived from the originally selected plant. Using plant tissue culturing can produce haploid or double haploid plant lines and generations. This minimizes the amount of genetic diversity among that plant species in order to select for desirable traits that will increase the fitness of the individuals. Using this method decreases the need for breeding multiple generations of plants to get a generation that is homologous for the desired traits, therefore save much time in the process. There are many plant tissue culturing techniques that can be used to achieve the haploid plants, but microspore culturing is currently the most promising for producing the largest numbers of them. \n\nGenetic modification of plants is achieved by adding a specific gene or genes to a plant, or by knocking down a gene with RNAi, to produce a desirable phenotype. The plants resulting from adding a gene are often referred to as transgenic plants. If for genetic modification genes of the species or of a crossable plant are used under control of their native promoter, then they are called cisgenic plants. Sometimes genetic modification can produce a plant with the desired trait or traits faster than classical breeding because the majority of the plant's genome is not altered.\n\nTo genetically modify a plant, a genetic construct must be designed so that the gene to be added or removed will be expressed by the plant. To do this, a promoter to drive transcription and a termination sequence to stop transcription of the new gene, and the gene or genes of interest must be introduced to the plant. A marker for the selection of transformed plants is also included. In the laboratory, antibiotic resistance is a commonly used marker: Plants that have been successfully transformed will grow on media containing antibiotics; plants that have not been transformed will die. In some instances markers for selection are removed by backcrossing with the parent plant prior to commercial release.\n\nThe construct can be inserted in the plant genome by genetic recombination using the bacteria \"Agrobacterium tumefaciens\" or \"A. rhizogenes\", or by direct methods like the gene gun or microinjection. Using plant viruses to insert genetic constructs into plants is also a possibility, but the technique is limited by the host range of the virus. For example, Cauliflower mosaic virus (CaMV) only infects cauliflower and related species. Another limitation of viral vectors is that the virus is not usually passed on the progeny, so every plant has to be inoculated.\n\nThe majority of commercially released transgenic plants are currently limited to plants that have introduced resistance to insect pests and herbicides. Insect resistance is achieved through incorporation of a gene from \"Bacillus thuringiensis\" (Bt) that encodes a protein that is toxic to some insects. For example, the cotton bollworm, a common cotton pest, feeds on Bt cotton it will ingest the toxin and die. Herbicides usually work by binding to certain plant enzymes and inhibiting their action. The enzymes that the herbicide inhibits are known as the herbicides \"target site\". Herbicide resistance can be engineered into crops by expressing a version of \"target site\" protein that is not inhibited by the herbicide. This is the method used to produce glyphosate resistant crop plants (See Glyphosate)\n\nGenetic modification can further increase yields by increasing stress tolerance to a given environment. Stresses such as temperature variation, are signalled to the plant via a cascade of signalling molecules which will activate a Transcription factor to regulate Gene expression. Overexpression of particular genes involved in cold acclimation has been shown to become more resistant to freezing, which is one common cause of yield loss\n\nGenetic modification of plants that can produce pharmaceuticals (and industrial chemicals), sometimes called \"pharming\", is a rather radical new area of plant breeding.\n\nModern plant breeding, whether classical or through genetic engineering, comes with issues of concern, particularly with regard to food crops. The question of whether breeding can have a negative effect on nutritional value is central in this respect. Although relatively little direct research in this area has been done, there are scientific indications that, by favoring certain aspects of a plant's development, other aspects may be retarded. A study published in the \"Journal of the American College of Nutrition\" in 2004, entitled \"Changes in USDA Food Composition Data for 43 Garden Crops, 1950 to 1999\", compared nutritional analysis of vegetables done in 1950 and in 1999, and found substantial decreases in six of 13 nutrients measured, including 6% of protein and 38% of riboflavin. Reductions in calcium, phosphorus, iron and ascorbic acid were also found. The study, conducted at the Biochemical Institute, University of Texas at Austin, concluded in summary: \"\"We suggest that any real declines are generally most easily explained by changes in cultivated varieties between 1950 and 1999, in which there may be trade-offs between yield and nutrient content.\"\"\n\nThe debate surrounding genetically modified food during the 1990s peaked in 1999 in terms of media coverage and risk perception, and continues today – for example, \"\"Germany has thrown its weight behind a growing European mutiny over genetically modified crops by banning the planting of a widely grown pest-resistant corn variety.\"\" The debate encompasses the ecological impact of genetically modified plants, the safety of genetically modified food and concepts used for safety evaluation like substantial equivalence. Such concerns are not new to plant breeding. Most countries have regulatory processes in place to help ensure that new crop varieties entering the marketplace are both safe and meet farmers' needs. Examples include variety registration, seed schemes, regulatory authorizations for GM plants, etc.\n\nPlant breeders' rights is also a major and controversial issue. Today, production of new varieties is dominated by commercial plant breeders, who seek to protect their work and collect royalties through national and international agreements based in intellectual property rights. The range of related issues is complex. In the simplest terms, critics of the increasingly restrictive regulations argue that, through a combination of technical and economic pressures, commercial breeders are reducing biodiversity and significantly constraining individuals (such as farmers) from developing and trading seed on a regional level. Efforts to strengthen breeders' rights, for example, by lengthening periods of variety protection, are ongoing.\n\nWhen new plant breeds or cultivars are bred, they must be maintained and propagated. Some plants are propagated by asexual means while others are propagated by seeds. Seed propagated cultivars require specific control over seed source and production procedures to maintain the integrity of the plant breeds results. Isolation is necessary to prevent cross contamination with related plants or the mixing of seeds after harvesting. Isolation is normally accomplished by planting distance but in certain crops, plants are enclosed in greenhouses or cages (most commonly used when producing F1 hybrids.)\n\nCritics of organic agriculture claim it is too low-yielding to be a viable alternative to conventional agriculture. However, part of that poor performance may be the result of growing poorly adapted varieties. It is estimated that over 95% of organic agriculture is based on conventionally adapted varieties, even though the production environments found in organic vs. conventional farming systems are vastly different due to their distinctive management practices. Most notably, organic farmers have fewer inputs available than conventional growers to control their production environments. Breeding varieties specifically adapted to the unique conditions of organic agriculture is critical for this sector to realize its full potential. This requires selection for traits such as:\n\nCurrently, few breeding programs are directed at organic agriculture and until recently those that did address this sector have generally relied on indirect selection (i.e. selection in conventional environments for traits considered important for organic agriculture). However, because the difference between organic and conventional environments is large, a given genotype may perform very differently in each environment due to an interaction between genes and the environment (see gene-environment interaction). If this interaction is severe enough, an important trait required for the organic environment may not be revealed in the conventional environment, which can result in the selection of poorly adapted individuals. To ensure the most adapted varieties are identified, advocates of organic breeding now promote the use of direct selection (i.e. selection in the target environment) for many agronomic traits.\n\nThere are many classical and modern breeding techniques that can be utilized for crop improvement in organic agriculture despite the ban on genetically modified organisms. For instance, controlled crosses between individuals allow desirable genetic variation to be recombined and transferred to seed progeny via natural processes. Marker assisted selection can also be employed as a diagnostics tool to facilitate selection of progeny who possess the desired trait(s), greatly speeding up the breeding process. This technique has proven particularly useful for the introgression of resistance genes into new backgrounds, as well as the efficient selection of many resistance genes pyramided into a single individual. Unfortunately, molecular markers are not currently available for many important traits, especially complex ones controlled by many genes.\n\nFor future agriculture to thrive there are necessary changes which must be made in accordance to arising global issues. These issues are arable land, harsh cropping conditions and food security which involves, being able to provide the world population with food containing sufficient nutrients. These crops need to be able to mature in several environments allowing for worldwide access, this is involves issues such as drought tolerance. These global issues are achievable through the process of plant breeding, as it offers the ability to select specific genes allowing the crop to perform at a level which yields the desired results.\n\nWith an increasing population, the production of food needs to increase with it. It is estimated that a 70% increase in food production is needed by 2050 in order to meet the Declaration of the World Summit on Food Security. But with the degradation of agricultural land, simply planting more crops is no longer a viable option. New varieties of plants can in some cases be developed through plant breeding that generate an increase of yield without relying on an increase in land area. An example of this can be seen in Asia, where food production per capita has increased twofold. This has been achieved through not only the use of fertilisers, but through the use of better crops that have been specifically designed for the area.\n\nPlant breeding can contribute to global food security as it is a cost-effective tool for increasing nutritional value of forage and crops. Improvements in nutritional value for forage crops from the use of analytical chemistry and rumen fermentation technology have been recorded since 1960; this science and technology gave breeders the ability to screen thousands of samples within a small amount of time, meaning breeders could identify a high performing hybrid quicker. The main area genetic increases were made was in vitro dry matter digestibility (IVDMD) resulting in 0.7-2.5% increase, at just 1% increase in IVDMD a single Bos Taurus also known as beef cattle reported 3.2% increase in daily gains. This improvement indicates plant breeding is an essential tool in gearing future agriculture to perform at a more advanced level.\n\nPlant breeding of hybrid crops has become extremely popular worldwide in an effort to combat the harsh environment. With long periods of drought and lack of water or nitrogen stress tolerance has become a significant part of agriculture. Plant breeders have focused on identifying crops which will ensure crops perform under these conditions; a way to achieve this is finding strains of the crop that is resistance to drought conditions with low nitrogen. It is evident from this that plant breeding is vital for future agriculture to survive as it enables farmers to produce stress resistant crops hence improving food security.\n\nIn countries that experience harsh winters such as Iceland, Germany and further east in Europe, plant breeders are involved in breeding for tolerance to frost, continuous snow-cover, frost-drought (desiccation from wind and solar radiation under frost) and high moisture levels in soil in winter.\n\nParticipatory plant breeding (PPB) is when farmers are involved in a crop improvement programme with opportunities to make decisions and contribute to the research process at different stages. Participatory approaches to crop improvement can also be applied when plant biotechnologies are being used for crop improvement. Local agricultural systems and genetic diversity are developed and strengthened by crop improvement, which participatory crop improvement (PCI) plays a large role. PPB is enhanced by farmers knowledge of the quality required and evaluation of target environment which affects the effectiveness of PPB.\n\n\n\n\n", "id": "30876044", "title": "Plant breeding"}
{"url": "https://en.wikipedia.org/wiki?curid=1464735", "text": "Developmental Studies Hybridoma Bank\n\nThe Developmental Studies Hybridoma Bank (DSHB) is a non-profit, global hybridoma bank. The DSHB is a National Resource established by the National Institute of Child Health and Human Development (NICHD) to bank and distribute at cost hybridomas and cell products to the general scientific community.\n\nThe mission of the DSHB is four-fold:\n\nThe DSHB is directed by David R. Soll at the University of Iowa. There are currently over 3000 hybridomas in the DSHB collection. They have obtained hybridoma collections from a variety of individuals and institutions including the Muscular Dystrophy Association, the National Cancer Institute, the NIH Common Fund, and the European Molecular Biology Laboratory (EMBL) and they eagerly await new collections. The DSHB has begun developing complex monoclonal antibody microarrays for specific cancer targets. First time customers must agree to the DSHB terms of usage that products will be used for research purposes only, and that they cannot be commercialized or distributed to a third party. Researchers also agree to acknowledge both the DSHB and the contributing investigator in publications that benefit from the use of DSHB products and provide the DSHB citations of all publications. Individuals or institutions can deposit hybridomas for distribution and archiving at no cost, and there is no maximum or minimum deposit. As the depositor, you have the option to allow the DSHB to distribute the hybridoma cells, or just the cell products. All contributions to the DSHB do not preclude the depositor from licensing cell lines for commercial purposes. The DSHB does not own any intellectual property on deposited antibodies. The intellectual property remains that of the scientist or institution that banks the hybridomas. As a non-profit organization, the DSHB covers the operating costs of maintaining, improving and producing products in the collection by selling the products at cost.\n\nThe DSHB was created in 1986 by the Institute of Child Health and Human Development (NIH) to bank and distribute hybridomas and the monoclonal antibodies (MAbs) they produce to the general scientific community in order to facilitate research. The DSHB has been self-funded since 1996. One of the first hybridomas deposited with the DSHB was MF 20 which recognizes all isoforms of skeletal myosin heavy chain. In April 1986, Dr. Donald Fischman, Cornell Medical School, deposited MF 20 with the DSHB. Nearly 30 years later, MF 20 remains one of the top ten most requested monoclonal antibodies.\n\nPopular targets that the DSHB provides products for include:\n\nNobel Prize and Alfred P. Sloan, Jr. Prize winner J. Michael Bishop deposited the anti c-MYC hybridoma 9e10 \n\nNobel Prize winner Sir John Gurdon deposited MyoD clone D7F2\n\nNobel Prize winner Eric F. Wieschaus deposited 7 hybridomas\n\nNational Academy of Sciences Members who have deposited hybridomas\nThe National Cancer Institute deposited 546 Monoclonal antibodies from the Protein Capture Reagents Program.\n\n", "id": "1464735", "title": "Developmental Studies Hybridoma Bank"}
{"url": "https://en.wikipedia.org/wiki?curid=14009", "text": "Hemicellulose\n\nA hemicellulose (also known as polyose) is any of several heteropolymers (matrix polysaccharides), such as arabinoxylans, present along with cellulose in almost all plant cell walls. While cellulose is crystalline, strong, and resistant to hydrolysis, hemicellulose has a random, amorphous structure with little strength. It is easily hydrolyzed by dilute acid or base as well as a myriad of hemicellulase enzymes.\n\nHemicelluloses include xylan, glucuronoxylan, arabinoxylan, glucomannan, and xyloglucan.\n\nThese polysaccharides contain many different sugar monomers. In contrast, cellulose contains only anhydrous glucose. For instance, besides glucose, sugar monomers in hemicellulose can include xylose, mannose, galactose, rhamnose, and arabinose. Hemicelluloses contain most of the D-pentose sugars, and occasionally small amounts of L-sugars as well. Xylose is in most cases the sugar monomer present in the largest amount, although in softwoods mannose can be the most abundant sugar. Not only regular sugars can be found in hemicellulose, but also their acidified form, for instance glucuronic acid and galacturonic acid can be present. Hemicellulose is often associated with cellulose, but it has different composition.\n\nUnlike cellulose, hemicellulose (also a polysaccharide) consists of shorter chains – 500–3,000 sugar units as opposed to 7,000–15,000 glucose molecules per polymer, as seen in cellulose. In addition, hemicellulose is a branched polymer, while cellulose is unbranched.\n\nHemicelluloses are embedded in the cell walls of plants, sometimes in chains that form a 'ground' - they bind with pectin to cellulose to form a network of cross-linked fibres.\n\nHemicelluloses are synthesised from sugar nucleotides in the cell's Golgi apparatus. Two models explain their synthesis: 1) a ‘2 component model' where modification occurs at two transmembrane proteins, and 2) a '1 component model' where modification occurs only at one transmembrane protein. After synthesis, hemicelluloses are transported to the plasma membrane via Golgi vesicles.\n\nAs percent content of hemicellulose increases in animal feed, the voluntary feed intake decreases.\n\nHemicellulose is represented by the difference between neutral detergent fiber (NDF) and acid detergent fiber (ADF).\n\nMicrofibrils are cross-linked together by hemicellulose homopolymers. Lignins assist and strengthen the attachment of hemicelluloses to microfibrils.\n\nHemicellulose found in hardwood trees is predominantly xylan with some glucomannan, while in softwoods it is mainly rich in galactoglucomannan and contains only a small amount of xylan. The average molecular weight is lower than that of cellulose at less than 30,000, as opposed to the 100,000 average molecular weight reported for cellulose.\n\n\n", "id": "14009", "title": "Hemicellulose"}
{"url": "https://en.wikipedia.org/wiki?curid=2536095", "text": "Actin-binding protein\n\nActin-binding proteins (also known as ABP) are proteins that bind to actin. This may mean ability to bind actin monomers, or polymers, or both.\n\nMany actin-binding proteins, including α-actinin, β-spectrin, dystrophin, utrophin and fimbrin, do this through the actin-binding calponin homology domain.\n\nThis is a list of actin-binding proteins in alphabetical order.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "id": "2536095", "title": "Actin-binding protein"}
{"url": "https://en.wikipedia.org/wiki?curid=2809585", "text": "Photobleaching\n\nIn optics, photobleaching (sometimes termed fading) is the photochemical alteration of a dye or a fluorophore molecule such that it permanently is unable to fluoresce. This is caused by cleaving of covalent bonds or non-specific reactions between the fluorophore and surrounding molecules. Such irreversible modifications in covalent bonds is caused by transition from a singlet state to the triplet state of the fluorophores. The number of excitation cycles vary to achieve full bleaching. In microscopy, photobleaching may complicate the observation of fluorescent molecules, since they will eventually be destroyed by the light exposure necessary to stimulate them into fluorescing. This is especially problematic in time-lapse microscopy.\n\nHowever, photobleaching may also be used prior to applying the (primarily antibody-linked) fluorescent molecules, in an attempt to quench autofluorescence. This can help to improve signal-to-noise ratio.\n\nPhotobleaching may also be exploited to study the motion and/or diffusion of molecules, for example via the FRAP, in which movement of cellular components can be confirmed by observing a recovery of fluorescence at the site of photobleaching, or FLIP techniques, in which multiple rounds of photobleaching is done so that the spread of fluorescence loss can be observed in cell.\n\nLoss of activity caused by photobleaching can be controlled by reducing the intensity or time-span of light exposure, by increasing the concentration of fluorophores, by reducing the frequency and thus the photon energy of the input light, or by employing more robust fluorophores that are less prone to bleaching (e.g. Alexa Fluors or DyLight Fluors). To a reasonable approximation, a given molecule will be destroyed after a constant exposure (intensity of emission X emission time X number of cycles) because, in a constant environment, each absorption-emission cycle has an equal probability of causing photobleaching.\n\nDepending on their specific chemistry, molecules can photobleach after absorbing just a few photons, while more robust molecules can undergo many absorption/emission cycles before destruction:\n\nThis use of the term \"lifetime\" is not to be confused with the \"lifetime\" measured by fluorescence lifetime imaging.\n\n\n", "id": "2809585", "title": "Photobleaching"}
{"url": "https://en.wikipedia.org/wiki?curid=3025998", "text": "TRAIL\n\nIn the field of cell biology, TNF-related apoptosis-inducing ligand (TRAIL), is a protein functioning as a ligand that induces the process of cell death called apoptosis.\n\nTRAIL is a cytokine that is produced and secreted by most normal tissue cells. It causes apoptosis primarily in tumor cells, by binding to certain death receptors. TRAIL and its receptors have been used as the targets of several anti-cancer therapeutics since the mid-1990s, such as Mapatumumab. However, as of 2013, these have not shown significant survival benefit.\n\nTRAIL has also been designated CD253 (cluster of differentiation 253) and TNFSF10 (tumor necrosis factor (ligand) superfamily, member 10).\n\nIn humans, the gene that encodes TRAIL is located at chromosome 3q26, which is not close to other TNF family members. The genomic structure of the TRAIL gene spans approximately 20 kb and is composed of five exonic segments 222, 138, 42, 106, and 1245 nucleotides and four introns of approximately 8.2, 3.2, 2.3 and 2.3 kb.\n\nThe TRAIL gene lacks TATA and CAAT boxes and the promotor region contains putative response elements for transcription factors GATA, AP-1, C/EBP, SP-1, OCT-1, AP3, PEA3, CF-1, and ISRE.\n\nTIC10 (which causes expression of TRAIL) was investigated in mice with various tumour types.\n\nSmall molecule ONC201 causes expression of TRAIL which kills some cancer cells.\n\nTRAIL shows homology to other members of the tumor necrosis factor superfamily. It is composed of 281 amino acids and has characteristics of a type II transmembrane protein (i.e. no leader sequence and an internal transmembrane domain). The N-terminal cytoplasmic domain is not conserved across family members, however, the C-terminal extracellular domain is conserved and can be proteolytically cleaved from the cell surface. TRAIL forms a homotrimer that binds three receptor molecules.\n\nTRAIL binds to the death receptors DR4 (TRAIL-RI) and DR5 (TRAIL-RII). The process of apoptosis is caspase-8-dependent. Caspase-8 activates downstream effector caspases including procaspase-3, -6, and -7, leading to activation of specific kinases. TRAIL also binds the receptors DcR1 and DcR2, which do not contain a cytoplasmic domain (DcR1) or contain a truncated death domain (DcR2). DcR1 functions as a TRAIL-neutralizing decoy-receptor. The cytoplasmic domain of DcR2 is functional and activates NFkappaB.\nIn cells expressing DcR2, TRAIL binding therefore activates NFkappaB, leading to transcription of genes known to antagonize the death signaling pathway and/or to promote inflammation.\n\nIn clinical trials only a small proportion of patients responded to various drugs that targeted TRAIL death receptors.\n\nTRAIL has been shown to interact with TNFRSF10B.\n\n\n", "id": "3025998", "title": "TRAIL"}
{"url": "https://en.wikipedia.org/wiki?curid=1445451", "text": "Chaperonin\n\nChaperonins are proteins that provide favourable conditions for the correct folding of other proteins, thus preventing aggregation. They prevent the misfolding of proteins, which prevents diseases such as Mad Cow Disease. Newly made proteins usually must fold from a linear chain of amino acids into a three-dimensional form. Chaperonins belong to a large class of molecules that assist protein folding, called molecular chaperones. The energy to fold proteins is supplied by adenosine triphosphate (ATP). Chaperonin proteins may also tag misfolded proteins to be degraded.\n\nThe structure of these chaperonins resemble two donuts stacked on top of one another to create a barrel.\n\nEach ring is composed of either 7, 8 or 9 subunits depending on the organism in which the chaperonin is found.\n\nGroup I chaperonins are found in bacteria as well as organelles of endosymbiotic origin: chloroplasts and mitochondria.\n\nThe GroEL/GroES complex in \"E. coli\" is a Group I chaperonin and the best characterized large (~ 1 MDa) chaperonin complex. \nGroEL/GroES may not be able to undo protein aggregates, but kinetically it competes in the pathway of misfolding and aggregation, thereby preventing aggregate formation.\n\nGroup II chaperonins, found in the eukaryotic cytosol and in archaea, are more poorly characterized.\n\nTRiC (TCP-1 Ring Complex, also called CCT for chaperonin containing TCP-1), the eukaryotic chaperonin, is composed of two rings of eight different though related subunits, each thought to be represented once per eight-membered ring. TRiC was originally thought to fold only the cytoskeletal proteins actin and tubulin but is now known to fold dozens of substrates.\n\nMm cpn (Methanococcus maripaludis chaperonin), found in the archaea Methanococcus maripaludis, is composed of sixteen identical subunits (eight per ring). It has been shown to fold the mitochondrial protein rhodanese; however, no natural substrates have yet been identified.\n\nGroup II chaperonins are not thought to utilize a GroES-type cofactor to fold their substrates. They instead contain a \"built-in\" lid that closes in an ATP-dependent manner to encapsulate its substrates, a process that is required for optimal protein folding activity.\n\nChaperonins undergo large conformational changes during a folding reaction as a function of the enzymatic hydrolysis of ATP as well as binding of substrate proteins and cochaperonins, such as GroES. These conformational changes allow the chaperonin to bind an unfolded or misfolded protein, encapsulate that protein within one of the cavities formed by the two rings, and release the protein back into solution. Upon release, the substrate protein will either be folded or will require further rounds of folding, in which case it can again be bound by a chaperonin.\n\nThe exact mechanism by which chaperonins facilitate folding of substrate proteins is unknown. According to recent analyses by different experimental techniques, GroEL-bound substrate proteins populate an ensemble of compact and locally expanded states that lack stable tertiary interactions. A number of models of chaperonin action have been proposed, which generally focus on two (not mutually exclusive) roles of chaperonin interior: passive and active. Passive models treat the chaperonin cage as an inert form, exerting influence by reducing the conformational space accessible to a protein substrate or preventing intermolecular interactions e.g. by aggregation prevention. The active chaperonin role is in turn involved with specific chaperonin–substrate interactions that may be coupled to conformational rearrangements of the chaperonin.\n\nProbably the most popular model of the chaperonin active role is the iterative annealing mechanism (IAM), which focus on the effect of iterative, and hydrophobic in nature, binding of the protein substrate to the chaperonin. According to computational simulation studies, the IAM leads to more productive folding by unfolding the substrate from misfolded conformations or by prevention from protein misfolding through changing the folding pathway.\n\nAs mentioned, all cells contain chaperonins. \n\nThese protein complexes appear to be essential for life in \"E. coli\", \"Saccharomyces cerevisiae\" and higher eukaryotes. While there are differences between eukaryotic, bacterial and archaeal chaperonins, the general structure and mechanism are conserved.\n\n\n", "id": "1445451", "title": "Chaperonin"}
{"url": "https://en.wikipedia.org/wiki?curid=501827", "text": "COPI\n\nCOPI is a coatomer, a protein complex that coats vesicles transporting proteins from the \"cis\" end of the Golgi complex back to the rough endoplasmic reticulum (ER), where they were originally synthesized, and between Golgi compartments. This type of transport is termed as \"retrograde transport\", in contrast to the \"anterograde transport\" associated with the COPII protein. The name \"COPI\" refers to the specific coat protein complex that initiates the budding process on the \"cis\"-Golgi membrane. The coat consists of large protein subcomplexes that are made of seven different protein subunits, namely α, β, β', γ, δ, ε and ζ.\n\nCoat protein, or COPI, is an ADP ribosylation factor (ARF)-dependent protein involved in membrane traffic. COPI was first identified in retrograde traffic from the \"cis\"-Golgi to the rough endoplasmic reticulum (ER) and is the most extensively studied of ARF-dependent adaptors. COPI consists of seven subunits which compose the heteroheptameric protein complex.\n\nThe primary function of adaptors is the selection of cargo proteins for their incorporation into nascent carriers. Cargo containing the sorting motifs KKXX and KXKXX interact with COPI to form carriers which are transported from the cis-Golgi to the ER. Current views suggest that ARFs are also involved in the selection of cargo for incorporation into carriers.\n\nADP ribosylation factor (ARF) is a GTPase involved in membrane traffic. There are 6 mammalian ARFs which are regulated by over 30 GEFs and GAPs. ARF is post-translationally modified at the N-terminus by the addition of the fatty acid myristate.\n\nARF cycles between GTP and GDP-bound conformations. In the GTP-bound form, ARF conformation changes such that the myristate and hydrophobic N-terminal become more exposed and associate with the membrane. The interconversion between GTP and GDP bound states is mediated by ARF guanine nucleotide exchange factors (GEFs) and ARF GTPase activating proteins (GAPs). At the membrane, ARF-GTP is hydrolyzed to ARF-GDP by ARF GAPs. Once in the GDP-bound conformation, ARF converts to a less hydrophobic conformation and dissociates from the membrane. Soluble ARF-GDP is converted back to ARF-GTP by GEFs.\n\nMembrane deformation and carrier budding occurs following the collection of interactions described above. The carrier then buds off of the donor membrane, in the case of COPI this membrane is the cis-Golgi, and the carrier moves to the ER where it fuses with the acceptor membrane and its content is expelled.\n\nOn the surface of a vesicle COPI molecules form symmetric trimers (\"triads\"). The curved triad structure positions the Arf1 molecules and cargo binding sites proximal to the membrane. The β′- and α-COP subunits form an arch over the γζβδ-COP subcomplex, orienting their N-terminal domains such that the K(X)KXX cargo-motif binding sites are optimally positioned against the membrane. Thus β′- and α-COP do not form a cage or lattice as in COPII and clathrin coats as previously suggested; instead, they are linked to one another via the γζβδ-COP subcomplexes, forming an interconnected assembly. The triads are linked together with contacts of variable valence making up four different types of contacts.\n\n", "id": "501827", "title": "COPI"}
{"url": "https://en.wikipedia.org/wiki?curid=3594278", "text": "Toll (gene family)\n\nThe toll genes encode members of the toll-like receptor class of proteins. Mutants in the toll gene were originally identified by 1995 Nobel Laureates Christiane Nüsslein-Volhard and Eric Wieschaus and colleagues in the fruit fly \"Drosophila melanogaster\" in 1985, and cloned by the laboratory of Kathryn Anderson in 1988. Since then, thirteen mammalian toll genes have been identified.\n\nIn flies, toll was first identified as a gene important in embryogenesis in establishing the dorsal-ventral axis. In 1996, toll was found to have a role in the fly's immunity to fungal infections. Both mammalian and invertebrate toll genes are required for innate immunity.\n\nToll-like receptors in mammals were identified in 1997 at Yale University by Ruslan Medzhitov and Charles Janeway. Concurrently, two separate studies, led by Shizuo Akira, Bruce A. Beutler and their respective colleagues discovered that the Toll-like receptors (TLRs) act as the principal sensors of infection in mammals.\n\nThe name of the gene family derives from Christiane Nüsslein-Volhard's 1985 exclamation, \"\" The exclamation, which translates as \"That's amazing!\" was in reference to the underdeveloped ventral portion of a fruit fly larva. The adjective \"toll\" is German for \"amazing\" or \"great\".\n\n", "id": "3594278", "title": "Toll (gene family)"}
{"url": "https://en.wikipedia.org/wiki?curid=2440776", "text": "Focal adhesion\n\nIn cell biology, focal adhesions (also cell–matrix adhesions or FAs) are large macromolecular assemblies through which mechanical force and regulatory signals are transmitted between the extracellular matrix (ECM) and an interacting cell. More precisely, focal adhesions are the sub-cellular structures that mediate the regulatory effects (i.e., signaling events) of a cell in response to ECM adhesion.\n\nFocal adhesions serve as the mechanical linkages to the ECM, and as a biochemical signaling hub to concentrate and direct numerous signaling proteins at sites of integrin binding and clustering. \nFocal adhesions are integrin-containing, multi-protein structures that form mechanical links between intracellular actin bundles and the extracellular substrate in many cell types. Focal adhesions are large, dynamic protein complexes through which the cytoskeleton of a cell connects to the ECM. They are limited to clearly defined ranges of the cell, at which the plasma membrane closes to within 15 nm of the ECM substrate. Focal adhesions are in a state of constant flux: proteins associate and disassociate with it continually as signals are transmitted to other parts of the cell, relating to anything from cell motility to cell cycle. Focal adhesions can contain over 100 different proteins, which suggests a considerable functional diversity. More than anchoring the cell, they function as signal carriers (sensors), which inform the cell about the condition of the ECM and thus affect their behavior. In sessile cells, focal adhesions are quite stable under normal conditions, while in moving cells their stability is diminished: this is because in motile cells, focal adhesions are being constantly assembled and disassembled as the cell establishes new contacts at the leading edge, and breaks old contacts at the trailing edge of the cell. One example of their important role is in the immune system, in which white blood cells migrate along the connective endothelium following cellular signals to damaged biological tissue.\n\nConnection between focal adhesions and proteins of the extracellular matrix generally involves integrins. Integrins bind to extra-cellular proteins via short amino acid sequences, such as the RGD motif (found in proteins such as fibronectin, laminin, or vitronectin), or the DGEA and GFOGER motifs found in collagen. Integrins are heterodimers which are formed from one beta and one alpha subunit. These subunits are present in different forms, their corresponding ligands classify these receptors into four groups: RGD receptors, laminin receptors, leukocyte-specific receptors and collagen receptors. Within the cell, the intracellular domain of integrin binds to the cytoskeleton via adapter proteins such as talin, α-actinin, filamin, vinculin and tensin. Many other intracellular signalling proteins, such as focal adhesion kinase, bind to and associate with this integrin-adapter protein–cytoskeleton complex, and this forms the basis of a focal adhesion.\n\nThe dynamic assembly and disassembly of focal adhesions plays a central role in cell migration. During cell migration, both the composition and the morphology of the focal adhesion change. Initially, small (0.25μm²) focal adhesions called focal complexes (FXs) are formed at the leading edge of the cell in lamellipodia: they consist of integrin, and some of the adapter proteins, such as talin, paxillin and tensin. Many of these focal complexes fail to mature and are disassembled as the lamellipodia withdraw. However, some focal complexes mature into larger and stable focal adhesions, and recruit many more proteins such as zyxin. Recruitment of components to the focal adhesion occurs in an ordered, sequential manner. Once in place, a focal adhesion remains stationary with respect to the extracellular matrix, and the cell uses this as an anchor on which it can push or pull itself over the ECM. As the cell progresses along its chosen path, a given focal adhesion moves closer and closer to the trailing edge of the cell. At the trailing edge of the cell the focal adhesion must be dissolved. The mechanism of this is poorly understood and is probably instigated by a variety of different methods depending on the circumstances of the cell. One possibility is that the calcium-dependent protease calpain is involved: it has been shown that the inhibition of calpain leads to the inhibition of focal adhesion-ECM separation. Focal adhesion components are amongst the known calpain substrates, and it is possible that calpain degrades these components to aid in focal adhesion disassembly\n\nThe assembly of nascent focal adhesions is highly dependent on the process of retrograde actin flow. This is the phenomenon in a migrating cell where actin filaments polymerize at the leading edge and flow back towards the cell body. This is the source of traction required for migration; the focal adhesion acts as a molecular clutch when it tethers to the ECM and impedes the retrograde movement of actin, thus generating the pulling (traction) force at the site of the adhesion that is necessary for the cell to move forward. This traction can be visualized with traction force microscopy. A common metaphor to explain actin retrograde flow is a large number of people being washed downriver, and as they do so, some of them hang on to rocks and branches along the bank to stop their downriver motion. Thus, a pulling force is generated onto the rock or branch that they are hanging on to. These forces are necessary for the successful assembly, growth, and maturation of focal adhesions.\n\nExtracellular mechanical forces, which are exerted through focal adhesions, can activate Src kinase and stimulate the growth of the adhesions. This indicates that focal adhesions may function as mechanical sensors, and suggests that force generated from myosin fibers could contribute to maturing the focal complexes.\nThis gains further support from the fact that inhibition of myosin-generated forces leads to slow disassembly of focal adhesions, by changing the turnover kinetics of the focal adhesion proteins.\n\nThe relationship between forces on focal adhesions and their compositional maturation, however, remains unclear. For instance, preventing focal adhesion maturation by inhibiting myosin activity or stress fiber assembly does not prevent forces sustained by focal adhesions, nor does it prevent cells from migrating. Thus force propagation through focal adhesions may not be sensed directly by cells at all time and force scales.\n\nTheir role in mechanosensing is important for durotaxis.\n\n\n", "id": "2440776", "title": "Focal adhesion"}
{"url": "https://en.wikipedia.org/wiki?curid=3666839", "text": "SMC protein\n\nSMC proteins represent a large family of ATPases that participate in many aspects of higher-order chromosome organization and dynamics. SMC stands for Structural Maintenance of Chromosomes.\n\nEukaryotes have at least six SMC proteins in individual organisms, and they form three distinct heterodimers with specialized functions:\n\nEach complex contains a distinct set of non-SMC regulatory subunits. Some organisms have variants of SMC proteins. For instance, mammals have a meiosis-specific variant of SMC1, known as SMC1β. The nematode \"Caenorhabditis elegans\" has an SMC4-variant that has a specialized role in dosage compensation.\n\nSMC proteins are conserved from bacteria to humans. Most bacteria have a single SMC protein in individual species that forms a homodimer. In a subclass of Gram-negative bacteria including \"Escherichia coli\", a distantly related protein known as MukB plays an equivalent role.\n\nSMC proteins are 1,000-1,500 amino-acid long. They have a modular structure that is composed of the following domains:\n\nSMC dimers form a V-shaped molecule with two long coiled-coil arms. To make such a unique structure, an SMC protomer is self-folded through anti-parallel coiled-coil interactions, forming a rod-shaped molecule. At one end of the molecule, the N-terminal and C-terminal domains together form an ATP-binding domain. The other end is called a hinge domain. Two protomers then dimerize through their hinge domains and assemble a V-shaped dimer. The length of the coiled-coil arms is ~50 nm long. Such long \"antiparallel\" coiled-coils are very rare, and found only among SMC proteins (and its relatives such as Rad50). The ATP-binding domain of SMC proteins is structurally related to that of ABC transporters, a large family of transmembrane proteins that actively transport small molecules across cellular membranes. It is thought that the cycle of ATP binding and hydrolysis modulates the cycle of closing and opening of the V-shaped molecule, but the detailed mechanisms of action of SMC proteins remain to be determined.\n\nThe following human genes encode SMC proteins:\n\n", "id": "3666839", "title": "SMC protein"}
{"url": "https://en.wikipedia.org/wiki?curid=3690047", "text": "Cryo-electron tomography\n\nElectron cryo-tomography (ECT, also called cryo-electron tomography, cryo-ET or CET) is an imaging technique used to produce high-resolution (~4 nm) three-dimensional views of samples, typically biological macromolecules and cells. ECT is a specialized application of transmission electron microscopy (TEM) in which samples are imaged as they are tilted, resulting in a series of 2D images that can be combined to produce a 3D reconstruction, similar to a CT scan of the human body. In contrast to other electron tomography techniques, samples are immobilized in non-crystalline (\"vitreous\") ice and imaged under cryogenic conditions (< −150 °C), allowing them to be imaged without dehydration or chemical fixation, which could otherwise disrupt or distort biological structures.\n\nIn electron microscopy (EM), samples are imaged in an ultra-high vacuum. Such a vacuum is incompatible with biological samples such as cells; the water would boil off, and the difference in pressure would explode the cell. In room-temperature EM techniques, samples are therefore prepared by fixation and dehydration. Another approach to stabilize biological samples, however, is to freeze them (cryo-electron microscopy). As in other cryo-electron microscopy techniques, samples for ECT (typically small cells (e.g. Bacteria, Archaea, or viruses) are prepared in standard aqueous media and applied to an EM grid. The grid is then plunged into a cryogen (typically ethane) so efficient that water molecules do not have time to rearrange into a crystalline lattice. The resulting water state is called \"vitreous ice\" and preserves native cellular structures, such as lipid membranes, that would normally be destroyed by freezing. Plunge-frozen samples are subsequently stored and imaged at liquid-nitrogen temperatures so that the water never warms enough to crystallize.\n\nSamples are imaged in a transmission electron microscope (TEM). As in other electron tomography techniques, the sample is tilted to different angles relative to the electron beam (typically every 1 or 2 degrees from about −60° to +60°), and an image is acquired at each angle. This tilt-series of images can then be computationally reconstructed into a three-dimensional view of the object of interest. This is called a tomogram, or tomographic reconstruction.\n\nIn transmission electron microscopy (TEM), because electrons interact strongly with matter, resolution is limited by the thickness of the sample. Therefore, for ECT, samples should be less than ~500 nm thick to achieve \"macromolecular\" resolution (~4 nm). For this reason, most ECT studies have focused on purified macromolecular complexes, viruses, or small cells such as those of many species of Bacteria and Archaea.\n\nLarger cells, and even tissues, can be prepared for ECT by thinning, either by cryo-sectioning or by focused ion beam (FIB) milling. In cryo-sectioning, frozen blocks of cells or tissue are sectioned into thin samples with a cryo-microtome. In FIB-milling, plunge-frozen samples are exposed to a focused beam of ions, typically gallium, that precisely whittle away material from the top and bottom of a sample, leaving a thin lamella suitable for ECT imaging.\n\nThe strong interaction of electrons with matter also results in an anisotropic resolution effect. As the sample is tilted during imaging, the electron beam interacts with a relatively greater cross-sectional area at higher tilt angles. In practice, tilt angles greater than approximately 60–70° do not yield much information and are therefore not used. This results in a \"missing wedge\" of information in the final tomogram that decreases resolution parallel to the electron beam.\n\nFor structures that are present in multiple copies in one or multiple tomograms, higher resolution (even ≤1 nm) can be obtained by subtomogram averaging. Similar to single particle analysis, subtomogram averaging computationally combines images of identical objects to increase the signal-to-noise ratio.\n\nA major obstacle in ECT is identifying structures of interest within complicated cellular environments. One solution is to apply correlated cryo-fluorescence light microscopy, and even super-resolution light microscopy (e.g. cryo-PALM), and ECT. In these techniques, a sample containing a fluorescently-tagged protein of interest is plunge-frozen and first imaged in a light microscope equipped with a special stage to allow the sample to be kept at sub-crystallization temperatures (<150 °C). The location of the fluorescent signal is identified and the sample is transferred to the cryo-TEM, where the same location is then imaged at high resolution by ECT.\n\n\n", "id": "3690047", "title": "Cryo-electron tomography"}
{"url": "https://en.wikipedia.org/wiki?curid=2235991", "text": "Cryo-electron microscopy\n\nCryo-electron microscopy (cryo-EM), or electron cryomicroscopy, is a form of transmission electron microscopy (TEM) where the sample is studied at cryogenic temperatures (generally liquid-nitrogen temperatures). Cryo-EM is gaining popularity in structural biology.\n\nThe utility of cryoelectron microscopy stems from the fact that it allows the observation of specimens that have not been stained or fixed in any way, showing them in their native environment. This is in contrast to X-ray crystallography, which requires crystallizing the specimen, which can be difficult, and placing them in non-physiological environments, which can occasionally lead to functionally irrelevant conformational changes.\n\nThe resolution of cryo-EM maps is improving steadily, and in 2014 some structures at near-atomic resolution had been obtained, including those of viruses, ribosomes, mitochondria, ion channels, and enzyme complexes as small as 170 kDa at a resolution of 4.5 Å. Bridget Carragher and colleagues at the Scripps National Resource for Automated Molecular Microscopy used techniques she and Clint Potter developed to create the first cryo-electron microscopy structural biology image with a resolution finer than 3 Ångströms, thereby elevating cryo-EM as a tool comparable to and potentially superior to traditional x-ray crystallography techniques. A 2.2 Å map of a bacterial enzyme beta-galactosidase was published in June 2015.\nA version of electron cryomicroscopy is cryo-electron tomography (CET), where a 3D reconstruction of a sample is created from tilted 2D images.\n\nThe original rationale for cryoelectron microscopy was as a means to fight radiation damage for biological specimens. The amount of radiation required to collect an image of a specimen in the electron microscope is high enough to be a potential source of specimen damage for delicate structures. In addition, the high vacuum required on the column of an electron microscope makes the environment for the sample quite harsh.\n\nThe problem of the vacuum was partially solved by the introduction of negative stains but even with negative stains biological samples are prone to structural collapse upon dehydration of the specimen. Embedding the samples in ice below the sublimation temperature was a possibility that was contemplated early on, but water tends to arrange into a crystalline lattice of lower density upon freezing and this can destroy the structure of anything that is embedded in it.\n\nIn the early '80s, several groups studying solid state physics were attempting to produce vitreous ice by different means, such as high pressure freezing or flash freezing. In a seminal paper in 1984, the group led by Jacques Dubochet at the European Molecular Biology Laboratory showed images of adenovirus embedded in a vitrified layer of water. This paper is generally considered to mark the origin of cryoelectron microscopy, and the technique has been developed to the point of becoming routine at numerous laboratories throughout the world.\n\nThe energy of the electrons used for imaging (80-300 kV) is high enough that covalent bonds can be broken. When imaging specimens vulnerable to radiation damage, it is necessary to limit the electron exposure used to acquire the image. These low exposures require that the images of thousands or even millions of identical frozen molecules be selected, aligned, and averaged to obtain high-resolution maps, using specialized software. A significant improvement in structural features was achieved in 2012 by the introduction of direct electron detectors and better computational algorithms.\n\nIn 2017, the Nobel Prize in Chemistry was awarded jointly to Jacques Dubochet, Joachim Frank and Richard Henderson, \"for developing cryo-electron microscopy for the high-resolution structure determination of biomolecules in solution\".\n\nThe biological material is spread on an electron microscopy grid and is preserved in a frozen-hydrated state by rapid freezing, usually in liquid ethane near liquid nitrogen temperature. By maintaining specimens at liquid nitrogen temperature or colder, they can be introduced into the high-vacuum of the electron microscope column. Most biological specimens are extremely radiosensitive, so they must be imaged with low-dose techniques (usefully, the low temperature of cryo-electron microscopy provides an additional protective factor against radiation damage).\n\nConsequently, the images are extremely noisy. For some biological systems it is possible to average images to increase the signal-to-noise ratio and retrieve high-resolution information about the specimen using the technique known as single particle analysis. This approach in general requires that the things being averaged are identical, although some limited conformational heterogeneity can now be studied (e.g. ribosome). Three-dimensional reconstructions from cryo-EM images of protein complexes and viruses have been solved to sub-nanometer or near-atomic resolution, allowing new insights into the structure and biology of these large assemblies.\n\nAnalysis of ordered arrays of protein, such as 2-D crystals of transmembrane proteins or helical arrays of proteins, also allows a kind of averaging which can provide high-resolution information about the specimen. This technique is called electron crystallography.\n\nThe thin film method is limited to thin specimens (typically < 500 nm) because the electrons cannot cross thicker samples without multiple scattering events. Thicker specimens can be vitrified by plunge freezing (cryofixation) in ethane (up to tens of μm in thickness) or more commonly by high pressure freezing (up to hundreds of μm). They can then be cut in thin sections (40 to 200 nm thick) with a diamond knife in a cryoultramicrotome at temperatures lower than -135 °C (devitrification temperature). The sections are collected on an electron microscope grid and are imaged in the same manner as specimen vitrified in thin film. This technique is called cryo-electron microscopy of vitreous sections (CEMOVIS) or cryo-electron microscopy of frozen-hydrated sections.\n\nIn addition to allowing vitrified biological samples to be imaged, cryo-EM can also be used to image material specimens that are too volatile in vacuum to image using standard, room temperature electron microscopy. For example, vitrified sections of liquid-solid interfaces can be extracted for analysis by cryo-EM, and sulfur, which is prone to sublimation in the vacuum of electron microscopes, can be stabilized and imaged in cryo-EM.\n\nA variety of techniques can be used in cryoelectron microscopy. Popular techniques include:\n\n\n\nPrimary database:\n", "id": "2235991", "title": "Cryo-electron microscopy"}
{"url": "https://en.wikipedia.org/wiki?curid=3788537", "text": "WormBook\n\nWormBook is an open access, comprehensive collection of original, peer-reviewed chapters covering topics related to the of the nematode worm \"Caenorhabditis elegans (C. elegans)\". WormBook also includes WormMethods, an up-to-date collection of methods and protocols for \"C. elegans\" researchers.\n\nWormBook is the online text companion to WormBase, the \"C. elegans\" model organism database. Capitalizing on the World Wide Web, WormBook links in-text references (e.g. genes, alleles, proteins, literature citations) with primary biological databases such as WormBase and PubMed. \"C. elegans\" was the first multicellular organism to have its genome sequenced and is a model organism for studying developmental genetics and neurobiology.\n\nThe content of WormBook is categorized into the sections listed below, each filled with a variety of relevant chapters. These sections include:\n\n", "id": "3788537", "title": "WormBook"}
{"url": "https://en.wikipedia.org/wiki?curid=3830525", "text": "Citrate synthase\n\nThe enzyme citrate synthase [E.C. 2.3.3.1 (previously 4.1.3.7)] exists in nearly all living cells and stands as a pace-making enzyme in the first step of the citric acid cycle (or Krebs cycle). Citrate synthase is localized within eukaryotic cells in the mitochondrial matrix, but is encoded by nuclear DNA rather than mitochondrial. It is synthesized using cytoplasmic ribosomes, then transported into the mitochondrial matrix. Citrate synthase is commonly used as a quantitative enzyme marker for the presence of intact mitochondria.\n\nCitrate synthase catalyzes the condensation reaction of the two-carbon acetate residue from acetyl coenzyme A and a molecule of four-carbon oxaloacetate to form the six-carbon citrate: \n\nOxaloacetate is regenerated after the completion of one round of the Krebs cycle.\n\nOxaloacetate is the first substrate to bind to the enzyme. This induces the enzyme to change its conformation, and creates a binding site for the acetyl-CoA. Only when this citroyl-CoA has formed will another conformational change cause thioester hydrolysis and release coenzyme A. This ensures that the energy released from the thioester bond cleavage will drive the condensation.\n\nCitrate synthase's 437 amino acid residues are organized into two main subunits, each consisting of 20 alpha-helices. These alpha helices compose approximately 75% of citrate synthase's tertiary structure, while the remaining residues mainly compose irregular extensions of the structure, save a single beta-sheet of 13 residues. Between these two subunits, a single cleft exists containing the active site. Two binding sites can be found therein: one reserved for citrate or oxaloacetate and the other for Coenzyme A. The active site contains three key residues: His274, His320, and Asp375 that are highly selective in their interactions with substrates.\nThe images to the left display the tertiary structure of citrate synthase in its opened and closed form. The enzyme changes from opened to closed with the addition of one of its substrates (such as oxaloacetate).\n\nCitrate synthase has three key amino acids in its active site (known as the catalytic triad) which catalyze the conversion of acetyl-CoA [HCC(=O)−SCoA] and oxaloacetate [OCCHC(=O)CO] into citrate [OCCHC(OH)(CO)CHCO] and H−SCoA in an aldol condensation reaction. This conversion begins with the negatively charged carboxylate side chain oxygen atom of Asp-375 deprotonating acetyl CoA’s alpha carbon atom to form an enolate anion which in turn is neutralized by protonation by His-274 to form an enol intermediate [HC=C(OH)−SCoA]. At this point, the epsilon nitrogen lone pair of electrons on His-274 formed in the last step abstracts the hydroxyl enol proton to reform an enolate anion that initiates a nucleophilic attack on the oxaloacetate’s carbonyl carbon [OCCHC(=O)CO] which in turn deprotonate the epsilon nitrogen atom of His-320. This nucleophilic addition results in the formation of citroyl−CoA [OCCHCH(CO)CHC(=O)−SCoA]. At this point, a water molecule is deprotonated by the epsilon nitrogen atom of His-320 and hydrolysis is initiated. One of the oxygen’s lone pairs nucleophilically attacks the carbonyl carbon of citroyl−CoA. This forms a tetrahedral intermediate and results in the ejection of −SCoA as the carbonyl reforms. The −SCoA is protonated to form HSCoA. Finally, the hydroxyl added to the carbonyl in the previous step is deprotonated and citrate [OCCHC(OH)(CO)CHCO] is formed.\n\nThe enzyme is inhibited by high ratios of ATP:ADP, acetyl-CoA:CoA, and NADH:NAD, as high concentrations of ATP, acetyl-CoA, and NADH show that the energy supply is high for the cell. It is also inhibited by succinyl-CoA, which resembles Acetyl-coA and acts as a uncompetitive inhibitor. Citrate inhibits the reaction and is an example of product inhibition.\nThe inhibition of citrate synthase by acetyl-CoA analogues has also been well documented and has been used to prove the existence of a single active site. These experiments have revealed that this single site alternates between two forms, which participate in ligase and hydrolase activity respectively. This protein may use the morpheein model of allosteric regulation. \n", "id": "3830525", "title": "Citrate synthase"}
{"url": "https://en.wikipedia.org/wiki?curid=2871940", "text": "Internal ribosome entry site\n\nAn internal ribosome entry site, abbreviated IRES, is a RNA element that allows for translation initiation in a cap-independent manner, as part of the greater process of protein synthesis. In eukaryotic translation, initiation typically occurs at the 5' end of mRNA molecules, since 5' cap recognition is required for the assembly of the initiation complex. The location for IRES elements is often in the 5'UTR, but can also occur elsewhere in mRNAs.\n\nIRES sequences were first discovered in 1988 in the poliovirus (PV) and encephalomyocarditis virus (EMCV) RNA genomes in the labs of Nahum Sonenberg and Eckard Wimmer, respectively. They are described as distinct regions of RNA molecules that are able to recruit the eukaryotic ribosome to the mRNA. This process is also known as cap-independent translation. It has been shown that IRES elements have a distinct secondary or even tertiary structure, but similar structural features at the levels of either primary or secondary structure that are common to all IRES segments have not been reported to date.\n\nIn recent years it has become common for molecular biologists to insert IRES sequences into their vectors to allow for expression of two genes from a single vector—for example, a transgene and a fluorescent reporter molecule. The first gene is initiated at the normal 5' cap, and the second gene is initiated at the IRES.\n\nIRESs are commonly located in the 5'UTR of RNA viruses and allow translation of the RNAs in a cap-independent manner. However, mRNAs of viruses from \"Dicistroviridae\" family possess two open reading frames (ORFs), and translation of each is directed by two distinct IRESs. It has also been suggested that some mammalian cellular mRNAs also have IRESs. These cellular IRES elements are thought to be located in eukaryotic mRNAs encoding genes involved in stress survival, and other processes critical to survival. As of September 2009, there are 60 animal and 8 plant viruses reported to contain IRES elements and 115 mRNA sequences containing them as well.\n\nIRESs are often used by viruses as a means to ensure that viral translation is active when host translation is inhibited. These mechanisms of host translation inhibition are varied, and can be initiated by both virus and host, depending on the type of virus. However, in the case of most picornaviruses, such as poliovirus, this is accomplished by viral proteolytic cleavage of eIF4G so that it cannot interact with the 5'cap binding protein eIF4E. Interaction between these two eukaryotic initiation factors (eIFs) of the eIF4F complex is necessary for 40S ribosomal subunit recruitment to the 5' end of mRNAs, which is further thought to occur with via mRNA 5'cap to 3' poly(A) tail loop formation. The virus may even use partially-cleaved eIF4G to aid in initiation of IRES-mediated translation.\n\nCells may also use IRESs to increase translation of certain proteins during mitosis and programmed cell death. In mitosis, the cell dephosphorylates eIF4E so that it has little affinity for the 5'cap. As a result, the 40S ribosomal subunit , and the translational machinery is diverted to IRES within the mRNA. Many proteins involved in mitosis are encoded by IRES mRNA. In programmed cell death, cleavage of eIF-4G, such as performed by viruses, decreases translation. Lack of essential proteins contributes to the death of the cell, as does translation of IRES mRNA sequences coding proteins involved in controlling cell death.\n\nTo date, the mechanism of viral IRES function is better characterized than the mechanism of cellular IRES function, which is still a matter of debate. HCV-like IRESs directly bind the 40S ribosomal subunit to position their initiator codons are located in ribosomal P-site without mRNA scanning. These IRESs still use the eukaryotic initiation factors (eIFs) eIF2, eIF3, eIF5, and eIF5B, but do not require the factors eIF1, eIF1A, and the eIF4F complex. In contrast, picornavirus IRESs do not bind the 40S subunit directly, but are recruited instead through the eIF4G-binding site. Many viral IRES (and cellular IRES) require additional proteins to mediate their function, known as IRES \"trans\"-acting factors (ITAFs). The role of ITAFs in IRES function is still under investigation.\n\nTesting a particular RNA sequence for IRES activity relies on a bicistronic reporter construct. When an IRES segment is located between two reporter open reading frames in a eukaryotic mRNA molecule (a bicistronic mRNA), it can drive translation of the downstream protein coding region independently of the 5'-cap structure bound to the 5' end of the mRNA molecule. In such a setup,both proteins are produced in the cell. The first reporter protein located in the first cistron is synthesized by the cap-dependent initiation, while translation initiation of the second protein is directed by the IRES element located in the intercistronic spacer between the two reporter protein coding regions. However, there are several caveats to be aware of when interpreting data produced using bicistronic reporter constructs. For example, there are several known cases of mis-reported IRES elements that were later recognized as promoter-containing regions. More recently, splice acceptor sites within several presumed IRES segments have been shown to be responsible for apparent IRES function in bicistronic reporter assays.\n\n\n", "id": "2871940", "title": "Internal ribosome entry site"}
{"url": "https://en.wikipedia.org/wiki?curid=3450551", "text": "Separase\n\nSeparase, also known as separin, is a cysteine protease responsible for triggering anaphase by hydrolysing cohesin, which is the protein responsible for binding sister chromatids during the early stage of anaphase. In humans, separin is encoded by the \"ESPL1\" gene.\n\nIn \"S. cerevisiae\", separase is encoded by the \"esp1\" gene. Esp1 was discovered by Kim Nasmyth and coworkers in 1998.\n\nStable cohesion between sister chromatids before anaphase and their timely separation during anaphase are critical for cell division and chromosome inheritance. In vertebrates, sister chromatid cohesion is released in 2 steps via distinct mechanisms. The first step involves phosphorylation of STAG1 or STAG2 in the cohesin complex. The second step involves cleavage of the cohesin subunit SCC1 (RAD21) by separase, which initiates the final separation of sister chromatids.\n\nIn \"S. cerevisiae\", Esp1 is coded by ESP1 and is regulated by the securin Pds1. The two sister chromatids are initially bound together by the cohesin complex until the beginning of anaphase, at which point the mitotic spindle pulls the two sister chromatids apart, leaving each of the two daughter cells with an equivalent number of sister chromatids. The proteins that bind the two sister chromatids, disallowing any premature sister chromatid separation, are a part of the cohesin protein family. One of these cohesin proteins crucial for sister chromatid cohesion is Scc1. Esp1 is a separase protein that cleaves the cohesin subunit Scc1 (RAD21), allowing sister chromatids to separate at the onset of anaphase during mitosis.\n\nWhen the cell is not dividing, separase is prevented from cleaving cohesin through its association with another protein, securin, as well as phosphorylation by the cyclin-CDK complex. This provides two layers of negative regulation to prevent inappropriate cohesin cleavage. Note that separase cannot function without initially forming the securin-separase complex in most organisms. This is because securin helps properly fold separase into the functional conformation. However, yeast does not appear to require securin to form functional separase because anaphase occurs in yeast even with a securin deletion.\n\nOn the signal for anaphase, securin is ubiquitinated and hydrolysed, releasing separase for dephosphorylation by the APC-Cdc20 complex. Active separase can then cleave Scc1 for release of the sister chromatids.\n\nSeparase initiates the activation of Cdc14 in early anaphase and Cdc14 has been found to dephosphorylate securin, thereby increasing its efficiency as a substrate for degradation. The presence of this positive feedback loop offers a potential mechanism for giving anaphase a more switch-like behavior.\n\n\n", "id": "3450551", "title": "Separase"}
{"url": "https://en.wikipedia.org/wiki?curid=5552733", "text": "Bradytroph\n\nA bradytroph is a strain of an organism that exhibits slow growth in the absence of an external source of a particular metabolite. This is usually due to a defect in an enzyme required in the metabolic pathway producing this chemical. Such defects are the result of mutations in the genes encoding these enzymes. As the organism can still produce small amounts of the chemical, the mutation is not lethal. In these bradytroph strains, rapid growth occurs when the chemical is present in the cell's growth media and the missing metabolite can be transported into the cell from the external environment. A bradytroph may also be referred to as a \"leaky auxotroph\".\n\nThe first usage of \"bradytroph\" was to describe \"Escherichia coli\" mutants partially defective in arginine biosynthesis. Among many other examples of bradytrophic strains of microorganisms are \"Bacillus subtilis\" strains with mutations affecting thiamine production and \"Saccharomyces cerevisiae\" strains with mutations that impair arginine biosynthesis.\n\n", "id": "5552733", "title": "Bradytroph"}
{"url": "https://en.wikipedia.org/wiki?curid=3532723", "text": "Lipoteichoic acid\n\nLipoteichoic acid (LTA) is a major constituent of the cell wall of gram-positive bacteria. These organisms have an inner (or cytoplasmic) membrane and, external to it, a thick (up to 80 nanometer) peptidoglycan layer. The structure of LTA varies between the different species of Gram positive bacteria and may contain long chains of ribitol or glycerol phosphate. LTA is anchored to the cell membrane via a diacylglycerol. It acts as regulator of autolytic wall enzymes (muramidases). It has antigenic properties being able to stimulate specific immune response.\n\nLTA may bind to target cells non-specifically through membrane phospholipids, or specifically to CD14 and to Toll-like receptors. Binding to TLR-2 has shown to induce NF-κB expression(a central transcription factor), elevating expression of both pro- and anti-apoptotic genes. Its activation also induces mitogen-activated protein kinases (MAPK) activation along with Phosphoinositide 3-kinase activation.\n\nLTA's molecular structure has been found to have the strongest hydrophobic bonds of an entire bacteria.\n\nSaid et al. showed that LTA causes an IL-10-dependent inhibition of CD4 T-cell expansion and function by up-regulating PD-1 levels on monocytes which leads to IL-10 production by monocytes after binding of PD-1 by PD-L.\n", "id": "3532723", "title": "Lipoteichoic acid"}
{"url": "https://en.wikipedia.org/wiki?curid=864490", "text": "Chemiosmosis\n\nChemiosmosis is the movement of ions across a semipermeable membrane, down their electrochemical gradient. An example of this would be the generation of adenosine triphosphate (ATP) by the movement of hydrogen ions across a membrane during cellular respiration or photosynthesis.\n\nHydrogen ions, or protons, will diffuse from an area of high proton concentration to an area of lower proton concentration, and an electrochemical concentration gradient of protons across a membrane can be harnessed to make ATP. This process is related to osmosis, the diffusion of water across a membrane, which is why it is called \"chemiosmosis\".\n\nATP synthase is the enzyme that makes ATP by chemiosmosis. It allows protons to pass through the membrane and uses the free energy difference to phosphorylate adenosine diphosphate (ADP), making ATP. The generation of ATP by chemiosmosis occurs in mitochondria and chloroplasts, as well as in most bacteria and archaea, an electron transport chain pumps H+ ions in the thylakoid spaces through thylakoid membranes. The energy from the electron movement through electron transport chains cross through ATP synthase which allows the proton to pass through them and use this free energy difference to photophosphorylate ADP making ATP.\n\nPeter D. Mitchell proposed the chemiosmotic hypothesis in 1961.\nThe theory suggests essentially that most adenosine triphosphate (ATP) synthesis in respiring cells comes from the electrochemical gradient across the inner membranes of mitochondria by using the energy of NADH and FADH formed from the breaking down of energy-rich molecules such as glucose. Mitchell won the Nobel Prize in 1976 for his chemiosmotic theory.\n\nMolecules such as glucose are metabolized to produce acetyl CoA as an energy-rich intermediate. The oxidation of acetyl coenzyme A (acetyl-CoA) in the mitochondrial matrix is coupled to the reduction of a carrier molecule such as nicotinamide adenine dinucleotide (NAD) and flavin adenine dinucleotide (FAD).\nThe carriers pass electrons to the electron transport chain (ETC) in the inner mitochondrial membrane, which in turn pass them to other proteins in the ETC. The energy available in the electrons is used to pump protons from the matrix across the stroma, storing energy in the form of a transmembrane electrochemical gradient. The protons move back across the inner membrane through the enzyme ATP synthase. The flow of protons back into the matrix of the mitochondrion via ATP synthase provides enough energy for ADP to combine with inorganic phosphate to form ATP. The electrons and protons at the last pump in the ETC are taken up by oxygen to form water.\n\nThis was a radical proposal at the time, and was not well accepted. The prevailing view was that the energy of electron transfer was stored as a stable high potential intermediate, a chemically more conservative concept. The problem with the older paradigm is that no high energy intermediate was ever found, and the evidence for proton pumping by the complexes of the electron transfer chain grew too great to be ignored. Eventually the weight of evidence began to favor the chemiosmotic hypothesis, and in 1978, Peter Mitchell was awarded the Nobel Prize in Chemistry.\n\nChemiosmotic coupling is important for ATP production in mitochondria, chloroplasts\nand many bacteria and archaea.\n\nThe movement of ions across the membrane depends on a combination of two factors:\nThese two gradients taken together can be expressed as an electrochemical gradient.\n\nLipid bilayers of biological membranes, however, are barriers for ions. This is why energy can be stored as a combination of these two gradients across the membrane. Only special membrane proteins like ion channels can sometimes allow ions to move across the membrane (see also: Membrane transport). In chemiosmotic theory transmembrane ATP synthases are very important. They convert energy of spontaneous flow of protons through them into chemical energy of ATP bonds.\n\nHence researchers created the term proton-motive force (PMF), derived from the electrochemical gradient mentioned earlier. It can be described as the measure of the potential energy stored as a combination of proton and voltage (electrical potential) gradients across a membrane. The electrical gradient is a consequence of the charge separation across the membrane (when the protons H move without a counterion, such as chloride Cl).\n\nIn most cases the proton-motive force is generated by an electron transport chain which acts as a proton pump, using the Gibbs free energy of redox reactions to pump protons (hydrogen ions) out across the membrane, separating the charge across the membrane. In mitochondria, energy released by the electron transport chain is used to move protons from the mitochondrial matrix (N side) to the stroma (P side). Moving the protons out of the mitochondrion creates a lower concentration of positively charged protons inside it, resulting in excess negative charge on the inside of the membrane. The electrical potential gradient is about -170 mV , negative inside (N). These gradients - charge difference and the proton concentration difference both create a combined electrochemical gradient across the membrane, often expressed as the proton-motive force (PMF). In mitochondria, the PMF is almost entirely made up of the electrical component but in chloroplasts the PMF is made up mostly of the pH gradient because the charge of protons H is neutralized by the movement of Cl and other anions. In either case, the PMF needs to be greater than about 460 mV (45 kJ/mol) for the ATP synthase to be able to make ATP.\n\nThe proton-motive force is derived from the Gibbs free energy. Let N denote the inside of a cell, and let P denote the outside. Then\n\nwhere\nThe molar Gibbs free energy change formula_2 is frequently interpreted as a molar electrochemical ion potential formula_12.\n\nFor an electrochemical proton gradient formula_13 and as a consequence:\n\nwhere\n\nMitchell defined the proton-motive force (PMF) as\nFor example, formula_17 implies formula_18. At formula_19 this equation takes the form:\n\nformula_20.\n\nNote that for spontaneous proton import from the P side (relatively more positive and acidic) to the N side (relatively more negative and alkaline), formula_21 is negative (similar to formula_2) whereas PMF is positive (similar to redox cell potential formula_23).\n\nIt is worth noting that, as with any transmembrane transport process, the PMF is directional. The sign of the transmembrane electric potential difference formula_24 is chosen to represent the change in potential energy per unit charge flowing into the cell as above. Furthermore, due to redox-driven proton pumping by coupling sites, the proton gradient is always inside-alkaline. For both of these reasons, protons flow in spontaneously, from the P side to the N side; the available free energy is used to synthesize ATP (see below). For this reason, PMF is defined for proton import, which is spontaneous. PMF for proton export, i.e., proton pumping as catalyzed by the coupling sites, is simply the negative of PMF(import).\n\nThe spontaneity of proton import (from the P to the N side) is universal in all bioenergetic membranes. This fact was not recognized before the 1990s, because the chloroplast thylakoid lumen was interpreted as an interior phase, but in fact it is topologically equivalent to the exterior of the chloroplast. Azzone et al. stressed that the inside phase (N side of the membrane) is the bacterial cytoplasm, mitochondrial matrix, or chloroplast stroma; the outside (P) side is the bacterial periplasmic space, mitochondrial intermembrane space, or chloroplast lumen. Furthermore, 3D tomography of the mitochondrial inner membrane shows its extensive invaginations to be stacked, similar to thylakoid disks; hence the mitochondrial intermembrane space is topologically quite similar to the chloroplast lumen.:\n\nThe energy expressed here as Gibbs free energy, electrochemical proton gradient, or proton-motive force (PMF), is a combination of two gradients across the membrane:\nWhen a system reaches equilibrium, formula_27; nevertheless, the concentrations on either side of the membrane need not be equal. Spontaneous movement across the potential membrane is determined by both concentration and electric potential gradients.\n\nThe molar Gibbs free energy formula_28 of ATP synthesis\nis also called phosphorylation potential. The equilibrium concentration ratio formula_30 can be calculated by comparing formula_31 and formula_28, for example in case of the mammalian mitochondrion:\n\nH / ATP = ΔG / (Δp / 10.4 kJ·mol/mV) = 40.2 kJ·mol / (173.5 mV / 10.4 kJ·mol/mV) = 40.2 / 16.7 = 2.4. The actual ratio of the proton-binding c-subunit to the ATP-synthesizing beta-subunit copy numbers is 8/3 = 2.67, showing that under these conditions, the mitochondrion functions at 90% (2.4/2.67) efficiency.\n\nIn fact, the thermodynamic efficiency is lower in eukaryotic cells because ATP must be exported from the matrix to the cytoplasm, and ADP and phosphate must be imported from the cytoplasm. This \"costs\" one \"extra\" proton import per ATP, hence the actual efficiency is only 65% (= 2.4/3.67).\n\nThe complete breakdown of glucose in the presence of oxygen is called cellular respiration. The last steps of this process occur in mitochondria. The reduced molecules NADH and FADH are generated by the Krebs cycle, glycolysis, and pyruvate processing. These molecules pass electrons to an electron transport chain, which uses the energy released to create a proton gradient across the inner mitochondrial membrane. ATP synthase then uses the energy stored in this gradient to make ATP. This process is called oxidative phosphorylation because it uses energy released by the oxidation of NADH and FADH2 to phospolyrize ADP into ATP.\n\nThe light reactions of photosynthesis generate ATP by the action of chemiosmosis. The photons in sunlight are received by the antenna complex of Photosystem II, which excites electrons to a higher energy level. These electrons travel down an electron transport chain, causing protons to be actively pumped across the thylakoid membrane into the thylakoid lumen. These protons then flow down their electrochemical potential gradient through an enzyme called ATP-synthase, creating ATP by the phosphorylation of ADP to ATP. The electrons from the initial light reaction reach Photosystem I, then are raised to a higher energy level by light energy and then received by an electron acceptor and reduce NADP+ to NADPH. The electrons lost from Photosystem II get replaced by the oxidation of water, which is \"split\" into protons and oxygen by the oxygen-evolving complex (OEC, also known as WOC, or the water-oxidizing complex). To generate one molecule of diatomic oxygen, 10 photons must be absorbed by photosystems I and II, four electrons must move through the two photosystems, and 2 NAPDH are generated (later used for carbon dioxide fixation in the Calvin Cycle).\n\nBacteria and archaea also can use chemiosmosis to generate ATP. Cyanobacteria, green sulfur bacteria, and purple bacteria synthesize ATP by a process called photophosphorylation. These bacteria use the energy of light to create a proton gradient using a photosynthetic electron transport chain. Non-photosynthetic bacteria such as \"E. coli\" also contain ATP synthase. In fact, mitochondria and chloroplasts are believed to have been formed when early eukaryotic cells ingested bacteria that could transfer energy using chemiosmosis. This is called the endosymbiotic theory.\n\nChemiosmotic phosphorylation is the third pathway that produces ATP from inorganic phosphate and an ADP molecule. This process is part of oxidative phosphorylation.\n\n\n\n", "id": "864490", "title": "Chemiosmosis"}
{"url": "https://en.wikipedia.org/wiki?curid=6317825", "text": "Death fold\n\nThe death fold is a tertiary structure motif commonly found in proteins involved in apoptosis or inflammation-related processes. This motif is commonly found in domains that participate in protein–protein interactions leading to the formation of large functional complexes. Examples of death fold domains include the death domain (DD), death effector domain (DED), Caspase Recruitment Domain (CARD), and pyrin domain (PYD).\n\nDeath fold domains are an evolutionarily conserved superfamily of domains that mediate apoptotic signaling. The two types of apoptosis, extrinsic and intrinsic, are tightly regulated by the interplay of activating and inhibitory pathways. The interactions between the four different death fold motifs are a unifying mechanism in both types of apoptosis.\n\nThere is a large difference in the primary amino acid sequence of the four different death fold motifs, but each has a similar three-dimensional structure. Death-fold motifs are characterized by six to seven tightly coiled alpha-helices arranged in a \"Greek-key\" fold. The motifs consist of several defined protein interactions with other suspected apoptotic roles (Lahm).\n\nCaspase recruitment domain (CARD)\nCARD-containing proteins are found throughout the animal kingdom and may also be present in fungi, plants, and prokaryotes. CARD domains are present on several mammalian procaspases, and have functions in apoptosis, cytokine processing, immune defense, and NF-κB activation. In insects and nematodes, CARDs so far seem restricted to apoptotic proteins.\n\nDeath domain (DD)\nDDs are found primarily in vertebrates (although they are also present in some other animals). DDs are contained on cytokine receptors in the TNF receptor family. DD proteins function in apoptosis and NF-κB signaling in mammals, but only NF-κB signaling \"Drosophila\".\n\nDeath effector domain (DED)\nDEDs are present on caspases and are involved in caspase activation. DED-containing caspases function in death receptor-induced apoptosis in mammals, but differ in insects where they are involved in NF-κB signaling and antibacterial responses.\n\nPYRIN\nPYRINS are the most recently discovered death-fold domain, and their functions and interactions have yet to be clearly elucidated.\n\nDeath-fold motifs are believed to exert their effects solely through monovalent, homotypic interactions. In these interactions death-folds bind to another death-fold containing domain through the same type of protein interaction domain. These interactions are highly specific, and there are no known interactions between different types of death-fold domains – in every known case the binding partners have homologous domain (DD-DD, CARD-CARD, DED-DED). The role of these homotypic interactions is thought to be self-assembly (Lahm). This results in large multi-subunit structures made of only one type of protein.\n\n", "id": "6317825", "title": "Death fold"}
{"url": "https://en.wikipedia.org/wiki?curid=5895205", "text": "Renucleation\n\nRenucleation technology enables scientists to transfer a fertilized nucleus of an ovum ( with diploid number 2n) into unfertilized one after destroying its nucleus using radiation.\n\nWhen the fertilized ovum is transplanted to the mother's ovary it develops into a normal individual which has gained its characters from the parents (source of the 2n nucleus).\n", "id": "5895205", "title": "Renucleation"}
{"url": "https://en.wikipedia.org/wiki?curid=6630855", "text": "Transfersome\n\n\"Transfersome\" is a trademark registered by the German company IDEA AG, which refers to its proprietary drug delivery technology. The name means “carrying body” and is derived from the Latin word 'transferre', meaning 'to carry across', and the Greek word 'soma', meaning 'a body'. A \"Transfersome\" carrier is an artificial vesicle designed to exhibit the characteristics of a cell vesicle or a cell engaged in exocytosis, and thus suitable for controlled and, potentially, targeted drug delivery.\n\nThe term \"Transfersome\" and the underlying concept were introduced in 1991 by Gregor Cevc. Numerous groups have since been working with similar carriers, frequently using different names (e.g., elastic vesicle, flexible vesicle, Ethosome, etc.) to describe them.\n\nIn a broader sense, a \"Transfersome\" is a highly adaptable, stress-responsive complex aggregate. The form preferred by researchers and pharmacologists is an ultradeformable vesicle possessing an aqueous core surrounded by the complex lipid bilayer. Interdependencies inherent in the local composition and shape of the bilayer makes the vesicle both self-regulating and self-optimizing. This enables the \"Transfersome\" to cross various transport barriers efficiently, and then act as a Drug carrier for non-invasive targeted drug delivery and sustained release of therapeutic agents.\n\nThe carrier aggregate is composed of at least one amphiphat (such as phosphatidylcholine), which in aqueous solvents self-assembles into a lipid bilayer that closes into a simple lipid vesicle. By addition of at least one bilayer softening component (such as a biocompatible surfactant or an amphiphile drug) lipid bilayer flexibility and permeability are greatly increased. The resulting \"Transfersome\" is optimized for flexibility and permeability, and can therefore adapt its shape to ambient conditions easily and rapidly by adjusting local concentration of each bilayer component to the local stress experienced at the bilayer. Since its basic organization is broadly similar to a liposome, a \"Transfersome\" differs from more conventional vesicles primarily by its \"softer\", more deformable, and better adjustable artificial membrane.\n\nAnother beneficial consequence of strong bilayer deformability is the increased affinity of a \"Transfersome\" to bind and retain water. An ultradeformable and highly hydrophilic vesicle always tends to avoid dehydration, which may involve a transport process related to, but not identical with forward osmosis. For example, a \"Transfersome\" vesicle applied on an open biological surface, such as non-occluded skin, tends to penetrate its barrier and migrate into the water-rich deeper strata to secure adequate hydration. Barrier penetration involves reversible bilayer deformation, but must not compromise either vesicle integrity or barrier properties for the underlying hydration affinity and gradient to remain unimpaired.\n\nSince it is too large to diffuse through the skin, the \"Transfersome \" must find and exploit a suitable route through the organ. Use of \"Transfersome\" vesicles for drug delivery therefore relies on the carrier’s ability to widen and overcome the hydrophilic pores in the skin or some other (e.g. plant cuticle) opening. The subsequent gradual release of the active agent from the drug carrier allows the drug molecules to diffuse and finally bind to their targets. Drug transport to an intra-cellular action site may also involve fusion of the carrier’s lipid bilayer with the cell membrane, unless the vesicle is taken up actively by the cell in the process called endocytosis.\n\nThe mechanical properties and transportability of a vesicle can be studied by measuring stress- or deformation-dependent vesicle bilayer elasticity and changes in permeability. In a single experiment, the objective may be reached by determining the pressure dependent area density of the \"Transfersome\" suspension flux through a nano-porous filter, with pores at least 50% smaller than the average vesicle size. For the proper \"Transfersome\" vesicles, the proportionality function derived by the experiment, so-called “Penetrability”, increases non-linearly with the flux driving force (head pressure), often sigmoidally). The bulk suspension viscosity governs the highest achievable penetrability; a suspension of ideal \"Transfersome\" vesicles, experiencing no friction in the barrier, therefore yields a similar maximum penetrability value as the comparably tested vesicles-suspending fluid. On the other hand, the characteristic pressure needed to achieve a significant transport rate with the vesicles suspension mainly depends on the adaptability of the bilayer being evaluated. Analysis of experimental Penetrability vs. Driving pressure curves can therefore yield the characteristic bilayer elasticity and permeability values, based on a theoretical description of material flow as an activated transport process.\n\n\"Transfersome\" technology is best suited for non-invasive delivery of therapeutic molecules across open biological barriers where \"Transfersome\" vesicles can transport molecules that are too big to diffuse through the barrier. Examples include systemic delivery of therapeutically meaningful amounts of macromolecules, such as insulin or interferon, across intact mammalian skin. Other applications include the transport of small molecule drugs which have certain physicochemical properties which would otherwise prevent them from diffusing across the barrier.\n\nAnother attraction of \"Transfersome\" technology is the carrier's ability to target peripheral, subcutaneous tissue. This ability relies on minimisation of the carrier-associated drug clearance through cutaneous blood vessels plexus: the non-fenestrated blood capillary walls in the skin together with the tight junctions between endothelial cells preclude vesicles getting directly into blood, thus maximising local drug retention and propensity to reach the peripheral tissue targets. The Non-steroidal anti-inflammatory drug (NSAID) ketoprofen in a \"Transfersome\" formulation gained marketing approval by the Swiss regulatory agency (SwissMedic) in 2007; the product is expected to be marketed under the trademark \"Diractin\". Further therapeutic products based on the \"Transfersome\" technology, according to IDEA AG, are in clinical development.\n\n\"Transfersome\" vesicles are prepared in a similar manner as liposomes, except that no separation of the vesicle-associated and free drug is required. Examples include sonicating, extrusion, low shear rates mixing (multilamellar liposomes), or high high-shear homogenisation unilamellar liposomes) of the crude vesicle suspension.\n\n\n", "id": "6630855", "title": "Transfersome"}
{"url": "https://en.wikipedia.org/wiki?curid=2592262", "text": "Protein subcellular localization prediction\n\nProtein subcellular localization prediction (or just protein localization prediction) involves the prediction of where a protein resides in a cell, its subcellular localization.\n\nIn general, prediction tools take as input information about a protein, such as a protein sequence of amino acids, and produce a predicted location within the cell as output, such as the nucleus, Endoplasmic reticulum, Golgi apparatus, extracellular space, or other organelles. The aim is to build tools that can accurately predict the outcome of protein targeting in cells.\n\nPrediction of protein subcellular localization is an important component of bioinformatics based prediction of protein function and genome annotation, and it can aid the identification of drug targets. \n\nExperimentally determining the subcellular localization of a protein can be a laborious and time consuming task. Immunolabeling or tagging (such as with a green fluorescent protein) to view localization using fluorescence microscope are often used. A high throughput alternative is to use prediction. \n\nThrough the development of new approaches in computer science, coupled with an increased dataset of proteins of known localization, computational tools can now provide fast and accurate localization predictions for many organisms. This has resulted in subcellular localization prediction becoming one of the challenges being successfully aided by bioinformatics, and machine learning.\n\nMany prediction methods now exceed the accuracy of some high-throughput laboratory methods for the identification of protein subcellular localization. Particularly, some predictors have been developed that can be used to deal with proteins that may simultaneously exist, or move between, two or more different subcellular locations. Experimental validation is typically required to confirm the predicted localizations.\n\nIn 1999 PSORT was the first published program to predict subcellular localization. Subsequent tools and websites have been released using techniques such as neural networks, support vector machine and protein motifs. Predictors can be specialized for proteins in different organisms. Some are specialized for eukaryotic proteins, some for human proteins, and some for plant proteins. Methods for the prediction of bacterial localization predictors, and their accuracy, have been reviewed.\n\nThe development of protein subcellular location prediction has been summarized in two comprehensive review articles. Recent tools and an experience report can be found in a recent paper by Meinken and Min (2012).\n\nKnowledge of the subcellular localization of a protein can significantly improve target identification during the drug discovery process. For example, secreted proteins and plasma membrane proteins are easily accessible by drug molecules due to their localization in the extracellular space or on the cell surface.\n\nBacterial cell surface and secreted proteins are also of interest for their potential as vaccine candidates or as diagnostic targets. Aberrant subcellular localization of proteins has been observed in the cells of several diseases, such as cancer and Alzheimer's disease. Secreted proteins from some archaea that can survive in unusual environments have industrially important applications.\n\nBy using prediction a high number of proteins can be assessed in order to find candidates that are trafficked to the desired location.\n\nThe results of subcellular localization prediction can be stored in databases. Examples include the multi-species database Compartments, FunSecKB2, a fungal database; PlantSecKB, a plant database; MetazSecKB, an animal and human database; and ProtSecKB, a protist database.\n\n", "id": "2592262", "title": "Protein subcellular localization prediction"}
{"url": "https://en.wikipedia.org/wiki?curid=4623509", "text": "Secretory protein\n\nA secretory protein is any protein, whether it be endocrine or exocrine, which is secreted by a cell. Secretory proteins include many hormones, enzymes, toxins, and antimicrobial peptides.\nSecretory proteins are synthesized in the endoplasmic reticulum.\n\nThe production of a secretory protein starts like any other protein. The mRNA is produced and transported to the cytosol where it interacts with a free cytosolic ribosome. The part that is produced first, the N-terminal, contains a signal sequence consisting of 6 to 12 amino acids with hydrophobic side chains. This sequence is recognised by a cytosolic protein, SRP (Signal Recognition Particle), which stops the translation and aids in the transport of the mRNA-ribosome complex to an SRP receptor found in the membrane of the endoplasmic reticulum. When it arrives at the ER, the signal sequence is transferred to the translocon, a protein-conducting channel in the membrane that allows the newly synthesized polypeptide to be translocated to the ER lumen. The dissociation of SRP from the ribosome restores the translation of the secretory protein. The signal sequence is removed and the translation continues while the produced chain moves through the translocon (cotranslational translocation).\n\nAfter the production of the protein is completed, it interacts with several other proteins to gain its final state.\n\nAfter translation, proteins within the ER make sure that the protein is folded correctly. If after a first attempt the folding is unsuccessful, a second folding is attempted. If this fails too the protein is exported to the cytosol and labelled for destruction.\nAside from the folding, there is also a sugar chain added to the protein.\nAfter these changes, the protein is transported to the Golgi apparatus by a coated vesicle using coating protein COPII.\n\nIn the Golgi apparatus, the sugar chains are modified by adding or removing certain sugars.\nThe secretory protein leaves the Golgi apparatus by an uncoated vesicle.\n\nMembrane proteins with functional areas on the cytosolic side of both the vesicle and cell membrane make sure the vesicle associates with the membrane. The vesicle membrane fuses with the cell membrane and so the protein leaves the cell. \nSome vesicles don't fuse immediately and await a signal before starting the fusing. This is seen in vesicles carrying neurotransmitter in presynaptic cells. This process constitutes an effective cell-cell signaling mechanism via membrane vesicle trafficking from secretory cell to the target cells in human or animal body. Recently, the process has been extended to host-pathogen interface, wherein, gram negative microbes secrete bacterial outer membrane vesicles containing fully conformed signal proteins and virulence factors via exocytosis of nano-sized vesicles, in order to control host or target cell activities and exploit their environment.\nUniProt contains manually curated secretory proteins. There are also computationally predicted secretory protein databases, these databases are listed in the Secretome section.\n\n\n", "id": "4623509", "title": "Secretory protein"}
{"url": "https://en.wikipedia.org/wiki?curid=6812911", "text": "Chemotactic selection\n\nChemotaxis receptors are expressed in the surface membrane with diverse dynamics, some of them have long-term characteristics as they are determined genetically, others have short-term moiety as their assembly is induced \"ad hoc\" in the presence of the ligand. The diverse feature of the chemotaxis receptors and ligands provides the possibility to select chemotactic responder cells with a simple chemotaxis assay. By chemotactic selection we can determine whether a still not characterized molecule acts via the long- or the short-term receptor pathway. Recent results proved that chemokines (e.g. IL-8, RANTES) are working on long-term chemotaxis receptors, while vasoactive peptides (e.g. endothelin) act more on the short-term ones. Term \"chemotactic selection\" is also used to design a technique which separates eukaryotic or prokaryotic cells upon their chemotactic responsiveness to selector ligands.\n", "id": "6812911", "title": "Chemotactic selection"}
{"url": "https://en.wikipedia.org/wiki?curid=6809196", "text": "Chemotactic range fitting\n\nChemotactic responses elicited by the ligand-receptor interactions are distinguished generally upon the optimal effective concentration(s) of the ligand. Nevertheless, correlation of the amplitude elicited and ratio of the responder cells compared to the total number are also characteristic features of the chemotactic signaling. Investigations of ligand families (e.g. amino acids or oligopeptides) proved that there is a fitting of ranges (amplitudes; number of responder cells) and chemotactic activities: chemoattractant moiety is accompanied with wide, while chemorepellent character narrow ranges.\n", "id": "6809196", "title": "Chemotactic range fitting"}
{"url": "https://en.wikipedia.org/wiki?curid=6809062", "text": "Chemokinesis\n\nChemokinesis is chemically prompted kinesis, a motile response of unicellular prokaryotic or eukaryotic organisms to chemicals that cause the cell to make some kind of change in their migratory/swimming behaviour. Changes involve an increase or decrease of speed, alterations of amplitude or frequency of motile character, or direction of migration. However, in contrast to chemotaxis, chemokinesis has a random, non-vectorial moiety, in general.\nDue to the random character, techniques dedicated to evaluate chemokinesis are partly different from methods used in chemotaxis research. One of the most valuable ways to measure chemokinesis is computer-assisted (see, e.g., Image J) checker-board analysis, which provides data about migration of identical cells, whereas, in Protozoa (e.g., Tetrahymena), techniques based on measurement of opalescence were also developed.\n\n", "id": "6809062", "title": "Chemokinesis"}
{"url": "https://en.wikipedia.org/wiki?curid=6918430", "text": "Matricity\n\nMatricity is the interaction of a matrix with its environment. This word is used particularly of protein interactions, where a polymerised protein (a matrix) interacts with a membrane or another polymer. \n\nProtein interactions can normally be described by their affinities for each other. The interactions of clustered proteins for multivalent ligands are described by avidities (avidity), while matricity describes a semisolid state interaction of a matrix with its environment. As an example matricity has been used to describe the interaction of polymerised clathrin with adaptor complexes bound to the membrane.\n", "id": "6918430", "title": "Matricity"}
{"url": "https://en.wikipedia.org/wiki?curid=5880015", "text": "Cytomics\n\nCytomics is the study of cell biology (cytology) and biochemistry in cellular systems at the single cell level.{ It combines all the bioinformatic knowledge to attempt to understand the molecular architecture and functionality of the cell system (Cytome). Much of this is achieved by using molecular and microscopic techniques that allow the various components of a cell to be visualised as they interact \"in vivo\".\n\nCytomes are the cellular systems, subsystems, and functional components of the \nbody. The cytome is the collection of the complex and dynamic cellular processes (structure and function) underlying physiological processes. It describes the structural and functional heterogeneity of the cellular diversity of an organism. \n\nThe Human Cytome Project is aimed at the study of the biological system structure and function of an organism at the cytome level.\n\n\n", "id": "5880015", "title": "Cytomics"}
{"url": "https://en.wikipedia.org/wiki?curid=6531976", "text": "Chemokine receptor\n\nChemokine receptors are cytokine receptors found on the surface of certain cells that interact with a type of cytokine called a chemokine. There have been 20 distinct chemokine receptors discovered in humans. Each has a 7-transmembrane (7TM) structure and couples to G-protein for signal transduction within a cell, making them members of a large protein family of G protein-coupled receptors. Following interaction with their specific chemokine ligands, chemokine receptors trigger a flux in intracellular calcium (Ca) ions (calcium signaling). This causes cell responses, including the onset of a process known as chemotaxis that traffics the cell to a desired location within the organism. Chemokine receptors are divided into different families, CXC chemokine receptors, CC chemokine receptors, CX3C chemokine receptors and XC chemokine receptors that correspond to the 4 distinct subfamilies of chemokines they bind. Four families of chemokine receptors differ in spacing of cysteine residues near N-terminal of the receptor.\n\nChemokine receptors are G protein-coupled receptors containing 7 transmembrane domains that are found predominantly on the surface of leukocytes. Approximately 19 different chemokine receptors have been characterized to date, which share many common structural features; they are composed of about 350 amino acids that are divided into a short and acidic N-terminal end, seven helical transmembrane domains with three intracellular and three extracellular hydrophilic loops, and an intracellular C-terminus containing serine and threonine residues that act as phosphorylation sites during receptor regulation. The first two extracellular loops of chemokine receptors are linked together by disulfide bonding between two conserved cysteine residues. The N-terminal end of a chemokine receptor binds to chemokine(s) and is important for ligand specificity. G-proteins couple to the C-terminal end, which is important for receptor signaling following ligand binding. Although chemokine receptors share high amino acid identity in their primary sequences, they typically bind a limited number of ligands. Chemokine receptors are redundant in their function as more than one chemokine is able to bind to a single receptor.\n\nIntracellular signaling by chemokine receptors is dependent on neighbouring G-proteins. G-proteins exist as a heterotrimer; they are composed of three distinct subunits. When the molecule GDP is bound to the G-protein subunit, the G-protein is in an inactive state. Following binding of the chemokine ligand, chemokine receptors associate with G-proteins, allowing the exchange of GDP for another molecule called GTP, and the dissociation of the different G protein subunits. The subunit called Gβ activates an enzyme known as Phospholipase C (PLC) that is associated with the cell membrane. PLC cleaves Phosphatidylinositol (4,5)-bisphosphate (PIP2) to form two second messenger molecules called inositol triphosphate (IP3) and diacylglycerol (DAG); DAG activates another enzyme called protein kinase C (PKC), and IP3 triggers the release of calcium from intracellular stores. These events promote many signaling cascades, effecting a cellular response. For example, when CXCL8 (IL-8) binds to its specific receptors, CXCR1 or CXCR2, a rise in intracellular calcium activates the enzyme phospholipase D (PLD) that goes on to initiate an intracellular signaling cascade called the MAP kinase pathway. At the same time the G-protein subunit Gα directly activates an enzyme called protein tyrosine kinase (PTK), which phosphorylates serine and threonine residues in the tail of the chemokine receptor, causing its desensitisation or inactivation. The initiated MAP kinase pathway activates specific cellular mechanisms involved in chemotaxis, degranulation, release of superoxide anions, and changes in the avidity of cell adhesion molecules called integrins. Chemokines and their receptors play a crucial role in cancer metastatis as they are involved in extravastation, migration, micrometastatis, and angiogenesis. This role of chemokine is strikingly similar to their normal function of localizing leukocytes to an inflammatory site.\n\nHuman Immunodeficiency virus uses CCR5 receptor to target and infect host T-cells in humans. It weakens the immune system by destroying the CD4+ T-helper cells, making the body more susceptible to other infections. CCR5-Δ32 is an allelic variant of CCR5 gene with a 32 base pair deletion that results in a truncated receptor. People with this allele are resistant to AIDS as HIV cannot bind to the non-functional CCR5 receptor. An unusually high frequency of this allele is found in European Caucasian population, with an observed cline towards the north. Most researchers have attributed the current frequency of this allele to two major epidemics of human history: plague and smallpox. Although this allele originated much earlier, its frequency rose dramatically about 700 years ago. This led scientists to believe that bubonic plague acted as a selective pressure that drove CCR5-Δ32 to high frequency. It was speculated that allele may have provided protection against the Yerisinia pestis, which is the causative agent for plague. Many in vivo mouse studies have refuted this claim by showing no protective effects of CCR5-Δ32 allele in mice infected with Y. pestis. Another theory that has gained more scientific support links the current frequency of the allele to smallpox epidemic. Although plague has killed a greater number people in a given time period, smallpox has collectively taken more lives. As smallpox has been dated back to 2000 years, a longer time period would have given smallpox enough time to exert selective pressure given an earlier origin of CCR5-Δ32. Population genetic models that analyzed geographic and temporal distribution of both plague and smallpox provide a much stronger evidence for smallpox as the driving factor of CCR5-Δ32. Smallpox has a higher mortality rate than plague, and it mostly affects children under the age of ten. From an evolutionary viewpoint, this results in greater loss of reproductive potential from a population which may explain increased selective pressure by smallpox. Smallpox was more prevalent in regions where higher CCR5-Δ32 frequencies are seen. Myxoma and variola major belong to the same family of viruses and myxoma has been shown to use CCR5 receptor to enter its host. Moreover, Yerisinia is a bacterium which is biologically distinct from viruses and is unlikely to have similar mechanism of transmission. Recent evidence provides a strong support for smallpox as the selective agent for CCR5-Δ32.\n\nFifty chemokines have been discovered so far, and most bind onto CXC and CC families. Two types of chemokines that bind to these receptors are inflammatory chemokines and homeostatic chemokines. Inflammatory chemokines are expressed upon leukocyte activation, whereas homeostatic chemokines show continual expression.\n\n", "id": "6531976", "title": "Chemokine receptor"}
{"url": "https://en.wikipedia.org/wiki?curid=7049417", "text": "Dose fractionation\n\nExperiments in radiation biology have found that as the absorbed dose of radiation increases, the number of cells which survive decreases. They have also found that if the radiation is \"fractionated\" into smaller doses, with one or more rest periods in between, fewer cells die. This is because of self-repair mechanisms which repair the damage to DNA and other biomolecules such as proteins. These mechanisms can be over expressed in cancer cells, so caution should be used in using results for a cancer cell line to make predictions for healthy cells if the cancer cell line is known to be resistant to cytotoxic drugs such as cisplatin. The DNA self repair processes in some organisms is exceptionally good; for instance, the bacterium Deinococcus radiodurans can tolerate a 15 000 Gy (1.5 MRad) dose.\n\nIn the graph below, called a cell survival curve, the dose vs. surviving fraction have been drawn for a hypothetical group of cells with and without a rest time for the cells to recover. Other than the recovery time partway through the irradiation, the cells would have been treated identically.\n\nThe human body contains many types of cells, and the human can be killed by the loss of a single type of cells in a vital organ. For many short-term radiation deaths due to what is commonly known as radiation sickness (3 to 30 days after exposure), it is the loss of bone marrow cells (which produce blood cells), and the loss of other cells in the wall of the intestines, that is fatal.\n\nFractionation also refers to a method of treating cancer with radiation therapy. When the total dose of radiation is divided into several, smaller doses over a period of several days, there are fewer toxic effects on healthy cells. This maximizes the effect of radiation on cancer and minimizes the negative side effects. Typical fractionation schemes divide the dose into 30 units delivered every weekday over six weeks, though current research is considering the benefits of accelerated fractionation (two deliveries per day and/or deliveries on weekends as well).\n\nHypofractionation is a treatment regimen that delivers higher doses of radiation in fewer visits. The logic behind this treatment is that applying greater amounts of radiation works to lower the effects of accelerated tumor growth that typically occurs during the later stages of radiotherapy.\n\nHyperfractionation is dividing the same total dose into more deliveries. Treatments are given more than once a day. Hyperfractionated radiation therapy is given over the same period of time (days or weeks) as standard radiation therapy.\n", "id": "7049417", "title": "Dose fractionation"}
{"url": "https://en.wikipedia.org/wiki?curid=7140680", "text": "Biomarker (cell)\n\nA biomarker, or biological marker, is defined as a \"cellular, biochemical or molecular alteration in cells, tissues or fluids that can be measured and evaluated to indicate normal biological processes, pathogenic processes, or pharmacological responses to a therapeutic intervention.\" Biomarkers characterize disease progression starting from the earliest natural history of the disease. Biomarkers assess disease susceptibility and severity, which allows one to predict outcomes, determine interventions and evaluate therapeutic responses. From a forensics and epidemiologic perspective, biomarkers offer unique insight about the relationships between environmental risk factors.\n\nThree broad classes of biomarkers are prognostic biomarkers, predictive biomarkers and pharmacodynamic biomarkers.\n\nPrognostic biomarkers give intervention-independent information on disease status through screening, diagnosis and disease monitoring. Prognostic biomarkers can signify individuals in the latent period of a disease's natural history, allowing optimal therapy and prevention until the disease's termination. Prognostic biomarkers give information on disease status by measuring the internal precursors that increase or decrease the likelihood of attaining a disease. For example, blood pressure and cholesterol are biomarkers for CVD. Prognostic biomarkers can be direct or indirect to the causal pathway of a disease. If a prognostic biomarker is a direct step in the causal pathway, it is one of the factors or products of the disease. A prognostic biomarker could be indirectly associated with a disease if it is related to a change caused by the exposure, or related to an unknown factor connected with the exposure or disease.\n\nPredictive biomarkers measure the effect of a drug and tell if the drug is having its expected activity, but do not offer any direct information on the disease. Predictive biomarkers are highly sensitive and specific; therefore they increase diagnostic validity of a drug or toxin's site-specific effect by eliminating recall bias and subjectivity from those exposed. For example, when an individual is exposed to a drug or toxin, the concentration of that drug or toxin within the body, or the biological effective dose, provides a more accurate prediction for the effect of the drug or toxin compared to an estimation or measurement of the toxin from the origin or external environment.\n\nPharmacodynamic (PD) biomarkers can measure the direct interaction between a drug and its receptor. Pharmacodynamic biomarkers reveal drug mechanisms, if the drug has its intended effect on the biology of the disease, ideal biological dosing concentrations, and physiologic response/resistance mechanisms. Pharmacodynamic biomarkers are particularly relevant in drug mechanisms of tumor cells, where pharmacodynamic endpoints for drug interventions can be assessed directly on tumor tissues. For example, protein phosphorylation biomarkers indicate alterations in target protein kinases and activation of downstream signaling molecules.\n\nBiomarkers can be classified on their clinical applications as molecular biomarkers, cellular biomarkers or imaging biomarkers.\n\nFour of the main types of molecular biomarkers are genomic biomarkers, transcriptomic biomarkers, proteomic biomarkers and metabolic biomarkers.\n\nGenomic biomarkers analyze DNA by identifying irregular sequences in the genome, typically a single nucleotide polymorphism. Genetic biomarkers are particularly significant in cancer because most cancer cell lines carry somatic mutations. Somatic mutations are distinguishable from hereditary mutations because the mutation is not in every cell; just the tumor cells, making them easy targets.\n\nTranscriptomic biomarkers analyze all RNA molecules, not solely the exome. Transcriptomic biomarkers reveal the molecular identity and concentration of RNA in a specific cell or population. Pattern-based RNA expression analysis provides increased diagnostic and prognostic capability in predicting therapeutic responses for individuals. For example, distinct RNA subtypes in breast cancer patients have different survival rates.\n\nProteomics permits the quantitative analysis and detection of changes to proteins or protein biomarkers. Protein biomarkers detect a variety of biological changes, such as protein-protein interactions, post-translational modifications and immunological responses. \n\nCellular biomarkers allow cells to be isolated, sorted, quantified and characterized by their morphology and physiology. Cellular biomarkers are used in both clinical and laboratory settings, and can discriminate between a large sample of cells based on their antigens. An example of a cellular biomarker sorting technique is Fluorescent-activated cell sorting.\n\nImaging biomarkers allow earlier detection of disease compared to molecular biomarkers, and streamline translational research in the drug discovery marketplace. For example, one could determine the percent of receptors a drug targets, shortening the time and money of research during the new drug development stage. Imaging biomarkers also are non-invasive, which is a clinical advantage over molecular biomarkers. Some of the image-based biomarkers are X-Ray, Computed Tomography (CT), Positron Emission Tomography (PET), Single Photo Emission Computed Tomography (SPECT) and Magnetic Resonance Imaging (MRI).\n\n", "id": "7140680", "title": "Biomarker (cell)"}
{"url": "https://en.wikipedia.org/wiki?curid=7125109", "text": "Nuclear transport\n\nThe entry and exit of large molecules from the cell nucleus is tightly controlled by the nuclear pore complexes (NPCs). Although small molecules can enter the nucleus without regulation, macromolecules such as RNA and proteins require association with transport factors like karyopherins called importins to enter the nucleus and exportins to exit.\n\nProtein that must be imported to the nucleus from the cytoplasm carry nuclear localization signals (NLS) that are bound by importins. A NLS is a sequence of amino acids that acts as a tag. They are diverse in their composition and most commonly hydrophilic, although hydrophobic sequences have also been documented. Proteins, transfer RNA, and assembled ribosomal subunits are exported from the nucleus due to association with exportins, which bind signaling sequences called nuclear export signals (NES). The ability of both importins and exportins to transport their cargo is regulated by the small Ras related GTPase, Ran.\n\nGTPases are enzymes that bind to a molecule called guanosine triphosphate (GTP) which they then hydrolyze to create guanosine diphosphate (GDP) and release energy. Ran is in a different conformation depending on whether it is bound to GTP or GDP. In its GDP bound state, Ran is capable of binding karyopherins (importins and exportins). Importins release cargo upon binding to RanGTP, while exportins must bind RanGTP to form a ternary complex with their export cargo. The dominant nucleotide binding state of Ran depends on whether it is located in the nucleus (RanGTP) or the cytoplasm (RanGDP).\n\nImportin proteins bind their cargo in the cytoplasm, after which they are able to interact with the nuclear pore complex and pass through its channel. Once inside the nucleus, interaction with Ran-GTP causes a conformational change in the importin that causes it to dissociate from its cargo. The resulting complex of importin and Ran-GTP then translocates to the cytoplasm, where a protein called Ran Binding Protein (RanBP) separates Ran-GTP from importin. Separation allows access to a GTPase activating protein (GAP) that binds Ran-GTP and induces the hydrolysis of GTP to GDP. The Ran-GDP produced from this process now binds the nuclear transport factor NUTF2 which returns it to the nucleoplasm. Now in the nucleus, the Ran-GDP interacts with a guanine nucleotide exchange factor (GEF) which replaces the GDP with GTP, resulting again in Ran-GTP, and beginning the cycle anew.\n\nNuclear export roughly reverses the import process; in the nucleus, the exportin binds the cargo and Ran-GTP and diffuses through the pore to the cytoplasm, where the complex dissociates. Ran-GTP binds GAP and hydrolyzes GTP, and the resulting Ran-GDP complex is restored to the nucleus where it exchanges its bound ligand for GTP. Hence, whereas importins depend on RanGTP to dissociate from their cargo, exportins require RanGTP in order to bind to their cargo.\n\nA specialized mRNA exporter protein moves mature mRNA to the cytoplasm after post-transcriptional modification is complete. This translocation process is actively dependent on the Ran protein, although the specific mechanism is not yet well understood. Some particularly commonly transcribed genes are physically located near nuclear pores to facilitate the translocation process.\n\nTRNA export is also dependent on the various modifications it undergoes, thus preventing export of improperly functioning tRNA. This quality control mechanism is important due to tRNA's central role in translation, where it is involved in adding amino acids to a growing peptide chain. The tRNA exporter in vertebrates is called \"exportin-t\". Exportin-t binds directly to its tRNA cargo in the nucleus, a process promoted by the presence of RanGTP. Mutations that affect tRNA's structure inhibit its ability to bind to exportin-t, and consequentially, to be exported, providing the cell with another quality control step. As described above, once the complex has crossed the envelope it dissociates and releases the tRNA cargo into the cytosol.\n\nMany proteins are known to have both NESs and NLSs and thus shuttle constantly between the nucleus and the cytosol. In certain cases one of these steps (i.e., nuclear import or nuclear export) is regulated, often by post-translational modifications.\n\nProtein shuttling can be assessed using a \"heterokaryon fusion assay\".\n\n", "id": "7125109", "title": "Nuclear transport"}
{"url": "https://en.wikipedia.org/wiki?curid=7251258", "text": "Proteinoplast\n\nProteinoplasts (sometimes called \"proteoplasts\", \"aleuroplasts\", and \"aleuronaplasts\") are specialized organelles found only in plant cells. Proteinoplasts belong to a broad category of organelles known as plastids. Because they lack pigment, proteinoplasts are more specifically a kind of leucoplast. They contain crystalline bodies of protein and can be the sites of enzyme activity involving those proteins. Proteinoplasts are found in many seeds, such as brazil nuts, peanuts and pulses. Although all plastids contain high concentrations of protein, proteinoplasts were identified in the 1960s and 1970s as having large protein inclusions that are visible with both light microscopes and electron microscopes. \n\nA book written in 2007 noted that no scientific research had been published in the previous 25 years on proteinoplasts.\n\n", "id": "7251258", "title": "Proteinoplast"}
{"url": "https://en.wikipedia.org/wiki?curid=2150549", "text": "Oxidative stress\n\nOxidative stress reflects an imbalance between the systemic manifestation of reactive oxygen species and a biological system's ability to readily detoxify the reactive intermediates or to repair the resulting damage. Disturbances in the normal redox state of cells can cause toxic effects through the production of peroxides and free radicals that damage all components of the cell, including proteins, lipids, and DNA. Oxidative stress from oxidative metabolism causes base damage, as well as strand breaks in DNA. Base damage is mostly indirect and caused by reactive oxygen species (ROS) generated, e.g. O (superoxide radical), OH (hydroxyl radical) and HO (hydrogen peroxide). Further, some reactive oxidative species act as cellular messengers in redox signaling. Thus, oxidative stress can cause disruptions in normal mechanisms of cellular signaling.\n\nIn humans, oxidative stress is thought to be involved in the development of Asperger syndrome, ADHD, cancer, Parkinson's disease, Lafora disease, Alzheimer's disease, atherosclerosis, heart failure, myocardial infarction, fragile X syndrome, Sickle Cell Disease, lichen planus, vitiligo, autism, infection, Chronic fatigue syndrome, and depression. However, reactive oxygen species can be beneficial, as they are used by the immune system as a way to attack and kill pathogens. Short-term oxidative stress may also be important in prevention of aging by induction of a process named mitohormesis.\n\nChemically, oxidative stress is associated with increased production of oxidizing species or a significant decrease in the effectiveness of antioxidant defenses, such as glutathione. The effects of oxidative stress depend upon the size of these changes, with a cell being able to overcome small perturbations and regain its original state. However, more severe oxidative stress can cause cell death, and even moderate oxidation can trigger apoptosis, while more intense stresses may cause necrosis.\n\nProduction of reactive oxygen species is a particularly destructive aspect of oxidative stress. Such species include free radicals and peroxides. Some of the less reactive of these species (such as superoxide) can be converted by oxidoreduction reactions with transition metals or other redox cycling compounds (including quinones) into more aggressive radical species that can cause extensive cellular damage. Most long-term effects are caused by damage to DNA. DNA damage induced by ionizing radiation is similar to oxidative stress, and these lesions have been implicated in aging and cancer. Biological effects of single-base damage by radiation or oxidation, such as 8-oxoguanine and thymine glycol, have been extensively studied. Recently the focus has shifted to some of the more complex lesions. Tandem DNA lesions are formed at substantial frequency by ionizing radiation and metal-catalyzed HO reactions. Under anoxic conditions, the predominant double-base lesion is a species in which C8 of guanine is linked to the 5-methyl group of an adjacent 3'-thymine (G[8,5- Me]T). Most of these oxygen-derived species are produced at a low level by normal aerobic metabolism. Normal cellular defense mechanisms destroy most of these. Likewise, any damage to cells is constantly repaired. However, under the severe levels of oxidative stress that cause necrosis, the damage causes ATP depletion, preventing controlled apoptotic death and causing the cell to simply fall apart.\n\nPolyunsaturated fatty acids, particularly arachidonic acid and linoleic acid, are primary targets for free radical and singlet oxygen oxidations. For example, in tissues and cells, the free radical oxidation of linoleic acid produces racemic mixtures of 13-hydroxy-9\"Z\",11\"E\"-octadecadienoic acid, 13-hydroxy-9\"E\",11\"E\"-octadecadienoic acid, 9-hydroxy-10\"E\",12-\"E\"-octadecadienoic acid (9-EE-HODE), and 11-hydroxy-9\"Z\",12-\"Z\"-octadecadienoic acid as well as 4-Hydroxynonenal while singlet oxygen attacks linoleic acid to produce (presumed but not yet proven to be racemic mixtures of) 13-hydroxy-9\"Z\",11\"E\"-octadecadienoic acid, 9-hydroxy-10\"E\",12-\"Z\"-octadecadienoic acid, 10-hydroxy-8\"E\",12\"Z\"-octadecadienoic acid, and 12-hydroxy-9\"Z\"-13-\"E\"-octadecadienoic (see 13-Hydroxyoctadecadienoic acid and 9-Hydroxyoctadecadienoic acid). Similar attacks on arachidonic acid produce a far larger set of products including various isoprostanes, hydroperoxy- and hydroxy- eicosatetraenoates, and 4-hydroxyalkenals. While many of these products are used as markers of oxidative stress, the products derived from linoleic acid appear far more predominant than arachidonic acid products and therefore easier to identify and quantify in, for example, atheromatous plaques. Certain linoleic acid products have also been proposed to be markers for specific types of oxidative stress. For example, the presence of racemic 9-HODE and 9-EE-HODE mixtures reflects free radical oxidation of linoleic acid whereas the presence of racemic 10-hydroxy-8\"E\",12\"Z\"-octadecadienoic acid and 12-hydroxy-9\"Z\"-13-\"E\"-octadecadienoic acid reflects singlet oxygen attack on linoleic acid. In addition to serving as markers, the linoleic and arachidonic acid products can contribute to tissue and/or DNA damage but also act as signals to stimulate pathways which function to combat oxidative stress.\n\nTable adapted from.\n\nOne source of reactive oxygen under normal conditions in humans is the leakage of activated oxygen from mitochondria during oxidative phosphorylation. However, \"E. coli\" mutants that lack an active electron transport chain produced as much hydrogen peroxide as wild-type cells, indicating that other enzymes contribute the bulk of oxidants in these organisms. One possibility is that multiple redox-active flavoproteins all contribute a small portion to the overall production of oxidants under normal conditions.\n\nOther enzymes capable of producing superoxide are xanthine oxidase, NADPH oxidases and cytochromes P450. Hydrogen peroxide is produced by a wide variety of enzymes including several oxidases. Reactive oxygen species play important roles in cell signalling, a process termed redox signaling. Thus, to maintain proper cellular homeostasis, a balance must be struck between reactive oxygen production and consumption.\n\nThe best studied cellular antioxidants are the enzymes superoxide dismutase (SOD), catalase, and glutathione peroxidase. Less well studied (but probably just as important) enzymatic antioxidants are the peroxiredoxins and the recently discovered sulfiredoxin. Other enzymes that have antioxidant properties (though this is not their primary role) include paraoxonase, glutathione-S transferases, and aldehyde dehydrogenases.\n\nThe amino acid methionine is prone to oxidation, but oxidized methionine can be reversible. Oxidation of methionine is shown to inhibit the phosphorylation of adjacent Ser/Thr/Tyr sites in proteins. This gives a plausible mechanism for cells to couple oxidative stress signals with cellular mainstream signaling such as phosphorylation.\n\nOxidative stress is suspected to be important in neurodegenerative diseases including Lou Gehrig's disease (aka MND or ALS), Parkinson's disease, Alzheimer's disease, Huntington's disease, Depression, and Multiple sclerosis. Indirect evidence via monitoring biomarkers such as reactive oxygen species, and reactive nitrogen species production, antioxidant defense indicates oxidative damage may be involved in the pathogenesis of these diseases, while cumulative oxidative stress with disrupted mitochondrial respiration and mitochondrial damage are related with Alzheimer's disease, Parkinson's disease, and other neurodegenerative diseases.\n\nOxidative stress is thought to be linked to certain cardiovascular disease, since oxidation of LDL in the vascular endothelium is a precursor to plaque formation. Oxidative stress also plays a role in the ischemic cascade due to oxygen reperfusion injury following hypoxia. This cascade includes both strokes and heart attacks. Oxidative stress has also been implicated in chronic fatigue syndrome. Oxidative stress also contributes to tissue injury following irradiation and hyperoxia, as well as in diabetes.\n\nOxidative stress is likely to be involved in age-related development of cancer. The reactive species produced in oxidative stress can cause direct damage to the DNA and are therefore mutagenic, and it may also suppress apoptosis and promote proliferation, invasiveness and metastasis. Infection by \"Helicobacter pylori\" which increases the production of reactive oxygen and nitrogen species in human stomach is also thought to be important in the development of gastric cancer.\n\nThe use of antioxidants to prevent some diseases is controversial. In a high-risk group like smokers, high doses of beta carotene increased the rate of lung cancer since high doses of beta-carotene in conjunction of high oxygen tension due to smoking results in a pro-oxidant effect and an antioxidant effect when oxygen tension isn't high. In less high-risk groups, the use of vitamin E appears to reduce the risk of heart disease. However, while consumption of food rich in vitamin E may reduce the risk of coronary heart disease in middle-aged to older men and women, using vitamin E supplements also appear to result in an increase in total mortality, heart failure, and hemorrhagic stroke. The American Heart Association therefore recommends the consumption of food rich in antioxidant vitamins and other nutrients, but does not recommend the use of vitamin E supplements to prevent cardiovascular disease. In other diseases, such as Alzheimer's, the evidence on vitamin E supplementation is also mixed. Since dietary sources contain a wider range of carotenoids and vitamin E tocopherols and tocotrienols from whole foods, \"ex post facto\" epidemiological studies can have differing conclusions than artificial experiments using isolated compounds. However, AstraZeneca's radical scavenging nitrone drug NXY-059 shows some efficacy in the treatment of stroke.\n\nOxidative stress (as formulated in Harman's free radical theory of aging) is also thought to contribute to the aging process. While there is good evidence to support this idea in model organisms such as \"Drosophila melanogaster\" and \"Caenorhabditis elegans\", recent evidence from Michael Ristow's laboratory suggests that oxidative stress may also promote life expectancy of \"Caenorhabditis elegans\" by inducing a secondary response to initially increased levels of reactive oxygen species. This process was previously named mitohormesis or mitochondrial hormesis on a purely hypothetical basis. The situation in mammals is even less clear. Recent epidemiological findings support the process of mitohormesis, however a 2007 meta-analysis indicating studies with a low risk of bias (randomization, blinding, follow-up) find that some popular antioxidant supplements (Vitamin A, Beta Carotene, and Vitamin E) may increase mortality risk (although studies more prone to bias reported the reverse).\n\nThe USDA removed the table showing the Oxygen Radical Absorbance Capacity (ORAC) of Selected Foods Release 2 (2010) table due to the lack of evidence that the antioxidant level present in a food translated into a related antioxidant effect in the body.\n\nMetals such as iron, copper, chromium, vanadium, and cobalt are capable of redox cycling in which a single electron may be accepted or donated by the metal. This action catalyzes production of reactive radicals and reactive oxygen species. The presence of such metals in biological systems in an uncomplexed form (not in a protein or other protective metal complex) can significantly increase the level of oxidative stress. These metals are thought to induce Fenton reactions and the Haber-Weiss reaction, in which hydroxyl radical is generated from hydrogen peroxide. The hydroxyl radical then can modify amino acids. For example, meta-tyrosine and ortho-tyrosine form by hydroxylation of phenylalanine. Other reactions include lipid peroxidation and oxidation of nucleobases. Metal catalyzed oxidations also lead to irreversible modification of R (Arg), K (Lys), P (Pro) and T (Thr) Excessive oxidative-damage leads to protein degradation or aggregation.\n\nThe reaction of transition metals with proteins oxidated by Reactive Oxygen Species or Reactive Nitrogen Species can yield reactive products that accumulate and contribute to aging and disease. For example, in Alzheimer's patients, peroxidized lipids and proteins accumulate in lysosomes of the brain cells.\n\nCertain organic compounds in addition to metal redox catalysts can also produce reactive oxygen species. One of the most important classes of these are the quinones. Quinones can redox cycle with their conjugate semiquinones and hydroquinones, in some cases catalyzing the production of superoxide from dioxygen or hydrogen peroxide from superoxide.\n\nThe immune system uses the lethal effects of oxidants by making production of oxidizing species a central part of its mechanism of killing pathogens; with activated phagocytes producing both ROS and reactive nitrogen species. These include superoxide , nitric oxide (•NO) and their particularly reactive product, peroxynitrite (ONOO-). Although the use of these highly reactive compounds in the cytotoxic response of phagocytes causes damage to host tissues, the non-specificity of these oxidants is an advantage since they will damage almost every part of their target cell. This prevents a pathogen from escaping this part of immune response by mutation of a single molecular target.\n\n", "id": "2150549", "title": "Oxidative stress"}
{"url": "https://en.wikipedia.org/wiki?curid=4501641", "text": "Stress granule\n\nStress granules are dense aggregations in the cytosol composed of proteins & RNAs that appear when the cell is under stress. The RNA molecules stored are stalled translation pre-initiation complexes: failed attempts to make protein from mRNA. Stress granules are 100–200 nm in size, not surrounded by membrane, and associated with the endoplasmatic reticulum. Note that there are also nuclear stress granules. This article is about the cytosolic variety.\n\nStress granules have long been proposed to have a function to protect RNAs from harmful conditions, thus their appearance under stress. The accumulation of RNAs into dense globules could keep them from reacting with harmful chemicals and safe-guard the information coded in their RNA sequence.\n\nStress granules might also function as a decision point for untranslated mRNAs. Molecules can go down one of three paths: further storage, degradation, or re-initiation of translation. Conversely, it has also been argued that stress granules are not important sites for mRNA storage nor do they serve as an intermediate location for mRNAs in transit between a state of storage and a state of degradation.\n\nEfforts to identify all RNAs within stress granules (the stress granule transcriptome) in an unbiased way by sequencing RNA from biochemically purified stress granule \"cores\" have shown that mRNAs may be only generically associated with stress granules, since particular mRNAs are not comparatively enriched in stress granules compared to the cytosol and nearly all mRNAs in the cell can be found in stress granules to some extent. Furthermore, it was estimated that only about 10% of the total mRNA in the cell is localized to stress granules, suggesting that stress granules only influence a minority of mRNAs in the cell and may not be as important for mRNA processing as previously thought.\n\nThe stress proteins that are the main component of stress granules in plant cells are molecular chaperones that sequester, protect, and possibly repair proteins that unfold during heat and other types of stress. Therefore, any association of mRNAs with stress granules may simply be a side effect of the association of partially unfolded RNA-binding proteins with stress granules, similar to the association of mRNAs with proteasomes.\n\nEnvironmental stressors trigger cellular signaling which eventually leads to the formation of stress granules. \"In vitro\", these stressors can include heat, cold, oxidative stress (sodium arsenite), endoplasmic reticulum stress (thapsigargin), proteasome inhibition (MG132), hyperosmotic stress, ultraviolet radiation, inhibition of eIF4A (pateamine A or RocA), or other stressors like puromycin that result in disassembled polysomes. Many of these stressors result in the activation of particular stress-associated kinases (HRI, PERK, PKR, and GCN2), translational inhibition and stress granule formation.\n\nStress granule formation is often downstream of the stress-activated phosphorylation of eukaryotic translation initiation factor eIF2α, but this isn't true for all types of stressors that induce stress granules. Further downstream, prion-like aggregation of the protein TIA-1 promotes the formation of stress granules. The term prion-like is used because aggregation of TIA-1 is concentration dependent, inhibited by chaperones, and because the aggregates are resistant to proteases. It has also been proposed that microtubules play a role in the formation of stress granules, maybe by transporting granule components. This hypothesis is based on the fact that disruption of microtubules with the chemical nocodazole blocks the appearance of the granules. Furthermore, many signaling molecules were shown to regulate the formation or dynamics of stress granules; these include the master energy sensor AMP-activated protein kinase (AMPK), the O-GlcNAc transferase enzyme (OGT), and the pro-apoptotic kinase ROCK1.\n\nStress granules and processing bodies share RNA and protein components, both appear under stress, and can physically associate with one another. The protein G3BP1 is necessary for the proper docking of processing bodies and stress granules to each other, which may be important for the preservation of polyadenylated mRNAs.\n\nAlthough some protein components are shared between stress granules and processing bodies, the majority of proteins in either structure are uniquely localized to either structure. While both stress granules and processing bodies are associated with mRNAs, processing bodies have been long proposed to be sites of mRNA degradation because they contain enzymes like DCP1/2 and XRN1 that are known to degrade mRNAs. However, others have demonstrated that mRNAs associated with processing bodies are largely translationally repressed but not degraded. It has also been proposed that mRNAs selected for degradation are passed from stress granules to processing bodies.\n\nThe complete proteome of stress granules is still unknown, but efforts have been made to catalog all of the proteins that have been experimentally demonstrated to transit into stress granules. Importantly, different stressors can result in stress granules with different protein components. Many stress granule-associated proteins have been identified by transiently stressing cultured cells and utilizing microscopy to detect the localization of a protein of interest either by expressing that protein fused to a fluorescent protein (i.e. green fluorescent protein (GFP)) and/or by fixing cells and using antibodies to detect the protein of interest along with known protein markers of stress granules (immunocytochemistry).\n\nIn 2016, stress granule \"cores\" were experimentally identified and then biochemically purified for the first time. Proteins in the cores were identified in an unbiased manner using mass spectrometry. This technical advance lead to the identification of hundreds of new stress granule-localized proteins.\n\nThe following is a list of proteins that have been demonstrated to localize to stress granules (compiled from ):\n\nReview articles:\nLaboratories:\n", "id": "4501641", "title": "Stress granule"}
{"url": "https://en.wikipedia.org/wiki?curid=608534", "text": "Coenobium (morphology)\n\nA coenobium (plural coenobia) is a colony containing a fixed number of cells, with little or no specialization. They occur in several groups of algae. The cells are often embedded in a mucilaginous matrix and may be motile or non-motile.\n\nExamples include \"Volvox\" and its relatives, \"Scenedesmus\", \"Pediastrum\", and \"Hydrodictyon\".\n", "id": "608534", "title": "Coenobium (morphology)"}
{"url": "https://en.wikipedia.org/wiki?curid=8258485", "text": "Ubiquitin-conjugating enzyme\n\nUbiquitin-conjugating enzymes, also known as E2 enzymes and more rarely as ubiquitin-carrier enzymes, perform the second step in the ubiquitination reaction that targets a protein for degradation via the proteasome. The ubiquitination process covalently attaches ubiquitin, a short protein of 76 amino acids, to a lysine residue on the target protein. Once a protein has been tagged with one ubiquitin molecule, additional rounds of ubiquitination form a polyubiquitin chain that is recognized by the proteasome's 19S regulatory particle, triggering the ATP-dependent unfolding of the target protein that allows passage into the proteasome's 20S core particle, where proteases degrade the target into short peptide fragments for recycling by the cell.\n\nA ubiquitin-activating enzyme, or E1, first activates the ubiquitin by covalently attaching the molecule to its active site cysteine residue. The activated ubiquitin is then transferred to an E2 cysteine. Once conjugated to ubiquitin, the E2 molecule binds one of several ubiquitin ligases or E3s via a structurally conserved binding region. The E3 molecule is responsible for binding the target protein substrate and transferring the ubiquitin from the E2 cysteine to a lysine residue on the target protein.\n\nA particular cell usually contains only a few types of E1 molecule, a greater diversity of E2s, and a very large variety of E3s. The E3 molecules responsible for substrate identification and binding are thus the mechanisms of substrate specificity in proteasomal degradation. Each type of E2 can associate with many E3s.\n\nThe following human genes encode ubiquitin-conjugating enzymes:\n\n\n", "id": "8258485", "title": "Ubiquitin-conjugating enzyme"}
{"url": "https://en.wikipedia.org/wiki?curid=7671308", "text": "Cytolysin\n\nCytolysin refers to the substance secreted by microorganisms, plants or animals that is specifically toxic to individual cells, in many cases causing their dissolution through lysis. Cytolysins that have a specific action for certain cells are named accordingly. For instance, the cytolysins responsible for the destruction of red blood cells, thereby liberating hemoglobins, are named \"hemolysins\", and so on. Cytolysins may be involved in immunity as well as in venoms.\n\nHemolysin is also used by certain bacteria, such as \"Listeria monocytogenes\", to disrupt the phagosome membrane of macrophages and escape into the cytoplasm of the cell.\n\nThe term \"Cytolysin\" or \"Cytolytic toxin\" was first introduced by Alan Bernheimer to describe membrane damaging toxins (MDTs) that have cytolytic effects to cells. The first kind of cytolytic toxin discovered have hemolytic effects on erythrocytes of certain sensitive species, such as Human. For this reason \"Hemolysin\" was first used to describe any MDTs. In the 1960s certain MDTs were proved to be destructive on cells other than erythrocytes, such as leukocytes. The term \"Cytolysin\" is then introduced by Bernheimer to replace \"Hemolysin\". Cytolysins can destruct membranes without creating lysis to cells. Therefore, \"membrane damaging toxins\" (MDTs) describes the essential actions of cytolysins. Cytolysins comprise more than 1/3 of all bacterial protein toxins. Bacterial protein toxins can be highly poisonous to human. For example, \"Botulinum\" is 3x10 more toxic than snake venom to human and its toxic dose is only 0.8x10 mg. A wide variety of gram-positive and gram-negative bacteria use cytolysin as their primary weapon for creating diseases, such as \"Clostridium perfringens\" and \"Staphylococcus\".\n\nA diverse range of studies has been done on Cytolysins. Since the 1970s, more than 40 new cytolysins have been discovered and grouped into different families. At genetic level, the genetic structures of about 70 Cytolysin proteins has been studied and published. The detailed process of membrane damage has also been surveyed. Rossjohn et al. presents the crystal structure of \"perfringolysin\" O, a thiol-activated cytolysin, which creates membrane holes on eukaryotic cells. A detailed model of membrane channel formation that reveals membrane insertion mechanism is constructed. Shatursky et al. studied the membrane insertion mechanism of Perfringolysin O (PFO), a cholesterol-dependent pore-forming cytolysin produced by pathogenic Clostridium perfringens. Instead of using a single amphipathic β hairpin per plypeptide, PFO monomer contains two amphipathic β hairpins, each spans the whole membrane. Larry et al. focused on the membrane penetrating models of RTX toxins, a family of MDT secreted by many gram-negative bacteria. The insertion and transport process of the protein from RTX to target lipid membrane was revealed.\n\nThe membrane-damaging cytolysins can be classified into three types based on their damaging mechanism:\n\nPore forming cytolysins (PFCs) comprise near 65% of all membrane-damaging cytolysins. The first pore forming cytolysin is discovered by Manfred Mayer in 1972 of the C5-C9 insertion of erythrocytes. PFCs can be produced by a wide variety of sources, such as bacteria, fungi and even plants. The pathogenic process of PFCs normally involves forming channels or pores at the target cells' membranes. Note that the pores can have many structures. A porin-like structure allows molecules of certain sizes to pass through. Electric fields distribute unevenly across the pore and enable the selection molecules that can get through. This type of structure is shown in \"staphylococcal\" α-hemolysin. A pore can also be formed through membrane fusions. Controlled by Ca, the membrane fusion of vesicles form water-filled pores from proteolipids.\n\nA more complex pore formation process involves a oligomerization process of several PFC monomers. The pore forming process comprise 3 basic steps. The cytolysins are produced by certain microorganisms at first. Sometimes the producer organism needs to create a pore at its own membrane to release such cytolysins, like the case colicins produced by \"Escherichia coli\". Cytolysins are released as protein monomers in a water-soluble state in this step. Note that cytolysins are often toxic to its producing hosts as well. For example, colicins consume nucleic acids of cells by using several enzymes. To prevent such toxicity, host cells produce immunity proteins for binding cytolysins before they do any damage inward.\n\nIn the second step, cytolysins adhere to target cell membranes by matching the \"\"receptors\"'\" on the membranes. Most receptors are proteins, but they can be other molecules as well, such as lipids or sugars. With the help of receptors, cytolysin monomers combines with each other and form clusters of oligomers. During this stage, cytolysins complete transition from water-soluble monomers state into oligomers state.\n\nFinally, the formed cytolysin clusters penetrate target cells' membranes and form membrane pores. The size of these pores varies from 1-2 nm ( \"S. aureus α-toxin\", \"E. coli α-hemolysin\", \"Aeromonas aerolysin\") to 25-30 nm (\"streplysin O\", \"pneumolysin\").\n\nDepending on how the pores are formed, the pore forming cytolysins fall into two categories. Those form pores using helices are named α-PFTs (Pore forming toxins). Those form pores using β-barrel structures are named β-PFTs. Some of the common α-PFTs and β-PFTs are summarized using a table.\nThe lethal effects of pore-forming cytolysins are performed by causing influx and outflux disorder in a single cell. Pores that allow ions like Na to pass through created imbalance in the target cell which exceeds its ion-balancing capacity. Attacked cells therefore expand to lysis. When target cell membranes are destructed, bacteria which produce the cytolysins can consume the intracellular elements of the cell, such as iron and cytokines. Some enzymes that decompose target-cells' critical structures can enter the cells without obstructions.\n\nOne specific type of cytolysin is the \"Cholesterol-dependent cytolysin\" (CDC). CDCs exist in many Gram-positive bacteria. The pore forming process of CDCs require the presence of cholesterols on target-cell membranes. The pore size created by CDC is large (25-30 nm) due to the oligomeric process of cytolysins. Note that cholesterol are not always necessary at during the adhering phase. For example, Intermedilysin requires only the presence of protein receptors when attaching to target cells and cholesterols are required at pore forming. The formation of pores through CDCs involve an additional step than the steps analyzed above. The water-soluble monomers oligomerize to form an intermediate product named \"pre-pore\" complex and then a β-barrel is penetrated into the membrane.\n\n", "id": "7671308", "title": "Cytolysin"}
{"url": "https://en.wikipedia.org/wiki?curid=501101", "text": "Clathrin\n\nClathrin is a protein that plays a major role in the formation of coated vesicles. Clathrin was first isolated and named by Barbara Pearse in 1976. It forms a triskelion shape composed of three clathrin heavy chains and three light chains. When the triskelia interact they form a polyhedral lattice that surrounds the vesicle. This is how clathrin gets its name, from the Latin \"clathratus\" meaning like a lattice. Coat-proteins, like clathrin, are used to build small vesicles in order to transport molecules within cells. The endocytosis and exocytosis of vesicles allows cells to communicate, to transfer nutrients, to import signaling receptors, to mediate an immune response after sampling the extracellular world, and to clean up the cell debris left by tissue inflammation. The endocytic pathway can be hijacked by viruses and other pathogens in order to gain entry to the cell during infection.\n\nThe clathrin triskelion is composed of three clathrin heavy chains interacting at their C-termini, each ~190 kDa heavy chain has a ~25 kDa light chain tightly bound to it. The three heavy chains provide the structural backbone of the clathrin lattice, and the three light chains are thought to regulate the formation and disassembly of a clathrin lattice. There are two forms of clathrin light chains, designated a and b. The main clathrin heavy chain, located on chromosome 17 in humans, is found in all cells. A second clathrin heavy chain gene, on chromosome 22, is expressed in muscle.\n\nClathrin heavy chain is often described as a leg, with subdomains, representing the foot (the N-terminal domain), followed by the ankle, distal leg, knee, proximal leg, and trimerization domains. The N-terminal domain consists of a seven-bladed β-propeller structure. The other domains form a super-helix of short alpha helices. This was originally determined from the structure of the proximal leg domain that identified and is composed of a smaller structural module referred to as clathrin heavy chain repeat motifs. The light chains bind primarily to the proximal leg portion of the heavy chain with some interaction near the trimerization domain. The β-propeller at the 'foot' of clathrin contains multiple binding sites for interaction with other proteins.\n\nWhen triskelia assemble together in solution, they can interact with enough flexibility to form 6-sided rings (hexagons) that yield a flat lattice, or 5-sided rings (pentagons) that are necessary for curved lattice formation. When many triskelions connect, they can form a basket-like structure. The structure shown, is built of 36 triskelia, one of which is shown in blue. Another common assembly is a truncated icosahedron. To enclose a vesicle, exactly 12 pentagons must be present in the lattice.\n\nIn a cell, clathrin triskelion in the cytoplasm binds to an adaptor protein that has bound membrane, linking one of its three feet to the membrane at a time. Clathrin cannot bind to membrane or cargo directly and instead uses adaptor proteins to do this. This triskelion will bind to other membrane-attached triskelia to form a rounded lattice of hexagons and pentagons, reminiscent of the panels on a soccer ball, that pulls the membrane into a bud. By constructing different combinations of 5-sided and 6-sided rings, vesicles of different sizes may assemble. The smallest clathrin cage commonly imaged, called a mini-coat, has 12 pentagons and only two hexagons. Even smaller cages with zero hexagons probably do not form from the native protein, because the feet of the triskelia are too bulky.\n\nLike many proteins, clathrin represents a perfect case of form following function; it performs critical roles in shaping rounded vesicles in the cytoplasm for intracellular trafficking. Clathrin-coated vesicles (CCV) selectively sort cargo at the cell membrane, trans-Golgi network, and endosomal compartments for multiple membrane traffic pathways. After a vesicle buds into the cytoplasm, the coat rapidly disassembles, allowing the clathrin to recycle while the vesicle gets transported to a variety of locations.\n\nAdaptor molecules are responsible for self-assembly and recruitment. Two examples of adaptor proteins are AP180 and epsin. AP180 is used in synaptic vesicle formation. It recruits clathrin to membranes and also promotes its polymerization. Epsin also recruits clathrin to membranes and promotes its polymerization, and can help deform the membrane, and thus clathrin-coated vesicles can bud. In a cell, a triskelion floating in the cytoplasm binds to an adaptor protein, linking one of its feet to the membrane at a time. The skelion will bind to other ones attached to the membrane to form a polyhedral lattice, skelion, which pulls the membrane into a bud. The skelion does not bind directly to the membrane, but binds to the adaptor proteins that recognize the molecules on the membrane surface.\n\nClathrin has another function aside from the coating of organelles. In non-dividing cells, the formation of clathrin-coated vesicles occurs continuously. Formation of clathrin-coated vesicles is shut down in cells undergoing mitosis. During mitosis, clathrin binds to the spindle apparatus, in complex with two other proteins: TACC3 and ch-TOG/CKAP5. Clathrin aids in the congression of chromosomes by stabilizing kinetochore fibers of the mitotic spindle. The amino-terminal domain of the clathrin heavy chain and the TACC domain of TACC3 make the microtubule binding surface for TACC3/ch-TOG/clathrin to bind to the mitotic spindle. The stabilization of kinetochore fibers requires the trimeric structure of clathrin in order to crosslink microtubules.\n\nClathrin-mediated endocytosis (CME) regulates many cellular physiological processes such as the internalization of growth factors and receptors, entry of pathogens, and synaptic transmission. It is believed that cellular invaders use the nutrient pathway to gain access to a cell's replicating mechanisms. Certain signalling molecules open the nutrients pathway. Two chemical compounds called Pitstop 1 and Pitstop 2, selective clathrin inhibitors, can interfere with the pathogenic activity, and thus protect the cells against invasion. These two compounds selectively block the endocytic ligand association with the clathrin terminal domain in vitro. However, the specificity of these compounds to block clathrin-mediated endocytosis has been questioned.\n\n\n\n", "id": "501101", "title": "Clathrin"}
{"url": "https://en.wikipedia.org/wiki?curid=8758178", "text": "FlyBase\n\nFlyBase is an online bioinformatics database and the primary repository of genetic and molecular data for the insect family \"Drosophilidae\". For the most extensively studied species and model organism, \"Drosophila melanogaster\", a wide range of data are presented in different formats. Information in FlyBase originates from a variety of sources ranging from large-scale genome projects to the primary research literature. These data types include mutant phenotypes, molecular characterization of mutant alleles and other deviations, cytological maps, wild-type expression patterns, anatomical images, transgenic constructs and insertions, sequence-level gene models and molecular classification of gene product functions. Query tools allow navigation of FlyBase through DNA or protein sequence, by gene or mutant name, or through terms from the several ontologies used to capture functional, phenotypic, and anatomical data. The database offers several different query tools in order to provide efficient access to the data available and facilitate the discovery of significant relationships within the database. Links between FlyBase and external databases, such as BDGP or modENCODE, provide opportunity for further exploration into other model organism databases and other resources of biological and molecular information. The FlyBase project is carried out by a consortium of \"Drosophila\" researchers and computer scientists at Harvard University and Indiana University in the United States, and University of Cambridge in the United Kingdom.\n\nFlyBase is one of the organizations contributing to the Generic Model Organism Database (GMOD).\n\n\"Drosophila melanogaster\" has been an experimental organism since the early 1900s, and has since been placed at the forefront of many areas of research. As this field of research spread and became global, researchers working on the same problems needed a way to communicate and monitor progress in the field. This niche was initially filled community newsletters such as the Drosophila Information Service (DIS), which dates back to 1934 when the field was starting to spread from Thomas Hunt Morgan’s lab. Material in these presented regular ‘catalogs’ of mutations bibliographies of the Drosophila literature. As computer infrastructure developed in the 80’s and 90’s, these newsletters gave way and merged with internet mailing lists, and these eventually became online resources and data. In 1992, data on the genetics and genomics of \"D. melanogaster\" and related species were electronically available over the Internet through the funded FlyBase, BDGP (Berkeley Drosophila Genome Project) and EDGP (European Drosophila Genome Project) informatics groups. These groups recognized that most genome project and community data types overlapped. They decided it would be of value to present the scientific community with an integrated view of the data. In October 1992, the National Center for Human Genome Research of the NIH funded the FlyBase project with the objective of designing, building and releasing a database of genetic and molecular information concerning \"Drosophila melanogaster\". FlyBase also receives support from the Medical Research Council, London. In 1998, the FlyBase consortium integrated the information into a single Drosophila genomics server.\n\nFlyBase contains a complete annotation of the \"Drosophila melanogaster\" genome that is updated several times per year. It also includes a searchable bibliography of research on \"Drosophila\" genetics in the last century. Information on current researchers, and a partial pedigree of relationships between current researchers, is searchable, based on registration of the participating scientist (Find a Person). The site also provides a large database of images illustrating the full genome, and several movies detailing embryogenesis (ImageBrowser).\n\nSearch Strategies - Gene reports for genes from all twelve sequenced Drosophila genomes are available in FlyBase. There are four main ways this data can be browsed: Precomputed Files, BLAST, Gbrowse, and Gene Report Pages. Gbrowse and precomputed files are for genome-wide analysis, bioinformatics, and comparative genomics. BLAST and gene report pages are for a specific gene, protein, or region across the species.\n\nWhen looking for cytology there are two main tools available. Use Cytosearch when looking for cytologically-mapped genes or deficiencies, that haven’t been molecularly mapped to the sequence. Use Gbrowse when looking for molecularly mapped sequences, insertions, or Affymetrix probes.\n\nThere are two main query tools in FlyBase. The first main query tool is called Jump to Gene (J2G). This is found in the top right of the blue navigation bar on every page of FlyBase. This tool is useful when you know exactly what you are looking for and want to go to the report page with that data. The second main query tool is called QuickSearch. This is located on the FlyBase homepage. This tool is most useful when you want to look up something quickly that you may only know a little about. Searching can be performed within D. melanogaster only or within all species. Data other than genes can be searched using the ‘data class’ menu.\nThe following provides two examples of research that is related to or uses FlyBase:\n\n\n\n\n", "id": "8758178", "title": "FlyBase"}
{"url": "https://en.wikipedia.org/wiki?curid=777462", "text": "Neuroblast\n\nA neuroblast or primitive nerve cell is a dividing cell that will develop into a neuron often after a migration phase. \nNeuroblasts differentiate from neural stem cells and are committed to the neuronal fate. The main difference between a neuroblast and a neuron is the ability to divide; neuroblasts can still undergo mitosis, whereas neurons are postmitotic.\n\nNeuroblasts are mainly present as precursors of neurons during embryonic development; however, they also constitute one of the cell types involved in adult neurogenesis. Adult neurogenesis is characterized by neural stem cell differentiation and integration in the mature adult mammalian brain. This process occurs in the dentate gyrus of the hippocampus and in the subventricular zones of the adult mammalian brain. Neuroblasts are formed when a neural stem cell, which can differentiate into any type of mature neural cell (i.e. neurons, oligodendrocytes, astrocytes, etc.), divides and becomes a transit amplifying cell. Transit amplifying cells are slightly more differentiated than neural stem cells and can divide asymmetrically to produce postmitotic neuroblasts or glioblasts, as well as other transit amplifying cells. A neuroblast, a daughter cell of a transit amplifying cell, is initially a neural stem cell that has reached the \"point of no return.\" A neuroblast has differentiated such that it will mature into a neuron and not any other neural cell type. Neuroblasts are being studied extensively as they have the potential to be used therapeutically to combat cell loss due to injury or disease in the brain, although their potential effectiveness is debated.\n\nNeuroblasts form the mantle layer which goes on to form the grey matter of the spinal cord. The outer layer to the mantle layer is the marginal layer and this contains the myelinated axons from the neuroblasts forming the white matter of the spinal cord.\n\nIn humans, neuroblasts produced by stem cells in the adult subventricular zone migrate into damaged areas after brain injuries. However, they are restricted to the subtype of small interneuron-like cells, and it is unlikely that they contribute to functional recovery of striatial circuits.\n\nResearchers Chris Doe, Corey Goodman and Mike Bate have characterized neuroblasts and their development in some detail in \"Drosophila melanogaster\".\n\nIn the neuroectoderm, small clusters of equivalent cells acquire the potential to become neuroblasts, through the expression of proneural genes. From there, one particular cell from each cluster is selected to become a neuroblast, through the action of the Notch signaling pathway. Once the future neuroblast cells are selected, they delaminate, then carry on dividing for a pre-programmed number of divisions.\n\nNeuroblasts divide asymmetrically at every stage, creating one cell that continues being a neuroblast, and one cell that becomes the Ganglion Mother Cell (GMC), which goes on to divide into 4 differentiated cells (neurons or glia). The switch from pluripotent neuroblast to differentiated cell fate is facilitated by the proteins Prospero, Numb, and Miranda. Prospero is a transcription factor that triggers differentiation. It is expressed in neuroblasts, but is kept out of the nucleus by Miranda, which tethers it to the cell basal cortex. This also results in asymmetric division, where Prospero localizes in only one out of the two daughter cells. After division, Prospero enters the nucleus, and the cell it is present in becomes the GMC.\n\nEach neuroblast goes on to create a specific sequence of cells with particular identities. This is partly based on the position of the neuroblast along the Anterior/Posterior and Dorsal/Ventral axes, and partly on a temporal sequence of transcription factors that are expressed in a specific order as neuroblasts undergo sequential divisions.\n\n", "id": "777462", "title": "Neuroblast"}
{"url": "https://en.wikipedia.org/wiki?curid=8854753", "text": "Calcium sparks\n\nA calcium spark is the microscopic release of calcium (Ca) from a store known as the sarcoplasmic reticulum (SR), located within muscle cells. This release occurs through an ion channel within the membrane of the SR, known as a ryanodine receptor (RyR), which opens upon activation. This process is important as it helps to maintain Ca concentration within the cell. It also initiates muscle contraction in skeletal and cardiac muscles and muscle relaxation in smooth muscles. Ca sparks are important in physiology as they show how Ca can be used at a subcellular level, to signal both local changes, known as local control, as well as whole cell changes.\n\nAs mentioned above, Ca sparks depend on the opening of ryanodine receptors, of which there are three types:\nOpening of the channel allows Ca to pass from the SR, into the cell. This increases the local Ca concentration around the RyR, by a factor of 10. Calcium sparks can either be evoked or spontaneous, as described below.\nElectrical impulses, known as action potentials, travel along the cell membrane (sarcolemma) of muscle cells. Located in the sarcolemma of smooth muscle cells are receptors, called dihydropyridine receptors (DHPR). In skeletal and cardiac muscle cells, however, these receptors are located within structures known as T-tubules, that are extensions of the plasma membrane penetrating deep into the cell (see figure 1). These DHPRs are located directly opposite to the ryanodine receptors, located on the sarcoplasmic reticulum and activation, by the action potential causes the DHPRs to change shape.\n\nIn cardiac and smooth muscle, activation of the DHPR results in it forming an ion channel. This allows Ca to pass into the cell, increasing the local Ca concentration, around the RyR. When four Ca molecules bind to the RyR, it opens, resulting in a larger release of Ca, from the SR . This process, of using Ca to activate release of Ca from the SR is known as calcium-induced calcium release.\n\nHowever, in skeletal muscle the DHPR touches the RyR. Therefore, the shape change of the DHPR activates the RyR directly, without the need for Ca to flood into the cell first. This causes the RyR to open, allowing Ca to be released from the SR.\n\nCa sparks can also occur in cells at rest (i.e. cells that have not been stimulated by an action potential). This occurs roughly 100 times every second in each cell and is a result of Ca concentration being too high. An increase in Ca within the SR is thought to bind to Ca sensitive sites on the inside of the RyR causing the channel to open. As well as this, a protein called calsequestrin (found within the SR) detaches from the RyR, when calcium concentration is too high, again allowing the channel to open (see sarcoplasmic reticulum for more details). Similarly, a decrease in Ca concentration within the SR has also proven to lower RyR sensitivity. This is thought to be due to the calsequestrin binding more strongly to the RyR, preventing it from opening and decreasing the likelihood of a spontaneous spark.\n\nThere are roughly 10,000 clusters of ryanodine receptors within a single cardiac cell, with each cluster containing around 100 ryanodine receptors. During a single spontaneous spark, when Ca is released from the SR, the Ca begins to move around the cell, in the same way that the smell of perfume spreads across a room when sprayed (see diffusion for more details). As the RyRs in the heart are activated by Ca, the movement of the Ca released during a spontaneous spark, can activate other neighbouring RyRs within the same cluster. However, there usually isn't enough Ca present in a single spark to reach a neighbouring cluster of receptors. The calcium can, however, signal back to the DHPR causing it to close and preventing further influx of calcium. This is known as negative feedback.\n\nAn increase in Ca concentration within the cell or the production of a larger spark, can lead to a large enough calcium released that the neighbouring cluster can be activated by the first. This is known as spark-induced spark activation and can lead to a Ca wave of calcium release spreading across the cell.\n\nDuring evoked Ca sparks, all clusters of ryanodine receptors, throughout the cell are activated at almost exactly the same time. This produces an increase in Ca concentration across the whole cell (not just locally) and is known as a whole cell Ca transient. This Ca then binds to a protein, called troponin, initiating contraction, through a group of proteins known as myofilaments.\n\nIn smooth muscle cells, the Ca released during a spark is used for muscle relaxation. This is because, the Ca that enters the cell via the DHPR in response to the action potential, stimulates both muscle contraction and calcium release from the SR. The Ca released during the spark, then activates two other ion channels on the membrane. One channel allows potassium ions to enter the cell, whereas the other allows chloride ions to leave the cell. The result of this movement of ions, is that the membrane voltage becomes more negative. This deactivates the DHPR (which was activated by the positive membrane potential produced by the action potential), causing it to close and stopping the flow of Cainto the cell, leading to relaxation.\n\nThe mechanism by which SR Ca release terminates is still not fully understood. Current main theories are outlined below:\n\nThis theory suggests that during a calcium spark, as calcium flows out of the SR, the concentration of Ca within the SR becomes too low. However, this is not believed to be the case for spontaneous sparks. This is because an average spark lasts around 200 milliseconds (one fifth of a second), however researchers have produced sparks lasting longer than 200 milliseconds, therefore showing that there is still enough Ca left within the SR after a 'normal' (200ms) spark. During the activation of a large number of ryanodine receptors however, as is the case during evoked sparks, the entire SR is depleted of Ca and therefore this mechanism could still play a part in the termination of evoked calcium sparks.\n\nDespite the complicated name, this idea simply suggests that all ryanodine receptors in a cluster, and the associated dihydropyridine receptors happen to randomly close at the same time. This would not only prevent calcium release from the SR, but it would also stop the stimulus for calcium release (i.e. the flow of calcium through the DHPR). However, due to the large numbers of RyRs and DHPRs in a single cell, this theory seems to be unrealistic, as there is a very small probability that they would all close together at exactly the same time.\n\nThis theory suggests that after activation of the RyR and the subsequent release of Ca, the channel closes briefly to recover. During this time, either the channel cannot be reopened, even if calcium is present (i.e. the RyR is inactivated) or the channel can be reopened, however more calcium is required to activate it than usual (i.e. the RyR is in an adaptation phase). This would mean that one-by-one the RyRs would close, thus ending the spark.\n\nThis theory suggests that the above three theories all play a role in preventing calcium release.\n\nSpontaneous Ca sparks were discovered in cardiac muscle cells, of rats, in 1992 by Peace Cheng and Mark B. Cannell in Jon Lederer's laboratory at the University of Maryland, Baltimore, U.S.A.\n\nInitially the idea was rejected by the scientific journal, Nature, who believed that the sparks were only present under laboratory conditions (i.e. they were artifacts), and so wouldn't occur naturally within the body. However they were quickly recognised as being of fundamental importance to muscle physiology, playing a huge role in excitation-contraction coupling.\n\nThe discovery was made possible due to improvements in confocal microscopes. This allowed for the detection of the release of Ca, which were highlighted using a substance known as fluo-3, which caused the Ca to glow. Ca “sparks” were so called because of the spontaneous, localised nature of the Ca release as well as the fact that they are the initiation event of excitation-contraction coupling.\n\nBecause of the importance of Ca sparks in explaining the gating properties of ryanodine receptors in situ (within the body), many studies have focused on improving their detectability in the hope that by accurately and reliably detecting all Ca spark events, their true properties can finally help us to answer the unsolved mystery of spark termination.\n\n\nSoftware\n", "id": "8854753", "title": "Calcium sparks"}
{"url": "https://en.wikipedia.org/wiki?curid=1487880", "text": "Isolecithal\n\nIsolecithal (\"Greek\" iso = equal, lekithos = yolk) refers to the even distribution of yolk in the cytoplasm of ovums of mammals and other vertebrates, notably fishes of the families Petromyzontidae, Amiidae, and Lepisosteidae. Isolecithal cells have two equal hemispheres of yolk. However, during cellular development, normally under the influence of gravity, some of the yolk settles to the bottom of the egg, producing an uneven distribution of yolky hemispheres. Such uneven cells are known as telolecithal and are common where there is sufficient yolk mass.\n\nIn the absence of a large concentration of yolk, four major cleavage types can be observed in isolecithal cells: radial holoblastic, spiral holoblastic, bilateral holoblastic, and rotational holoblastic cleavage. These holoblastic cleavage planes pass all the way through isolecithal zygotes during the process of cytokinesis. Coeloblastula is the next stage of development for eggs that undergo this radial cleavaging. In mammals, because the isolecithal cells have only a small amount of yolk, they require immediate implantation onto the uterine wall to receive nutrients.\n\n", "id": "1487880", "title": "Isolecithal"}
{"url": "https://en.wikipedia.org/wiki?curid=1787566", "text": "Histiocyte\n\nA histiocyte is an animal cell that is part of the mononuclear phagocyte system (also known as the reticuloendothelial system or lymphoreticular system). The mononuclear phagocytic system is part of the organism's immune system. The histiocyte is a tissue macrophage or a dendritic cell (histio, diminutive of histo, meaning \"tissue\", and cyte, meaning \"cell\").\n\nHistiocytes are derived from the bone marrow by multiplication from a stem cell. The derived cells migrate from the bone marrow to the blood as monocytes. They circulate through the body and enter various organs, where they undergo differentiation into histiocytes, which are part of the mononuclear phagocytic system (MPS).\n\nHowever, the term \"histiocyte\" has been used for multiple purposes in the past, and some cells called \"histocytes\" do not appear to derive from monocytic-macrophage lines. (The term Histiocyte can also simply refer to a cell from monocyte origin outside the blood system, such as in a tissue (as in rheumatoid arthritis as palisading histiocytes surrounding fibrinoid necrosis of rheumatoid nodules).\n\nSome sources consider Langerhans cell derivatives to be histiocytes. The Langerhans cell histiocytosis embeds this interpretation into its name.\n\nHistiocytes have common histological and immunophenotypical characteristics (demonstrated by immunostains). Their cytoplasm is eosinophilic and contains variable amounts of lysosomes. They bear membrane receptors for opsonins, such as IgG and the fragment C3b of complement. They express LCAs (leucocyte common antigens) CD45, CD14, CD33, and CD4 (also expressed by T helper cells).\n\nThese histiocytes are part of the immune system by way of two distinct functions: phagocytosis and antigen presentation. Phagocytosis is the main process of macrophages and antigen presentation the main property of dendritic cells (so called because of their star-like cytoplasmic processes).\n\nMacrophages and dendritic cells are derived from common bone marrow precursor cells that have undergone different differentiation (as histiocytes) under the influence of various environmental (tissue location) and growth factors such as GM-CSF, TNF and IL-4. The various categories of histocytes are distinguishable by their morphology, phenotype, and size.\n\nA subset of cells differentiates into Langerhans cells; this maturation occurs in the squamous epithelium, lymph nodes, spleen, and bronchiolar epithelium. Langerhans cells are antigen-presenting cells but have undergone further differentiation. Skin Langerhans cells express CD1a, as do cortical thymocytes (cells of the cortex of the thymus gland). They also express S-100, and their cytoplasm contains tennis-racket like ultra-structural inclusions called Birbeck granules.\n\nHistiocytoses describe neoplasias wherein the proliferative cell is the histiocyte.\n\nThe most common histiocyte disorders are Langerhans' cell histiocytosis and haemophagocytic lymphohistiocytosis.\n\n", "id": "1787566", "title": "Histiocyte"}
{"url": "https://en.wikipedia.org/wiki?curid=7137955", "text": "Cortactin\n\nCortactin (from \"\"cortical actin\" binding protein\") is a monomeric protein located in the cytoplasm of cells that can be activated by external stimuli to promote polymerization and rearrangement of the actin cytoskeleton, especially the actin cortex around the cellular periphery. It is present in all cell types. When activated, it will recruit Arp2/3 complex proteins to existing actin microfilaments, facilitating and stabilizing nucleation sites for actin branching. Cortactin is important in promoting lamellipodia formation, invadopodia formation, cell migration, and endocytosis.\n\nIn humans, cortactin is encoded by the \"CTTN\" gene on chromosome 11.\n\nCortactin is a thin, elongated monomer that consists of an amino-terminal acidic (NTA) region; 37-residue-long segments that are highly conserved among cortactin proteins of all species and repeated up to 6.5 times in tandem (“cortactin repeats”); a proline-rich region; and an SH3 domain. This basic structure is highly conserved among all species that express cortactin.\n\nCortactin is activated via phosphorylation, by tyrosine kinases or serine/threonine kinases, in response to extracellular signals like growth factors, adhesion sites, or pathogenic invasion of the epithelial layer.\n\nThe SH3 domain of certain tyrosine kinases, such as the oncogene Src kinase, binds to cortactin’s proline-rich region and phosphorylates it on Tyr421, Tyr466, and Tyr482. Once activated in this way, it can bind to filamentous actin (F-actin) with the fourth of its cortactin repeats. As the concentration of phosphorylated cortactin increases in specific regions within the cell, the monomers each begin to recruit an Arp2/3 complex to F-actin. It binds to Arp2/3 with an aspartic acid-aspartic acid-tryptophan (DDW) sequence in its NTA region, a motif that is often seen in other actin nucleation-promoting factors (NPFs).\n\nCertain serine/threonine kinases, such as ERK, can phosphorylate cortactin on Ser405 and Ser418 in the SH3 domain. Activated like this, it still associates with Arp2/3 and F-actin, but will also allow other actin NPFs, most importantly N-WASp (Neuronal Wiskott-Aldrich syndrome protein), to bind to the complex as well; when phosphorylated by tyrosine kinases, other NPFs are excluded. The ability of these other NPFs to bind the Arp2/3 complex while cortactin is also bound could come from new interactions with cortactin’s SH3 domain, which is in a different conformation when phosphorylated by Ser/Thr kinases and thus may be more open to interactions with other NPFs. Having other NPFs bind to the Arp2/3 complex at the same time as cortactin may enhance nucleation site stability.\n\nInactive cortactin diffuses throughout the cytoplasm, but upon phosphorylation, the protein begins to target certain areas in the cell. Cortactin-assisted Arp2/3-nucleated actin branches are most prominent in the actin cortex, around the periphery of the cell. A phosphorylated cortactin monomer binds to, activates, and stabilizes an Arp2/3 complex on preexisting F-actin, which provides a nucleation site for a new actin branch to form from the “mother” filament. Branches formed from cortactin-assisted nucleation sites are very stable; cortactin has been shown to inhibit debranching. Thus, polymerization and branching of actin is promoted in areas of the cell where cortactin is localized.\n\nCortactin is very active in lamellipodia, protrusions of the cell membrane formed by actin polymerization and treadmilling that propel the cell along a surface as it migrates towards some target.\n\nCortactin acts as a link between extracellular signals and lamellipodial “steering.” When a receptor tyrosine kinase on the cell membrane binds to an adhesion site, for example, cortactin will be phosphorylated locally to the area of binding, activate and recruit Arp2/3 to the actin cortex in that region, and thus stimulate cortical actin polymerization and movement of the cell in that direction. Macrophages, highly motile immune cells that engulf cellular debris and pathogens, are propelled by lamellipodia and identify/migrate toward a target via chemotaxis; thus, cortactin must also be activated by receptor kinases that pick up a large variety of chemical signals.\n\nStudies have implicated cortactin in both clathrin-mediated endocytosis and clathrin-independent endocytosis. In both kinds of endocytosis, it has long been known that actin localizes to sites of vesicle invagination and is a vital part of the endocytic pathway, but the actual mechanisms by which actin facilitates endocytosis are still unclear. Recently, however, it has been found that dynamin, the protein responsible for breaking the newly formed vesicular bud off the inside of the plasma membrane, can associate with the SH3 domain of cortactin. Since cortactin recruits the Arp2/3 complexes that lead to actin polymerization, this suggests that it may play an important part in linking vesicle formation to the as yet unknown functions actin has in endocytosis.\n\nAmplification of the genes encoding cortactin—in humans, EMS1—has been found to occur in certain tumors. Overexpression of cortactin can lead to highly-active lamellipodia in tumor cells, dubbed “invadopodia.” These cells are especially invasive and migratory, making them very dangerous, for they can easily spread cancer across the body into other tissues.\n\nCortactin has been shown to interact with:\n\n", "id": "7137955", "title": "Cortactin"}
{"url": "https://en.wikipedia.org/wiki?curid=6587682", "text": "Cytoplast\n\nCytoplast, in Medical Science is Defined as Cell membrane plus Cytoplasm,So Sometimes used to describe a cell in which the nucleus has been removed.\n\nSimple explanation is here\n\nProtoplasm = Cytoplasm + Nucleoplasm\n\nProtoplast = Protoplasm + Plasma membrane\n\nSo, Cytoplasm = Protoplasm - Nucleoplasm and\n\nCytoplast = Cytoplasm + Plasma membrane\n\n", "id": "6587682", "title": "Cytoplast"}
{"url": "https://en.wikipedia.org/wiki?curid=9109164", "text": "Ki-67 (protein)\n\nAntigen KI-67 also known as Ki-67 or MKI67 is a protein that in humans is encoded by the \"MKI67\" gene (antigen identified by monoclonal antibody Ki-67).\n\nAntigen KI-67 is a nuclear protein that is associated with and may be necessary for cellular proliferation. Furthermore, it is associated with ribosomal RNA transcription. Inactivation of antigen KI-67 leads to inhibition of ribosomal RNA synthesis.\n\nThe Ki-67 protein (also known as MKI67) is a cellular marker for proliferation. It is strictly associated with cell proliferation. During interphase, the Ki-67 antigen can be exclusively detected within the cell nucleus, whereas in mitosis most of the protein is relocated to the surface of the chromosomes. Ki-67 protein is present during all active phases of the cell cycle (G, S, G, and mitosis), but is absent in resting (quiescent) cells (G). Cellular content of Ki-67 protein markedly increases during cell progression through S phase of the cell cycle.. In breast cancer Ki67 identifies a high proliferative subset of patients with ER-positive breast cancer who derive greater benefit from adjuvant chemotherapy \n\nKi-67 is an excellent marker to determine the growth fraction of a given cell population. The fraction of Ki-67-positive tumor cells (the \"Ki-67 labeling index\") is often correlated with the clinical course of cancer. The best-studied examples in this context are carcinomas of the prostate, brain and the breast and nephroblastoma and neuroendocrine tumours. For these types of tumors, the prognostic value for survival and tumor recurrence have repeatedly been proven in uni- and multivariate analysis.\n\nKi-67 and MIB-1 monoclonal antibodies are directed against different epitopes of the same proliferation-related antigen. Ki-67 and MIB1 may be used on fixed sections. MIB-1 is used in clinical applications to determine the \"Ki-67 labelling index\". One of its primary advantages over the original Ki-67 antibody (and the reason why it has essentially supplanted the original antibody for clinical use) is that it can be used on formalin-fixed paraffin-embedded sections, after heat-mediated antigen retrieval (see next section below).\n\nThe Ki-67 protein was originally defined by the prototype monoclonal antibody Ki-67, which was generated by immunizing mice with nuclei of the Hodgkin lymphoma cell line L428. The name is derived from the city of origin (Kiel, Germany) and the number of the original clone in the 96-well plate.\n\nKi-67 (protein) has been shown to interact with CBX3.\n\n", "id": "9109164", "title": "Ki-67 (protein)"}
{"url": "https://en.wikipedia.org/wiki?curid=454203", "text": "Monocyte\n\nMonocytes are a type of \"leukocyte\", or white blood cell. They are the largest type of leukocyte and can differentiate into macrophages and myeloid lineage dendritic cells. As a part of the vertebrate innate immune system monocytes also influence the process of adaptive immunity. There are at least three subclasses of monocytes in human blood based on their phenotypic receptors.\n\nMonocytes are amoeboid in appearance, and have agranulated cytoplasm. Containing unilobar nuclei, these cells are one of the types of mononuclear leukocytes which shelter azurophil granules. The archetypal geometry of the monocyte nucleus is ellipsoidal; metaphorically bean-shaped or kidney-shaped, although the most significant distinction is that the nuclear envelope should not be hyperbolically furcated into lobes. Contrast to this classification occurs in polymorphonuclear leukocytes. Monocytes compose 2% to 10% of all leukocytes in the human body and serve multiple roles in immune function. Such roles include: replenishing resident macrophages under normal conditions; migration within approximately 8–12 hours in response to inflammation signals from sites of infection in the tissues; and differentiation into macrophages or dendritic cells to effect an immune response. In an adult human, half of the monocytes are stored in the spleen. These change into macrophages after entering into appropriate tissue spaces, and can transform into foam cells in endothelium.\n\nMonocytes are produced by the bone marrow from precursors called monoblasts, bipotent cells that differentiated from hematopoietic stem cells. Monocytes circulate in the bloodstream for about one to three days and then typically move into tissues throughout the body where they differentiate into macrophages and dendritic cells. They constitute between three and eight percent of the leukocytes in the blood. About half of the body's monocytes are stored as a reserve in the spleen in clusters in the red pulp's Cords of Billroth. Moreover, monocytes are the largest corpuscle in blood.\n\nMonocytes which migrate from the bloodstream to other tissues will then differentiate into tissue resident macrophages or dendritic cells. Macrophages are responsible for protecting tissues from foreign substances, but are also suspected to be important in the formation of important organs like the heart and brain. They are cells that possess a large smooth nucleus, a large area of cytoplasm, and many internal vesicles for processing foreign material.\n\nMonocytes and their macrophage and dendritic-cell progeny serve three main functions in the immune system. These are phagocytosis, antigen presentation, and cytokine production. Phagocytosis is the process of uptake of microbes and particles followed by digestion and destruction of this material. Monocytes can perform phagocytosis using intermediary (opsonising) proteins such as antibodies or complement that coat the pathogen, as well as by binding to the microbe directly via pattern-recognition receptors that recognize pathogens. Monocytes are also capable of killing infected host cells via antibody-dependent cell-mediated cytotoxicity. Vacuolization may be present in a cell that has recently phagocytized foreign matter.\n\nMany factors produced by other cells can regulate the chemotaxis and other functions of monocytes. These factors include most particularly chemokines such as monocyte chemotactic protein-1 (CCL2) and monocyte chemotactic protein-3 (CCL7); certain arachidonic acid metabolites such as Leukotriene B4 and members of the 5-Hydroxyicosatetraenoic acid and 5-oxo-eicosatetraenoic acid family of OXE1 receptor agonists (e.g., 5-HETE and 5-oxo-ETE); and N-Formylmethionine leucyl-phenylalanine and other N-formylated oligopeptides which are made by bacteria and activate the formyl peptide receptor 1.\n\nMicrobial fragments that remain after such digestion can serve as antigens. The fragments can be incorporated into MHC molecules and then trafficked to the cell surface of monocytes (and macrophages and dendritic cells). This process is called antigen presentation and it leads to activation of T lymphocytes, which then mount a specific immune response against the antigen.\n\nOther microbial products can directly activate monocytes and this leads to production of pro-inflammatory and, with some delay, of anti-inflammatory cytokines. Typical cytokines produced by monocytes are TNF, IL-1, and IL-12.\n\nThere are at least three types of monocytes in human blood:\n\n\nWhile in humans the level of CD14 expression can be used to differentiate non-classical and intermediate monocytes, the slan cell surface marker was shown to give an unequivocal separation of the two cell types.\n\nGhattas et al. state that the \"intermediate\" monocyte population is likely to be a unique subpopulation of monocytes, as opposed to a developmental step, due to their comparatively high expression of surface receptors involved in reparative processes(including vascular endothelial growth factors type 1 and 2, CXCR4, and Tie-2) as well as evidence that the \"intermediate\" subset is specifically enriched in the bone marrow. After stimulation with microbial products the CD14+CD16++ monocytes produce high amounts of pro-inflammatory cytokines like tumor necrosis factor and interleukin-12.\n\nSaid et al. showed that activated monocytes express high levels of PD-1 which might explain the higher expression of PD-1 in CD14+CD16++ monocytes as compared to CD14++CD16- monocytes. Triggering monocytes-expressed PD-1 by its ligand PD-L1 induces IL-10 production which activates CD4 Th2 cells and inhibits CD4 Th1 cell function.\n\nIn mice, monocytes can be divided in two subpopulations. Inflammatory monocytes (Cx3CR1, CCR2, Ly6C), which are equivalent to human classical CD14 CD16 monocytes and resident monocytes (Cx3CR1, CCR2, Ly6C), which are equivalent to human non-classical CD14 CD16 monocytes. Resident monocytes have the ability to patrol along the endothelium wall in the steady state and under inflammatory conditions.\nIn man a monocyte crawling behavior, similar to the patrolling in mice, has been demonstrated both for the classical and the non-classical monocytes.\n\nA \"monocyte count\" is part of a complete blood count and is expressed either as a percentage of monocytes among all white blood cells or as absolute numbers. Both may be useful but these cells became valid diagnostic tools only when monocyte subsets are determined.\n\nMonocytosis is the state of excess monocytes in the peripheral blood. It may be indicative of various disease states.\nExamples of processes that can increase a monocyte count include:\n\nA high count of CD14+CD16++ monocytes is found in severe infection (sepsis) \nIn the field of atherosclerosis high numbers of the CD14++CD16+ intermediate monocytes were shown to be predictive of cardiovascular events in at risk populations.\n\nMonocytopenia is a form of leukopenia associated with a deficiency of monocytes.\nA very low count of these cells is found after therapy with immuno-suppressive glucocorticoids.\nAlso, non-classical slan+ monocytes are strongly reduced in patients with hereditary diffuse leukoencephalopathy with axonal spheroids (HDLS), a neurologic disease associated\nwith mutations in the macrophage colony-stimulating factor receptor gene.\n\n\"In vitro\", monocytes can differentiate into dendritic cells by adding the cytokines granulocyte macrophage colony-stimulating factor (GM-CSF) and interleukin 4.\n\n\n", "id": "454203", "title": "Monocyte"}
{"url": "https://en.wikipedia.org/wiki?curid=8429968", "text": "Humster\n\nA humster is a hybrid cell line made from hamster oocyte fertilized with human sperm. It always consists of single cells, and cannot form a multi-cellular being.\n\nHumsters are routinely created for mainly two reasons:\n\nSomatic cell hybrids between hamster or mouse and man have been used for mapping of various traits at least since the 1970s.\n\nRecombinant DNA\n\n\n", "id": "8429968", "title": "Humster"}
{"url": "https://en.wikipedia.org/wiki?curid=6691427", "text": "Ran (gene)\n\nRan (RAs-related Nuclear protein) also known as GTP-binding nuclear protein Ran is a protein that in humans is encoded by the RAN gene. Ran is a small 25 kDa protein that is involved in transport into and out of the cell nucleus during interphase and also involved in mitosis. It is a member of the Ras superfamily.\n\nRan is a small G protein that is essential for the translocation of RNA and proteins through the nuclear pore complex. The Ran protein has also been implicated in the control of DNA synthesis and cell cycle progression, as mutations in Ran have been found to disrupt DNA synthesis.\n\nRan exists in the cell in two nucleotide-bound forms: GDP-bound and GTP-bound. RanGDP is converted into RanGTP through the action of RCC1, the nucleotide exchange factor for Ran. RCC1 is also known as RanGEF (Ran Guanine nucleotide Exchange Factor). Ran's intrinsic GTPase-activity is activated through interaction with Ran GTPase activating protein (RanGAP), facilitated by complex formation with Ran-binding protein (RanBP). GTPase-activation leads to the conversion of RanGTP to RanGDP, thus closing the Ran cycle.\n\nRan can diffuse freely within the cell, but because RCC1 and RanGAP are located in different places in the cell, the concentration of RanGTP and RanGDP differs locally as well, creating concentration gradients that act as signals for other cellular processes. RCC1 is bound to chromatin and therefore located inside the nucleus. RanGAP is cytoplasmic in yeast and bound to the nuclear envelope in plants and animals. In mammalian cells, it is SUMO modified and attached to the cytoplasmic side of the nuclear pore complex via interaction with the nucleoporin RanBP2 (Nup358). This difference in location of the accessory proteins in the Ran cycle leads to a high RanGTP to RanGDP ratio inside the nucleus and an inversely low RanGTP to RanGDP ratio outside the nucleus. In addition to a gradient of the nucleotide bound state of Ran, there is a gradient of the protein itself, with a higher concentration of Ran in the nucleus than in the cytoplasm. Cytoplasmic RanGDP is imported into the nucleus by the small protein NTF2 (Nuclear Transport Factor 2), where RCC1 can then catalyze exchange of GDP for GTP on Ran.\n\nRan is involved in the transport of proteins across the nuclear envelope by interacting with karyopherins and changing their ability to bind or release cargo molecules. Cargo proteins containing a nuclear localization signal (NLS) are bound by importins and transported into the nucleus. Inside the nucleus, RanGTP binds to importin and releases the import cargo. Cargo that needs to get out of the nucleus into the cytoplasm binds to exportin in a ternary complex with RanGTP. Upon hydrolysis of RanGTP to RanGDP outside the nucleus, the complex dissociates and export cargo is released.\n\nDuring mitosis, the Ran cycle is involved in mitotic spindle assembly and nuclear envelope reassembly after the chromosomes have been separated. During prophase, the steep gradient in RanGTP-RanGDP ratio at the nuclear pores breaks down as the nuclear envelope becomes leaky and disassembles. RanGTP concentration stays high around the chromosomes as RCC1, a nucleotide exchange factor, stays attached to chromatin. RanBP2 (Nup358) and RanGAP move to the kinetochores where they facilitate the attachment of spindle fibers to chromosomes. Moreover, RanGTP promotes spindle assembly by mechanisms similar to mechanisms of nuclear transport: the activity of spindle assembly factors such as NuMA and TPX2 is inhibited by the binding to importins. By releasing importins, RanGTP activates these factors and therefore promotes the assembly of the mitotic spindle . In telophase, RanGTP hydrolysis and nucleotide exchange are required for vesicle fusion at the reforming nuclear envelopes of the daughter nuclei.\n\nRAN is an androgen receptor (AR) coactivator (ARA24) that binds differentially with different lengths of polyglutamine within the androgen receptor. Polyglutamine repeat expansion in the AR is linked to spinal and bulbar muscular atrophy (Kennedy's disease). RAN coactivation of the AR diminishes with polyglutamine expansion within the AR, and this weak coactivation may lead to partial androgen insensitivity during the development of spinal and bulbar muscular atrophy.\n\nRan has been shown to interact with:\n\nThe expression of Ran is repressed by the microRNA miR-10a.\n\n\n", "id": "6691427", "title": "Ran (gene)"}
{"url": "https://en.wikipedia.org/wiki?curid=9760859", "text": "Cell-free system\n\nA cell-free system is an \"in vitro\" tool widely used to study biological reactions that happen within cells apart from a full cell system, thus reducing the complex interactions typically found when working in a whole cell. Subcellular fractions can be isolated by ultracentrifugation to provide molecular machinery that can be used in reactions in the absence of many of the other cellular components. Eukaryotic and prokaryotic cell internals have been used for creation of these simplified environments. These systems have enabled cell-free synthetic biology to emerge, providing control over what reaction is being examined, as well as its yield, and lessening the considerations otherwise invoked when working with more sensitive live cells.\n\nCell-free systems may be divided into two primary classifications: cell extract-based, which remove components from within a whole cell for external use, and purified enzyme-based, which use purified components of the molecules known to be involved in a given process. The cell extract-based type are susceptible to problems like quick degradation of components outside their host, as shown in a study by Kitaoka \"et al.\" where a cell-free translation system based on \"Escherichia coli\" (\"E. coli\"), of the cell extract-based type, had the mRNA template degrade very quickly and led to the halt of protein synthesis.\n\nThe methods of preparation vary between situations of both types of cell-free systems.\n\nNobel prize winner Eduard Buchner was arguably the first to present a cell-free system using yeast extracts, but since then alternative sources have been found. \"E. coli\", wheat germ, and rabbit reticulocytes have all proven useful to create cell-free systems by extraction of their interior components. \"E. coli\" 30S extracts have been acquired, for example, by grinding the bacteria with alumina, followed by further cleaning. Similarly, wheat germ has been ground with acid-washed sand or powdered glass to open the cell membranes up. Rabbit reticulocytes have been lysed in a solution of MgCl and had the extract filtered away from the membranes by centrifugation.\n\nCell-free synthetic pathway biotransformation biosystems can be prepared by mixing a number of purified enzymes and coenzymes. For example, tightly coupled ribosomes, which are compact and highly active, have been extracted and refined from \"E. coli\" through sucrose-density-gradient centrifugation.\n\nCell-free synthetic pathway biotransformation biosystems are proposed as a new low-cost biomanufacturing platform compared to microbial fermentation used for thousands of years. Cell-free biosystems have several advantages suitable in industrial applications:\n\n\n\"In vitro\" biosystems can be easily controlled and accessed without membranes. Notably, in work leading to a Nobel prize the Nirenberg and Matthaei experiment used a cell-free system, of the cell extract-based type, to incorporate chosen amino acids tagged radioactively into synthesized proteins with 30S extracted from \"E. coli\". More recent studies, such as the study done by Spirin \"et al.\" with prokaryotic and eukaryotic version of their cell-free translation system, have also synthesized proteins with increased production, incorporating techniques like continuous flow to add materials and remove products. With such advances in yield, productivity applications have been expanded, such as the synthesis of fusion proteins to potentially serve as vaccines for B-cell lymphomas. Additionally, cell-free protein synthesis is becoming a new alternative choice for fast protein synthesis.\n\nEngineering of metabolic processes have been achieved through cell-free systems. Bujara \"et al.\", for example, were able to use glycolytic network extracts, consisting of enzymes from \"E. coli\" that produced dihydroxyacetone phosphate, to analyze in real-time the metabolite concentrations while altering enzyme levels, with the end result of optimal production of dihydroxyacetone phosphate. Further, Calhoun and Swartz were able to use a glycolytic intermediate to fuel a cell-free system, enabling relatively inexpensive ATP generation compared to reagent usage in phosphoenolpyruvate reactions.\n\nCell-free systems have also been used to incorporate unnatural amino acids. Shimizu \"et al.\" were able to change a stop codon to a sense codon by omitting the RF1 release factor, indicating ability to insert desired amino acids in unnatural situations. This is of use in systems where working inside a cell is problematic, such as the process of amino acid metabolism preventing specific labelling of amino acids that would be useful in multidimensional NMR spectroscopy. Kigawa \"et al.\"were able to successfully label amino acids in a cell-free system where amino acid metabolism was no longer present, thus making such systems useful to NMR studies.\n", "id": "9760859", "title": "Cell-free system"}
{"url": "https://en.wikipedia.org/wiki?curid=9833509", "text": "CX3CR1\n\nCX3C chemokine receptor 1 (CX3CR1) also known as the fractalkine receptor or G-protein coupled receptor 13 (GPR13) is a protein that in humans is encoded by the \"CX3CR1\" gene. As the name suggests, this receptor binds the chemokine CX3CL1 (also called neurotactin or fractalkine).\n\nThe fractalkine ligand CX3CL1 is a transmembrane protein and chemokine involved in the adhesion and migration of leukocytes. The protein encoded by the CX3CR1 gene is a receptor for the fractalkine ligand.\n\nExpression of this receptor appears to be associated with lymphocytes. CX3CR1 is also expressed by monocytes and plays a major role in the survival of monocytes.\n\nFractalkine signaling has also recently been discovered to play a developmental role in the migration of microglia in the central nervous system to their synaptic targets, where phagocytosis and synaptic refinement occur. CX3CR1 knockout mice had more synapses on cortical neurons than wild-type mice.\n\nCX3CR1 also is a coreceptor for HIV-1, and some variations in this gene lead to increased susceptibility to HIV-1 infection and rapid progression to AIDS.\n\nCX3CR1 variants have been described to modify the survival time and the progression rate of patients with amyotrophic lateral sclerosis.\n\nMutations in CX3CR1 are associated to .\n", "id": "9833509", "title": "CX3CR1"}
{"url": "https://en.wikipedia.org/wiki?curid=9900287", "text": "Lymphokine-activated killer cell\n\nIn cell biology, a lymphokine-activated killer cell (also known as a LAK cell) is a white blood cell that has been stimulated to kill tumor cells. If lymphocytes are cultured in the presence of Interleukin 2, it results in the development of effector cells which are cytotoxic to tumor cells.\n\nIt has been shown that lymphocytes, when exposed to Interleukin 2, are capable of lysing fresh, non-cultured cancer cells, both primary and metastatic. LAK cells respond to these lymphokines, particularly IL-2, by lysing tumor cells that were already known to be resistant to NK cell activity.\n\nThe mechanism of LAK cells is distinctive from that of natural killer cells because they can lyse cells that NK cells cannot. LAK cells are also capable of acting against cells that do not display the major histocompatibility complex, as has been shown by the ability to cause lysis in non-immunogenic, allogeneic and syngeneic tumors. LAK cells are specific to tumor cells and do not display activity against normal cells.\n\nLAK cells, along with the administration of IL-2 have been experimentally used to treat cancer in mice and humans, but there is very high toxicity with this treatment - Severe fluid retention was the major side effect of therapy, although all side effects resolved after interleukin-2 administration was stopped.\n", "id": "9900287", "title": "Lymphokine-activated killer cell"}
{"url": "https://en.wikipedia.org/wiki?curid=9806247", "text": "Neutrophil extracellular traps\n\nNeutrophil extracellular traps (NETs) are networks of extracellular fibers, primarily composed of DNA from neutrophils, which bind pathogens. Neutrophils are the immune system's first-line of defense against infection and have conventionally been thought to kill invading pathogens through two strategies: engulfment of microbes and secretion of anti-microbials. In 2004, a novel third function was identified: formation of NETs. NETs allow neutrophils to kill extracellular pathogens while minimizing damage to the host cells. Upon \"in vitro\" activation with the pharmacological agent phorbol myristate acetate (PMA), Interleukin 8 (IL-8) or lipopolysaccharide (LPS), neutrophils release granule proteins and chromatin to form an extracellular fibril matrix known as NETs through an active process.\n\nHigh-resolution scanning electron microscopy has shown that NETs consist of stretches of DNA and globular protein domains with diameters of 15-17 nm and 25 nm, respectively. These aggregate into larger threads with a diameter of 50 nm. However, under flow conditions, NETs can form much larger structures, reaching hundreds of nanometers in length and width.\n\nAnalysis by immunofluorescence corroborated that NETs contain proteins from azurophilic granules (neutrophil elastase, cathepsin G and myeloperoxidase), specific granules (lactoferrin), tertiary granules (gelatinase), and the cytoplasm; however, CD63, actin, tubulin and various other cytoplasmatic proteins are not present in NETs.\n\nNETs disarm pathogens with antimicrobial proteins such as neutrophil elastase, cathepsin G and histones that have a high affinity for DNA. NETs provide for a high local concentration of antimicrobial components and bind, disarm, and kill microbes extracellularly independent of phagocytic uptake. In addition to their antimicrobial properties, NETs may serve as a physical barrier that prevents further spread of the pathogens. Furthermore, delivering the granule proteins into NETs may keep potentially injurious proteins like proteases from diffusing away and inducing damage in tissue adjacent to the site of inflammation.\n\nMore recently, it has also been shown that not only bacteria but also pathogenic fungi such as \"Candida albicans\" induce neutrophils to form NETs that capture and kill \"C. albicans\" hyphal as well as yeast-form cells. NETs have also been documented in association with \"Plasmodium falciparum\" infections in children.\n\nWhile it was originally proposed that NETs would be formed in tissues at a site of bacterial/yeast infection, NETs have also been shown to form within blood vessels during sepsis (specifically in the lung capillaries and liver sinusoids). Intra-vascular NET formation is tightly controlled and is regulated by platelets, which sense severe infection via platelet TLR4 and then bind to and activate neutrophils to form NETs. Platelet-induced NET formation occurs very rapidly (in minutes) and may or may not result in death of the neutrophils. NETs formed in blood vessels can catch circulating bacteria as they pass through the vessels. Trapping of bacteria under flow has been imaged directly in flow chambers \"in vitro\" and intravital microscopy demonstrated that bacterial trapping occurs in the liver sinusoids and lung capillaries (sites where platelets bind neutrophils).\n\nNET activation and release, or NETosis, is a dynamic process that can come in two forms, suicidal and vital NETosis. Overall, many of the key components of the process are similar for both types of NETosis, however, there are key differences in stimuli, timing, and ultimate end result.\n\nThe full NETosis activation pathway is still under investigation but a few key proteins have been identified and slowly a full picture of the pathway is emerging. The process is thought to begin with NADPH oxidase activation of protein-arginine deiminase 4 (PAD4) via reactive-oxygen species (ROS) intermediaries. PAD4 is responsible for the citrullination of histones in the neutrophil, resulting in decondensation of chromatin. Azurophilic granule proteins such as myeloperoxidase (MPO) and neutrophil elastase (NE) then enter the nucleus and further the decondensation process, resulting in the rupture of the nuclear envelope. The uncondensed chromatin enter the cytoplasm where additional granule and cytoplasmic proteins are added to the early-stage NET. The end result of the process then depends on which NETosis pathway is activated.\n\nSuicidal NETosis was first described in a 2007 study that noted that the release of NETs resulted in neutrophil-death through a different pathway than apoptosis or necrosis. In suicidal NETosis, the intracellular NET formation is followed by the rupture of the plasma membrane, releasing it into the extracellular space. This NETosis pathway can be initiated through activation of Toll-like Receptors (TLRs), Fc receptors, and complement receptors with various ligands such as antibodies, PMA, and so on. The current understanding is that upon activation of these receptors, downstream signaling results in the release of calcium from the endoplasmic reticulum. This intracellular influx of calcium in turn activates NADPH oxidase, resulting in activation of the NETosis pathway as described above. Of note, suicidal NETosis can take hours, even with high levels of PMA stimulation, while vital NETosis that can be completed in a matter of minutes.\n\nVital NETosis can be stimulated by bacterial lipopolysaccharide (LPS), other \"bacterial products, TLR4-activated platelets, or complement proteins in tandem with TLR2 ligands.\" Vital NETosis is made possible through the blebbing of the nucleus, resulting in a DNA-filled vesicle that is exocytosed and leaves the plasma membrane intact. Its rapid formation and release does not result in neutrophil death, however, the cell is without DNA, raising questions about whether a cell without DNA can be considered alive. It has been noted that neutrophils can continue to phagocytose and kill microbes after vital NETosis, highlighting the neutrophil's anti-microbial versatility.\n\nThe formation of NETs is regulated by the lipoxygenase pathway – during certain forms of activation (including contact with bacteria) neutrophil 5-lipoxygenase forms 5-HETE-phospholipids that inhibit NET formation. Evidence from laboratory experiments suggests that NETs are cleaned away by macrophages that phagocytose and degrade them.\n\nNETs might also have a deleterious effect on the host, because the exposure of extracellular histone complexes could play a role during the development of autoimmune diseases like systemic lupus erythematosus. NETs could also play a role in inflammatory diseases, as NETs could be identified in preeclampsia, a pregnancy related inflammatory disorder in which neutrophils are known to be activated. NETs have also been reported in the colon mucosa of patients with the inflammatory bowel disease ulcerative colitis. NETs have also been associated with the production of IgG antinuclear double stranded DNA antibodies in children infected with \"P. falciparum\" malaria.\n\nNETs also have a role in thrombosis.\n\nThese observations suggest that NETs might play an important role in the pathogenesis of infectious, inflammatory and thrombotic disorders.\n\n", "id": "9806247", "title": "Neutrophil extracellular traps"}
{"url": "https://en.wikipedia.org/wiki?curid=10965310", "text": "Prefoldin\n\nPrefoldin is a family of proteins used in protein folding complexes. It is classified as a heterohexameric molecular chaperone in both archaea and eukarya, including humans. A prefoldin molecule works as a transfer protein in conjunction with a molecule of chaperonin to form a chaperone complex and correctly fold other nascent proteins. One of prefoldin's main uses in eukarya is the formation of molecules of actin for use in the eukaryotic cytoskeleton.\n\nPrefoldin is one family of chaperone proteins found in the domains of eukarya and archaea. Prefoldin acts in combination with other molecules to promote protein folding in cells where there are many other competing pathways for folding. Chaperone proteins perform non-covalent assembly of other polypeptide-containing structures \"in vivo\". They are implicated in the folding of most other proteins.\n\nIn archaea, prefoldins are believed to function in combination with group II chaperonins in \"de novo\" protein folding. In eukarya however, prefoldins have acquired a more specific function: they are used to establish correct tubular assembly for many tubular proteins, such as actin. Actin accounts for 5-10% of all protein found in eukaryotic cells, which therefore means that prefoldin is quite prevalent in the cells. Actin is made of two strings of beads wound round each other and is one of the three main parts of the cytoskeleton of eukaryotic cells. Prefoldin bonds specifically to cytosolic chaperonin protein. This complex of prefoldin and chaperonin then forms molecules of actin in the cytosol. The prefoldin acts as a transporter molecule that transports bound, unfolded target proteins to the chaperonin (C-CPN) molecule.\n\nFor example, the prefoldin that is used in the formation of actin also transfers α or β tubulin to a cytosolic chaperonin. The prefoldin, however, does not form a ternary complex with tubulin and chaperonin. Once the tubulins are in contact with the chaperonin, the prefoldin automatically lets go and leaves the active site, due to its high affinity for the chaperonin molecule. Once the prefoldin is in contact with the chaperonin protein, it loses its affinity for the unfolded target protein.\n\nPrefoldin is triggered only to bind to nonnative target proteins in the cytosol so that it will only bind to unfolded proteins. Unlike many other molecular chaperones, prefoldin does not use chemical energy, in the form of adenosine triphosphate (ATP), to promote protein folding.\n\nPrefoldin was found by the laboratory of Nicholas J. Cowan from the Department of Biochemistry at the New York University Medical Center. It was discovered using chromatography. Unfolded labeled β-actin from bovine testes was put into solution. This solution contained an excess of cytosolic chaperonin (C-CPN), a eukaryotic chaperone protein necessary for actin folding. After gel filtration of the actin, the actin complex, consisting of actin and its bonded proteins, began to form and the molecular weight of the complex was observed. Gel electrophoresis was used to analyze the protein complex, the complex formed a single band that was excised and ran on an SDS gel. It resolved into five bands, therefore proving that a heterooligomeric protein is used to bind to unfolded actin. The discovery paper was published on May 29, 1998 in the journal \"Cell\".\n\nThe laboratory of Ulrich Hartl at the Max Planck Institute for Biochemistry in Martinsried, Germany, has identified an archaeal homolog of prefoldin that also functions as a molecular chaperone. Eukaryotic prefoldin likely evolved from archaea, as it is not present (or has been lost) from bacteria.\n\nPrefoldin is a hetero hexameric protein consisting of two α subunits and four β subunits. The structure of the archaeal homologue was first solved by Siegert \"et al.\". Another archaeal prefoldin structure was then published by Clark \"et al.\". The beta subunits contain 120 amino acid residues each, while the α subunits contain 140 amino acid residues each. Each subunit was found to have a width of 8.4 nm in the archaea \"Methanococcus thermoautrophicum\". The height was calculated at 1.8-2.6 nm. The subunits are arranged by hydrophobic interactions with two β barrels at the center and coiled-coil α helices protruding down from them as if it were a jellyfish.\n\n", "id": "10965310", "title": "Prefoldin"}
{"url": "https://en.wikipedia.org/wiki?curid=11336212", "text": "Acrasin\n\nEach species of slime mold has its own specific chemical messenger, which are collectively referred to as acrasins. These chemicals signal that lots of individual cells should move towards each other to form a single large cell or plasmodium. One of the earliest acrasins to be identified was cAMP, found in the species Dictyostelium discoideum by Brian Shaffer, which exhibits a complex swirling-pulsating spiral pattern when forming a pseudoplasmodium.\n\nThe term acrasin was descriptively named after Acrasia from Edmund Spenser's Faerie Queene, who seduced men against their will and then transformed them into beasts. Acrasia is itself a play on the Greek akrasia that describes loss of free will.\n\n", "id": "11336212", "title": "Acrasin"}
{"url": "https://en.wikipedia.org/wiki?curid=1704568", "text": "Dephosphorylation\n\nDephosphorylation is the removal of a phosphate (PO) group from an organic compound by hydrolysis. It is a reversible post-translational modification. Dephosphorylation and its counterpart, phosphorylation, activate and deactivate enzymes by detaching or attaching phosphoric esters and anhydrides. A notable occurrence of dephosphorylation is the conversion of ATP to ADP and inorganic phosphate.\n\nDephosphorylation employs a type of hydrolytic enzyme, or hydrolase, which cleave ester bonds. The prominent hydrolase subclass used in dephosphorylation is phosphatase. Phosphatase removes phosphate groups by hydrolysing phosphoric acid monoesters into a phosphate ion and a molecule with a free hydroxyl (-OH) group.\n\nThe reversible phosphorylation-dephosphorylation reaction occurs in every physiological process, making proper function of protein phosphatases necessary for organism viability. Because protein dephosphorylation is a key process involved in cell signalling, protein phosphatases are implicated in conditions such as cardiac disease, diabetes, and Alzheimer's disease.\n\nThe discovery of dephosphorylation came from a series of experiments examining the enzyme phosphorylase isolated from rabbit skeletal muscle. In 1955, Edwin Krebs and Edmond Fischer used radiolabeled ATP to determine that phosphate is added to the serine residue of phosphorylase to convert it from its \"b\" to \"a\" form via phosphorylation. Subsequently, Krebs and Fischer showed that this phosphorylation is part of a kinase cascade. Finally, after purifying the phosphorylated form of the enzyme, phosphorylase \"a\", from rabbit liver, ion exchange chromatography was used to identify phosphoprotein phosphatase I and II.\n\nSince the discovery of these dephosphorylating proteins, the reversible nature of phosphorylation and dephosphorylation has been associated with a broad range of functional proteins, primarily enzymatic, but also including nonenzymatic proteins. Edwin Krebs and Edmond Fischer won the 1992 Nobel Prize in Physiology or Medicine for the discovery of reversible protein phosphorylation.\n\nPhosphorylation and dephosphorylation of hydroxyl groups belonging to neutral but polar amino acids such as serine, threonine, and tyrosine within specific target proteins is a fundamental part of the regulation of every physiologic process. Phosphorylation involves the covalent modification of the hydroxyl with a phosphate group through the nucleophilic attack of the alpha phosphate in ATP by the oxygen in the hydroxyl. Dephosphorylation involves removal of the phosphate group through a hydration reaction by addition of a molecule of water and release of the original phosphate group, regenerating the hydroxyl. Both processes are reversible and either mechanism can be used to activate or deactivate a protein. Phosphorylation of a protein produces many biochemical effects, such as changing its conformation to alter its binding to a specific ligand to increase or reduce its activity. Phosphorylation and dephosphorylation can be used on all types of substrates, such as structural proteins, enzymes, membrane channels, signaling molecules, and other kinases and phosphatases. The sum of these processes is referred to as phosphoregulation. The deregulation of phosphorylation can lead to disease.\n\nDuring the synthesis of proteins, polypeptide chains, which are created by ribosomes translating mRNA, must be processed before assuming a mature conformation. The dephosphorylation of proteins is a mechanism for modifying behavior of a protein, often by activating or inactivating an enzyme. Components of the protein synthetic apparatus also undergo phosphorylation and dephosphorylation and thus regulate the rates of protein synthesis.\n\nAs part of postranslational modifications, phosphate groups may be removed from serine, threonine, or tyrosine. As such, pathways of intracellular signal transduction depend on sequential phosphorylation and dephosphorylation of a wide variety of proteins.\n\n ATP + HO --> ADP + HPO + H\n\nAdenosine triphosphate, or ATP, acts as a free energy \"currency\" in all living organisms. In a spontaneous dephosphorylation reaction 30.5 kJ/mol is released, which is harnessed to drive cellular reactions. Overall, nonspontaneous reactions coupled to the dephosphorylation of ATP are spontaneous, due to the negative free energy change of the coupled reaction. This is important in driving oxidative phosphorylation. ATP is dephosphorylated to ADP and inorganic phosphate.\n\nOn the cellular level, the dephosphorylation of ATPases determines the flow of ions into and out of the cell. Proton pump inhibitors are a class of drug that acts directly on ATPases of the gastrointestinal tract.\n\n\"See Role of dephosphorylation in disease\"\n\nOther molecules besides ATP undergo dephosphorylation as part of other biological systems. Different compounds produce different free energy changes as a result of dephosphorylation.\n\nPsilocybin also relies on dephosphorylation to be metabolized into psilocin and further eliminated. No information on psilocybin's effect on the change in free energy is currently available.\n\nThe first protein complex of the photosynthesis component light-dependent reactions is referred to as photosystem II. The complex utilizes an enzyme to capture photons of light, providing the greater photosynthesis process with all of the electrons needed to produce ATP. Photosystem II is particularly temperature sensitive, and desphosphorylation has been implicated as a driver of plasticity in responding to varied temperature. Accelerated protein dephosphorylation in photosynthetic thylakoid membranes occurs at elevated temperatures, directly impacting the desphosphorylation of key proteins within the photosystem II complex.\n\nExcessive dephosphorylation of the membrane ATPases and proton pumps in the gastrointestinal tract leads to higher secretory rates of caustic peptic acids. These result in heartburn and esophagitis. In combination with \"Helicobacter pylori\" infection, peptic ulcer disease is caused by the elevated pH dephosphorylation elicits.\n\nThe microtubule-associated protein tau is abnormally hyperphosphorylated when isolated from the brain of patients who suffer from Alzheimer's disease. This is due to the dysfunction of dephosphorylation mechanisms at specific amino acids on the tau protein. Tau dephosphorylation is catalysed by protein phosphatase-2A and phosphatase-2B. Deficiency or modification of one or both proteins may be involved in abnormal phosphorylation of tau in Alzheimer's disease\n\nDephosphorylation has also been linked to cardiac disease, particularly the alteration of actin-myosin interactions that are key for providing the underlying force of a heartbeat. Dephosphorylation is a key part of the myosin cycling kinetics that directly control the actin-myosin interactions. When the dephosphorylation process is interrupted, calcium dependent cardiac contraction is impaired or fully disabled.\n\nResearch has also suggested that modifications to dephosphorylation impact physiological processes implicated in Diabetes mellitus. The kinetics of dephosphorylation of insulin receptor substrate-1/2, Akt, and ERK1/2, phosphoproteins are shown to be involved in insulin receptor signaling, and \"in vitro\" models demonstrate that changes to dephosphorylation kinetics impact upstream and downstream insulin stimulation.\n\nInhibition of proton pumps significantly decreases the acidity of the gastrointestinal tract, reducing the symptoms of acid-related diseases. The resulting change in pH decreases survival of the bacteria \"H.pylori\", a major cause of peptic ulcer disease. Once the proton pump inhibitor eradicates this bacteria within the gut, reversing erosive reflux.\nTreating heart disease has improved with the use of drugs that inhibit AMPK via dephosphorylation. \nIn the treatment of diabetes, sulfonylurea drugs are able to stimulate dephosphorylation of the glucose transporter GLUT4, decreasing insulin resistance and increasing and glucose utilization.\n\nDephosphorylation can play a key role in molecular biology, particularly cloning using restriction enzymes. The cut ends of a vector may re-ligate during a ligation step due to phosphorylation. By using a desphosphorylating phosphatase, re-ligation can be avoided. These alkaline phosphatases are often sourced naturally, most commonly from calf intestine, and are abbreviated as CIP.\n\nPhosphatase\n\nPhosphorylation\n", "id": "1704568", "title": "Dephosphorylation"}
{"url": "https://en.wikipedia.org/wiki?curid=4102360", "text": "Filopodia\n\nFilopodia (also microspikes) are slender cytoplasmic projections that extend beyond the leading edge of lamellipodia in migrating cells. They contain actin filaments cross-linked into bundles by actin-binding proteins, e.g. fascin and fimbrin. Filopodia form focal adhesions with the substratum, linking it to the cell surface. Many types of migrating cells display filopodia, which are thought to be involved in both sensation of chemotropic cues, and resulting changes in directed locomotion.\n\nActivation of the Rho family of small Ras-related GTPases, particularly cdc42 and their downstream intermediates results in the polymerization of actin fibers by Ena/Vasp homology proteins. Growth factors bind to receptor tyrosine kinases resulting in the polymerization of actin filaments, which, when cross-linked, make up the supporting cytoskeletal elements of filopodia. Rho activity also results in activation by phosphorylation of ezrin-moesin-radixin family proteins that link actin filaments to the filopodia membrane.\n\nFilopodia have roles in sensing, migration and cell-cell interaction. To close a wound in vertebrates, growth factors stimulate the formation of filopodia in fibroblasts to direct fibroblast migration and wound closure. In developing neurons, filopodia extend from the growth cone at the leading edge. In neurons deprived of filopodia by partial inhibition of actin filaments polymerization, growth cone extension continues as normal but direction of growth is disrupted and highly irregular. Filopodia-like projections have also been linked to dendrite creation when new synapses are formed in the brain. In macrophages, filopodia act as phagocytic tentacles and pull bound objects towards the cell for phagocytosis.\n\nFilopodia are also used for movement of bacteria between cells, so as to evade the host immune system. The intracellular bacteria \"Ehrlichia\" are transported between cells through the host cell filopodia induced by the pathogen during initial stages of infection. Viruses were shown to be transported along filopodia toward the cell body, leading to cell infection. Directed transport of receptor-bound epidermal growth factor (EGF) along filopodia has also been described, supporting the proposed sensing function of filopodia.\n\n", "id": "4102360", "title": "Filopodia"}
{"url": "https://en.wikipedia.org/wiki?curid=961291", "text": "Glycocalyx\n\nThe glycocalyx, also known as the pericellular matrix, is a glycoprotein and glycolipid covering that surrounds the cell membranes of some bacteria, epithelia and other cells.\n\nMost animal epithelial cells have a fuzz-like coat on the external surface of their plasma membranes. This coating consists of several carbohydrate moieties of membrane glycolipids and glycoproteins, which serve as backbone molecules for support. Generally, the carbohydrate portion of the glycolipids found on the surface of plasma membranes helps these molecules contribute to cell-cell recognition, communication, and intercellular adhesion.\n\nThe glycocalyx is a type of identifier that the body uses to distinguish between its own healthy cells and transplanted tissues, diseased cells, or invading organisms. Included in the glycocalyx are cell-adhesion molecules that enable cells to adhere to each other and guide the movement of cells during embryonic development. The glycocalyx plays a major role in regulation of endothelial vascular tissue, including the modulation of red blood cell volume in capillaries.\n\nThe slime on the outside of a fish is an example of glycocalyx. The term was initially applied to the polysaccharide matrix coating epithelial cells, but its functions have been discovered to go well beyond that.\n\nThe glycocalyx is located on the apical surface of vascular endothelial cells which line the lumen. When vessels are stained with cationic dyes such as Alcian blue stain, transmission electron microscopy shows a small, irregularly shaped layer extending approximately 50–100 nm into the lumen of a blood vessel. Another study used cryo-transmission electron microscopy and showed that the endothelial glycocalyx could be up to 11μm thick. It is present throughout a diverse range of microvascular beds (capillaries) and macrovessels (arteries and veins). The glycocalyx also consists of a wide range of enzymes and proteins that regulate leukocyte and thrombocyte adherence, since its principal role in the vasculature is to maintain plasma and vessel wall homeostasis. These enzymes and proteins include:\n\nThe enzymes and proteins listed above serve to reinforce the glycocalyx barrier against vascular and other diseases. Another main function of the glycocalyx within the vascular endothelium is that it shields the vascular walls from direct exposure to blood flow, while serving as a vascular permeability barrier. Its protective functions are universal throughout the vascular system, but its relative importance varies depending on its exact location in the vasculature. In microvascular tissue, the glycocalyx serves as a vascular permeability barrier by inhibiting coagulation and leukocyte adhesion. It is important that leukocytes do not stick to the vascular wall because they are important components of the immune system that must be able to travel to a specific region of the body when needed. In arterial vascular tissue, the glycocalyx also inhibits coagulation and leukocyte adhesion, but through mediation of shear stress-induced nitric oxide (NO) release. Another protective function throughout the cardiovascular system is its ability to affect the filtration of interstitial fluid from capillaries into the interstitial space\n\nResearch has shown that the glycocalyx, which is located on the apical surface of endothelial cells, is composed of a negatively charged network of proteoglycans, glycoproteins, and glycolipids.\n\nBecause the glycocalyx is so prominent throughout the cardiovascular system, disruption to this structure has detrimental effects that can cause disease. Certain stimuli that cause atheroma may lead to enhanced sensitivity of vasculature. Initial dysfunction of the glycocalyx can be caused by hyperglycemia or oxidized LDL which then causes atherothrombosis. In microvasculature, dysfunction of the glycocalyx leads to internal fluid imbalance, and potentially edema. In arterial vascular tissue, glycocalyx disruption causes inflammation and atherothrombosis.\n\nExperiments have been performed in order to test precisely how the glycocalyx can be altered or damaged. One particular study used an isolated perfused heart model designed to facilitate detection of the state of the vascular barrier portion, and sought to cause insult-induced shedding of the glycocalyx to ascertain the cause and effect relationship between glycocalyx shedding and vascular permeability. It was hypothesized that hypoxic perfusion of the glycocalyx was sufficient to initiate a degradation mechanism of the endothelial barrier. The study found that flow of oxygen throughout the blood vessels did not have to be completely absent (ischemic hypoxia), but that minimal levels of oxygen were sufficient to cause the degradation. Shedding of the glycocalyx can be triggered by inflammatory stimuli, such as tumor necrosis factor-alpha (TNF). Whatever the stimulus is, however, shedding of the glycocalyx leads to a drastic increase in vascular permeability. It is disadvantageous for vascular walls to be permeable, since that would enable passage of some macromolecules or other harmful antigens.\n\nFluid shear stress is also a potential problem if the glycocalyx is degraded for any reason. This type of frictional stress is caused by the movement of viscous fluid (i.e. blood) along the lumen boundary. Another similar experiment was carried out to determine what kinds of stimuli cause fluid shear stress. The initial measurement was taken with intravital microscopy, which showed a slow-moving plasma layer, the glycocalyx, of 1 micrometer thick. Light dye damaged the glycocalyx minimally, but that small change increased capillary hematocrit. Thus, fluorescence light microscopy should not be used to study the glycocalyx because that particular method uses a dye. The glycocalyx can also be reduced in thickness when treated with oxidized LDL. These stimuli, along with many other factors, can cause damage to the delicate glycocalyx. These studies are evidence that the glycocalyx plays a crucial role in cardiovascular system health.\n\nA glycocalyx, literally meaning \"sugar coat\" (\"glykys\" = sweet, \"kalyx\" = husk), is a network of polysaccharides that project from cellular surfaces of bacteria, which classifies it as a universal surface component of a bacterial cell, found just outside the bacterium cell wall. A distinct, gelatinous glycocalyx is called a capsule, whereas an irregular, diffuse layer is called a slime layer. This coat is extremely hydrated and stains with ruthenium red.\n\nBacteria growing in natural ecosystems, such as in soil, bovine intestines, or the human urinary tract, is surrounded by some sort of glycocalyx-enclosed microcolony. It serves to protect the bacterium from harmful phagocytes by creating capsules or allowing the bacterium to attach itself to inert surfaces, like teeth or rocks, via biofilms (e.g. \"Streptococcus pneumoniae\" attaches itself to either lung cells, prokaryotes, or other bacteria which can fuse their glycocalyxes to envelop the colony).\n\nA glycocalyx can also be found on the apical portion of microvilli within the digestive tract, especially within the small intestine. It creates a meshwork 0.3 micrometers thick and consists of acidic mucopolysaccharides and glycoproteins that project from the apical plasma membrane of epithelial absorptive cells. It provides additional surface for adsorption and includes enzymes secreted by the absorptive cells that are essential for the final steps of digestion of proteins and sugars.\n\n\n", "id": "961291", "title": "Glycocalyx"}
{"url": "https://en.wikipedia.org/wiki?curid=2279144", "text": "Microdialysis\n\nMicrodialysis is a minimally-invasive sampling technique that is used for continuous measurement of free, unbound analyte concentrations in the extracellular fluid of virtually any tissue. Analytes may include endogenous molecules (e.g. neurotransmitter, hormones, glucose, etc.) to assess their biochemical functions in the body, or exogenous compounds (e.g. pharmaceuticals) to determine their distribution within the body. The microdialysis technique requires the insertion of a small microdialysis catheter (also referred to as microdialysis probe) into the tissue of interest. The microdialysis probe is designed to mimic a blood capillary and consists of a shaft with a semipermeable hollow fiber membrane at its tip, which is connected to inlet and outlet tubing. The probe is continuously perfused with an aqueous solution (perfusate) that closely resembles the (ionic) composition of the surrounding tissue fluid at a low flow rate of approximately 0.1-5μL/min. Once inserted into the tissue or (body)fluid of interest, small solutes can cross the semipermeable membrane by passive diffusion. The direction of the analyte flow is determined by the respective concentration gradient and allows the usage of microdialysis probes as sampling as well as delivery tools. The solution leaving the probe (dialysate) is collected at certain time intervals for analysis.\n\nThe microdialysis principle was first employed in the early 1960s, when push-pull canulas and dialysis sacs were implanted into animal tissues, especially into rodent brains, to directly study the tissues' biochemistry. While these techniques had a number of experimental drawbacks, such as the number of samples per animal or no/limited time resolution, the invention of continuously perfused dialytrodes in 1972 helped to overcome some of these limitations. Further improvement of the dialytrode concept resulted in the invention of the \"hollow fiber\", a tubular semipermeable membrane with a diameter of ~200-300μm, in 1974. Today's most prevalent shape, the needle probe, consists of a shaft with a hollow fiber at its tip and can be inserted by means of a guide cannula into the brain and other tissues.\n\nThere are a variety of probes with different membrane and shaft length combinations available. The molecular weight cutoff of commercially available microdialysis probes covers a wide range of approximately 6-100kD, but also 1MD is available. While water-soluble compounds generally diffuse freely across the microdialysis membrane, the situation is not as clear for highly lipophilic analytes, where both successful (e.g. corticosteroids) and unsuccessful microdialysis experiments (e.g. estradiol, fusidic acid) have been reported. However, the recovery of water-soluble compounds usually decreases rapidly if the molecular weight of the analyte exceeds 25% of the membrane’s molecular weight cutoff.\n\nDue to the constant perfusion of the microdialysis probe with fresh perfusate, a total equilibrium cannot be established. This results in dialysate concentrations that are lower than those measured at the distant sampling site. In order to correlate concentrations measured in the dialysate with those present at the distant sampling site, a calibration factor (recovery) is needed. The recovery can be determined at steady-state using the constant rate of analyte exchange across the microdialysis membrane. The rate at which an analyte is exchanged across the semipermeable membrane is generally expressed as the analyte’s extraction efficiency. The extraction efficiency is defined as the ratio between the loss/gain of analyte during its passage through the probe (C−C) and the difference in concentration between perfusate and distant sampling site (C−C).\nIn theory, the extraction efficiency of a microdialysis probe can be determined by: 1) changing the drug concentrations while keeping the flow rate constant or 2) changing the flow rate while keeping the respective drug concentrations constant. At steady-state, the same extraction efficiency value is obtained, no matter if the analyte is enriched or depleted in the perfusate. Microdialysis probes can consequently be calibrated by either measuring the loss of analyte using drug-containing perfusate or the gain of analyte using drug-containing sample solutions. To date, the most frequently used calibration methods are the low-flow-rate method, the no-net-flux method, the dynamic (extended) no-net-flux method, and the retrodialysis method. The proper selection of an appropriate calibration method is critically important for the success of a microdialysis experiment. Supportive in vitro experiments prior to the use in animals or humans are therefore recommended. In addition, the recovery determined in vitro may differ from the recovery in humans. Its actual value therefore needs to be determined in every in vivo experiment.\n\nThe low-flow-rate method is based on the fact that the extraction efficiency is dependent on the flow-rate. At high flow-rates, the amount of drug diffusing from the sampling site into the dialysate per unit time is smaller (low extraction efficiency) than at lower flow-rates (high extraction efficiency). At a flow-rate of zero, a total equilibrium between these two sites is established (C = C). This concept is applied for the (low-)flow-rate method, where the probe is perfused with blank perfusate at different flow-rates. Concentration at the sampling site can be determined by plotting the extraction ratios against the corresponding flow-rates and extrapolating to zero-flow. The low-flow-rate method is limited by the fact that calibration times may be rather long before a sufficient sample volume has been collected.\n\nDuring calibration with the no-net-flux-method, the microdialysis probe is perfused with at least four different concentrations of the analyte of interest (C) and steady-state concentrations of the analyte leaving the probe are measured in the dialysate (C). The recovery for this method can be determined by plotting C−C over C and computing the slope of the regression line. If analyte concentrations in the perfusate are equal to concentrations at the sampling site, no-net flux occurs. Respective concentrations at the no-net-flux point are represented by the x-intercept of the regression line. The strength of this method is that, at steady-state, no assumptions about the behaviour of the compound in the vicinity of the probe have to be made, since equilibrium exists at a specific time and place. However, under transient conditions (e.g. after drug challenge), the probe recovery may be altered resulting in biased estimates of the concentrations at the sampling site. To overcome this limitation, several approaches have been developed that are also applicable under non-steady-state conditions. One of these approaches is the dynamic no-net-flux method.\n\nWhile a single subject/animal is perfused with multiple concentrations during the no-net-flux method, multiple subjects are perfused with a single concentration during the dynamic no-net-flux (DNNF) method. Data from the different subjects/animals is then combined at each time point for regression analysis allowing determination of the recovery over time. The design of the DNNF calibration method has proven very useful for studies that evaluate the response of endogenous compounds, such as neurotransmitters, to drug challenge.\n\nDuring retrodialysis, the microdialysis probe is perfused with an analyte-containing solution and the disappearance of drug from the probe is monitored. The recovery for this method can be computed as the ratio of drug lost during passage (C−C) and drug entering the microdialysis probe (C). In principle, retrodialysis can be performed using either the analyte itself (retrodialysis by drug) or a reference compound (retrodialysis by calibrator) that closely resembles both the physiochemical and the biological properties of the analyte. Despite the fact that retrodialysis by drug cannot be used for endogenous compounds as it requires absence of analyte from the sampling site, this calibration method is most commonly used for exogenous compounds in clinical settings.\n\nThe microdialysis technique has undergone much development since its first use in 1972, when it was first employed to monitor concentrations of endogenous biomolecules in the brain. Today's area of application has expanded to monitoring free concentrations of endogenous as well as exogenous compounds in virtually any tissue. Although microdialysis is still primarily used in preclinical animal studies (e.g. laboratory rodents, dogs, sheep, pigs), it is now increasingly employed in humans to monitor free, unbound drug tissue concentrations as well as interstitial concentrations of regulatory cytokines and metabolites in response to homeostatic perturbations such as feeding and/or exercise.\n\nWhen employed in brain research, microdialysis is commonly used to measure neurotransmitters (e.g. dopamine, serotonin, norepinephrine, acetylcholine, glutamate, GABA) and their metabolites, as well as small neuromodulators (e.g. cAMP, cGMP, NO), amino acids (e.g. glycine, cysteine, tyrosine), and energy substrates (e.g. glucose, lactate, pyruvate). Exogenous drugs to be analyzed by microdialysis include new antidepressants, antipsychotics, and many other drugs that have their pharmacological effect site in the brain. Applications in other organs include the skin (assessment of bioavailability and bioequivalence of topically applied dermatological drug products), and monitoring of glucose concentrations in patients with diabetes (intravascular or subcutaneous probe placement). The latter may even be incorporated into an artificial pancreas system for automated insulin administration.\n\nMicrodialysis has also found increasing application in environmental research, sampling a diversity of compounds from waste-water and soil solution, including saccharides, metal ions, organic acids, and low molecular weight nitrogen. Given the destructive nature of conventional soil sampling methods, microdialysis has potential to estimate fluxes of soil ions that better reflect an undisturbed soil environment.\n\n\n", "id": "2279144", "title": "Microdialysis"}
{"url": "https://en.wikipedia.org/wiki?curid=1617243", "text": "Hyperphosphorylation\n\nHyperphosphorylation occurs when a biochemical with multiple phosphorylation sites is fully saturated. Hyperphosphorylation is one of the signaling mechanisms used by the cell to regulate mitosis. When these mechanisms fail, developmental problems or cancer are a likely outcome. The mechanism appears to be largely conserved throughout eukaryote species. \n\nThe dynamics of mitosis are similar to a state machine. In a healthy cell, checkpoints between phases permit a new phase to begin only when the previous phase is complete and successful. At these checkpoints, gatekeeper molecules block or allow events, depending on their level of phosphorylation. Kinases are responsible for adding phosphate groups and phosphatases for removing them. Cyclins are molecules that manage the timing of cell cycle events. Cyclin dependent kinases pair up with cyclins to become operational. Cyclins are named because they are created or destroyed at predetermined points within the cell cycle. Kinase inhibitors add another level of modulation. Kinase inhibitors are grouped into classes and are assigned not very descriptive acronyms. These include INKS for inhibitors of kinase, KIPS for kinase inhibitors and CKIPS for cyclin dependent kinases inhibitors. \n\nScientists have used a variety of tools to unravel the role of hyperphosphorylation. These include the study of knockout genes, the use of antibodies to block receptors on particular molecules, the use of temperature sensitive mutants, and microarrays to monitor the expression of particular genes. Yeast are a popular species for study because of the rapid cell cycle. \n\nRb is one of the most studied checkpoint molecules. It is so named because defects in Rb are linked to retinoblastoma. In its unphosphorylated state it blocks the transition from G0 or resting state to S or synthesis. It does this in at least 3 ways. It inhibits RNA synthesis, it prevents chromosomes from unwinding and it binds E2F, a factor needed for DNA synthesis. When it is hyperphosphorylated, Rb becomes inactive, releasing bound E2F and allowing phase S to proceed. \n\nWee is a protein that operates at the G2 to metaphase checkpoint. Wee becomes active if errors occur in the DNA synthesis phase. It blocks entry into metaphase until the problem is resolved. Like Rb, wee becomes inactive when hyperphosphorylated. \n\nIn contrast Mad1 is active when hyperphosphorylated. In its active state it is part of the checkpoint that blocks transition to anaphase. Cdc2, part of the metaphase entry checkpoint, is active depending on the pattern of phosphorylation.\n", "id": "1617243", "title": "Hyperphosphorylation"}
{"url": "https://en.wikipedia.org/wiki?curid=1000067", "text": "Splenocyte\n\nA splenocyte can be any one of the different white blood cell types as long as it is situated in the spleen or purified from splenic tissue.\nSplenocytes consist of a variety of cell populations such as T and B lymphocytes, dendritic cells and macrophages, which have different immune functions.\n", "id": "1000067", "title": "Splenocyte"}
{"url": "https://en.wikipedia.org/wiki?curid=8399975", "text": "Non-mevalonate pathway\n\nThe non-mevalonate pathway—also appearing as the mevalonate-independent pathway and the 2-\"C\"-methyl--erythritol 4-phosphate/1-deoxy--xylulose 5-phosphate (MEP/DOXP) pathway—is an alternative metabolic pathway for the biosynthesis of the isoprenoid precursors isopentenyl pyrophosphate (IPP) and dimethylallyl pyrophosphate (DMAPP). The currently preferred name for this pathway is the MEP pathway, since MEP is the first committed metabolite on the route to IPP.\n\nThe classical mevalonate pathway or HMG-CoA reductase pathway is a metabolic pathway from the biosynthesis of isoprenoid precursors present in most higher eukaryotes and some bacteria. It is important for the production of IPP and DMAPP, which serve as the basis for the biosynthesis of isoprenoid (terpenoid) molecules used in processes as diverse as protein prenylation, cell membrane maintenance, the synthesis of hormones, protein anchoring and \"N\"-glycosylation.\n\nBacteria, plants, and apicomplexan protozoa—such as malaria parasites—are able to produce isoprenoid precursors using an alternative pathway, the MEP pathway, which is a \"non-mevalonate pathway.\" In the case of plants and certain protozoa, the biosynthesis of IPP/DMAPP takes place in plastid organelles. Plants synthesise isoprenoid precursors using the mevalonate pathway in the cytoplasm and using the MEP pathway in their chloroplasts. Bacteria that use the pathway include important pathogens such \"Mycobacterium tuberculosis\".\n\nThe reactions of the non-mevalonate pathway are as follows, taken primarily from Eisenreich and co-workers, except where the bold labels are additional local abbreviations to assist in connecting the table to the scheme above:\n\nDXP reductoisomerase (also known as: DXR, DOXP reductoisomerase, IspC, MEP synthase), is a key enzyme in the MEP pathway. It can be inhibited by the natural productfosmidomycin, which is under study as a starting point to develop a candidate antibacterial or antimalarial drug.\n\nThe intermediate, HMB-PP, is a natural activator of human Vγ9/Vδ2 T cells, the major γδ T cell population in peripheral blood, and cells that \"play a crucial role in the immune response to microbial pathogens\".\n\n", "id": "8399975", "title": "Non-mevalonate pathway"}
{"url": "https://en.wikipedia.org/wiki?curid=2073471", "text": "Beta oxidation\n\nIn biochemistry and metabolism, beta-oxidation is the catabolic process by which fatty acid molecules are broken down in the cytosol in prokaryotes and in the mitochondria in eukaryotes to generate acetyl-CoA, which enters the citric acid cycle, and NADH and FADH, which are co-enzymes used in the electron transport chain. It is named as such because the beta carbon of the fatty acid undergoes oxidation to a carbonyl group. Beta-oxidation is primarily facilitated by the mitochondrial trifunctional protein, an enzyme complex associated with the inner mitochondrial membrane, although some fatty acids are oxidized in peroxisomes.\n\nThe overall reaction for one cycle of beta oxidation is:\n\nFatty acid catabolism consists of:\n\nFree fatty acids cannot penetrate any biological membrane due to their negative charge. Free fatty acids must cross the cell membrane through specific transport proteins, such as the SLC27 family fatty acid transport protein. Once in the cytosol, the following processes bring fatty acids into the mitochondrial matrix so that beta-oxidation can take place.\n\nOnce the fatty acid is inside the mitochondrial matrix, beta-oxidation occurs by cleaving two carbons every cycle to form acetyl-CoA. The process consists of 4 steps.\n\n\nFatty acids are oxidized by most of the tissues in the body. However, some tissues such as the red blood cells (which do not contain mitochondria), and cells of the central nervous system (because fatty acids cannot cross the blood-brain barrier into the interstitial fluids that bathe these cells) do not use fatty acids for their energy requirements, but instead use carbohydrates or ketone bodies.\n\nBecause many fatty acids are not fully saturated or do not have an even number of carbons, several different mechanisms have evolved, described below.\n\nOnce inside the mitochondria, each cycle of β-oxidation, liberating a two carbon unit (acetyl-CoA), occurs in a sequence of four reactions:\n\nThis process continues until the entire chain is cleaved into acetyl CoA units. The final cycle produces two separate acetyl CoAs, instead of one acyl CoA and one acetyl CoA. For every cycle, the Acyl CoA unit is shortened by two carbon atoms. Concomitantly, one molecule of FADH, NADH and acetyl CoA are formed.\n\nIn general, fatty acids with an odd number of carbons are found in the lipids of plants and some marine organisms. Many ruminant animals form a large amount of 3-carbon propionate during the fermentation of carbohydrates in the rumen.\n\nChains with an odd-number of carbons are oxidized in the same manner as even-numbered chains, but the final products are propionyl-CoA and succinyl-CoA.\n\nPropionyl-CoA is first carboxylated using a bicarbonate ion into D-stereoisomer of methylmalonyl-CoA, in a reaction that involves a biotin co-factor, ATP, and the enzyme propionyl-CoA carboxylase. The bicarbonate ion's carbon is added to the middle carbon of propionyl-CoA, forming a D-methylmalonyl-CoA. However, the D conformation is enzymatically converted into the L conformation by methylmalonyl-CoA epimerase, then it undergoes intramolecular rearrangement, which is catalyzed by methylmalonyl-CoA mutase (requiring B as a coenzyme) to form succinyl-CoA. The succinyl-CoA formed can then enter the citric acid cycle.\n\nHowever, whereas acetyl-CoA enters the citric acid cycle by condensing with an existing molecule of oxaloacetate, succinyl-CoA enters the cycle as a principal in its own right. Thus the succinate just adds to the population of circulating molecules in the cycle and undergoes no net metabolization while in it. When this infusion of citric acid cycle intermediates exceeds cataplerotic demand (such as for aspartate or glutamate synthesis), some of them can be extracted to the gluconeogenesis pathway, in the liver and kidneys, through phosphoenolpyruvate carboxykinase, and converted to free glucose.\n\nβ-Oxidation of unsaturated fatty acids poses a problem since the location of a cis bond can prevent the formation of a trans-Δ bond. These situations are handled by an additional two enzymes, Enoyl CoA isomerase or 2,4 Dienoyl CoA reductase.\n\nWhatever the conformation of the hydrocarbon chain, β-oxidation occurs normally until the acyl CoA (because of the presence of a double bond) is not an appropriate substrate for acyl CoA dehydrogenase, or enoyl CoA hydratase:\n\n\nTo summarize:\n\nFatty acid oxidation also occurs in peroxisomes when the fatty acid chains are too long to be handled by the mitochondria. The same enzymes are used in peroxisomes as in the mitochondrial matrix, and acetyl-CoA is generated. It is believed that very long chain (greater than C-22) fatty acids, branched fatty acids, some prostaglandins and leukotrienes undergo initial oxidation in peroxisomes until octanoyl-CoA is formed, at which point it undergoes mitochondrial oxidation.\n\nOne significant difference is that oxidation in peroxisomes is not coupled to ATP synthesis. Instead, the high-potential electrons are transferred to O, which yields HO. It does generate heat however. The enzyme catalase, found exclusively in peroxisomes, converts the hydrogen peroxide into water and oxygen.\n\nPeroxisomal β-oxidation also requires enzymes specific to the peroxisome and to very long fatty acids. There are three key differences between the enzymes used for mitochondrial and peroxisomal β-oxidation:\n\nPeroxisomal oxidation is induced by a high-fat diet and administration of hypolipidemic drugs like clofibrate.\n\nThe ATP yield for every oxidation cycle is theoretically a maximum yield of 17, as NADH produces 3 ATP, FADH produces 2 and a full rotation of the citric acid cycle produces 12. In practice it's closer to 14 ATP for a full oxidation cycle as in practice the theoretical yield isn't attained - it's generally closer to 2.5 ATP per NADH molecule produced, 1.5 for each FADH Molecule produced and this equates to 10 per cycle of the TCA (according to the P/O ratio), broken down as follows:\n\nFor an even-numbered saturated fat (C), n - 1 oxidations are necessary, and the final process yields an additional acetyl CoA. In addition, two equivalents of ATP are lost during the activation of the fatty acid. Therefore, the total ATP yield can be stated as:\n\nor\nFor instance, the ATP yield of palmitate (C, \"n = 8\") is:\n\nRepresented in table form:\n\nFor sources that use the larger ATP production numbers described above, the total would be 129 ATP ={(8-1)*17+12-2} equivalents per palmitate.\n\nBeta-oxidation of unsaturated fatty acids changes the ATP yield due to the requirement of two possible additional enzymes.\n\nThe reactions of beta oxidation and part of citric acid cycle present structural similarities in three of four reactions of the beta oxidation: the oxidation by FAD, the hydration, and the oxidation by NAD. Such comparison viewed using Fischer projection and the polygonal model as well. Each enzyme of these metabolic pathways presents structural similarity.\n\nThere are at least 25 enzymes and specific transport proteins in the β-oxidation pathway. Of these, 18 have been associated with human disease as inborn errors of metabolism.\n\n\n", "id": "2073471", "title": "Beta oxidation"}
{"url": "https://en.wikipedia.org/wiki?curid=5821492", "text": "Martinotti cell\n\nMartinotti cells are small multipolar neurons with short branching dendrites. They are scattered throughout various layers of the cerebral cortex, sending their axons up to the cortical layer I where they form axonal arborization. The arbors transgress multiple columns in layer VI and make contacts with the distal tuft dendrites of pyramidal cells. \n\nRecent research suggests that Martinotti cells are associated with a cortical dampening mechanism. When the pyramidal neuron, which is the most common type of neuron in the brain, starts getting overexcited, Martinotti cells start sending inhibitory signals to the surrounding neurons. \nHistorically, the discovery of Martinotti cells has been mistakenly attributed to Giovanni Martinotti 1888, although it is now accepted that they were actually discovered in 1889 by Carlo Martinotti (1859–1908), a student of Camillo Golgi.\n\n", "id": "5821492", "title": "Martinotti cell"}
{"url": "https://en.wikipedia.org/wiki?curid=4361880", "text": "Diauxie\n\nDiauxie is a Greek word coined by Jacques Monod to mean two growth phases. The word is used in English in cell biology to describe the growth phases of a microorganism in batch culture as it metabolizes a mixture of two sugars. Rather than metabolizing the two available sugars simultaneously, microbial cells commonly consume them in a sequential pattern, resulting in two separate growth phases.\n\nJacques Monod discovered diauxic growth in 1941 during his experiments with \"Escherichia coli\" and \"Bacillus subtilis\". While growing these bacteria on various combination of sugars during his doctoral thesis research, Monod observed that often two distinct growth phases are clearly visible in batch culture, as seen in Figure 1.\n\nDuring the first phase, cells preferentially metabolize the sugar on which it can grow faster (often glucose but not always). Only after the first sugar has been exhausted do the cells switch to the second. At the time of the \"diauxic shift\", there is often a lag period during which cells produce the enzymes needed to metabolize the second sugar.\n\nMonod later put aside his work on diauxic growth and focused on the \"lac\" operon model of gene expression, which led to a Nobel prize.\n\nDiauxie occurs because organisms use operons or multiple sets of genes to control differently the expression of enzymes needed to metabolize the different nutrients or sugars they encounter. If an organism allocates its energy and other resources (e.g. amino acids) to synthesize enzymes needed to metabolize a sugar that can only support a slower growth rate and not use all or most of its available resources to synthesize the enzymes that metabolize a different sugar providing a faster growth rate, such an organism will be at a reproductive disadvantage compared to those that choose to grow on the faster growth supporting sugar. Through evolution, organisms have developed the ability to regulate their genetic control mechanisms so as to only express those genes resulting in the fastest growth rate. For example, when grown in the presence of both glucose and maltose, \"Lactococcus lactis\" will produce enzymes to metabolize glucose first, altering its gene expression to use maltose only after the supply of glucose has been exhausted.\n\nIn the case of the baker's or brewer's yeast \"Saccharomyces cerevisiae\" growing on glucose with plenty of aeration, the diauxic growth pattern is commonly observed in batch culture. During the first growth phase, when there is plenty of glucose and oxygen available, the yeast cells prefer glucose fermentation to aerobic respiration even though aerobic respiration is the more efficient pathway to grow on glucose. Contrary to the more commonly invoked Pasteur effect, this phenomenon of preferring the faster growth supporting fermentation is closer to the Warburg effect observed in faster growing tumors. The intracellular genetic regulatory mechanisms have evolved to enforce this choice, as fermentation provides a faster growth rate for the yeast cells than the aerobic respiration of glucose. After glucose is depleted, the fermentative product ethanol is oxidised in a noticeably slower second growth phase, if oxygen is available.\n\nIn the 1940s, Monod hypothesized that a single enzyme could adapt to metabolize different sugars. It took 15 years of further work to show that this was incorrect. During his work on the lac operon of \"E. coli\", Joshua Lederberg isolated β-galactosidase and found it in greater quantities in colonies grown on lactose compared to other sugars. Melvin Cohn in Monod's lab at the Pasteur Institute then found that β-galactosides induced enzyme activity. The idea of enzyme adaptation was thus replaced with the concept of enzyme induction, in which a molecule induces expression of a gene or operon, often by binding to a repressor protein and preventing it from attaching to the operator.\n\nIn the case of the bacterial diauxic shift from glucose to lactose metabolism, a proposed mechanism suggested that glucose initially inhibits the ability of the enzyme adenylate cyclase to synthesize cyclic AMP (cAMP). cAMP, in turn, is required for the catabolite activator protein (CAP) to bind to DNA and activate the transcription of the lac operon, which includes genes necessary for lactose metabolism. The presence of allolactose, a metabolic product of lactose, is sensed through the activity of the lac repressor, which inhibits transcription of the lac operon until lactose is present. Thus, if glucose is present, cAMP levels remain low, so CAP is unable to activate transcription of the lac operon, regardless of the presence or absence of lactose. Upon the exhaustion of the glucose supply, cAMP levels rise, allowing CAP to activate the genes necessary for the metabolism of other food sources, including lactose if it is present.\n\nMore recent research however suggests that the cAMP model is not correct in this instance since cAMP levels remain identical under glucose and lactose growth conditions, and a different model has been proposed and it suggests that the lactose-glucose diauxie in \"E. coli\" may be caused mainly by inducer exclusion. In this model, glucose transport via the EIIA shuts down lactose permease when glucose is being transported into the cell, so lactose is not transported into cell and used. While the cAMP/CAP mechanism may not play a role in the glucose/lactose diauxie, it is a suggested mechanism for other diauxie .\n", "id": "4361880", "title": "Diauxie"}
{"url": "https://en.wikipedia.org/wiki?curid=12219719", "text": "Cellular waste product\n\nCellular waste products are formed as a by-product of cellular respiration, a series of processes and reactions that generate energy for the cell, in the form of ATP. Two examples of cellular respiration creating cellular waste products are aerobic respiration and anaerobic respiration.\n\nEach pathway generates different waste products.\n\nWhen in the presence of oxygen, cells use aerobic respiration to obtain energy from glucose molecules.\n\nSimplified Theoretical Reaction: CHO + 6O → 6CO + 6HO + ~ 30ATP\n\nCells undergoing aerobic respiration produce 6 molecules of carbon dioxide, 6 molecules of water, and up to 30 molecules of ATP (adenosine triphosphate), which is directly used to produce energy, from each molecule of glucose in the presence of surplus oxygen.\n\nIn aerobic respiration, oxygen serves as the recipient of electrons from the electron transport chain. Aerobic respiration is thus very efficient because oxygen is a strong oxidant. \nAerobic respiration proceeds in a series of steps, which also increases efficiency - since glucose is broken down gradually and ATP is produced as needed, less energy is wasted as heat. This strategy results in the waste products HO and CO being formed in different amounts at different phases of respiration. CO is formed in Pyruvate decarboxylation, HO is formed in oxidative phosphorylation, and both are formed in the citric acid cycle. \nThe simple nature of the final products also indicates the efficiency of this method of respiration. All of the energy stored in the carbon-carbon bonds of glucose is released, leaving CO and HO. Although there is energy stored in the bonds of these molecules, this energy is not easily accessible by the cell. All usable energy is efficiently extracted.\n\nAnaerobic respiration is done by aerobic organisms when there is not sufficient oxygen in a cell to undergo aerobic respiration as well as by cells called anaerobes that selectively perform anaerobic respiration even in the presence of oxygen. \nIn anaerobic respiration, weak oxidants like sulfate and nitrate serve as oxidants in the place of oxygen.\n\nGenerally, in anaerobic respiration sugars are broken down into carbon dioxide and other waste products that are dictated by the oxidant the cell uses. Whereas in aerobic respiration the oxidant is always oxygen, in anaerobic respiration it varies. Each oxidant produces a different waste product, such as nitrite, succinate, sulfide, methane, and acetate. \nAnaerobic respiration is correspondingly less efficient than aerobic respiration. In the absence of oxygen, not all of the carbon-carbon bonds in glucose can be broken to release energy. A great deal of extractable energy is left in the waste products. \nAnaerobic respiration generally occurs in prokaryotes in environments that do not contain oxygen.\n\nFermentation is another process by which cells can extract energy from glucose. It is not a form of cellular respiration, but it does generate ATP, break down glucose, and produce waste products. \nFermentation, like aerobic respiration, begins by breaking glucose into two pyruvate molecules. From here, it proceeds using endogenous organic electron receptors, whereas cellular respiration uses exogenous receptors, such as oxygen in aerobic respiration and nitrate in anaerobic respiration. These varied organic receptors each generate different waste products. \nCommon products are lactic acid, lactose, hydrogen, and ethanol. Carbon dioxide is also commonly produced.\nFermentation occurs primarily in anaerobic conditions, although some organisms such as yeast use fermentation even when oxygen is plentiful.\n\nSimplified Theoretical Reaction: CHO formula_1 2CHO + 2 ATP (120 kJ) \nLactic Acid Fermentation is commonly known as the process by which mammalian muscle cells produce energy in anaerobic environments, as in instances of great physical exertion, and is the simplest type of fermentation. It starts along the same pathway as aerobic respiration, but once glucose is converted to pyruvate proceeds down one of two pathways and produces only two molecules of ATP from each molecule of glucose. In the homolactic pathway, it produces lactic acid as waste. In the heterolactic pathway, it produces lactic acid as well as ethanol and carbon dioxide. \nLactic acid fermentation is relatively inefficient. The waste products lactic acid and ethanol have not been fully oxidized and still contain energy, but it requires the addition of oxygen to extract this energy.\n\nGenerally, lactic acid fermentation occurs only when aerobic cells are lacking oxygen . However, some aerobic mammalian cells will preferentially use lactic acid fermentation over aerobic respiration. This phenomenon is called the Warburg effect and is found primarily in cancer cells. Muscles cells under great exertion will also use lactic acid fermentation to supplement aerobic respiration. Lactic acid fermentation is somewhat faster, although less efficient, than aerobic respiration, so in activities like sprinting it can help quickly provide needed energy to muscles.\n\nCellular respiration takes place in the cristae of the mitochondria within cells. Depending on the pathways followed, the products are dealt with in different ways.\n\nCO is excreted from the cell via diffusion into the blood stream, where it is transported in three ways:\n\nHO also diffuses out of the cell into the blood stream, from where it is excreted in the form of perspiration, water vapor in breath, or urine from the kidneys. Water, along with some dissolved solutes, are removed from blood circulation in the nephrons of the kidney and eventually excreted as urine.\n\nThe products of fermentation can be processed different ways, depending on the cellular conditions.\n\nLactic acid tends to accumulate in the muscles, which causes pain of the muscle and joint as well as fatigue. It also creates a gradient which induces water to flow out of cells and increases blood pressure. Research suggests that lactic acid may also play a role in lowering levels of potassium in the blood. It can also be converted back to pyruvate or converted back to glucose in the liver and fully metabolized by aerobic respiration.\n\n", "id": "12219719", "title": "Cellular waste product"}
{"url": "https://en.wikipedia.org/wiki?curid=12223150", "text": "Fusion mechanism\n\nThe fusion mechanism is the mechanism by which cell fusion takes place. Cell fusion is the formation of a hybrid cell from two different cells of different species. Cells from the same organism may fuse together as well. This is often observed during lytic viral infection, where alterations of the cell can be seen under a light microscope. These include changes in morphology, formation of vacuoles and fusion of cells to form syncytia.\n\nThe term \"cell fusion mechanism\" refers to the receptors required for cells to fuse, whereas the term \"cell fusion\" refers to the action of formation of the new cell.\n\nOne example of the cellular fusion mechanism is that of HIV infecting the body. HIV infects by fusing with the membranes of immune system cells. In order for HIV to fuse with a cell, it must be able to bind to the receptors CD4, CCR5, and CXCR4.\n\n", "id": "12223150", "title": "Fusion mechanism"}
{"url": "https://en.wikipedia.org/wiki?curid=12543181", "text": "Ribonucleoprotein particle\n\nA ribonucleoprotein particle or RNP is a complex formed between RNA and RNA-binding proteins (RBPs). The term 'RNP foci' is also used to denote an intracellular compartment involved in processing of RNA transcripts.\n\nRBPs interact with RNA through binding motifs. Aromatic amino acid residues in this RNA binding motif result in stacking interactions with RNA. Lysine residues in the helical portion of RNA binding proteins help to stabilize interactions with nucleic acids. This nucleic acid binding is a result of the force of attraction between the positive electrical charge of lysine side chains and the negative electrical charge of nucleic acid phosphate backbones. It is hypothesized that RNA sequences, called elements, in the 3'-untranslated region determine the binding of RBPs, and that these RBPs determine the post-transcriptional fate of mRNAs.\n\nRNP granules are a highly diverse group of compartments. These include stress granules, processing bodies, and exosomes in somatic cells. Many RNP granules are cell type and/or species specific. For example, chromatoid bodies are found only in male germ cells, whereas transport granules have so far been found only in neurons and oocytes. RNP granules function mainly by physically separating or associating transcripts with proteins. They function in the storage, processing, degradation and transportation of their associated transcripts.\n\nRNP granules have been shown to have particular importance in cells where post-transcriptional regulation is of vital importance. For example, in neurons where transcripts must be transported and stored in dendrites for the formation and strengthening of connections, in oocytes/embryos where mRNAs are stored for years before being translated, and in developing sperm cells where transcription is halted before development is complete.\n\n", "id": "12543181", "title": "Ribonucleoprotein particle"}
{"url": "https://en.wikipedia.org/wiki?curid=4094126", "text": "MAFA\n\nMAFA (Mast cell function-associated antigen) is a type II membranal glycoprotein, first identified on the surface of rat mucosal-type mast cells of the RBL-2H3 line. More recently, human and mouse homologues of MAFA have been discovered yet also (or only) expressed by NK and T-cells.\n\nThe intracellular domain of MAFA contains a single immunoreceptor tyrosine-based inhibitory motif (ITIM), which classifies MAFA as a member of an inhibitory receptor superfamily. The inhibitory capacity of MAFA is best defined in mast cells, where MAFA keeps in check the antigen-induced (i.e. Fc epsilon RI-induced) secretion of inflammatory mediators.\n", "id": "4094126", "title": "MAFA"}
{"url": "https://en.wikipedia.org/wiki?curid=12659090", "text": "Guanosine pentaphosphate\n\n(p)ppGpp, guanosine pentaphosphate or tetraphosphate is an alarmone which is involved in the stringent response in bacteria, causing the inhibition of RNA synthesis when there is a shortage of amino acids present. This causes translation to decrease and the amino acids present are therefore conserved. Furthermore, ppGpp causes the up-regulation of many other genes involved in stress response such as the genes for amino acid uptake (from surrounding media) and biosynthesis.\n\nppGpp and pppGpp were first identified by Michael Cashel in the 1960s. These nucleotides were found to accumulate rapidly in \"Escherichia coli\" cells starved for amino acids, and inhibit synthesis of ribosomal and transfer RNAs. It is now known that (p)ppGpp is also produced in response to other stressors, including carbon and phosphate starvation.\n\nA complete absence of (p)ppGpp causes multiple amino acid requirements, poor survival of aged cultures, aberrant cell division, morphology, and immotility, as well as being locked in a growth mode during entry into starvation.\n\nThe synthesis and degradation of (p)ppGpp have been most extensively characterized in the model system \"E. coli\". (p)ppGpp is created via pppGpp synthase, also known as RelA, and is converted from pppGpp to ppGpp via pppGpp phosphohydrolase. RelA is associated with about every one in two hundred ribosomes and it becomes activated when an uncharged transfer RNA (tRNA) molecule enters the A site of the ribosome, due to the shortage of amino acid required by the tRNA. If a mutant bacterium is \"relA\" it is said to be relaxed and no regulation of RNA production due to amino acid absence is seen.\n\n\"E. coli\" produces a second protein responsible for degradation of (p)ppGpp, termed SpoT. When the amino acid balance in the cell is restored, (p)ppGpp is hydrolysed by SpoT. This protein also has the capacity to synthesize (p)ppGpp, and seems to be the primary synthase under certain conditions of stress. Most other bacteria encode a single protein that is responsible for both synthesis and degradation of (p)ppGpp, generally homologs of SpoT.\n\nTargets of (p)ppGpp include rRNA operons, of which there are seven in \"Escherichia coli\" (a commonly used bacterial model organism), all of which have 2 promoters. When (p)ppGpp associates with the promoter it affects the RNA polymerase enzyme's ability to bind and initiate transcription. It is thought that (p)ppGpp may affect the stability of the open complex formed by RNA polymerase on DNA and therefore affect promoter clearance. Its presence also leads to an increase in pausing during transcription elongation and it competes with nucleoside triphosphate substrates.\n\nThere is now a consensus that (p)ppGpp is a determinant of growth rate control rather than nucleoside triphosphate (NTP) substrate concentrations.\n\nppGpp inhibits IF2-mediated fMet-Phe initiation dipeptide formation, probably by interfering with 30S and 50S subunit interactions. E. coli accumulates more ppGpp than pppGpp during amino acid starvation, and ppGpp has about 8-fold greater efficiency than that of pppGpp. While B. subtilis accumulates more pppGpp than ppGpp.\n\nIn E. coli amino acid starvation inhibited DNA replication at the initiation stage at oriC, most probably owing to the lack of the DnaA replication initiation protein. In B. subtilis, the replication arrest due to (p)ppGpp accumulation is caused by the binding of an Rtp protein to specific sites about 100-200kb away from oriC in both directions. DNA primase (DnaG) was directly inhibited by (p)ppGpp. Unlike E. coli, B. subtilis accumulates more pppGpp than ppGpp; the more abundant nucleotide is a more-potent DnaG inhibitor. ppGpp can bind with Obg protein which belongs to the conserved, small GTPase protein family. Obg protein interacts with several regulators (RsbT, RsbW, RsbX) necessary for the stress activation of sigma B.\n\nThe (p)ppGpp levels of the host seem to act as a sensor for phage lambda development, primarily affecting transcription. Modest ppGpp levels inhibit pR and active pE, pI, and paQ promoters in vivo and have effects in vitro that seem to favor lysogeny. In contrast, absent or high concentrations of (p)ppGpp favor lysis. Modest ppGpp levels favor lysogeny by leading to low HflB (FtsH). When ppGpp is either absent or high, HflB protease levels are high; this leads to lower CII (a lysogeny-promoting phage protein)\nand favors lysis.\n\nOne of the key elements of promoters inhibited by (p)ppGpp is the presence of a GC-rich discriminator, defined as a region between TATA-box (-10 box) and +1 nt (where +1 is the transcription start sit). Promoters negatively regulated by ppGpp have a 16-bp linker, in contrast with the 17-bp consensus. Promoters activated by ppGpp seem to have an AT-rich discriminator and linger linkers (for example, the his promoter linker is 18 bp).\n\nGenetic evidence suggesting that RNAP was the target of ppGpp came from the discovery that M+ mutants (also called stringent RNAP mutants) display in vitro and in vivo mimicry of physiology and transcription regulation conferred by (p)ppGpp, even in its absence. Cross-linking ppGpp to RNAP reinforced this notion. Structural details of an association between ppGpp and RNAP came from the analysis of cocrystals that positioned ppGpp in the secondary channel of RNAP near the catalytic center.\n\nDksA is a 17-kDa protein, its structure is similar to GreA and GreB, which are well-characterized transcriptional elongation factors. GreA and GreB bind directly to RNAP rather than DNA and act by inserting their N-terminal coiled-coil finger domain through the RNAP secondary channel. Two conserved acidic residues at the tip of the finger domain are necessary to induce RNAP's intrinsic ability to cleave backtracked RNA. DksA also possesses two acidic residues at its finger tip, but it does not induce nucleolytic cleavage activity. Instead, these residues are proposed to stabilize ppGpp binding to RNAP by mutual coordination of an Mg2+ ion that is crucial for polymerization.\n\nppGpp directly inhibits transcription from ribosomal promoters. One model is ppGpp and DksA together and independently decrease the stability of the open complexes formed on DNA by RNAP. Another model is the trapping mechanism. In this model, RNAP is trapped by ppGpp in closed complexes and is unable to initiate transcription. Thus, ppGpp seems to act at many levels, and the mechanism of its action is a complex outcome of several factors, intrinsic promoter properties not being the least of them. The transcription activation by ppGpp can be direct or indirect. Direct activation occurs when RNAP interacts with effectors, such as ppGpp, DksA or both, to increase transcription from a given promoter. Indirect activation by these effectors of one promoter relies on inhibition of other (strong) promoters, leading to increased availability of RNAP that indirectly activates transcription initiation. The promoters that activated directly by ppGpp include P\"argI\", P\"thrABC\", P\"livJ\", and P\"hisG\". The indirectly activation promoters include these dependent on sigma factors: S, H, N, E. When strong promoters, such as \"rrn\", are inhibited, there more RNAP are available for these alternative sigma factors.\n\nWhen (p)ppGpp is absent, pathogenicity is compromised for reasons that vary with the organism studied. Deleting \"rel\"A and \"spo\"T genes, but not \"rel\"A alone, gave a (p)ppGpp state that resulted in strong attenuation in mice and noninvasiveness in vitro. Vaccine tests reveal that 30 days after single immunization with the (p)ppGpp strain, mice were protected from challenge with wild-type Salmonella at a dose 10-fold above the established LD.\n\n", "id": "12659090", "title": "Guanosine pentaphosphate"}
{"url": "https://en.wikipedia.org/wiki?curid=8868378", "text": "Axenic\n\nIn biology, axenic describes the state of a culture in which only a single species, variety, or strain of organism is present and entirely free of all other contaminating organisms. The earliest axenic cultures were of bacteria or unicellular eukaryotes, but axenic cultures of many multicellular organisms are also possible. Axenic culture is also an important tool for the study of symbiotic and parasitic organisms in a controlled manner.\n\nAxenic cultures of microorganisms are typically prepared by subculture of an existing mixed culture. This may involve use of a dilution series, in which a culture is successively diluted to the point where subsamples of it contain only a few individual organisms, ideally only a single individual (in the case of an asexual species). These subcultures are allowed to grow until the identity of their constituent organisms can be ascertained. Selection of those cultures consisting solely of the desired organism produces the axenic culture. Subculture selection may also involve manually sampling the target organism from an uncontaminated growth front in an otherwise mixed culture, and using this as an inoculum source for the subculture.\n\nAxenic cultures are usually checked routinely to ensure that they remain axenic. One standard approach with microorganisms is to spread a sample of the culture onto an agar plate, and to incubate this for a fixed period of time. The agar should be an enriched medium that will support the growth of common \"contaminating\" organisms. Such \"contaminating\" organisms will grow on the plate during this period, identifying cultures that are no longer axenic.\n\nAs axenic cultures are derived from very few organisms, or even a single individual, they are useful because the organisms present within them share a relatively narrow gene pool. In the case of an asexual species derived from a single individual, the resulting culture should consist of identical organisms (though processes such as mutation and horizontal gene transfer may introduce a degree of variability). Consequently, they will generally respond in a more uniform and reproducible fashion, simplifying the interpretation of experiments.\n\nThe axenic culture of some pathogens is complicated because they normally thrive within host tissues which exhibit properties that are difficult to replicate \"in vitro\". This is especially true in the case of intracellular pathogens. However, careful replication of key features of the host environment can resolve these difficulties (e.g. host metabolites, dissolved oxygen), such as with the Q fever pathogen, \"Coxiella burnetii\".\n\n", "id": "8868378", "title": "Axenic"}
{"url": "https://en.wikipedia.org/wiki?curid=13092651", "text": "Cell synchronization\n\nCell Synchronization is a process by which cells at different stages of the cell cycle in a culture are brought to the same phase. \"Cell synchrony\" is required to study the progression of cells through the cell cycle. The types of synchronizations are broadly categorized into two groups: \"Physical Fractionation\" and \"Chemical Blockade.\"\n\nPhysical fractionation or cell separation techniques, based on the following characteristics are in use.\nThe two commonly used techniques are:\n\nThe physical characteristics — cell size and sedimentation velocity — are operative in the technique of centrifugal elutriation. Centrifugal elutriator (from Beckman) is an advanced device for increasing the sedimentation rate so that the yield and resolution of cells is better. The cell separation is carried out in a specially designed centrifuge and rotor.\n\nFluorescence-activated cell sorting (FACS) is a technique for sorting out the cells based on the differences that can be detected by light scatter (e.g. cell size) or fluorescence emission (by penetrated DNA, RNA, proteins, antigens).\nThe procedure involves passing of a single stream of cells through a laser beam so that the scattered light from the cells can be detected and recorded. There are two instruments in use based on its principle:\n\nThe cells can be separated by blocking metabolic reactions. Two types of metabolic blockades are in use:\n\nDuring the S phase of cell cycle, DNA synthesis can be inhibited by using inhibitors such as thymidine, aminopterin, hydroxyurea and cytosine arabinoside. The effects of these inhibitors are variable for this. The cell cycle is predominantly blocked in S phase that results in viable cells.\n\nElimination of serum from the culture medium for about 24 hours results in the accumulation of cells at G1 phase. This effect of nutritional deprivation can be restored by their addition by which time the cell synchrony occurs.\n\n", "id": "13092651", "title": "Cell synchronization"}
{"url": "https://en.wikipedia.org/wiki?curid=3450582", "text": "Securin\n\nSecurin is a protein involved in control of the metaphase-anaphase transition and anaphase onset. Following bi-orientation of chromosome pairs and inactivation of the spindle checkpoint system, the underlying regulatory system, which includes securin, produces an abrupt stimulus that induces highly synchronous chromosome separation in anaphase.\n\nSecurin is initially present in the cytoplasm and binds to separase, a protease that degrades the cohesin rings that link the two sister chromatids. Separase is vital for onset of anaphase. This securin-separase complex is maintained when securin is phosphorylated by , inhibiting ubiquitination. When bound to securin, separase is not functional.\n\nIn addition, both securin and separase are well-conserved proteins (Figure 1). Note that separase cannot function without initially forming the securin-separase complex. This is because securin helps properly fold separase into the functional conformation. However, yeast does not appear to require securin to form functional separase as anaphase occurs in yeast with a securin deletion mutation.\n\nSecurin has 5 known phosphorylation sites that are targets of Cdk1; 2 sites at the N-terminal in the Ken-Box and D-box region are known to affect APC recognition and ubiquitination (Figure 2). To initiate the onset of anaphase, securin is dephosphorylated by Cdc14 and other phosphatases. Dephosphorylated securin is recognized by the Anaphase-Promoting Complex (APC) bound primarily to Cdc20 (Cdh1 is also an activating substrate of APC). The APC complex ubiquitinates securin and targets it for degradation by 26S proteasome. This results in free separase that is able to destroy cohesin and initiate chromosome separation.\n\nIt is thought that securin integrates multiple regulatory inputs to make separase activation switch-like, resulting in sudden, coordinated anaphase. This likely involves a network with several feedback loops, including positive feedback which leads to switch-like behavior. One proposed signaling pathway generating switch-like behavior contains a positive feedback loop for activation of Cdc14 by separase, leading to dephosphorylation and degradation of securin (Figure 3).\n\nDavid Morgan’s group found that segregation time of chromosomes 4 and 5 is significantly elongated in budding-yeast strains with mutations in the 2 N-terminal securin phosphorylation sites and securin deletion strains. In addition, these mutant strains exhibited very high rates of mis-segregation compared to normal behavior. Switch-like characteristics are necessary to trigger quick, coordinated chromosomal segregation in anaphase. This means that strong inactivation of separase by securin followed by sudden, rapid destruction of securin and activation of separase is vital for proper anaphase.\n\nOverall, securin and separase act in an anaphase-regulating network. Figure 4 depicts a potential network diagram.\n\n", "id": "3450582", "title": "Securin"}
{"url": "https://en.wikipedia.org/wiki?curid=7178651", "text": "Side population\n\nA side population (SP) in flow cytometry is a sub-population of cells that is distinct from the main population on the basis of the markers employed. By definition, cells in a side population have distinguishing biological characteristics (for example, they may exhibit stem cell-like characteristics), but the exact nature of this distinction depends on the markers used in identifying the side population.\nSide populations have been identified in cancer and may be the cells that efflux chemotherapy drugs, accounting for the resistance of cancer to chemotherapy.\nRecent studies on testicular stem cells indicate that more than 40% of the SP (defined in this case as cells that show higher efflux of DNA-binding dye Hoechst 33342) was undifferentiated spermatogonia, while other differentiated fractions were represented by only 0.2%. SP cells can rapidly efflux lipophilic fluorescent dyes to produce a characteristic profile based on fluorescence-activated flow cytometric analysis. Previous studies have demonstrated SP cells in bone marrow obtained from patients with acute myeloid leukemia, suggesting that these cells might be candidate leukemic stem cells, and recent studies have found a SP of tumor progenitor cells in human solid tumors. These new data indicate that the ability of malignant SP cells to expel anticancer drugs may directly improve their survival and sustain their clonogenicity during exposure to cytostatic drugs, allowing disease recurrence when therapy is withdrawn. Identification of a tumor progenitor population with intrinsic mechanisms for cytostatic drug resistance might also provide clues for improved therapeutic intervention. The molecules involved in effluxing Hoechst 33342 are members of the ATP-binding cassette family, such as MDR1 (P-glycoprotein) and ABCG2.\n", "id": "7178651", "title": "Side population"}
{"url": "https://en.wikipedia.org/wiki?curid=14501387", "text": "Entosis\n\nEntosis (from Greek ἐντός \"entos\", \"within\" and -ωσις \"-osis\", \"disease\") is the invasion of a living cell into another cell's cytoplasm. The process was discovered by Overholtzer, et al. as reported in \"Cell\".\n\nEntotic cells, also referred to as cell-in-cell structures, are triggered by loss of attachment to the extracellular matrix (ECM). This internalization of one cell by another is dependent on adherens junctions, and is driven by a Rho-dependent process, involving actin polymerization and myosin II activity in the internalized cell. Adherens junctions bind cells together by linking cadherin transmembrane protein complexes of adjacent cells to the cytoskeleton. When certain cell types are detached from the ECM and have lost adhesion, the compaction force between neighboring cells can cause them to push into their neighbors, forming the trademark cell-in-cell structures. Though cell-in-cell structures commonly refer to the interaction between two neighboring cells, entosis has been observed involving more than two cells. In the case of an entotic structure formed between three cells, the middle cell acts as both an internalizing and an outer host cell simultaneously.\n\nAneuploidy, a condition in which non-disjunction gives rise to gametes with an abnormal number of chromosomes, is one of the most prevalent phenotypes of human tumors. The underlying cause of aneuploidy remains highly debated; however, entosis is shown to perturb cytokinesis (cytoplasmic division) and trigger the formation of aneuploid cells. This would be in line with past research, as cell-in-cell structures have been widely observed in the focused study of many human tumors, including lung, breast, and endometrial stromal carcinomas.\n\nA cell trapped by entosis is initially alive and can divide inside the cell that has enveloped it. On occasion, the entotic cell will be released by the host cell, but most internalized cells are eventually killed. Normal cells can kill themselves via apoptosis, involving the programmed engulfment and phagocytic ingestion of a cell by another. Entosis differs greatly from apoptosis in that the entotic process exhibits behavior closely resembling cellular invasion rather than cellular engulfment. Cancer cells adaptively avoid apoptosis, allowing them to live and multiply indefinitely, making it difficult to design drugs that effectively kill tumors. Therefore, entosis acts as a nonapoptotic cell death mechanism, and could possibly be a new way in which cancer cells can be killed.\n\n", "id": "14501387", "title": "Entosis"}
{"url": "https://en.wikipedia.org/wiki?curid=2991457", "text": "Synapsis\n\nSynapsis (also called syndesis) is the pairing of two homologous chromosomes that occurs during meiosis. It allows matching-up of homologous pairs prior to their segregation, and possible chromosomal crossover between them. Synapsis takes place during prophase I of meiosis. When homologous chromosomes synapse, their ends are first attached to the nuclear envelope. These end-membrane complexes then migrate, assisted by the extranuclear cytoskeleton, until matching ends have been paired. Then the intervening regions of the chromosome are brought together, and may be connected by a protein-RNA complex called the synaptonemal complex. Autosomes undergo synapsis during meiosis, and are held together by a protein complex along the whole length of the chromosomes called the synaptonemal complex. Sex chromosomes also undergo synapsis; however, the synaptonemal protein complex that holds the homologous chromosomes together is only present at one end of each sex chromosome. \n\nThis is not to be confused with mitosis. Mitosis also has prophase, but does not ordinarily do pairing of two homologous chromosomes.\n\nWhen the non-sister chromatids intertwine, segments of chromatids with similar sequence may break apart and be exchanged in a process known as genetic recombination or \"crossing-over\". This exchange produces a chiasma, a region that is shaped like an X, where the two chromosomes are physically joined. At least one chiasma per chromosome often appears to be necessary to stabilise bivalents along the metaphase plate during separation. The crossover of genetic material also provides a possible defence against 'chromosome killer' mechanisms, by removing the distinction between 'self' and 'non-self' through which such a mechanism could operate. A further consequence of recombinant synapsis is to increase genetic variability within the offspring. Repeated recombination also has the general effect of allowing genes to move independently of each other through the generations, allowing for the independent concentration of beneficial genes and the purging of the detrimental.\n\nFollowing synapsis, a type of recombination referred to as synthesis dependent strand annealing (SDSA) occurs frequently. SDSA recombination involves information exchange between paired non-sister homologous chromatids, but not physical exchange. SDSA recombination does not cause crossing-over. Both the non-crossover and crossover types of recombination function as processes for repairing DNA damage, particularly double-strand breaks (see Genetic recombination).\n\nThe central function of synapsis is therefore the identification of homologues by pairing, an essential step for a successful meiosis. The processes of DNA repair and chiasma formation that take place following synapsis have consequences at many levels, from cellular survival through to impacts upon evolution itself.\n\nIn mammals, surveillance mechanisms remove meiotic cells in which synapsis is defective. One such surveillance mechanism is meiotic silencing that involves the transcriptional silencing of genes on asynapsed chromosomes. Any chromosome region, either in males or females, that is asynapsed is subject to meiotic silencing. ATR, BRCA1 and gammaH2AX localize to unsynapsed chromosomes at the pachytene stage of meiosis in human oocytes and this may lead to chromosome silencing. The DNA damage response protein TOPBP1 has also been identified as a crucial factor in meiotic sex chromosome silencing. DNA double-strand breaks appear to be initiation sites for meiotic silencing.\n\nIn female \"Drosophila melanogaster\" fruit flies, meiotic chromosome synapsis occurs in the absence of recombination. Thus synapsis in \"Drosophila\" is independent of meiotic recombination, consistent with the view that synapsis is a precondition required for the initiation of meiotic recombination. Meiotic recombination is also unnecessary for homologous chromosome synapsis in the nematode \"Caenorhabditis elegans\".\n\n", "id": "2991457", "title": "Synapsis"}
{"url": "https://en.wikipedia.org/wiki?curid=14975920", "text": "Cellular adaptation\n\nIn cell biology and pathophysiology, cellular adaptation refers to changes made by a cell in response to adverse environmental changes. The adaptation may be physiologic(al) (normal) or pathologic(al) (abnormal). Five minor types of adaptation include atrophy, hypertrophy, hyperplasia, dysplasia, and metaplasia.\n\nAtrophy is a decrease in cell size. If enough cells in an organ atrophy the entire organ will decrease in size. Thymus atrophy during early human development (childhood) is an example of physiologic atrophy. Skeletal muscle atrophy is a common pathologic adaptation to skeletal muscle disuse (commonly called \"disuse atrophy\"). Tissue and organs especially susceptible to atrophy include skeletal muscle, cardiac muscle, secondary sex organs, and the brain.\n\nHypertrophy is an increase in cell size. If enough cells of an organ hypertrophy so will the whole organ. The heart and kidneys have increased susceptibility to hypertrophy. Hypertrophy involves an increase in intracellular protein rather than cytosol (intracellular fluid). Hypertrophy may be caused by mechanical signals (e.g., stretch) or trophic signals (e.g., growth factors). An example of physiologic hypertrophy is in skeletal muscle with sustained weight bearing exercise. An example of pathologic hypertrophy is in cardiac muscle as a result of hypertension.\n\nHyperplasia is an increase in the number of cells. It is the result of increased cell mitosis, or division. The two types of physiologic hyperplasia are compensatory and hormonal. Compensatory hyperplasia permits tissue and organ regeneration. It is common in epithelial cells of the epidermis and intestine, liver hepatocytes, bone marrow cells, and fibroblasts. It occurs to a lesser extent in bone, cartilage, and smooth muscle cells. Hormonal hyperplasia occurs mainly in organs that depend on estrogen. For example, the estrogen-dependent uterine cells undergo hyperplasia and hypertrophy following pregnancy. Pathologic hyperplasia is an abnormal increase in cell division. A common pathologic hyperplasia in women occurs in the endometrium and is called endometriosis.\n\nMetaplasia occurs when a differentiated cell of a certain type is replaced by another cell type, which may be less differentiated. It is a reversible process thought to be caused by stem cell reprogramming. Stem cells are found in epithelia and embryonic mesenchyme of connective tissue. A prominent example of metaplasia involves the changes associated with the respiratory tract in response to inhalation of irritants, such as smog or smoke. The bronchial cells convert from mucus-secreting, ciliated, columnar epithelium to non-ciliated, squamous epithelium incapable of secreting mucus. These transformed cells may become dysplasic or cancerous if the stimulus (e.g., cigarette smoking) is not removed. The most common example of metaplasia is Barrett's esophagus, when the non-keratinizing squamous epithelium of the esophagus undergoes metaplasia to become mucinous columnar cells, ultimately protecting the esophagus from acid reflux originating in the stomach. If stress persists, metaplasia can progress to dysplasia and eventually carcinoma; Barrett's esophagus, for example, can eventually progress to adenocarcinoma of the esophagus if not treated.\n\nDysplasia refers to abnormal changes in cellular shape, size, and/or organization. Dysplasia is not considered a true adaptation; rather, it is thought to be related to hyperplasia and is sometimes called \"atypical hyperplasia\". Tissues prone to dysplasia include cervical and respiratory epithelium, where it is strongly associated with the development of cancer; it may also be involved in the development of breast cancer. Although dysplasia is reversible, if stress persists, then dysplasia progresses to irreversible carcinoma.\n\n", "id": "14975920", "title": "Cellular adaptation"}
{"url": "https://en.wikipedia.org/wiki?curid=15202596", "text": "Paracrine regulator\n\nParacrine regulator is a cell or group of cells from the diffuse neuroendocrine system known as APUDs that produce amines or peptides.\n\n", "id": "15202596", "title": "Paracrine regulator"}
{"url": "https://en.wikipedia.org/wiki?curid=397456", "text": "Lysis\n\nLysis ( ; Greek λύσις \"lýsis\", \"a loosing\" from λύειν \"lýein\", \"to unbind\") refers to the breaking down of the membrane of a cell, often by viral, enzymic, or osmotic (that is, \"lytic\" ) mechanisms that compromise its integrity. A fluid containing the contents of lysed cells is called a \"lysate\". In molecular biology, biochemistry, and cell biology laboratories, cell cultures may be subjected to lysis in the process of purifying their components, as in protein purification, DNA extraction, RNA extraction, or in purifying organelles.\n\nMany species of bacteria are subject to lysis by the enzyme lysozyme, found in animal saliva, egg white, and other secretions. Phage lytic enzymes (lysins) produced during bacteriophage infection are responsible for the ability of these viruses to lyse bacterial cells. Penicillin and related β-lactam antibiotics cause the death of bacteria through enzyme-mediated lysis that occurs after the drug causes the bacterium to form a defective cell wall. If cell wall is completely lost, the bacterium is referred as a protoplast if penicillin was used on gram-positive bacteria, and spheroplast when used on gram-negative bacteria.\n\nCytolysis occurs when a cell bursts due to an osmotic imbalance that has caused excess water to move into the cell.\n\nCytolysis can be prevented by several different mechanisms, including the contractile vacuole that exists in some paramecia, which rapidly pump water out of the cell. Cytolysis does not occur under normal conditions in plant cells because plant cells have a strong cell wall that contains the osmotic pressure, or turgor pressure, that would otherwise cause cytolysis to occur.\n\nOncolysis refers to the destruction of neoplastic cells or of a tumour.\n\nIt is also used to refer to the reduction of any swelling.\n\nPlasmolysis is the contraction of cells within plants due to the loss of water through osmosis. In a hypertonic environment, the cell membrane peels off of the cell wall and the vacuole collapses. These cells will eventually wilt and die unless the flow of water caused by osmosis can stop the contraction of the cell membrane.\n\nErythrocytes' hemoglobin release free radicals in response to pathogens when lysed by them. This can damage the pathogens.\n\nCell lysis is used in laboratories to break open cells and purify or further study their contents. Lysis in the laboratory may be affected by enzymes or detergents or other chaotropic agents. Mechanical disruption of cell membranes, as by repeated freezing and thawing, sonication, pressure, or filtration may also be referred to as lysis. Many laboratory experiments are sensitive to the choice of lysis mechanism; often it is desirable to avoid mechanical shear forces that would denature or degrade sensitive macromolecules, such as proteins and DNA, and different types of detergents can yield different results. The unprocessed solution immediately after lysis but before any further extraction steps is often referred to as a \"crude lysate\".\n\nFor example, lysis is used in western and Southern blotting to analyze the composition of specific proteins, lipids, and nucleic acids individually or as complexes. Depending on the detergent used, either all or some membranes are lysed. For example, if only the cell membrane is lysed then gradient centrifugation can be used to collect certain organelles. Lysis is also used for protein purification, DNA extraction, and RNA extraction.\n\n", "id": "397456", "title": "Lysis"}
{"url": "https://en.wikipedia.org/wiki?curid=14829737", "text": "Segrosome\n\nSegrosomes are protein complexes that ensure accurate segregation (partitioning) of plasmids or chromosomes during bacterial cell division.\n\nJust as higher forms of life have evolved a complex mitotic apparatus to partition duplicated DNA during cell division, bacteria require a specialized apparatus to partition their duplicated DNA. In bacteria, segrosomes perform the function similar to that performed by mitotic spindle. Therefore, segrosomes can be thought of as minimalist spindles.\n\nSegrosomes are usually composed of three basic components- the DNA (plasmid or chromosome) that needs to be segregated into daughter cells, a motor protein that provides the necessary physical forces for accomplishing the segregation and a DNA binding protein that connects the DNA and the motor protein, to form the complete segrosome complex.\n\nThe majority of motor proteins participating in plasmid segrosomes are Walker-type or ParM type ATPases. Segrosome formation could be a highly regulated and ordered process to ensure its coupling with the other events of the bacterial cell cycle. Recently segrosomal complexes derived from the tubulin family of cytoskeletal proteins, which are GTPases have been discovered in megaplasmids found in \"Bacillus\" species.\n\n\n", "id": "14829737", "title": "Segrosome"}
{"url": "https://en.wikipedia.org/wiki?curid=14854417", "text": "Protein phosphorylation\n\nProtein phosphorylation is a post-translational modification of proteins in which an amino acid residue is phosphorylated by a protein kinase by the addition of a covalently bound phosphate group. Phosphorylation alters the structural conformation of a protein, causing it to become activated, deactivated, or modifying its function. The reverse reaction of phosphorylation is called dephosphorylation, and is catalyzed by protein phosphatases. Protein kinases and phosphatases work independently and in a balance to regulate the function of proteins. The amino acids most commonly phosphorylated are serine, threonine, and tyrosine in eukaryotes, and histidine in prokaryotes and plants, which play important and well-characterized roles in signaling pathways and metabolism. However, many other amino acids can also be phosphorylated in cells, including arginine, lysine, aspartic acid, glutamic acid and cysteine. Recent evidence (preprinted at BioRxiv) suggests widespread human protein phosphorylation on multiple non-canonical amino acids, including motifs containing phosphorylated histidine, aspartate, glutamate, arginine and lysine in HeLa cell extracts. Due to the chemical lability of these phosphorylated residues, special procedures and separation techniques are required for their preservation alongside classical Ser, Thr and Tyr phosphorylation.\nProtein phosphorylation was first reported in 1906 by Phoebus Levene at the Rockefeller Institute for Medical Research with the discovery of phosphorylated vitellin. However, it was nearly 50 years until the enzymatic phosphorylation of proteins by protein kinases was discovered.\n\nIn 1906, Phoebus Levene at the Rockefeller Institute for Medical Research identified phosphate in the protein vitellin (phosvitin), and by 1933 had detected phosphoserine in casein, with Fritz Lipmann. However, it took another 20 years before Eugene P. Kennedy described the first ‘enzymatic phosphorylation of proteins’. The first phosphorylase enzyme was discovered by Carl and Gerty Cori in the late 1930s. Carl and Gerty Cori found two forms of glycogen phosphorylase which they named A and B but did not correctly understand the mechanism of the B form to A form conversion. The interconversion of phosphorylase b to phosphorylase a was later described by Edmond Fischer and Edwin Krebs, as well as, Wosilait and Sutherland, involving a phosphorylation/dephosphorylation mechanism. It was found that an enzyme, named phosphorylase kinase and Mg-ATP were required to phosphorylate glycogen phosphorylase by assisting in the transfer of the γ-phosphoryl group of ATP to a serine residue on phosphorylase b. Protein phosphatase 1 is able to catalyze the dephosphorylation of phosphorylated enzymes by removing the phosphate group. Earl Sutherland explained in 1950, that the activity of phosphorylase was increased and thus glycogenolysis stimulated when liver slices were incubated with adrenalin and glucagon. Phosphorylation was considered a specific control mechanism for one metabolic pathway until the 1970s, when Lester Reed discovered that mitochondrial pyruvate dehydrogenase complex was inactivated by phosphorylation. Also in the 1970s, the term multisite phosphorylation was coined in response to the discovery of proteins that are phosphorylated on two or more residues by two or more kinases. In 1975, it was shown that cAMP-dependent proteins kinases phosphorylate serine residues on specific amino acid sequence motifs. Ray Erikson discovered that v-Src was a kinase and Tony Hunter found that v-Src phosphorylated tyrosine residues on proteins in the 1970s. In the early 1980, the amino-acid sequence of the first protein kinase was determined which helped geneticists understand the functions of regulatory genes. In the late 1980s and early 1990s, the first protein tyrosine phosphatase (PTP1B) was purified and the discovery, as well as, cloning of JAK kinases was accomplished which led to many in the scientific community to name the 1990s as the decade of protein kinase cascades. Edmond Fisher and Edwin Krebs were awarded the Nobel prize in 1992 “for their discoveries concerning reversible protein phosphorylation as a biological regulatory mechanism”.\n\nPhosphorylation introduces a charged and hydrophilic group in the side chain of amino acids, possibly changing a protein's structure by altering interactions with nearby amino acids. Some proteins such as p53 contain multiple phosphorylation sites, facilitating complex, multi-level regulation. Because of the ease with which proteins can be phosphorylated and dephosphorylated, this type of modification is a flexible mechanism for cells to respond to external signals and environmental conditions.\n\nRegulatory roles of phosphorylation include:\n\n\n\n\n\nWhile tyrosine phosphorylation is found in relatively low abundance, it is well studied due to the ease of purification of phosphotyrosine using antibodies. Receptor tyrosine kinases are an important family of cell surface receptors involved in the transduction of extracellular signals such as hormones, growth factors, and cytokines. Binding of a ligand to a monomeric receptor tyrosine kinase stabilizes interactions between two monomers to form a dimer, after which the two bound receptors phosphorylate tyrosine residues in \"trans\". Phosphorylation and activation of the receptor activates a signaling pathway through enzymatic activity and interactions with adaptor proteins. Signaling through the epidermal growth factor receptor (EGFR), a receptor tyrosine kinase, is critical for the development of multiple organ systems including the skin, lung, heart, and brain. Excessive signaling through the EGFR pathway is found in many human cancers.\n\nCyclin-dependent kinases (CDKs) are serine-threonine kinases which regulate progression through the eukaryotic cell cycle. CDKs are catalytically active only when bound to a regulatory cyclin. Animal cells contain at least nine distinct CDKs which bind to various cyclins with considerable specificity. CDK inhibitors (CKIs) block kinase activity in the cyclin-CDK complex to halt the cell cycle in G1 or in response to environmental signals or DNA damage. The activity of different CDKs activate cell signaling pathways and transcription factors that regulate key events in mitosis such as the G1/S phase transition. Earlier cyclin-CDK complexes provide the signal to activate subsequent cyclin-CDK complexes.\n\nThere are thousands of distinct phosphorylation sites in a given cell since:\n\nSince phosphorylation of any site on a given protein can change the function or localization of that protein, understanding the \"state\" of a cell requires knowing the phosphorylation state of its proteins. For example, if amino acid Serine-473 (\"S473\") in the protein AKT is phosphorylated, AKT is, in general, functionally active as a kinase. If not, it is an inactive kinase.\n\nPhosphorylation sites are crucial for proteins and their transportation and functions. They are the covalent modification of proteins through reversible phosphorylation. This enables proteins to stay inbound within a cell since the negative phosphorylated site disallows their permeability through the cellular membrane. Protein dephosphorylation allows the cell to replenish phosphates through release of pyrophosphates which saves ATP use in the cell. An example of phosphorylating enzyme is found in \"E. coli\" bacteria. It possesses alkaline phosphatase in its periplasmic region of its membrane. The outermost membrane is permeable to phosphorylated molecules however the inner cytoplasmic membrane is impermeable due to large negative charges. In this way, the \"E. coli\" bacteria stores proteins and pyrophosphates in its periplasmic membrane until either are needed within the cell.\n\nRecent advancement in phosphoproteomic identification has resulted in the discoveries of countless phosphorylation sites in proteins. This required an integrative medium for accessible data in which known phosphorylation sites of proteins are organized. A curated database of dbPAF was created, containing known phosphorylation sites in \"H. sapiens\", \"M. musculus\", \"R. norvegicus\", \"D. melanogaster\", \"C. elegans\", \"S. pombe\" and \"S. cerevisiae\". The database currently holds 294,370 non-redundant phosphorylation sites of 40,432 proteins. Other tools of phosphorylation prediction in proteins include NetPhos for eukaryotes, NetPhosBac for bacteria and ViralPhos for viruses.\n\nThere are a large variety of serine residues, and the phosphorylation of each residue can lead to different metabolic consequences. \n\nTyrosine phosphorylation is fast to react and the reaction can be reversed. Being one of the major regulatory mechanisms in signal transduction - cell growth, differentiation, migration and metabolic homeostasis are cellular processes maintained by tyrosine phosphorylation. The function of protein tyrosine kinases and protein-tyrosine phosphatase counterbalances the level of phosphotyrosine on any protein. The malfunctioning of specific chains of protein tyrosine kinases and protein tyrosine phosphatase has been linked to multiple human diseases such as obesity, insulin resistance, and type 2 diabetes mellitus. Phosphorylation on tyrosine doesn't occur in just eukaryotes but has been discovered to occur in a selection of bacterial species and present among prokaryotes. Phosphorylation on tyrosine maintains the cellular regulation in bacteria similar to its function in eukaryotes.\n\nArginine phosphorylation in many Gram-positive bacteria marks proteins for degradation by a Clp protease.\n\nRecent evidence (see BioRxiv) suggests widespread human protein phosphorylation on multiple non-canonical amino acids, including motifs containing phosphorylated histidine, aspartate, glutamate, arginine and lysine in HeLa cell extracts. Due to the chemical and thermal lability of these phosphorylated residues, special procedures and separation techniques are required for preservation alongside the heat stable 'classical' Ser, Thr and Tyr phosphorylation.\n\nProtein phosphorylation is common among all clades of life, including all animals, plants, fungi, bacteria, and archaea. The origins of protein phosphorylation mechanisms are ancestral and have diverged greatly between different species. In eukaryotes, it is estimated that between 30 - 65% of all proteins may be phosphorylated, with tens or even hundreds of thousands of distinct phosphorylation sites. Some phosphorylation sites appear to have evolved as conditional \"off\" switches, blocking the active site of an enzyme, such as in the prokaryotic metabolic enzyme isocitrate dehydrogenase. However, in the case of proteins that must be phosphorylated to be active, it is less clear how they could have emerged from non-phosphorylated ancestors. It has been shown that a subset of serine phosphosites are often replaced by acidic residues such as aspartate and glutamate between different species. These anionic residues can interact with cationic residues such as lysine and arginine to form salt bridges, stable non-covalent interactions that alter a protein's structure. These phosphosites often participate in salt bridges, suggesting that some phosphorylation sites evolved as conditional \"on\" switches for salt bridges, allowing these proteins to adopt an active conformation only in response to a specific signal.\n\nThere are ~600 known eukaryotic protein kinases, making them one of the largest gene families. Most phosphorylation is carried out by a single superfamily of protein kinases that share a conserved kinase domain. Protein phosphorylation is highly conserved in pathways central to cell survival, such as cell cycle progression relying on Cyclin-dependent kinases (CDKs), but individual phosphorylation sites are often flexible. Targets of CDK phosphorylation often have phosphosites in disordered segments, which are found in non-identical locations even in close species. Conversely, targets of CDK phosphorylation in structurally defined regions are more highly conserved. While CDK activity is critical for cell growth and survival in all eukaryotes, only very few phosphosites show strong conservation of their precise positions. Positioning is likely to be highly important for phosphates that allosterically regulate protein structure, but much more flexible for phosphates that interact with phosphopeptide-binding domains to recruit regulatory proteins.\n\nProtein phosphorylation is a reversible post-translational modification of proteins. In eukaryotes, protein phosphorylation functions in cell signaling, gene expression, and differentiation. It is also involved in DNA replication during the cell cycle, and the mechanisms that cope with stress-induced replication blocks. Compared to eukaryotes, prokaryotes use Hanks-type kinases and phosphatases for signal transduction. Whether or not the phosphorylation of proteins in bacteria can also regulate processes like DNA repair or replication still remains unclear.\n\nCompared to the protein phosphorylation of prokaryotes, studies of protein phosphorylation in eukaryotes from yeast to human cells have been rather extensive. It is known that eukaryotes rely on the phosphorylation of the hydroxyl group on the side chains of serine, threonine, and tyrosine for cell signaling. These are the main regulatory post-translational modifications in eukaryotic cells but the protein phosphorylation of prokaryotes are less intensely studied. While serine, threonine, and tyrosine are phosphorylated in eukaryotes, histidine and aspartate is phosphorylated in prokaryotes, plants and non-plant eukaryotes. In bacteria, histidine phosphorylation occurs in the phosphoenolpyruvate-dependent phosphotransferase systems (PTSs), which are involved in the process of internalization as well as the phosphorylation of sugars.\n\nProtein phosphorylation by protein kinase was first shown in \"E. coli\" and \"Salmonella typhimurium\" but has since been demonstrated in many other bacterial cells. It was found that bacteria use histidine and aspartate phosphorylation as a model for bacterial signaling transduction but in the last few years there has been evidence that has shown that serine, threonine, and tyrosine phosphorylation are also present in bacteria. It was shown that bacteria carry kinases and phosphatases similar to that of their eukaryotic equivalent but they have also developed unique kinases and phosphatases not found in eukaryotes.\n\nAbnormal protein phosphorylation has been implicated in a number of diseases, notably cancer, but also Alzheimer's disease, Parkinson's disease, and other degenerative disorders.\n\nTau protein belongs to a group of Microtubule Associated Proteins (MAPs) which, among several things, help stabilize microtubules in cells, including neurons. Association and stabilizing activity of tau protein depends on its phosphorylated state. In Alzheimer's disease, due to misfoldings and abnormal conformational changes in tau protein structure, it is rendered ineffective at binding to microtubules and thus unable to keep the neural cytoskeletal structure organized during neural processes; in fact abnormal tau inhibits and disrupts microtubule organization and disengages normal tau from microtubules into cytosolic phase. The misfoldings lead to the abnormal aggregation into fibrillary tangles inside the neurons, the hallmark of Alzheimer's disease. There is an adequate amount that the tau protein needs to be phosphorylated to function, but hyperphosphorylation of tau protein is thought to be one of the major influences on its incapacity to associate. Kinases PP1, PP2A, PP2B, and PP2C dephosphorylate tau protein \"in vitro\", and their activities have found to be reduced in areas of the brain in Alzheimer patients. Tau phosphoprotein is three to fourfold hyperphosphorylated in an Alzheimer patient compared to an aged non-afflicted individual. Alzheimer disease tau seems to remove MAP1 and MAP2 (two other major associated proteins) from microtubules and this deleterious effect is reversed when dephosphorylation is performed, evidencing hyperphosphorylation as the sole cause of the crippling activity.\n\nα-Synuclein is a protein that is associated with Parkinson's disease. This protein is coded by the PARRK1 gene and in its native form, α-Synuclein is involved in the recycling of the synaptic vesicles that carry neurotransmitters and naturally occurs in an unfolded form. Elevated levels of α-Synuclein are found in patients with Parkinson's disease, and there seems to be a positive correlation between the amount of the α-Synuclein protein present in the patient and the severity of the disease.\n\nPhosphorylation of the amino acid Ser in the α-Synuclein protein has a profound effect on the severity of the disease. There seem to be correlation between the total α-Synuclein concentration (unphosphorylated) and the severity of the symptoms in Parkinson's disease patients. Healthy patients seem to have higher levels of unphosphorylated α-Synuclein than patients with Parkinson's disease. Moreover, the measurement of the changes in the ratio of concentrations of phosphorylated α-Synuclein to unphosphorylated α-Synuclein within a patient could be a potential marker of the disease progression\n\nPhosphorylation of Ser is associated with the aggregation of the protein and further damage to the nervous system. Furthermore, the aggregation of phosphorylated α-Synuclein can be enhanced if a presynaptic scaffold protein Sept4 is present in insufficient quantities. It is important to note that direct interaction of α-Synuclein with Sept4 protein inhibits the phosphorylation of Ser.\n", "id": "14854417", "title": "Protein phosphorylation"}
{"url": "https://en.wikipedia.org/wiki?curid=16663884", "text": "Necrotaxis\n\nNecrotaxis embodies a special type of chemotaxis when the chemoattractant molecules are released from necrotic or apoptotic cells. Investigations of necrotaxis proved that ability to sense substances released from dying cells is present in unicellular level (e.g. Paramecium) as well as in vertebrates (see interactions of leukocytes with corpse of dead cells). Composition of the substances inducing necrotaxis is rather complex, some of them are still obscure. However, depending on the chemical character of molecules released, necrotaxis can accumulate or repel cells, which underlines the pathophysiological significance of the phenomenon.\nModel experiments of necrotaxis deal with special way of killing the target cells. For this purpose laser irradiation is used frequently. Several mathematical models are also available to describe the special locomotor characteristics of this migratory response of cells.\n", "id": "16663884", "title": "Necrotaxis"}
{"url": "https://en.wikipedia.org/wiki?curid=14464979", "text": "Outline of cell biology\n\nThe following outline is provided as an overview of and topical guide to cell biology:\n\nCell biology – A branch of biology that includes study of cells regarding their physiological properties, structure, and function; the organelles they contain; interactions with their environment; and their life cycle, division, and death. This is done both on a microscopic and molecular level. Cell biology research extends to both the great diversities of single-celled organisms like bacteria and the complex specialized cells in multicellular organisms like humans. Formerly, the field was called cytology (from Greek κύτος, \"kytos\", \"a hollow;\" and -λογία, \"-logia\").\n\nCell biology can be described as all of the following:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHistory of cell biology – is intertwined with the history of biochemistry and the history of molecular biology. Other articles pertaining to the history of cell biology include:\n\n\n\n\n\n\n", "id": "14464979", "title": "Outline of cell biology"}
{"url": "https://en.wikipedia.org/wiki?curid=16866820", "text": "Nuclear export signal\n\nA nuclear export signal (NES) is a short amino acid sequence of 4 hydrophobic residues in a protein that targets it for export from the cell nucleus to the cytoplasm through the nuclear pore complex using nuclear transport. It has the opposite effect of a nuclear localization signal, which targets a protein located in the cytoplasm for import to the nucleus. The NES is recognized and bound by exportins. In silico analysis of known NESs found the most common spacing of the hydrophobic residues to be LLLL, where \"L\" is a hydrophobic residue (often leucine) and \"x\" is any other amino acid; the spacing of these hydrophobic residues may be explained by examination of known structures that contain an NES, as the critical residues usually lie in the same face of adjacent secondary structures within a protein, which allows them to interact with the exportin. Ribonucleic acid (RNA) is composed of nucleotides, and thus, lacks the nuclear export signal to move out of the nucleus. As a result, most forms of RNA will bind to a protein molecule to form a ribonucleoprotein complex to be exported from the nucleus.\n\nNuclear export first begins with the binding of Ran-GTP (a G-protein) to exportin. This causes a shape change in exportin, increasing its affinity for the export cargo. Once the cargo is bound, the Ran-exportin-cargo complex moves out of the nucleus through the nuclear pore. GTPase activating proteins (GAPs) then hydrolyze the Ran-GTP to Ran-GDP, and this causes a shape change and subsequent exportin release. Once no longer bound to Ran, the exportin molecule loses affinity for the nuclear cargo as well, and the complex falls apart. Exportin and Ran-GDP are recycled to the nucleus separately, and guanine exchange factor (GEF) in the nucleus switches the GDP for GTP on Ran.\n\nNES signals were first discovered in the human immunodeficiency virus type 1 (HIV-1) Rev protein and cAMP-dependent protein kinase inhibitor (PKI). The karyopherin receptor CRM1 has been identified as the export receptor for leucine-rich NESs in several organisms and is an evolutionarily conserved protein. The export mediated by CRM1 can be effectively inhibited by the fungicide leptomycin B (LMB), providing excellent experimental verification of this pathway.\n\nOther proteins of various functions have also been experimentally inhibited of the NES signal such as the cyto-skeletal protein actin, which functions include cell motility and growth. The use of LBM as a NES inhibitor proved successful for actin resulting in accumulation of the protein within the nucleus, concluding universal functionality of NES throughout various protein functional groups.\n\nNot all NES substrates are constitutively exported from the nucleus, meaning that CRM1-mediated export is a regulated event. Several ways of regulating NES-dependent export have been reported. These include masking/unmasking of NESs, phosphorylation and even disulfide bond formation as a result of oxidation.\n\nThe binding of NES to the export receptor of a protein gives the universal export function of NES an individually specified activation of export to each protein. Studies of specified NES amino acid sequences for particular proteins show the possibility of blocking the NES activation of one protein with an inhibitor for that amino acid sequence while other proteins of the same nucleus remain unaffected.\n\nNESbase is a database of proteins, experimentally authenticated leucine-rich nuclear export signals (NES). A study was conducted by Center for Biological Sequence Analysis, Technical University of Denmark; and Department of Protein Chemistry, University of Copenhagen to validate NESbase version 1.0. Every entry in its database includes information whether nuclear export signals were sufficient for export or if it was only mediated transport by CRM1, the export receptor.\n", "id": "16866820", "title": "Nuclear export signal"}
