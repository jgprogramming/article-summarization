{"url": "https://en.wikipedia.org/wiki?curid=10625535", "text": "Cross-boundary subsidy\n\nCross-boundary subsidies are caused by organisms or materials that cross or traverse habitat patch boundaries, subsidizing the resident populations. The transferred organisms and materials may provide additional predators, prey, or nutrients to resident species, which can affect community and food web structure. Cross-boundary subsidies of materials and organisms occur in landscapes composed of different habitat patch types, and so depend on characteristics of those patches and on the boundaries in between them. Human alteration of the landscape, primarily through fragmentation, has the potential to alter important cross-boundary subsidies to increasingly isolated habitat patches. Understanding how processes that occur outside of habitat patches can affect populations within them may be important to habitat management.\n\nThe concept of cross-boundary subsidies developed out of a merging of ideas from the studies of landscape ecology and food web ecology. The ideas from landscape ecology allow the study of population, community, and food web dynamics to incorporate spatial relationships between landscape elements into an understanding of such dynamics (Polis et al. 1997).\n\nJanzen (1986) first defined cross-boundary subsidies as a process whereby organisms that disperse from one patch into another impact resident organisms by providing increased food resources or opportunities for reproduction, thus serving as a subsidy to the residents. By this definition, only the cross-boundary movement of organisms is considered, but broader definitions of cross-boundary subsidies can also include materials such as nutrients and detritus (i.e. Marburg et al. 2006, Facelli and Pickett 1991).\n\nCross-boundary subsidies are a subset of the more general process of spatial subsidies (see Polis et al. 1997). Cross-boundary subsidies acknowledge the presence and role of the boundary between different habitat patches in mediating flows of organisms and materials. In contrast, spatial subsidies require only that external inputs of materials and organisms originate from outside the patch of interest.\n\nFew attempts have been made to combine landscape and food web ecology in such a way that explicitly recognizes the importance of cross-boundary subsidies and spatial features of the landscape on food web dynamics. Often, spatial subsidies are treated as subsidies that simply arrive from outside the patch of interest, not addressing the landscape patterns and processes that may affect the movement of these inputs, such as boundary characteristics and patch connectivity. Polis et al. (1997) published a thorough review of spatially subsidized food web dynamics, focusing on the effect of subsidies on population, community, consumer-resource, and food web dynamics. One of the main conclusions was that subsidies of consumer species (organisms that eat other organisms to obtain energy) resulted in declines of food resources in the recipient patch. Callaway and Hastings (2002) built off Polis et al.’s conclusion with a model to show that subsidized consumers may not always drive down the resource in the recipient patch if consumers move between patches frequently. This might occur because consumers often move for reasons other than food resource acquisition.\n\nCadenasso et al. (2003) developed a framework for studying ecological boundaries, which has implications for understanding the dynamics of specific cross-boundary subsidies. The boundary is defined as the zone of the steepest gradient of change in some characteristic from one patch to another, such as rapidly decreasing light levels as habitat transitions from a field to a forest. In this framework, flows across variable landscapes are characterized by the type of flow (materials, energy, organisms, etc.), patch contrast (architecture, composition, process), and boundary structure (architecture, composition, symbolic and perceptual features). Considering a cross-boundary subsidy in terms of this framework shows how the boundary itself can mediate the subsidy. For example, Cadenasso and Pickett (2001) found that the decreased lateral vegetation at the boundary between a forest and field increased the amount of seeds transferred into the forest interior.\n\nAnother conceptual model that specifically considers cross-boundary subsidies is a model developed by Rand et al. (2006) of spillover from agriculture to wildland patches by predatory insects. The edge is permeable to insects that are habitat generalists and therefore capable of easily crossing the boundary between agriculture and wildland patches, whereas it is considered impermeable to insects that specialize on a particular patch type and cannot cross the boundary. In this model, edge permeability (habitat specialists vs. generalists), patch productivity, and complementary resource use (use of resources obtained in both agriculture and wildland patches) determine the expected impact of cross-boundary subsidies by predatory insects (Fig. 1).\n\nA spatial subsidy, in the context of landscape ecology, is a doner-mediated resource (nutrient, detritus, prey) which is passed from one habitat to a recipient (consumer) in a second habitat. As a result, the productivity of the recipient is increased (Polis et al., 1997). For example, a bear eats a salmon and acquires the resources that have passed through the marine environment across the habitat boundary and into a terrestrial environment.\n\nThe idea of a subsidy of materials or organisms across a patch boundary affecting resident populations has clear parallels with source-sink dynamics (Fagan et al. 1999). In this theory, local populations are connected by dispersal, and the extinction of local populations can be prevented through immigration from neighboring patches (Pulliam 1988). In source-sink dynamics, it is assumed that individuals from more productive patches will move to less productive patches with unsustainable populations (Pulliam 1988). Many examples of cross-boundary subsidies can be thought of as exhibiting source-sink dynamics. Rand et al. (2006) found that insects in a high productivity agricultural patch were able to sustain local populations in a lower productivity wildland patch through continued dispersal from the agricultural patch. The effect of these subsidies to local patches can also impact populations of other species in the recipient food web, because the subsidized population may compete with or prey upon other species more effectively than they would be able to without such an influx (Fagan et al. 1999).\n\nCross-boundary subsidies have important impacts on species interactions and food web dynamics. Subsidies of materials and organisms can affect all trophic, or feeding, levels of food webs either directly or indirectly. Inputs of nutrient and detritus from another patch generally increase the population growth of the resident producers (plants) and detritivores (Polis et al. 1997). Increased growth at the producer level can result in a bottom-up trophic effect, in which increases in populations at lower trophic levels support a higher population of consumers than would otherwise be possible in a closed system (Polis et al. 1997). allochthonous detrital inputs can also have strong impacts on food web dynamics over a variety of temporal scales, ranging from seconds to millennia, as in the case of fossil fuel formation from build-up of detritus over millennia (Moore et al. 2004).\n\nMany food webs rely on cross-boundary subsidies of detritus for sources of energy and nutrients (Huxel and McCann 1998). For example, a series of lakes in Wisconsin were examined for the presence of Coarse woody debris (CWD) and the characteristics of the surrounding landscape that might control its input to lakes. Coarse woody debris in these lakes is important for providing habitat and food resources for a variety of organisms including small fish (Werner and Hall 1988), algae, and detritivores (Bowen et al. 1998). Marburg et al. (2006) compared variation within and among lakes in CWD. They found that subsidies of CWD to lakes were lower when the lakes had human development along the shore. Development along the lakeshore can be thought of as an alteration to the characteristics of the patch boundary between the lake and forest. In this case, development decreased both forest density that is the source of CWD and also the permeability of the boundary to flows of CWD (Marburg et al. 2006).\n\nIn addition to bottom-up effects, top-down effects may also occur due to cross-boundary subsidies. In top-down effects, subsidies of consumers at the top level of the food web control populations at lower levels more so than would be expected by only the action of resident consumers (Polis et al. 1997). Consumers that cross boundaries may have a greater effect on the recipient patch population if prey in the recipient patch have a lower population growth rate than prey in the source patch (Fagan et al. 1999, Rand et al. 2006). Thus, cross-boundary subsidies may alter predator-prey/competitive interactions that can result in a disproportionate impact on the communities of the recipient patch.\n\nIn subsidizing top trophic levels, effects may also be felt at all lower trophic levels in a phenomenon known as a trophic cascade. An example of a trophic cascade that also acted as a cross-boundary subsidy is illustrated in a study by Knight et al. (2005) in which changes in the trophic structure of one ecosystem resulted in an effect that cascaded to the adjacent ecosystem. In ponds containing fish, dragonfly larvae were kept to a minimum by fish predation. The resulting low density of adult dragonfly predators led to a high density of bee pollinators. With fish present in adjacent ponds, bees were able to pollinate more flowers in the adjacent upland ecosystem than they were when fish were absent. The dragonfly population could be thought of as subsidized by the absence of fish predation. That subsidy was then transferred across the pond-upland boundary by adult dragonfly movement to affect the interaction between bee pollinators and plants.\n\nAs landscapes become increasingly fragmented due to human activity, the influence of patch boundaries on individual patches becomes relatively more important (Murcia 1995). fragmentation can both cut off necessary subsidies to patches and increase the magnitude of subsidies from adjacent patches. For example, in a study of fragmentation of wildlands in an agriculturally dominated landscape, subsidies of habitat specialist insects to wildland patches were prevented by surrounding small, wildland patches with inhospitable agricultural land. This isolation reduced the potential for gene flow and long-term persistence of the population. Subsidies of other insects that specialized on agricultural crops were increased to wildland populations, increasing their effect on the resident wildland species (Duelli 1990).\n\nChanging the internal structure and composition of a patch may substantially alter cross-boundary subsidies. Logging may temporarily increase subsidies of nutrients and detritus to adjacent streams (Likens et al. 1970). Invasive species introduced to agricultural patches may act as a subsidy to adjacent wildland invasive populations, preventing native species establishment, even within the protected area (Janzen 1983).\n\nHuman alterations of patch characteristics may also curtail cross-boundary subsidies such as overfishing in marine systems, which may drastically reduce potentially crucial marine subsidies of organisms to freshwater and riparian systems (Zhang et al. 2003). For example, Helfield and Naiman (2002) found that riparian trees in Alaska obtain 24-26% of their nitrogen from marine sources, transferred from migrating salmon. In this system, salmon that feed in the ocean, incorporating marine nitrogen into their biomass, later return to their natal small streams where they spawn and die. Salmon carcasses transferred across the stream-riparian zone boundary by terrestrial predators or flooding events subsidized growth of terrestrial plants. Thus, marine overfishing may affect the productivity of Alaskan forests that depend on subsidies of marine-derived nitrogen.\n\nAs discussed above, cross-boundary subsidies depend on the characteristics of the patch boundary. Human-induced changes in these characteristics can affect boundary permeability to certain organisms or materials. For example, a cross-boundary subsidy of leaf litter from forest to an adjacent open field may be attenuated at the boundary if a road is present, making the boundary less permeable to flows of leaf litter (Facelli and Pickett 1991).\n\nHabitat management might benefit from recognizing the effect that humans may have on both individual patches and on the dynamics between patches. In such cases, managers may need to focus on patterns and processes that occur outside of their patch of interest, as these factors may also be important to internal population dynamics. An understanding of boundary features that influence the various flows of interest is necessary in managing for those flows.\n\nThe implications of invasive species and the use of biological control agents may also be closely related to the idea of cross-boundary subsidies. Introducing species into one patch for biocontrol may have unforeseen consequences on dynamics within adjacent patches.\n\nOther fields, such as public policy, can also benefit from considering cross-boundary subsidies. For example, governments often provide financial subsidies to fisheries, which have a negative effect on those ecosystems by encouraging overfishing (Munro and Sumaila 2002). Understanding what processes affect how those financial resources flow across that particular government-industry boundary is important to the maintenance of marine food webs. Considering cross-boundary effects will be essential to a complete understanding of potential consequences of human action on the landscape.\n\n", "id": "10625535", "title": "Cross-boundary subsidy"}
{"url": "https://en.wikipedia.org/wiki?curid=23737622", "text": "Alternative stable state\n\nIn ecology, the theory of alternative stable states (sometimes termed alternate stable states or alternative stable equilibria) predicts that ecosystems can exist under multiple \"states\" (sets of unique biotic and abiotic conditions). These alternative states are non-transitory and therefore considered stable over ecologically-relevant timescales. Ecosystems may transition from one stable state to another, in what is known as a state shift (sometimes termed a phase shift or regime shift), when perturbed. Due to ecological feedbacks, ecosystems display resistance to state shifts and therefore tend to remain in one state unless perturbations are large enough. Multiple states may persist under equal environmental conditions, a phenomenon known as hysteresis. Alternative stable state theory suggests that discrete states are separated by ecological thresholds, in contrast to ecosystems which change smoothly and continuously along an environmental gradient.\n\nAlternative stable state theory was first proposed by Richard Lewontin (1969), but other early key authors include Holling (1973), Sutherland (1974), May (1977), and Scheffer et al. (2001). In the broadest sense, alternative stable state theory proposes that a change in ecosystem conditions can result in an abrupt shift in the state of the ecosystem, such as a change in population (Barange, M. et al. 2008) or community composition. Ecosystems can persist in states that are considered stable (i.e., can exist for relatively long periods of time). Intermediate states are considered unstable and are, therefore, transitory. Because ecosystems are resistant to state shifts, significant perturbations are usually required to overcome ecological thresholds and cause shifts from one stable state to another. The resistance to state shifts is known as \"resilience\" (Holling 1973).\n\nState shifts are often illustrated heuristically by the ball-in-cup model (Holling, C.S. et al., 1995) Biodiversity in the functioning of ecosystems: an ecological synthesis. In Biodiversity Loss, Ecological and Economical Issues (Perrings, C.A. et al., eds), pp. 44–83, Cambridge University Press). A ball, representing the ecosystem, exists on a surface where any point along the surface represents a possible state. In the simplest model, the landscape consists of two valleys separated by a hill. When the ball is in a valley, or a \"domain of attraction\", it exists in a stable state and must be perturbed to move from this state. In the absence of perturbations, the ball will always roll downhill and therefore will tend to stay in the valley (or stable state). State shifts can be viewed from two different viewpoints, the \"community perspective\" and the \"ecosystem perspective\". The ball can only move between stable states in two ways: (1) moving the ball or (2) altering the landscape. The community perspective is analogous to moving the ball, while the ecosystem perspective is analogous to altering the landscape.\n\nThese two viewpoints consider the same phenomenon with different mechanisms. The community perspective considers ecosystem variables (which change relatively quickly and are subject to feedbacks from the system), whereas the ecosystem perspective considers ecosystem parameters (which change relatively slowly and operate independent of the system). The community context considers a relatively constant environment in which multiple stable states are accessible to populations or communities. This definition is an extension of stability analysis of populations (e.g., Lewontin 1969; Sutherland 1973) and communities (e.g., Drake 1991; Law and Morton 1993). The ecosystem context focuses on the effect of exogenic \"drivers\" on communities or ecosystems (e.g., May 1977; Scheffer et al. 2001; Dent et al. 2002). Both definitions are explored within this article.\n\nEcosystems can shift from one state to another via a significant perturbation directly to state variables. State variables are quantities that change quickly (in ecologically-relevant time scales) in response to feedbacks from the system (i.e., they are dependent on system feedbacks), such as population densities. This perspective requires that different states can exist simultaneously under equal environmental conditions, since the ball moves only in response to a state variable change.\n\nFor example, consider a very simple system with three microbial species. It may be possible for the system to exist under different community structure regimes depending on initial conditions (e.g., population densities or spatial arrangement of individuals) (Kerr et al. 2002). Perhaps under certain initial densities or spatial configurations, one species dominates over all others, while under different initial conditions all species can mutually coexist. Because the different species interact, changes in populations affect one another synergistically to determine community structure. Under both states the environmental conditions are identical. Because the states have resilience, following small perturbations (e.g., changes to population size) the community returns to the same configuration while large perturbations may induce a shift to another configuration.\n\nThe community perspective requires the existence of alternative stable states (i.e., more than one valley) before the perturbation, since the landscape is not changing. Because communities have some level of resistance to change, they will stay in their domain of attraction (or stable state) until the perturbation is large enough to force the system into another state. In the ball-and-cup model, this would be the energy required to push the ball up and over a hill, where it would fall downhill into a different valley.\n\nIt is also possible to cause state shifts in another context, by indirectly affecting state variables. This is known as the ecosystem perspective. This perspective requires a change in environmental parameters that affect the behavior of state variables. For example, birth rate, death rate, migration, and density-dependent predation indirectly alter the ecosystem state by changing population density (a state variable). Ecosystem parameters are quantities that are unresponsive (or respond very slowly) to feedbacks from the system (i.e., they are independent of system feedbacks). The stable state landscape is changed by environmental drivers, which may result in a change in the quantity of stable states and the relationship between states.\n\nBy the ecosystem perspective, the landscape of the ecological states is changed, which forces a change in the ecosystem state. Changing the landscape can modify the number, location, and resilience of stable states, as well as the unstable intermediate states. By this view, the topography in the ball-and-cup model is not static, as it is in the community perspective. This is a fundamental difference between the two perspectives.\n\nAlthough the mechanisms of community and ecosystem perspectives are different, the empirical evidence required for documentation of alternative stable states is the same. In addition, state shifts are often a combination of internal processes and external forces (Scheffer et al. 2001). For example, consider a stream-fed lake in which the pristine state is dominated by benthic vegetation. When upstream construction releases soils into the stream, the system becomes turbid. As a result, benthic vegetation cannot receive light and decline, increasing nutrient availability and allowing phytoplankton to dominate. In this state shift scenario the state variables changing are the populations of benthic vegetation and phytoplankton, and the ecosystem parameters are turbidity and nutrient levels. So, whether identifying mechanisms of variables or parameters is a matter of formulation (Beisner et al. 2003).\n\nHysteresis is an important concept in alternative stable state theory. In this ecological context, hysteresis refers to the existence of different stable states under the same variables or parameters. Hysteresis can be explained by \"path-dependency\", in which the equilibrium point for the trajectory of \"A → B\" is different from for \"B → A\". In other words, it matters which way the ball is moving across the landscape. Some ecologists (e.g., Scheffer et al. 2001) argue that hysteresis is a prerequisite for the existence of alternative stable states. Others (e.g., Beisner et al. 2003) claim that this is not so; although shifts often involve hysteresis, a system can show alternative stable states yet have equal paths for \"A → B\" and \"B → A\".\n\nHysteresis can occur via changes to variables or parameters. When variables are changed the ball is pushed from one domain of attraction to another, yet the same push from the other direction cannot return the ball to the original domain of attraction. When parameters are changed a modification to the landscape results in a state shift, but reversing the modification does not result in a reciprocal shift.\n\nA real-world example of hysteresis is helpful to illustrate the concept. Coral reef systems can dramatically shift from pristine coral-dominated systems to degraded algae-dominated systems when populations grazing on algae decline. The 1983 crash of sea urchin populations in Caribbean reef systems released algae from top-down (herbivory) control, allowing them to overgrow corals and resulting in a shift to a degraded state. When urchins rebounded, the high (pre-crash) coral cover levels did not return, indicating hysteresis (Mumby et al. 2007).\n\nIn some cases, state shifts under hysteresis may be irreversible. For example, tropical cloud forests require high moisture levels, provided by clouds that are intercepted by the canopy (via condensation). When deforested, moisture delivery ceases. Therefore, reforestation is often unsuccessful because conditions are too dry to allow the trees to grow (Wilson and Agnew 1992). Even in cases where there is no obvious barrier to recovery, alternative states can be remarkably persistent: an experimental grassland heavily fertilized for 10 years lost much of its biodiversity, and was still in this state 20 years later.\n\nBy their very nature, basins of attraction display resilience. Ecosystems are resistant to state shifts – they will only undergo shifts under substantial perturbations – but some states are more resilient than others. In the ball-and-cup model, a valley with steep sides has greater resilience than a shallow valley, since it would take more force to push the ball up the hill and out of the valley.\n\nResilience can change in stable states when environmental parameters are shifted. Often, humans influence stable states by reducing the resilience of basins of attraction. There are at least three ways in which anthropogenic forces reduce resilience (Folke et al. 2004): (1) Decreasing diversity and functional groups, often by top-down effects (e.g., overfishing); (2) altering the physico-chemical environment (e.g., climate change, pollution, fertilization); or (3) modifying disturbance regimes to which organisms are adapted (e.g., bottom trawling, coral mining, etc.). When the resilience is decreased, ecosystems can be pushed into alternative, and often less-desirable, stable states with only minor perturbations. When hysteresis effects are present, the return to a more-desirable state is sometimes impossible or impractical (given management constraints). Shifts to less-desirable states often entail a loss of ecosystem service and function, and have been documented in an array of terrestrial, marine, and freshwater environments (reviewed in Folke et al. 2004).\n\nMost work on alternative stable states has been theoretical, using mathematical models and simulations to test ecological hypotheses. Other work has been conducted using empirical evidence from surveying, historical records, or comparisons across spatial scales. There has been a lack of direct, manipulative experimental tests for alternative stable states. This is especially true for studies outside of controlled laboratory conditions, where state shifts have been documented for cultures of microorganisms.\n\nVerifying the existence of alternative stable states carries profound implications for ecosystem management. If stable states exist, gradual changes in environmental factors may have little effect on a system until a threshold is reached, at which point a catastrophic state shift may occur. Understanding the nature of these thresholds will help inform the design of monitoring programs, ecosystem restoration, and other management decisions. Managers are particularly interested in the potential of hysteresis, since it may be difficult to recover from a state shift (Beisner et al. 2003). The mechanisms of feedback loops that maintain stable states are important to understand if we hope to effectively manage an ecosystem with alternative stable states.\n\nEmpirical evidence for the existence of alternative stable states is vital to advancing the idea beyond theory. Schröder et al. (2005) reviewed the current ecological literature for alternative stable states and found 35 direct experiments, of which only 21 were deemed valid. Of these, 62% (14) showed evidence for and 38% (8) showed no evidence for alternative stable states. However, the Schröder et al. (2005) analysis required evidence of hysteresis, which is not necessarily a prerequisite for alternative stable states. Other authors (e.g., Scheffer et al. 2001; Folke et al. 2004) have had less-stringent requirements for the documentation of alternative stable states.\n\nState shifts via the community perspective have been induced experimentally by the addition or removal of predators, such as in Paine's (1966) work on keystone predators (i.e., predators with disproportionate influence on community structure) in the intertidal zone (although this claim is refuted by Schröder et al. 2005). Also, Beisner et al. (2003) suggest that commercially exploited fish populations can be forced between alternative stable states by fishing pressure due to Allee effect that work at very low population sizes. Once a fish population falls below a certain threshold, it will inevitably go extinct when low population densities make replacement of adults impossible due to, for example, the inability to find mates or density-dependent mortality. Since populations cannot return from extinction, this is an example of an irreversible state shift.\n\nAlthough alternative stable state theory is still in its infancy, empirical evidence has been collected from a variety of biomes:\n\n\n", "id": "23737622", "title": "Alternative stable state"}
{"url": "https://en.wikipedia.org/wiki?curid=23589578", "text": "Assimilative capacity\n\nAssimilative capacity refers to the ability of a body of water to cleanse itself; its capacity to \nreceive waste waters or toxic substances without deleterious effects and without damage to aquatic life or humans who consume the water. \nIt is level to which water body or nature control the toxicity without affecting the aquatic life.\n\nAssimilative capacity is a quantitatively useful concept codified in the Clean Water Act and other laws and regulations that is unrelated to the perception of an environmental crisis. Assimilative capacity specifically refers to the capacity for a water body to absorb constituents without exceeding a specific concentration, such as a water quality objective. Water quality objectives are set and periodically revised by regulatory agencies, such as the EPA, to define the limits of water quality for different uses, which include human health, but also other ecologically important functions, wildlife habitat, irrigated agriculture, etc. For example, if the irrigation water quality objective for salt is 450 mg/L of total dissolved solids, the assimilative capacity of a water body would be the amount of salt that could be added to the water such that it's concentration would not exceed 450 mg/L.\n", "id": "23589578", "title": "Assimilative capacity"}
{"url": "https://en.wikipedia.org/wiki?curid=24956896", "text": "AquaMaps\n\nAquaMaps is a collaborative project with the aim of producing computer-generated (and ultimately, expert reviewed) predicted global distribution maps for marine species on a 0.5 x 0.5 degree grid of the oceans based on data available through online species databases such as FishBase and SeaLifeBase and species occurrence records from OBIS or GBIF and using an environmental envelope model (see niche modelling) in conjunction with expert input. The underlying model represents a modified version of the relative environmental suitability (RES) model developed by Kristin Kaschner to generate global predictions of marine mammal occurrences.\n\nAccording to the AquaMaps website on August 2013, the project held standardized distribution maps for over 17,300 species of fishes, marine mammals and invertebrates.\nThe project is also expanding to incorporate freshwater species, with more than 600 biodiversity maps for freshwater fishes of the Americas available as at November 2009. AquaMaps predictions have been validated successfully for a number of species using independent data sets and the model was shown to perform equally well or better than other standard species distribution models, when faced with the currently existing suboptimal input data sets.\n\nIn addition to displaying individual maps per species, AquaMaps provides tools to generate species richness maps by higher taxon, plus a spatial search for all species overlapping a specified grid square. There is also the facility to create custom maps for any species via the web by modifying the input parameters and re-running the map generating algorithm in real time, and a variety of other tools including the investigation of effects of climate change on species distributions (see relevant section of the AquaMaps search page).\n\nThe project is coordinated by Dr Rainer Froese of IFM-GEOMAR and involves contributions from other research institutes including the Evolutionary Biology and Ecology Lab, Albert-Ludwigs-University Freiburg, University of British Columbia (UBC), the Swedish Museum of Natural History (NRM - Naturhistoriska Riksmuseet), the WorldFish Center in Malaysia, and CSIRO Marine and Atmospheric Research in Australia. The creation of AquaMaps is supported by MARA, Pew Fellows Program in Marine Conservation, INCOFISH, Sea Around Us Project, Biogeoinformatics of Hexacorals, FishBase and SeaLifeBase.\n\n\n", "id": "24956896", "title": "AquaMaps"}
{"url": "https://en.wikipedia.org/wiki?curid=6420688", "text": "Phage ecology\n\nBacteriophages (phages), potentially the most numerous \"organisms\" on Earth, are the viruses of bacteria (more generally, of prokaryotes). Phage ecology is the study of the interaction of bacteriophages with their environments.\n\nPhages are obligate intracellular parasites meaning that they are able to reproduce only while infecting bacteria. Phages therefore are found only within environments that contain bacteria. Most environments contain bacteria, including our own bodies (called normal flora). Often these bacteria are found in large numbers. As a consequence, phages are found almost everywhere.\n\nAs a rule of thumb, many phage biologists expect that phage population densities will exceed bacterial densities by a ratio of 10-to-1 or more (VBR or virus-to-bacterium ratio; see for a summary of actual data). As there exist estimates of bacterial numbers on Earth of approximately 10, there consequently is an expectation that 10 or more individual virus (mostly phage) particles exist , making phages the most numerous category of \"organisms\" on our planet.\n\nBacteria (along with archaea) appear to be highly diverse and there possibly are millions of species. Phage-ecological interactions therefore are quantitatively vast: huge numbers of interactions. Phage-ecological interactions are also qualitatively diverse: There are huge numbers of environment types, bacterial-host types, and also individual phage types\n\nThe study of phage ecology reflects established scientific disciplines in ecological studies in scope, the most obvious being general ecology. Accordingly, phage ecology is treated under the following heads \"organismal\" ecology, population ecology, community ecology, and ecosystem ecology. Phage ecology also may be considered (though mostly less well formally explored) from perspectives of phage behavioral ecology, evolutionary ecology, functional ecology, landscape ecology, mathematical ecology, molecular ecology, physiological ecology (or ecophysiology), and spatial ecology. Phage ecology additionally draws (extensively) from microbiology, particularly in terms of environmental microbiology, but also from an enormous catalog (90 years) of study of phage and phage-bacterial interactions in terms of their physiology and, especially, their molecular biology.\n\nPhage \"organismal\" ecology is primarily the study of the evolutionary ecological impact of phage growth parameters:\n\n\nAnother way of envisioning phage \"organismal\" ecology is that it is the study of phage adaptations that contribute to phage survival and transmission to new hosts or environments. Phage \"organismal\" ecology is the most closely aligned of phage ecology disciplines with the classical molecular and molecular genetic analyses of bacteriophage.\n\nFrom the perspective of ecological subdisciplines, we can also consider phage behavioral ecology, functional ecology, and physiological ecology under the heading of phage \"organismal\" ecology. However, as noted, these subdisciplines are not as well developed as more general considerations of phage \"organismal\" ecology. Phage growth parameters often evolve over the course of phage experimental adaptation studies.\n\nIn the mid 1910s, when phage were first discovered, the concept of phage was very much a whole-culture phenomenon (like much of microbiology), where various types of bacterial cultures (on solid media, in broth) were visibly cleared by phage action. Though from the start there was some sense, especially by Fėlix d'Hėrelle, that phage consisted of individual \"organisms\", in fact it wasn't until the late 1930s through the 1940s that phage were studied, with rigor, as individuals, e.g., by electron microscopy and single-step growth experiments. Note, though, that for practical reasons much of \"organismal\" phage study is of their properties in bulk culture (many phage) rather than the properties of individual phage virions or individual infections.\n\nThis somewhat whole-organismal view of phage biology saw its heyday during the 1940s and 1950s, before giving way to much more biochemical, molecular genetic, and molecular biological analyses of phage, as seen during the 1960s and onward. This shift, paralleled in much of the rest of microbiology , represented a retreat from a much more ecological view of phages (first as bacterial killers, and then as organisms unto themselves). However, the organismal view of phage biology lives on as a foundation of phage ecological understanding. Indeed, it represents a key thread that ties together the ecological thinking on phage ecology with the more \"modern\" considerations of phage as molecular model systems.\n\nThe basic experimental toolkit of phage \"organismal\" ecology consists of the single-step growth (or one-step growth;) experiment and the phage adsorption curve. Single-step growth is a means of determining the phage latent period (example), which is approximately equivalent (depending on how it is defined) to the phage period of infection. Single-step growth experiments also are employed to determine a phage's burst size, which is the number of phage (on average) that are produced per phage-infected bacterium.\n\nThe adsorption curve is obtained by measuring the rate at which phage virion particles (see Virion#Structure) attach to bacteria. This is usually done by separating free phage from phage-infected bacteria in some manner so that either the loss of not currently infecting (free) phage or the gain of infected bacteria may be measured over time.\n\nA population is a group of individuals which either do or can interbreed or, if incapable of interbreeding, then are recently derived from a single individual (a clonal population). Population ecology considers characteristics that are apparent in populations of individuals but either are not apparent or are much less apparent among individuals. These characteristics include so-called intraspecific interactions, that is between individuals making up the same population, and can include competition as well as cooperation. Competition can be either in terms of rates of population growth (as seen especially at lower population densities in resource-rich environments) or in terms of retention of population sizes (seen especially at higher population densities where individuals are directly competing over limited resources). Respectively, these are population-density independent and dependent effects.\n\nPhage population ecology considers issues of rates of phage population growth, but also phage-phage interactions as can occur when two or more phage adsorb an individual bacterium.\n\nA community consists of all of the biological individuals found within a given environment (more formally, within an ecosystem), particularly when more than one species is present. Community ecology studies those characteristics of communities that either are not apparent or which are much less apparent if a community consists of only a single population. Community ecology thus deals with interspecific interactions. Interspecific interactions, like intraspecific interactions, can range from cooperative to competitive but also to quite antagonistic (as are seen, for example, with predator-prey interactions). An important consequence of these interactions is coevolution.\n\nThe interaction of phage with bacteria is the primary concern of phage community ecologists. Bacteria have developed mechanisms that prevent phage from having an effect on them, which has led to this evolutionary arms race between the phage and their host bacteria. Bacterial resistance to phage puts pressure on the phage to develop stronger effects on the bacteria. The Red Queen hypothesis describes this relationship, as the organisms must constantly adapt and evolve in order to survive. This relationship is important to understand as phage are now being used for more practical and medicinal purposes.\n\nBacteria have developed multiple defense mechanisms to fight off the effects of bacteriophage. In experimentation, amount of resistance can be determined by how much of a plate (generally agar with bacteria, infected with phage) ends up being clear. The clearer, the less resistant as more bacteria have been lysed. The most common of these defense mechanisms is called the restriction-modification system (RM system). In this system, foreign DNA trying to enter the bacterial host is restricted by endonucleases that recognize specific base pairs within the DNA, while the DNA of the cell is protected from restriction due to methylase. RM systems have evolved to keep up with the ever-changing bacteria and phage. In general, these RM types differ in the nucleotide sequences that they recognize. However, there is an occasional slip where the endonuclease misses the DNA sequence of the phage and the phage DNA is able to enter the cell anyway, becoming methylated and protected against the endonuclease. This accident is what can spur the evolution of the RM system. Phage can acquire or use the enzyme from the host cell to protect their own DNA, or sometimes they will have proteins that dismantle the enzyme that is meant to restrict the phage DNA. Another option is for the phage to insert different base pairs into its DNA, thereby confusing the enzyme.\n\nAnother mechanism employed by bacteria is referred to as CRISPR. This stands for “clustered regularly interspersed palindromic repeats” which means that the immunity to phages by bacteria has been acquired via adding spacers of DNA that are identical to that of the DNA from the phage. Some phage have been found to be immune to this mechanism as well. In some way or another, the phage have managed to get rid of the sequence that would be replicated.\n\nA third way that bacteria have managed to escape the effects of bacteriophage is by abortive infection. This is a last resort option- when the host cell has already been infected by the phage. This method is not ideal for the host cell, as it still leads to its death. The redeeming feature of this mechanism is the fact that it interferes with the phage processes and prevents it from then moving on to infect other cells.\n\nPhage are also capable of interacting with species other than bacteria, e.g., such as phage-encoded exotoxin interaction with animals. Phage therapy is an example of applied phage community ecology.\n\nAn ecosystem consists of both the biotic and abiotic components of an environment. Abiotic entities are not alive and so an ecosystem essentially is a community combined with the non-living environment within which that ecosystem exists. Ecosystem ecology naturally differs from community ecology in terms of the impact of the community on these abiotic entities, and \"vice versa\". In practice, the portion of the abiotic environment of most concern to ecosystem ecologists is inorganic nutrients and energy.\n\nPhage impact the movement of nutrients and energy within ecosystems primarily by lysing bacteria. Phage can also impact abiotic factors via the encoding of exotoxins (a subset of which are capable of solubilizing the biological tissues of living animals). Phage ecosystem ecologists are primarily concerned with the phage impact on the global carbon cycle, especially within the context of a phenomenon known as the microbial loop.\n\n", "id": "6420688", "title": "Phage ecology"}
{"url": "https://en.wikipedia.org/wiki?curid=25112011", "text": "Species homogeneity\n\nIn ecology, species homogeneity is a lack of biodiversity. Species richness is the fundamental unit in which to assess the homogeneity of an environment. Therefore, any reduction in species richness, especially endemic species, could be argued as advocating the production of a homogenous environment.\n\nHomogeneity in agriculture and forestry; in particular, industrial agriculture and forestry use a limited number of species. About 7,000 plants (2.6% of all plant species) have been collected or cultivated for human consumption. Of these, a mere 200 have been domesticated and only a dozen contribute about 75% of the global intake of plant-derived calories.\n\n95% of world consumption of protein derives from a few domesticated species, i.e. poultry, cattle and pigs. There are about 1,000 commercial fish species, but in aquaculture fewer than 10 species dominate global production. Human food production therefore rests on the tips of pyramids of biodiversity, leaving the majority of species not utilised and not domesticated.\n\nSpecies naturally migrate and expand their ranges, utilising new habitats and resources, e.g. the cattle egret. These natural invasions, an incursion in the absence of anthropogenic influences, occur \"when an intervening barrier is removed, or through the development of biotic or abiotic transportation mechanisms, able to overcome the barrier in question\". Introductions, or human-mediated invasions, have in the last century become more frequent. It is estimated that on an average day more than 3,000 species alone are in transit aboard ocean-going vessels.\n\n", "id": "25112011", "title": "Species homogeneity"}
{"url": "https://en.wikipedia.org/wiki?curid=3269260", "text": "Functional ecology\n\nFunctional ecology is a branch of ecology that focuses on the roles, or functions, that species play in the community or ecosystem in which they occur. In this approach, physiological, anatomical, and life history characteristics of the species are emphasized. The term \"function\" is used to emphasize certain physiological processes rather than discrete properties, describe an organisms role in a trophic system, or illustrate the effects of natural selective processes on an organism. This sub-discipline of ecology represents the crossroads between ecological patterns and the processes and mechanisms that underlie them. It focuses on traits represented in large number of species and can be measured in two ways. The first being screening, which involves measuring a trait across a number of species, and the second being empiricism, which provides quantitative relationships for the traits measured in screening. Functional ecology often emphasizes an integrative approach, using organismal traits and activities to understand community dynamics and ecosystem processes, particularly in response to the rapid global changes occurring in earth’s environment.\n\nFunctional ecology sits at the nexus of several disparate disciplines and serves as the unifying principle between evolutionary ecology, evolutionary biology, genetics and genomics, and traditional ecological studies.\n\nThe scientific journal \"Functional Ecology\" is published by the British Ecological Society since 1987.\n\n", "id": "3269260", "title": "Functional ecology"}
{"url": "https://en.wikipedia.org/wiki?curid=1254336", "text": "Applied ecology\n\nApplied ecology is a subfield within ecology, which considers the application of the science of ecology to real-world (usually management) questions. It is an integrated treatment of the ecological, social, and biotechnological aspects of natural resource conservation and management. It is also called ecological or environmental technology. Applied ecology typically focuses on geomorphology, soils, and plant communities as the underpinnings for vegetation and wildlife (both game and non-game) management.\n\nAspects of applied ecology include:\n\n\nMajor journals in the field include:\n\n\nRelated organizations include:\n\n\nww.ser.org\n\nwww.esa.org\n\nSkelly, David K, Friedenburg,L.Kealoha, Applied Ecology,DOI: 10.1093/OBO/9780199830060-0039\n\nLubchenco,Jane,Entering the Century of the Environment: A New Social Contract for Science,Science 23 Jan 1998:\nVol. 279, Issue 5350, pp. 491–497\nDOI: 10.1126/science.279.5350.491\n\nVol. 16, No. 8 (Aug., 1966), pp. 524–527\n\nHobbs,Richard J, Hallett,Lauren M, Ehrlich, Paul R, and Mooney,Harold A,Intervention Ecology: Applying\nEcological Science in the Twenty-first Century,BioScience (2011) 61 (6): 442-450.\ndoi: 10.1525/bio.2011.61.6.6\n", "id": "1254336", "title": "Applied ecology"}
{"url": "https://en.wikipedia.org/wiki?curid=3219945", "text": "Metabolic rift\n\nMetabolic rift is Karl Marx's notion of the \"irreparable rift in the interdependent process of social metabolism,\"—Marx's key conception of ecological crisis tendencies under capitalism. Marx theorized a rupture in the metabolic interaction between humanity and the rest of nature emanating from capitalist production and the growing division between town and country.\n\nMetabolic rift, according to John Bellamy Foster who coined the term, is the development of Marx's earlier work in the \"Economic and Philosophical Manuscripts\" on species-being and the relationship between humans and nature. Metabolism is Marx's \"mature analysis of the alienation of nature,\" and presents \"a more solid—and scientific—way in which to depict the complex, dynamic interchange between human beings and nature, resulting from human labor.\"\n\nAs opposed to those who have attributed to Marx a disregard for nature and responsibility for the environmental problems of the Soviet Union and other purportedly communist states, Foster sees in the theory of metabolic rift evidence of Marx's ecological perspective. The theory of metabolic rift \"enable[ed] [Marx] to develop a critique of environmental degradation that anticipated much of present-day ecological thought,\" including questions of sustainability.\n\nMarx's writings on metabolism were developed during England's \"second\" agricultural revolution (1815–1880), a period which was characterized by the development of soil chemistry and the growth of the use of chemical fertilizer. The depletion of soil fertility, or \"soil exhaustion,\" had become a key concern for capitalist society, and demand for fertilizer was such that Britain and other powers initiated explicit policies for the importation of bone and guano, including raiding of Napoleonic battlefields and catacombs, British monopolization of Peruvian guano supplies, and, in the United States, \"the imperial annexation of any islands thought to be rich in [guano]\" through the Guano Islands Act (1856).\n\nMarx's theory drew heavily on contemporary advances in agricultural chemistry unknown to earlier classical economists such as Ricardo and Malthus. For them, different levels of soil fertility (and thus rent) was attributed \"almost entirely to the natural or absolute productivity of the soil,\" with improvement (or degradation) playing only a minor role.\n\nGerman agricultural chemist Justus von Liebig, in his \"Organic Chemistry in Its Applications to Agriculture and Physiology\" (1840), presented the first convincing explanation of the role of soil nutrients in the growth of plants. In 1842, Liebig expanded the use of the term metabolism (\"Stoffwechsel\"), from referring to material exchanges in the body, up to the biochemical processes of natural systems.\n\nFoster argues that Liebig's work became more critical of capitalist agriculture as time went on. From the standpoint of nutrient cycling, the socio-economic relationship between rural and urban areas was self-evidently contradictory, hindering the possibility of sustainability:\nIf it were practicable to collect, with the least loss, all the solid and fluid excrements of the inhabitants of the town, and return to each farmer the portion arising from produce originally supplied by him to the town, the productiveness of the land might be maintained almost unimpaired for ages to come, and the existing store of mineral elements in every fertile field would be amply sufficient for the wants of increasing populations.\n\nMarx rooted his theory of social-ecological metabolism in Liebig's analysis but connected it to his understanding of the labor process. Marx understood that, throughout history, it was through labor that humans appropriated nature to satisfy their needs. Thus the metabolism, or interaction, of society with nature is \"a universal and perpetual condition.\"\n\nIn Capital, Marx integrated his materialist conception of nature with his materialist conception of history. Fertility, Marx argued, was not a natural quality of the soil, but was rather bound up with the social relations of the time. By conceptualizing the complex, interdependent processes of material exchange and regulatory actions that link human society with non-human nature as \"metabolic relations,\" Marx allowed these processes to be both \"nature-imposed conditions\" and subject to human agency, a dynamic largely missed, according to Foster, by the reduction of ecological questions to issues of value.\n\nThe central contribution of the metabolic rift perspective is to locate socio-ecological contradictions internal to the development of capitalism. Later socialists expanded upon Marx's ideas, including Nikolai Bukharin in \"Historical Materialism\" (1921) and Karl Kautsky in \"The Agrarian Question\" (1899), which developed questions of the exploitation of the countryside by the town and the \"fertilizer treadmill\" that resulted from metabolic rift.\n\nContemporary eco-socialist theorists aside from Foster have also explored these directions, including James O'Connor, who sees capitalist undervaluing of nature as leading to economic crisis, what he refers to as \nthe second contradiction of capitalism.\n\nScholars from a variety of disciplines have drawn on Marx's metabolic approach and the concept of metabolic rift in analyzing the relation of society to the rest of nature. With increasing amounts of carbon dioxide being released into the environment from capitalist production, the theory of a carbon rift has also immerged.\n\nThe metabolic rift is characterized in different ways by historical materialists. For Jason W. Moore, the distinction between social and natural systems is empirically false and theoretically arbitrary; following a different reading of Marx, Moore views metabolisms as relations of human and extra-human natures. In this view, capitalism's metabolic rift unfolds through the town-country division of labor, itself a \"bundle\" of relations between humans and the rest of nature. Moore sees it as constitutive of the endless accumulation of capital. Moore's perspective, although also rooted in historical materialism, produces a widely divergent view from that of Foster and others about what makes ecological crisis and how it relates to capital accumulation.\n\nNine months after Foster's groundbreaking article appeared, Moore argued that the origins of the metabolic rift were not found in the 19th century but in the rise of capitalism during the \"long\" 16th century. The metabolic rift was not a consequence of industrial agriculture but capitalist relations pivoting on the law of value. Moore consequently focuses attention on the grand movements of primitive accumulation, colonialism, and the globalization of town-country relations that characterized early modern capitalism. There were, in this view, not one but many metabolic rifts; every great phase of capitalist development organized nature in new ways, each one with its own metabolic rift. In place of agricultural revolutions, Moore emphasizes recurrent agro-ecological revolutions, assigned the historical task of providing cheap food and cheap labor, in the history of capitalism, an interpretation that extends the analysis to the food crises of the early 21st century.\n\nUp until the 16th or 17th centuries, cities' metabolic dependency upon surrounding countryside (for resources, etc.), coupled with the technological limitations to production and extraction, prevented extensive urbanization. Early urban centers were bioregionally defined, and had relatively light \"footprints,\" recycling city nightsoils back into the surrounding areas.\n\nHowever, with the rise of capitalism, cities expanded in size and population. Large-scale industry required factories, raw material, workers, and large amounts of food. As urban economic security was dependent upon its metabolic support system, cities now looked further afield for their resource and waste flows. As spatial barriers were broken down, capitalist society \"violated\" what were previously \"nature-imposed conditions of sustainability.\"\n\nWith trade and expansion, food and fiber were shipped longer distances. The nutrients of the soil were sent to cities in the form of agricultural produce, but these same nutrients, in the form of human and animal waste, were not returned to the land. Thus there was a one-way movement, a \"robbing of the soil\" in order to maintain the socio-economic reproduction of society.\n\nMarx thus linked the crisis of pollution in cities with the crisis of soil depletion. The rift was a result of the antagonistic separation of town and country, and the social-ecological relations of production created by capitalism were ultimately unsustainable. From \"Capital\", volume 1, on \"Large-scale Industry and Agriculture\":\nCapitalist production collects the population together in great centres, and causes the urban population to achieve an ever-growing preponderance. This has two results. On the one hand it concentrates the historical motive force of society; on the other hand, \"it disturbs the metabolic interaction between man and the earth, i.e. it prevents the return to the soil of its constituent elements consumed by man in the form of food and clothing; hence it hinders the operation of the eternal natural condition for the lasting fertility of the soil\"...But by destroying the circumstances surrounding that metabolism...it compels its systematic restoration as a regulative law of social production, and in a form adequate to the full development of the human race...All progress in capitalist agriculture is a progress in the art, not only of robbing the worker, but of robbing the soil; all progress in increasing the fertility of the soil for a given time is a progress toward ruining the more long-lasting sources of that fertility...\"Capitalist production, therefore, only develops the techniques and the degree of combination of the social process of production by simultaneously undermining the original sources of all wealth—the soil and the worker\".\n\nThe concept of metabolic rift captures \"the material estrangement of human beings within capitalist society from the natural conditions which formed the basis for their existence.\" However, Marx also emphasizes the importance of historical change. It was both necessary and possible to rationally govern human metabolism with nature, but this was something \"completely beyond the capabilities of bourgeois society.\" In a future society of freely associated producers, however, humans could govern their relations with nature via collective control, rather than through the blind power of market relations. In \"Capital\", volume 3, Marx states:\nFreedom, in this sphere...can consist only in this, that socialized man, the associated producers, govern the human metabolism with nature in a rational way, bringing it under their own collective control rather than being dominated by it as a blind power; accomplishing it with the least expenditure of energy and in conditions most worthy and appropriate for their human nature.\nBut Marx did not argue that a sustainable relation to the earth was an automatic result of the transition to socialism. Rather, there was a need for planning and measures to address the division of labor and population between town and country and for the restoration and improvement of the soil.\n\nDespite Marx's assertion that a concept of ecological sustainability was \"of very limited practical relevance to capitalist society,\" as it was incapable of applying rational scientific methods and social planning due to the pressures of competition, the theory of metabolic rift may be seen as relevant to, if not explicitly invoked in, many contemporary debates and policy directions of environmental governance.\n\nThere is a rapidly growing body of literature on social-ecological metabolism. While originally limited to questions of soil fertility—essentially a critique of capitalist agriculture—the concept of metabolic rift has since been taken up in numerous fields and its scope expanded. For example, Clausen and Clark (2005) have extended the use of metabolic rift to marine ecology, while Moore (2000) uses the concept to discuss the broader concerns of global environmental crises and the viability of capitalism itself. Fischer-Kowalski (1998) discusses the application of \"the biological concept of metabolism to social systems,\" tracing it through several contributing scientific traditions, including biology, ecology, social theory, cultural anthropology, and social geography. A social metabolism approach has become \"one of the most important paradigms for the empirical analysis of the society-nature-interaction across various disciplines,\" particularly in the fields of industrial metabolism and material flow analysis.\n\nDavid Harvey points out that much of the environmental movement has held (and in some areas continues to hold) a profound anti-urban sentiment, seeing cities as \"the highpoint of plundering and pollution of all that is good and holy on planet earth.\" The problem is that such a perspective focuses solely on a particular form of nature, ignoring many people's lived experience of the environment and the importance of cities in ecological processes and as ecological sites in their own right.\n\nIn contrast, Erik Swyngedouw and other theorists have conceptualized the city as an ecological space through urban political ecology, which connects material flows within cities and between the urban and non-urban.\n\nIn city planning policy circles, there has been a recent movement toward urban sustainability. Hodson and Marvin discuss a \"new eco-urbanism\" that seeks to integrate environment and infrastructure, \"bundling\" architecture, ecology and technology in order to \"internalize\" energy, water, food, waste and other material flows. Unlike previous efforts to integrate nature into the city, which, according to Harvey, were primarily aesthetic and bourgeois in nature, these new efforts are taking place in the context of climate change, resource constraints and the threat of environmental crises.\n\nIn contrast to the traditional approach of capitalist urbanization, which sought more and more distant sources for material resources and waste sinks (as seen in the history of Los Angeles water), eco-urban sites would re-internalize their own resources and re-circulate wastes. The goal is autarky and greater ecological and infrastructural self-reliance through \"closed-loop systems\" that reduce reliance on external networks. Although difficult given the reliance on international supply chains, urban food movements are working to reduce the commodification of food and individual and social forms of alienation from food within cities. This takes place within actually existing conditions of neoliberalization, suggesting that healing metabolic rifts will be a process that requires both social and ecological transformations. \n\nHowever, critics link these efforts to \"managerial environmentalism,\" and worry that eco-urbanism too closely falls into an \"urban ecological security\" approach, echoing Mike Davis' analysis of securitization and fortress urbanism. A Marxist critique might also question the feasibility of sustainable cities within the context of a global capitalist system.\n\n\n", "id": "3219945", "title": "Metabolic rift"}
{"url": "https://en.wikipedia.org/wiki?curid=1628599", "text": "Ecology (disciplines)\n\nEcology is a broad biological science and can be divided into many sub-disciplines using various criteria. Many of these fields overlap, complement and inform each other, and few of these disciplines exist in isolation. For example, the population ecology of an organism is a consequence of its behavioral ecology and intimately tied to its community ecology. Methods from molecular ecology might inform the study of the population, and all kinds of data are modeled and analyzed using quantitative ecology techniques. \n\nWhen discussing the study of a single species, a distinction is usually made between its \"biology\" and its \"ecology\". For example, \"polar bear biology\" might include the study of the polar bear's physiology, morphology, pathology and ontogeny, whereas \"polar bear ecology\" would include a study of its prey species, its population and metapopulation status, distribution, dependence on environmental conditions, etc. In that sense, there can be as many subdisciplines of ecology as there are species to study. \n\nEcology can also be classified on the basis of:\n\n\nSpecialized branches of ecology include, among others:\n\n\nEcology also plays important roles in many inter-disciplinary fields:\n\n\nEcology has also inspired (and lent its name to) other non-biological disciplines such as\n\n\nFinally, ecology is used to describe several philosophies or ideologies, such as \n\n", "id": "1628599", "title": "Ecology (disciplines)"}
{"url": "https://en.wikipedia.org/wiki?curid=2168513", "text": "Vital rates\n\nVital rates refer to how fast vital statistics change in a population (usually measured per 1000 individuals). There are 2 categories within vital rates: crude rates and refined rates.\n\nCrude rates measure vital statistics in a general population (overall change in births and deaths per 1000).\n\nRefined rates measure the change in vital statistics in a specific demographic (such as age, sex, race, etc.).\n", "id": "2168513", "title": "Vital rates"}
{"url": "https://en.wikipedia.org/wiki?curid=6747934", "text": "Sand dune ecology\n\nSand dune ecology describes the biological and physico-chemical interactions that are a characteristic of sand dunes.\n\nSand dune systems are excellent places for biodiversity, partly because they are not very productive for agriculture, and partly because disturbed, stressful and stable habitats are present in proximity to each other. Many of them are protected as nature reserves, and some are parts of larger conservation areas, incorporating other coastal habitats like salt marches, mud flats, grasslands, scrub and woodland.\n\nSand dunes provide a range of habitats for a range of unusual, interesting and characteristic plants that can cope with disturbed habitats. In the UK these may include restharrow \"Ononis repens\", sand spurge \"Euphorbia arenaria\" and ragwort \"Senecio vulgaris\" - such plants are termed ruderals.\n\nOther very specialised plants are adapted to the accretion of sand, surviving the continual burial of their shoots by sending up very rapid vertical growth. Marram grass, \"Ammophila arenaria\" specialises in this, and is largely responsible for the formation and stabilisation of many dunes by binding sand grains together. The sand couch-grass \"Elytrigia juncea\" also performs this function on the seaward edge of the dunes, and is responsible, with some other pioneers like the sea rocket \"Cakile maritima\", for initiating the process of dune building by trapping wind blown sand.\n\nIn accreting situations small mounds of vegetation or tide-washed debris form and tend to enlarge as the wind-speed drops in the lee of the mound, allowing blowing sand (picked up from the off-shore banks) to fall out of the air stream. The pioneering plants are physiologically adapted to withstand the problems of high salt contents in the air and soil, and are good examples of stress tolerators, as well as having some ruderal characteristics.\n\nOn the inland side of dunes conditions are less severe, and links type grasslands develop with a range of grassland herbs which benefit from the reasonable nutrient status and moderately high pH of the more stable soils, especially when enough humus has accumulated in stabilised soils for water retention to be improved. Species like red fescue and lady's bedstraw are adapted to compete with each other - for nutrients, growing space and light, and are known as CSR plants - i.e. having features of Competitors, Stress tolerators and Ruderals in more or less equal proportions.\n\nThere may also be areas in old blow-outs where groundwater is near the surface, and often rises to cause flooding in the winter. Frequent, but intermittent waterlogging of the roots requires adaptations to stress, so the proportions of stress tolerators are increased here.\n\nIn nutrient-rich water, however there are some plants with very competitive strategies, like the reed (\"Phragmites australis\"). This is an example of a plant which makes rapid growth and suppresses other species by monopolising root and shoot space and shading out the opposition. Even its own seedlings are prevented from establishing within the existing population, but seeds are blown for long distances in copious quantities to start new colonies, whilst mature populations extend by rapid vegetative growth of lateral underground shoots - rhizomes.\n\n", "id": "6747934", "title": "Sand dune ecology"}
{"url": "https://en.wikipedia.org/wiki?curid=25754996", "text": "Invasive Species Forecasting System\n\nThe Invasive Species Forecasting System, or simply ISFS, is a modeling environment for creating predictive habitat suitability maps for invasive species. It was developed by the National Aeronautics and Space Administration (NASA) in cooperation with various Department of Interior bureaus, including the United States Geological Survey (USGS), the Bureau of Land Management (BLM), and the National Park Service (NPS). \n", "id": "25754996", "title": "Invasive Species Forecasting System"}
{"url": "https://en.wikipedia.org/wiki?curid=26349919", "text": "Harrington paradox\n\nHarrington paradox is a notion in the environmental and ecological economics describing the compliance of firms to the environmental regulations. The paradox was first described in Winston Harrington's paper in 1988 and was based on the research over monitoring, realization and compliance to ecological standards in the USA from the end of the 1970s to the beginning of the 1980s. According to the paradox, the firms in general comply with ecological standards in spite of the fact that:\n\n\nFirms' compliance at such level is contrary to the rational crime theory of Gary Becker which describes the behavior of profit maximizing entities. The rational firms will comply to the standards only in case the expected fine is higher than the cost of compliance. In order to explain the paradox it was suggested that firms exhibit altruism or self-image concern.\n\nThe empirical data observing the paradox is rare. In the research conducted by Norwegian Climate and Pollution Agency in 2001 no serious violations were revealed, but in the majority of firms (80%) there were minor deviations from standards. The fact that in Norway there is low frequency of monitoring and the fine system for minor violations is light can not bring strong evidence to the paradox, as major violations imply very strict punishments which is conforming to the rational crime theory.\n\n\n", "id": "26349919", "title": "Harrington paradox"}
{"url": "https://en.wikipedia.org/wiki?curid=26488448", "text": "Biosorption\n\nBiosorption is a physiochemical process that occurs naturally in certain biomass which allows it to passively concentrate and bind contaminants onto its cellular structure. Biosorption can be defined as the ability of biological materials to accumulate heavy\nmetals from wastewater through metabolically mediated or physico-chemical pathways of uptake. Though using biomass in environmental cleanup has been in practice for a while, scientists and engineers are hoping this phenomenon will provide an economical alternative for removing toxic heavy metals from industrial wastewater and aid in environmental remediation.\n\nPollution interacts naturally with biological systems. It is currently uncontrolled, seeping into any biological entity within the range of exposure. The most problematic contaminants include heavy metals, pesticides and other organic compounds which can be toxic to wildlife and humans in small concentration. There are existing methods for remediation, but they are expensive or ineffective. However, an extensive body of research has found that a wide variety of commonly discarded waste including eggshells, bones, peat, fungi, seaweed, yeast and carrot peels can efficiently remove toxic heavy metal ions from contaminated water. Ions from metals like mercury can react in the environment to form harmful compounds like methylmercury, a compound known to be toxic in humans. In addition, adsorbing biomass, or biosorbents, can also remove other harmful metals like: arsenic, lead, cadmium, cobalt, chromium and uranium. Biosorption may be used as an environmentally friendly filtering technique. Chitosan is among the biological adsorbents used for heavy metals removal without negative environmental impacts.\n\nThe idea of using biomass as a tool in environmental cleanup has been around since the early 1900s when Arden and Lockett discovered certain types of living bacteria cultures were capable of recovering nitrogen and phosphorus from raw sewage when it was mixed in an aeration tank. This discovery became known as the activated sludge process which is structured around the concept of bioaccumulation and is still widely used in wastewater treatment plants today. It wasn't until the late 1970s when scientists noticed the sequestering characteristic in dead biomass which resulted in a shift in research from bioaccumulation to biosorption.\n\nThough bioaccumulation and biosorption are used synonymously, they are very different in how they sequester contaminants:\n\nBiosorption is a metabolically passive process, meaning it does not require energy, and the amount of contaminants a sorbent can remove is dependent on kinetic equilibrium and the composition of the sorbents cellular surface. Contaminants are adsorbed onto the cellular structure. \n\nBioaccumulation is an active metabolic process driven by energy from a living organism and requires respiration. \n\nBoth bioaccumulation and biosorption occur naturally in all living organisms however, in a controlled experiment conducted on living and dead strains of \"bacillus sphaericus\" it was found that the biosorption of chromium ions was 13–20% higher in dead cells than living cells.\n\nIn terms of environmental remediation, biosorption is preferable to bioaccumulation because it occurs at a faster rate and can produce higher concentrations. Since metals are bound onto the cellular surface, biosorption is a reversible process whereas bioaccumulation is only partially reversible.\n\nSince biosorption is determined by equilibrium, it is largely influenced by pH, the concentration of biomass and the interaction between different metallic ions.\n\nFor example, in a study on the removal of pentachlorophenol (PCP) using different strains of fungal biomass, as the pH changed from low pH to high pH (acidic to basic) the amount of removal decreased by the majority of the strains, however one strain was unaffected by the change. In another study on the removal of copper, zinc and nickel ions using a composite sorbent as the pH increased from low to high the sorbent favored the removal of copper ions over the zinc and nickel ions. Because of the variability in sorbent this might be a drawback to biosorption, however, more research will be necessary.\n\nEven though the term biosorption may be relatively new, it has been put to use in many applications for a long time. One very widely known use of biosorption is seen in activated carbon filters. They can filter air and water by allowing contaminants to bind to their incredibly porous and high surface area structure. The structure of the activated carbon is generated as the result of charcoal being treated with oxygen. Another type of carbon, sequestered carbon, can be used as a filtration media. It is made by carbon sequestration, which uses the opposite technique as for creating activated carbon. It is made by heating biomass in the absence of oxygen. The two filters allow for biosorption of different types of contaminants due to their chemical compositions — one with infused oxygen and the other without.\n\nMany industrial effluents contain toxic metals that must be removed. Removal can be accomplished with biosorption techniques. It is an alternative to using man-made ion-exchange resins, which cost ten times more than biosorbents. The cost is so much less, because the biosorbents used are often waste from farms or they are very easy to regenerate, as is the case with seaweed and other unharvested biomass. \n\nIndustrious biosorption is often done by using sorption columns as seen in Figure 1. Effluent containing heavy metal ions is fed into a column from the top. The biosorbents adsorb the contaminants and let the ion-free effluent to exit the column at the bottom. The process can be reversed to collect a highly concentrated solution of metal contaminants. The biosorbents can then be re-used or discarded and replaced.\n", "id": "26488448", "title": "Biosorption"}
{"url": "https://en.wikipedia.org/wiki?curid=27064677", "text": "Occupancy frequency distribution\n\nIn macroecology and community ecology, an occupancy frequency distribution (OFD) is the distribution of the numbers of species occupying different numbers of areas. It was first reported in 1918 by the Danish botanist Christen C. Raunkiær in his study on plant communities. The OFD is also known as the species-range size distribution in literature.\n\nA typical form of OFD is a bimodal distribution, indicating the species in a community is either rare or common, known as Raunkiaer's law of distribution of frequencies. That is, with each species assigned to one of five 20%-wide occupancy classes, Raunkiaer's law predicts bimodal distributions within homogenous plant formations with modes in the first (0-20%) and last (81-100%) classes. Although Raunkiaer's law has long been discounted as an index of plant community homogeneity, the method of using occupancy classes to construct OFDs is still commonly used for both plant and animal assemblages. Henry Gleason commented on this law in a 1929 \"Ecology\" article: \"In conclusion we may say that Raunkiaer's law is merely an expression of the fact that in any association there are more species with few individuals than with many, that the law is most apparent when quadrats are chosen of the most serviceable size to show frequency, and that it is obscured or lost if the quadrats are either too large or too small.\" Evidently, there are different shapes of OFD found in literature. Tokeshi reported that approximately 46% of observations have a right-skewed unimodal shape, 27% bimodal, and 27% uniform. A recent study reaffirms about 24% bimodal OFDs in among 289 real communities.\n\nAs pointed out by Gleason, the variety shapes of OFD can be explained, to a large degree, by the size of the sampling interval. For instance, McGeoch and Gaston (2002) show that the number of satellite (rare) species declines with the increase of sampling grains, but the number of core (common) species increases, showing a tendency from a bimodal OFD towards a right-skewed unimodal distribution. This is because species range, measured as occupancy, is strongly affected by the spatial scale and its aggregation structure, known often as the scaling pattern of occupancy. Such scale dependence of occupancy has a profound effect on other macroecological patterns, such as the occupancy-abundance relationship.\n\nOther factors that have been proposed to be able to affect the shape of OFD include the degree of habitat heterogeneity, species specificity, landscape productivity, position in the geographic range, species dispersal ability and the extinction–colonization dynamics.\n\nThree basic models have been proposed to explain the bimodality found in occupancy frequency distributions.\n\nRandom sampling of individuals from either lognormal or log-series rank abundance distributions (where random choice of an individual from a given species was proportional to its frequency) may produce bimodal occupancy distributions. This model is not particularly sensitive or informative as to the mechanisms generating bimodality in occupancy frequency distributions, because the mechanisms generating the lognormal species abundance distribution are still under heavy debate.\n\nBimodality may be generated by colonization-extinction metapopulation dynamics associated with a strong rescue effect. This model is appropriate to explain the range structure of a community that is influenced by metapopulation processes, such as dispersal and local extinction. However, it is not robust because the shape of the occupancy frequency distribution generated by this model is highly sensitive\nto species immigration and extinction parameters. The metapopulation model does also not explain scale dependence in the occupancy frequency distribution.\n\nThe third model that describes bimodality in the occupancy frequency distribution is based on the scaling pattern of occupancy under a self-similar assumption of species distributions (called the occupancy probability transition [OPT] model). The OPT model is based on Harte et al.'s bisection scheme (although not on their probability rule) and the recursion probability of occupancy at different scales. The OPT model has been shown to support two empirical observations:\n\nThe OPT model demonstrates that the sample grain of a study, sampling adequacy, and the distribution of species saturation coefficients (a measure of the fractal dimensionality of a species distribution) in a community are together largely able to explain the patterns commonly found in empirical occupancy distributions. Hui and McGeoch (2007) further show that the self-similarity in species distributions breaks down according to a power relationship with spatial scales, and we therefore adopt a power-scaling assumption for modeling species occupancy distributions. The bimodality in occupancy frequency distributions that is common in species communities, is confirmed to a result for certain mathematical and statistical properties of the probability distribution of occupancy. The results thus demonstrate that the use of the bisection method in combination with a power-scaling assumption is more appropriate for modeling species distributions than the use of a self-similarity assumption, particularly at fine scales. This model further provokes the Harte-Maddux debate: Harte et al. demonstrated that the power law form of the species–area relationship may be derived from a bisected, self-similar landscape and a community-level probability rule. However, Maddux showed that this self-similarity model generates biologically unrealistic predictions. Hui and McGeoch (2008) resolve the Harte–Maddux debate by demonstrating that the problems identified by Maddux result from an assumption that the probability of occurrence of a species at one scale is independent of its probability of occurrence at the next, and further illustrate the importance of considering patterns of species co-occurrence, and the way in which species occupancy patterns change with scale, when modeling species distributions.\n\n", "id": "27064677", "title": "Occupancy frequency distribution"}
{"url": "https://en.wikipedia.org/wiki?curid=1810870", "text": "Reconciliation ecology\n\nReconciliation ecology is the branch of ecology which studies ways to encourage biodiversity in human-dominated ecosystems. Michael Rosenzweig first articulated the concept in his book \"Win-Win Ecology\", based on the theory that there is not enough area for all of earth’s biodiversity to be saved within designated nature preserves. Therefore, humans should increase biodiversity in human-dominated landscapes. By managing for biodiversity in ways that do not decrease human utility of the system, it is a \"win-win\" situation for both human use and native biodiversity. The science is based in the ecological foundation of human land-use trends and species-area relationships. It has many benefits beyond protection of biodiversity, and there are numerous examples of it around the globe. Aspects of reconciliation ecology can already be found in management legislation, but there are challenges in both public acceptance and ecological success of reconciliation attempts.\n\nTraditional conservation is based on \"reservation and restoration\"; reservation meaning setting pristine lands aside for the sole purpose of maintaining biodiversity, and restoration meaning returning human impacted ecosystems to their natural state. However, reconciliation ecologists argue that there is too great a proportion of land already impacted by humans for these techniques to succeed.\n\nWhile it is difficult to measure exactly how much land has been transformed by human use, estimates range from 39 to 50%. This includes agricultural land, pastureland, urban areas, and heavily harvested forest systems. An estimated 50% of arable land is already under cultivation. Land transformation has increased rapidly over the last fifty years, and is likely to continue to increase. Beyond direct transformation of land area, humans have impacted the global biogeochemical cycles, leading to human caused change in even the most remote areas. These include addition of nutrients such nitrogen and phosphorus, acid rain, ocean acidification, redistribution of water resources, and increased carbon dioxide in the atmosphere. Humans have also changed species compositions of many landscapes that they do not dominate directly by introducing new species or harvesting native species. This new assemblage of species has been compared to previous mass extinctions and speciation events caused by formation of land bridges and colliding of continents.\n\nThe need for reconciliation ecology was derived from patterns of species distribution and diversity. The most relevant of these patterns is the species-area curve which states that a larger geographic area will contain higher species diversity. This relationship has been supported by so large a body of research that some scholars consider it to be an ecological law.\n\nThere are two main reasons for the relationship between number of species and area, both of which can be used as an argument for conservation of larger areas. The habitat heterogeneity hypothesis claims that a larger geographic area will have a greater variety of habitat types, and therefore more species adapted to each unique habitat type. Setting aside a small area will not encompass enough habitat variety to contain a large variety of species. The equilibrium hypothesis draws from the theory of island biogeography as described by MacArthur and Wilson. Large areas have large populations, which are less likely to go extinct through stochastic processes. The theory assumes that speciation rates are constant with area, and a lower extinction rate coupled with higher speciation leads to more species.\n\nThe species-area relationship has often been applied to conservation, often quantitatively. The simplest and most commonly used formula was first published by Frank W. Preston. The number of species present in a given area increases in relationship to that area with the relationship S = cA where S is the number of species, A is the area, and c and z are constants which vary with the system under study. This equation has frequently been used for designing reserve size and placement (see SLOSS debate). The most common version of the equation used in reserve design is the formula for inter-island diversity, which has a z-value between 0.25-0.55, meaning protecting 5% of the available habitat will preserve 40% of the species present. However, inter-provincial species area relationships have z-values closer to 1, meaning protecting 5% of habitat will only protect 5% of species diversity.\n\nTaken together, proponents of reconciliation ecology see the species-area relationship and human domination of a large percentage of the earth's area as a sign that we will not be able to set aside enough land to protect all of life's biodiversity. There can be negative effects of setting land aside because it means the remaining land is used more intensely. For example, less land is required for crop production when high levels of inorganic fertilizer is applied, but these chemicals will affect nearby land set aside for natural ecosystems. The direct benefits of land transformation for the growing world population often make it ethically difficult to justify the tradeoff between biodiversity and human use. Reconciled ecosystems are ones in which humans dominate, but natural biodiversity is encouraged to persist within the human landscape. Ideally, this creates a more sustainable socio-ecological system and does not necessitate a trade off between biodiversity and human use.\n\nHow can understanding of species' natural history aid their effective conservation in human-dominated ecosystems? Humans often conduct activities that allow for the incorporation of other species, whether as a by-product or as a result of a focus on nature. Traditional natural history can only inform how best to do this to a certain degree, because landscapes have been changed so dramatically. However, there is much more to learn through direct study of species' ecology in human-dominated ecosystems, through what is known as focused natural history. Rosenzweig cites four examples: shrikes (Laniidae) thrived in altered landscapes when wooden fence post perches allowed them easy access to pouncing on prey, but inhospitable steel fence posts contributed to their decline. Replacing steel fence posts with wood fence posts reverses the shrikes' decline and allows humans to determine the reasons for the distribution and abundance of shrikes. Additionally, the cirl bunting (\"Emberiza cirlus\") thrived on farms when fields alternated between harvests and hay, but declined where farmers began to plant winter grain crops, natterjack toads (\"Bufo calamatus\") declined when reductions in sheep grazing ceased to alter ponds to their preferred shape and depth, and longleaf pine (\"Pinus palustris\") declined in the Southeastern United States when lack of wildfires prevented its return after timbering. Thus, applying focused natural history in human-dominated landscapes can contribute to conservation efforts.\n\nThe emerging concept of ecosystem services (coined by the Millennium Ecosystem Assessment in 2005) changed the way ecologists perceived so-called \"ordinary species\" : as abundant species represent the bulk of biomass and biological processes, even if they don't appear directly threatened their conservation constitutes as a major concern for maintaining these services on which rely both human societies and rarer species. Reconciliation ecology then proposes to take care of such species and to maintain (or restore) ecological processes in human-dominated ecosystems, hence creating ecological corridors and preserving a good functioning of biological cycles.\n\nReconciliation ecologists believe increasing biodiversity within human dominated landscapes will help to save global biodiversity. This is sometimes preferable to traditional conservation because it does not impair human use of the landscape and therefore may be more acceptable to stakeholders. However, not only will it encourage biodiversity in the areas where it takes place, but many scholars cite other benefits of including biodiversity in human landscapes on both global conservation activities and human well-being.\n\nIncreasing wildlife habitat in human-dominated systems not only increases \"in situ\" biodiversity, it also aids in conservation of surrounding protected areas by increasing connectivity between habitat patches. This may be especially important in agricultural systems where buffers, live fences, and other small habitat areas can serve as stops between major preserves. This concept forms the basis of the subdiscipline countryside biogeography which studies the potential of the matrix between preserves to provide habitat for species moving from preserve to preserve.\n\nPlacing importance on native ecosystems and biodiversity within human landscapes increases human exposure to natural areas, which has been shown to increase appreciation of nature. Studies have shown that students who participate in outdoor education programs show a greater understanding of their environment, greater willingness to act in order to save the environment, and even a greater enthusiasm for school and learning. Green spaces have also been shown connect urban dwellers of all ages with nature, even when dominated by invasive species. Reconnecting people with nature is especially important for conservation because there is a tendency for people to use the biodiversity present in the landscape they grew up in as a point of comparison for future trends (see Shifting baseline).\n\nThe results of reconciliation ecology can also improve human well-being. E. O. Wilson has hypothesized that humans have an innate desire to be close to nature (see Biophilia), and numerous studies have linked natural settings to decreased stress and faster recovery during hospital stays.\n\nMany examples of native plants and animals taking advantage of human dominated landscapes have been unintentional, but may be enhanced as part of reconciliation ecology. Others are intentional redesigns of human landscapes to better accommodate native biodiversity. These have been going on for many hundreds of years including examples within agricultural systems, urban and suburban systems, marine systems, and even industrial areas.\n\nWhile Rosenzweig formalized the concept, humans have been encouraging biodiversity within human landscapes for millennia. In the Trebon Biosphere Reserve of the Czech Republic, a system of human-engineered aquaculture ponds built in the 1500s not only provides a profitable harvest of fish, but also provides habitat for a hugely diverse wetland ecosystem. Many cities in Europe take pride in their local population of storks, which nest on roofs or in church towers that replace the trees they would naturally nest in. There are records of humans maintaining plants in pleasure gardens as early as ancient Mesopotamia, with an especially strong tradition of incorporating gardens into the architecture of human landscapes in China.\n\nAgroforestry provides many examples of reconciliation ecology at work. In tropical agroforestry systems, crops such as coffee or fruit trees are cultivated under a canopy of shade trees, providing habitat for tropical forest species outside of protected areas. For example, shade-grown coffee plantations typically have lower tree diversity than unmanaged forests, however they have much higher tree species diversity and richness than other agricultural methods. Agriculture that mimics nature, encourages natural forest species along with the crops, and also takes pressure off nearby uncultivated forest areas where people are allowed to collect forest products. The understory can also be managed with reconciliation ecology: allowing weeds to grow among crops (minimizing labor and preventing the invasion of noxious weed species) and leaving fallowlands alongside farmed areas can enhance understory plant richness with associated benefits for native insects and birds compared to other agricultural practices.\n\nThe oil palm (\"Elaeis guineensis\") provides another example of the potential of reconciliation ecology. It is one of the most important and rapidly expanding tropical crops, so lucrative because it is used in many products throughout the world. Unfortunately, oil-palm agriculture is one of the main drivers of forest conversion in Southeast Asia and is devastating for native biodiversity, perhaps even more so than logging. However, attempts are being made to foster the sustainability of this industry. As a monoculture, oil palm is subject to potentially devastating attacks from insect pests. Many companies are attempting an integrated pest management approach which encourages the planting of species that support predators and parasitoids of these insect pests, as well as an active native bird community. Experiments have shown that a functioning bird community, especially at higher densities, can serve to reduce insect herbivory on oil palms, promoting increased crop yields and profits. Thus, oil palm plantation managers can participate in reconciliation ecology by promoting local vegetation that is beneficial to insectivorous birds, including maintaining ground plants that serve as nesting sites, thereby protecting natural communities. Additionally, steps such as maintaining riparian buffer zones or natural forest patches can help to slow the loss of biodiversity within oil palm plantation landscapes. By engaging in these environmentally friendly practices, fewer chemicals and less effort are required to maintain both plantation productivity and ecosystem services.\n\nThere are many grazing practices that also encourage native biodiversity. In Rosenzweig’s book he uses the example of a rancher in Arizona who intentionally deepened his cattle ponds in order to save a population of threatened leopard frogs (\"Rana chiricahuensis\"), with no detriment to the use of those tanks for cattle, and a similar situation has occurred with the vulnerable California tiger salamander (\"Ambystoma californiense\") in the Central Valley of California. Research has shown that without cattle grazing, many of the remaining vernal pools would dry too early for the salamanders to complete their life cycle under global climate change predictions. In Central America, a large percentage of pastureland is fenced using live trees which are not only low maintenance for the farmer, but also provide habitat for birds, bats, and invertebrates which cannot persist in open pastureland. Another example from Rosenzweig involves encouraging loggerhead shrikes (\"Lanius ludovicianus\") to populate pastureland by placing perches around the pasture. These are all simple, low-cost ways to encourage biodiversity without negatively impacting the human uses of the landscape.\n\nUrban ecology can be included under the umbrella of reconciliation ecology and it tackles biodiversity in cities, the most extreme of human-dominated landscapes. Cities occupy less than 3% of global surface area, but are responsible for a majority of carbon emissions, residential water use, and wood use. Cities also have unique climatic conditions such as the urban heat island effect, which can greatly affect biodiversity. There is a growing trend among city managers to take biodiversity into account when planning city development, especially in rapidly growing cities. Cities often have surprisingly high plant biodiversity due to their normally high degree of habitat heterogeneity and high numbers of gardens and green spaces cultivated to include a large variety of species. However, these species are often not native, and a large part of the total urban biodiversity is usually made up of exotic species.\n\nBecause cities are so highly impacted by human activities, restoration to the pristine state is not possible, however there are modifications that can be made to increase habitat without negatively impacting human needs. In urban rivers, addition of large woods and floating islands to provide habitat, modifications to walls and other structures to mimic natural banks, and buffer areas to reduce pollutants can all increase biodiversity without reducing the flood control and water supply services. Urban green spaces can be re-designed to encourage natural ecosystems rather than manicured lawns, as is seen in the National Wildlife Federation’s Backyard Wildlife Habitat program. Peregrine falcons (\"Falco peregrinus\"), which were once endangered by pesticide use, are frequently seen nesting in tall urban buildings throughout North America, feeding chiefly on the introduced rock dove. The steep walls of buildings mimic the cliffs peregrines naturally nest in and the rock doves replace the native prey species that were driven out of urban areas.\n\nIn Florida, the Florida manatee (\"Trichechus manatus latirostris\") uses warm water discharged from power plants as a refuge when the temperature of the Gulf of Mexico drops. These warm areas replace the warm springs that manatees once naturally used in the winter. These springs have been drained or cut off from open water by human uses. American crocodiles (\"Crocodylus acutus\") have a similar habitat in the cooling canals of the Turkey Point power plant, where an estimated 10% of the total North American population of the species lives.\n\nWastewater treatment systems have shown potential for reconciliation ecology on numerous occasions. Man-made wetlands designed to remove nitrogen before runoff from agriculture enters the Everglades in Florida are used as breeding sites for a number of birds, including the endangered wood stork (\"Mycteria americana\"). Stormwater treatment ponds can provide important breeding habitat for amphibians, especially where natural wetlands have been drained by human development.\n\nCoral reefs have been intensively impacted by human use, including overfishing and mining of the reef itself. One reconciliation approach to this problem is building artificial reefs that not only provide valuable habitat for aquatic species, but also protect nearby islands from storms when the natural structure has been mined away. Even structures as simple as scrap metal and automobiles can be used as habitat, providing added benefits of freeing space in landfills.\n\nGovernmental intervention can aid in encouraging private landowners to create habitat or otherwise increase biodiversity on their land. The United States' Endangered Species Act requires landowners to halt any activities negatively affecting endangered species on their land, which is a disincentive for them to encourage endangered species to settle on their land in the first place. To help mediate this problem, the US Fish and Wildlife Service has instituted safe harbor agreements whereby the landowner engages in restoration on their land to encourage endangered species, and the government agrees not to place further regulation on their activities should they want to reverse the restoration at a later date. This practice has already led to an increase in aplomado falcons (\"Falco femoralis\") in Texas and red-cockaded woodpeckers (\"Picoides borealis\") in the Southeastern US.\n\nAnother example is the US Department of Agriculture’s Conservation Reserve Program (CRP). The CRP was originally put in place to protect soil from erosion, but also has major implications for conservation of biodiversity. In the program, landowners take their land out of agricultural production and plant trees, shrubs, and other permanent, erosion controlling vegetation. Unintended, but ecologically significant consequences of this were the reduction of runoff, improved water quality, creation of wildlife habitat, and possible carbon sequestration.\n\nWhile reconciliation ecology attempts to modify the human world to encourage biodiversity without negatively impacting human use, there are still difficulties in getting broad acceptance of the idea. For example, addition of large woods to urban river systems, which provides critical habitat structure for native fish and invertebrates may be seen as \"untidy\" and a sign of poor management by residents. Similarly, many suburban areas do not allow long, unkempt lawns that provide useful wildlife habitat because of perceived damage to property values. Many humans have negative feelings toward certain species, especially predators such as wolves, which are often based more on perceived risk than actual risk of loss or injury resulting from the animal.\nEven with cooperation of the human element of the equation, reconciliation ecology can not help every species. Some animals, such as several species of waterfowl, show strong avoidance behaviors toward humans and any form of human disturbance. No matter how nice an urban park is built, the proximity of humans will scare away some birds. Other species must maintain large territories, and barriers that abound in human habitats, such as roads, will stop them from coexisting with humans. These animals will require undisturbed land set aside for them.\n\nThere is hence a double social challenge for reconciliation ecology : making people's perception of biodiversity evolve, and then changing relating norms and policies so as to better consider biodiversity as a positive component in our habitat.\n\n\n", "id": "1810870", "title": "Reconciliation ecology"}
{"url": "https://en.wikipedia.org/wiki?curid=18997355", "text": "ECOFIT\n\nECOFIT is multi-institutional ecological and paleoecology operation started in Lima in 1992. It specializes in montitoring ecology and paleo-ecology of tropical forests, in parts of South America and also in coastal Central Africa.\n\nThe program involves the study of fossils and soils of tropical forests particularly related to the Holocene period.\n", "id": "18997355", "title": "ECOFIT"}
{"url": "https://en.wikipedia.org/wiki?curid=14768005", "text": "Conservation psychology\n\nConservation psychology is the scientific study of the reciprocal relationships between humans and the rest of nature, with a particular focus on how to encourage conservation of the natural world. Rather than a specialty area within psychology itself, it is a growing field for scientists, researchers, and practitioners of all disciplines to come together and better understand the earth and what can be done to preserve it. This network seeks to understand why humans hurt or help the environment and what can be done to change such behavior. The term \"conservation psychology\" refers to any fields of psychology that have understandable knowledge about the environment and the effects humans have on the natural world. Conservation psychologists use their abilities in \"greening\" psychology and make society ecologically sustainable. The science of conservation psychology is oriented toward environmental sustainability, which includes concerns like the conservation of resources, conservation of ecosystems, and quality of life issues for humans and other species.\n\nOne common issue is a lack of understanding of the distinction between conservation psychology and the more-established field of environmental psychology, which is the study of transactions between individuals and all their physical settings, including how people change both the built and the natural environments and how those environments change them. Environmental psychology began in the late 1960s (the first formal program with that name was established at the City University of New York in 1968), and is the term most commonly used around the world. Its definition as including human transactions with both the natural and built environments goes back to its beginnings, as exemplified in these quotes from three 1974 textbooks: \"Environmental psychology is the study of the interrelationship between behavior and the built and natural environment\" and \"...the natural environment is studied as both a problem area, with respect to environmental degradation, and as a setting for certain recreational and psychological needs\", and a third that included a chapter entitled The Natural Environment and Behavior.\n\nConservation psychology, proposed more recently in 2003 and mainly identified with a group of US academics with ties to zoos and environmental studies departments, began with a primary focus on the relations between humans and animals. Introduced in ecology, policy, and biology journals, some have suggested that it should be expanded to try to understand why humans feel the need to help or hurt the environment, along with how to promote conservation efforts.\n\nPsychologists from all fields including philosophy, biology, sociology, industrial and organizational, health, and consumer psychology, along with many other subfields like environmental education and conservation biology come together to put their knowledge to practice in educating others to work together and encourage a congruous relationship between humans and the environment around them. These psychologists work together with places such as zoos and aquariums. Zoos and aquariums may seem to only be places of recreation and fun but are actually trying hard to put positive messages out and to educate the public on the homes and needs of the animals that live there. They are trying to find ways to interact and teach the public the consequences of their day to day actions to the animals and the environment rather than simply viewing the animals. Psychologists and sociologists have been visiting workshops and think tanks at the zoos to evaluate if the animals are being viewed and shown to the best of their ability while still giving informative knowledge to the public.\n\nWhat characterizes conservation psychology research is that in addition to descriptive and theoretical analyses, studies will explore how to cause the kinds of changes that lessen the impact of human behavior on the natural environment, and that lead to more sustainable and harmonious relationships. Some of the research being done with respect to conservation is estimating exactly how much land and water resources are being used by each human at this point along with projected future growth. Also important to consider is the partitioning of land for this future growth. Additionally, conservation efforts look at the positive and negative consequences for the biodiversity of plant and animal life after humans have used the land to their advantage. In addition to creating better conceptual models, more applied research is needed to: 1) identify the most promising strategies for fostering ways of caring about nature, 2) find ways to reframe debates and strategically communicate to the existing values that people have, 3) identify the most promising strategies for shifting the societal discourse about human–nature relationships, and 4) measure the success of these applications with respect to the conservation psychology mission. The ultimate success of conservation psychology will be based on whether its research resulted in programs and applications that made a difference with respect to environmental sustainability. We need to be able to measure the effectiveness of the programs in terms of their impact on behavior formation or behavior change, using tools developed by conservation psychologists.\n\nConservation psychology research has broken down the four most important tenets of promoting positive conservation attitudes into \"the four 'I's\". These include: Information, Identity, Institutions, and Incentives. Research has been done in all four categories.\n\nStudies have shown that the way in which crises are presented is a key predictor for how people will react to them. When people hear that they personally can help to alleviate a crisis through their conservation efforts, just by simple actions with their personal energy use, they are more likely to conserve. However, if people are told that the other people around them are overusing energy, it increases selfish behavior and causes people to actually consume more.\n\nTeaching people about the benefits of conservation, including easy ways to help conserve, is an effective way to inform about and promote more environmentally friendly behavior. Additionally, research has shown that making sure people understand more about the boundaries of land they can help preserve actually improves positive attitudes towards conservation. When people know more about local regions they can help protect, they will care more. Knowing more about the regions includes knowing the extent of the biodiversity in that region, and being sure that the ecosystem will remain healthy and protected. Cost analysis is another important factor. People do not want to take risks on valuable lands, which in places like California, could be worth billions.\n\nIn general, people like to fit in and identify with their peer social groups. Studies have shown people identify more intimately with close friends and family, which is why conservation campaigns try to directly address the most amount of people. The \"think of the children\" argument for conservation follows this logic by offering a group everyone can relate to and feel close to. Studies have also shown that this need to fit in among peer social groups can be reinforced positively or negatively: giving positive feedback on energy bills for conserving in their homes encourages people to continue lower energy use. Examples of negative reinforcement include the use of negative press against companies infamous for heavy pollution.\n\nAnother interesting line of research looks at how people identify positively or negatively with certain issues. One relevant idea is the notion of \"consistency attitudes\". Studies have shown that people tend to take a good association they have, and then use this to make positive or negative links with other, related things. For example, if someone thinks it is a good idea to protect old Pacific forests, this will positively form a link to also want to protect smaller forests and even grasslands. This same line of thinking can cause someone who supports the protection of old Pacific forests to start thinking negatively about the creation of more logging roads. Other studies on consistency attitudes have shown that, with one particular issue, people like to align their preferences with each other. This has been shown repeatedly while looking at political ideologies and racial attitudes, and studies have shown that this can also include environmental issues. Finally, other studies have shown that how people identify an ecosystem geographically can affect their concern for it. For instance, when people think of saving the rainforests, they often think of this as a global problem and support it more readily. However, lesser known but still significant local ecosystems remain ignored and unprotected.\n\nAnother approach that has been considered is the use of organized institutions and government as the leaders for promoting conservation. However, these leaders can only be effective if they are trusted. Studies from previous crises where conserving resources was extremely necessary showed that people were more likely to obey energy restrictions and follow certain leaders when they felt they could trust the people directing them. People need to understand that they are being encouraged to act a certain way out of necessity, and that they are not being misled.\n\nIncentivizing conservation through rewards and fines is another approach. Studies have shown that people who identify more with their community need less incentives to conserve than those who do not identify strongly with their surrounding community. For corporations, monetary incentives have been shown to work for companies showing some effort to make their buildings and practices more \"green\". Studies have also shown that doing something as simple as putting a water meter in homes has helped incentivize conservation by letting people track their energy consumption levels. Finally, studies have shown that when giving fines, it is better to start with very small and then raise it for repeated violations. If the fines are too high, the issue becomes too economic, and people start to mistrust the authorities enforcing the fines.\n\nConservation psychology assesses as a whole four different concepts. At the country's first Conservation Psychology conference these four things were discussed. The first is the main original topic of the field, and the other three are topics with a previous history in environmental psychology.\n\nThe first topic being discussed is the connection of humans and animals. The Multi-Institutional Research Project (MIRP) works diligently on finding ways to develop a compassionate stance towards animals in the public eye. Many different questions were assessed to find answers to questions concerning ways to help develop loving attitudes for animals and the earth. With these questions and answers, effective educational and interpretive programs were made that would help review the progress.\n\nThe second concept that was discussed at the conference concerned connections of humans and places. A new language of conservation will be supported if there are abundant opportunities for meaningful interactions with the natural world in both urban and rural settings. Unfortunately, as biodiversity is lost, every generation has fewer chances to experience nature. There were many questions asked concerning how humans in their everyday lives could be persuaded or educated well enough to make them want to join in programs or activities that help maintain biodiversity in their proximity. Local public and private organizations were asked to come together to help find ways to protect and manage local land, plants, and animals. Other discussions came to whether people on an individual or community level would voluntarily choose to become involved in maintaining and protecting their local biodiversity. These plus many other important questions were contemplated. Techniques in marketing are a key tool in helping people connect to their environment. If an identity could be connected from the environment to towns becoming more urbanized, maybe those living there would be more prone to keep it intact.\n\nThe third discussion covered the aspects of producing people who act environmentally friendly. Collectively, any activities that support sustainability, either by reducing harmful behaviors or by adopting helpful ones, can be called conservation behaviors. Achieving more sustainable relationships with nature will basically require that large numbers of people change their reproductive and consumptive behaviors. Any action, small or large, that helps the environment in any way is a good beginning to a future of generations who only practice environmentally friendly behavior. This may seem to be a far-fetched idea but with any help at all in educating those who do not know the repercussions of their actions could help achieve this. Approaches to encouraging a change in behavior were thought about carefully. Many do not want to change their way of life. A more simplistic lifestyle rather than their materialistic, current lives hurt their environment around them rather than help, but could people willingly change? To take public transportation rather than drive a car, recycling, turning off lights when they are not needed, all these things are very simple yet a nuisance to actually follow through with. Would restructuring tax-code help people to want to change their attitudes? Any concept to reach the goal of helping people act ecologically aware was discussed and approached. Some empirical evidence shows that simply \"being the change you want to see in the world\" can influence others to behave in more environmentally friendly ways as well.\n\nThe fourth and final point at the first Conservation Psychology convention was the discussion of the values people have to their environment. Understanding our relationship to the natural world well enough so that we have a language to celebrate and defend that relationship is another research area for conservation psychology. According to the biophilia hypothesis, the human species evolved in the company of other life forms, and we continue to rely physically, emotionally, and intellectually on the quality and richness of our affiliations with natural diversity. A healthy and diverse natural environment is considered an essential condition for human lives of satisfaction and fulfillment. Where did they get these values and are they ingrained to the point they cannot be changed? How can environmentally educated people convey value-based communication to a community, a nation, or even on a global level? National policy for this model is something that is desired but under such a strong political scrutiny this could be very challenging. Advocates for biodiversity and different programs came together to try to find methods of changing Americans' values concerning their environment and different methods to express and measure them.\n\nConservation biology was originally conceptualized as a crisis-oriented discipline, with the goal of providing principles and tools for preserving biodiversity. This is a branch of biology that is concerned with preserving genetic variation in plants and animals. This scientific field evolved to study the complex problems surrounding habitat destruction and species protection. The objectives of conservation biologists are to understand how humans affect biodiversity and to provide potential solutions that benefit both humans and non-human species. It is understood in this field that there are underlying fields of biology that could readily help to have a better understanding and contribute to conservation of biodiversity. Biological knowledge alone is not sufficient to solve conservation problems, and the role of the social sciences in solving these problems has become increasingly important. With the knowledge of conservation biology combined with other fields, much was thought to be gained. Psychology is defined as the scientific study of human thought, feeling, and behavior. Psychology was one of the fields that could take its concepts and apply them to conservation. It was also always understood that in the field of psychology there could be much aid to be given, the field only had to be developed. Psychology can help in providing insight into moral reasoning and moral functioning, which lie in the heart of human–nature relationships. Everyone that is now involved from the field of psychology had knowledge of ways to conceptualize the relationship of humans to their environment. Biology has always been involved in advances of conservation considering biodiversity, and the organisms in it are part of the main field of biology. Psychology has been absent from conservation for some time, but educators and scientists are realizing that with the help of both we can come to a better understanding of humans and their social interactions with their environment and everything in it.\n\n\n\n", "id": "14768005", "title": "Conservation psychology"}
{"url": "https://en.wikipedia.org/wiki?curid=20679746", "text": "Rewilding (anarchism)\n\nRewilding means to return to a more wild or natural state; it is the process of undoing domestication. The term emerged from the green anarchism and anarcho-primitivism, the beliefs that many humans have been \"civilized\" or \"domesticated\" by industrialization and sedentary social stratification. Such a process is compared to how dogs have been domesticated from what was a common ancestor with wolves, resulting in a loss in health and vibrancy. Supporters of rewilding argue that through the process of domestication, human wildness has been altered by force.\n\nRewilding is about dismantling the culture of human domestication and returning to the lifeways of nomadic human cultures. Though often associated with primitive skills and learning knowledge of wild plants and animals, it emphasizes regenerative land management techniques employed by hunter-gatherers and horticulturalists, as well as development of the senses and fostering deepening personal relationships with members of other species and the natural world. Rewilding intends to create permanently wild human cultures beyond domestication.\n\nRewilding is considered a holistic approach to living, as opposed to skills, practices or a specific set of knowledge.\n\nRewilding is most associated with green anarchy and anarcho-primitivism or anti-civilization and post-civilization anarchism in general.\n\nWithin a modern and scientific social context, rewilding entails both experiential and \"book knowledge\" to produce a community that is both respectful of individual liberties and beneficial to all involved, including all non-human species. Participants in such events and communities directly reap the benefits of the communities' actions and efforts. Instead of seeking to \"return\" to an earlier state of human existence or go \"back to the land\", rewilding seeks to take the experiences and time spent here in civilization and combine the lessons that have been learned from both the past and the present to create a more ideal society.\n\nIn 2012 musician/clown Zack de la Rouda, released the album \"Rewild Or Die\"\n\nIn 2015 activist/musician Jadis Mercado, released the album \"Rewild Things\"\n\n\n", "id": "20679746", "title": "Rewilding (anarchism)"}
{"url": "https://en.wikipedia.org/wiki?curid=206243", "text": "Biocoenosis\n\nA biocenosis (UK English, \"biocoenosis\", also biocenose, biocoenose, biotic community, biological community, ecological community, life assemblage,) coined by Karl Möbius in 1877, describes the interacting organisms living together in a habitat (biotope).\n\nIn the palaeontological literature, the term distinguishes \"life assemblages\", which reflect the original living community, living together at one place and time. In other words, it is an assemblage of fossils or a community of specific time, which is different from \"death assemblages\" (thanatocoenoses). No palaeontological assemblage will ever completely represent the original biological community (i.e. the biocoenosis, in the sense used by an ecologist); the term thus has somewhat different meanings in a palaeontological and an ecological context.\n\nBased on the concept of biocenosis, ecological communities can take in various forms\n\nThe geographical extent of a biocenose is limited by the requirement of a more or less uniform species composition.\n\nAn ecosystem, originally defined by Tansley (1935), is a biotic community (or biocenosis) along with its physical environment (or \"biotope\"). In ecological studies, biocenosis is the emphasis on relationships between species in an area. These relationships are an additional consideration to the interaction of each species with the physical environment.\n\nBiotic communities vary in size, and larger ones may contain smaller ones. Species interactions are evident in food or feeding relationships. A method of delineating biotic communities is to map the food network to identify which species feed upon which others and then determine the system boundary as the one that can be drawn through the fewest consumption links relative to the number of species within the boundary.\n\nMapping biotic communities is important identifying sites needing environmental protection, such as the British Site of Special Scientific Interest (SSSIs). The Australian Department of the Environment and Heritage maintains a register of \"Threatened Species and Threatened Ecological Communities\" under the Environment Protection and Biodiversity Conservation Act 1999 (EPBC Act).\n\n", "id": "206243", "title": "Biocoenosis"}
{"url": "https://en.wikipedia.org/wiki?curid=20606605", "text": "Ecology of contexts\n\nThe ecology of contexts is a term used in many disciplines and refers to the dynamic interplay of contexts and demands that constrain and define an entity.\n\nAn agroecosystem exists amid contexts including climate, soil, plant genetics, government policies, and the personal beliefs and predilections of the agriculturalist. Not only are these contexts too numerous to list in their entirety for any agroecosystem, but their interactions are so complex it is impossible to perfectly characterize a system, let alone predict the effect a given perturbation will have on the whole. At the same time, all of these contexts are dynamic, albeit at wildly diverging time scales, so the ecology of contexts for an agroecosystem is fundamentally mutable. An awareness of the ecology of contexts is helpful for agroecologists, as the nearly axiomatic acceptance dynamic, and thereby unperfectable, nature of agroecosystems precludes the often damaging notion of a best or ideal approach to agroecosystem management as well as an awareness of the complexity of the response that can result from any perturbation of the system.\n\nThis concept of the ecology of contexts provides a useful epistemological device for understanding agroecosystems.\n\nIn child development, for instance, it can refer to the nested scales at which influences on children reside, from the individual (e.g. age) to the broadest elements, like government policies or cultural attitudes.\n\nFrom computer science is the concept of ecology of context-aware computing, where a device's operation is tempered by information the device itself has about how the environment will affect its functioning and vice versa.\n\nIn the field of music therapy, Trygve Aasgaard dealt with the reciprocity of an ecology of contexts, seeing the role of music in therapy as responsive to cultural and other contexts, while at the same time forming part of the environmental context.\nThis dual relationship of an entity in an ecology of contexts underscores the ecological analogy, with its emphasis on holonic interactions.\n", "id": "20606605", "title": "Ecology of contexts"}
{"url": "https://en.wikipedia.org/wiki?curid=26114602", "text": "Back-story (production)\n\nBack-story, in the production of consumer goods, is information about the effects of their production.\n", "id": "26114602", "title": "Back-story (production)"}
{"url": "https://en.wikipedia.org/wiki?curid=315203", "text": "Bionomics\n\nIn ecology, bionomics (Greek: bio = life; nomos = law) is the comprehensive study of an organism and its relation to its environment. As translated from the French word \"Bionomie\", its first use in English was in the period of 1885-1890. Another way of expressing this word is the term currently referred to as \"ecology\". An example of studies of this type is Richard B. Selander's Bionomics, Systematics and Phylogeny of Lytta, a Genus of Blister Beetles (Coleoptera, Meloidae), Illinois Biological Monographs: number 28, 1960. \n/Users/vittorioingegnoli/Desktop/BIONOMICS.docx\nBionomics transforms many principles of traditional Ecology, recognizing that Life on Earth is hierarchically organized in complex systems, acting as living entities well farther populations and communities.\n“Level of biological organization integrating complex systems of plants, animals and humans in a living Entity recognizable in a territory as characterized by suitable emerging properties in a determined spatial configuration”. (Ingegnoli, 2011, 2015; Ingegnoli, Bocchi, Giglio, 2017)\n\nIngegnoli V, Bocchi S, Giglio E (2017) Landscape Bionomics: a Systemic Approach to Understand and Govern Territorial Development. WSEAS Transactions on Environment and Development, Vol.13, pp. 189-195 \nIngegnoli V (2015) Landscape Bionomics. Biological-Integrated Landscape Ecology. Springer, Heidelberg, Milan, New York. Pp. XXIV + 431 \nIngegnoli, V. (2011). Bionomia del paesaggio. L’ecologia del paesaggio biologico-integrata per la formazione di un “medico” dei sistemi ecologici. Springer-Verlag, Milano, pp. XX+340. \n", "id": "315203", "title": "Bionomics"}
{"url": "https://en.wikipedia.org/wiki?curid=11336837", "text": "Global hectare\n\nThe global hectare (gha) is a measurement unit for quantifying both the ecological footprint of people or activities as well as the biocapacity of the earth or its regions. One global hectare represents the average productivity of all biologically productive areas (measured in hectares) on earth in a given year. Examples of biologically productive areas include cropland, forests, and fishing grounds; they do not include deserts, glaciers, and the open ocean. \"Global hectare per person\" refers to the amount of biologically productive land and water available per person on the planet. The total number of global hectares is approximately 11.3 billion, averaging about 1.8 global hectares per person (2004). A total of 13.4 billion hectares were used, or 2.2 global hectares per person, meaning about 20% more was consumed than produced. This is possible because there are natural reserves all around the globe that function as backup food, material and energy supplies, although only for a relatively short period of time. Due to rapid population growth, these reserves are being depleted at an ever increasing tempo. See Earth Overshoot Day.\n\nThe global hectare is a useful measure of biocapacity as it can convert things like human dietary requirements into a physical area, which can show how many people a certain region on earth can sustain, assuming current technologies and agricultural methods. It can be used as a way of determining the relative carrying capacity of the earth.\n\nA given hectare of land may be measured in equivalent global hectares. For example, a hectare of lush area with high rainfall would be scale higher in global hectares than would a hectare of desert.\n\nIt can also be used to show that consuming different foods may increase the earth's ability to support larger populations. To illustrate, producing meat generally requires more land and energy than what producing vegetables requires; sustaining a meat-based diet would require a less populated planet.\n\nThe average global hectare would occupy the area of a standard hectare. A hectare (; symbol ha) is a unit of area equal to (a square 100 metres on each side, or, a square 328.08 feet on each side), 2.471 acre, 0.00386102 square miles, or one square hectometre (100 metres squared).\n", "id": "11336837", "title": "Global hectare"}
{"url": "https://en.wikipedia.org/wiki?curid=5224295", "text": "Myco-heterotrophy\n\nMyco-heterotrophy (from Greek μύκης \"mykes\", \"fungus\", ἕτερος \"heteros\", \"another\", \"different\" and τροφή \"trophe\", \"nutrition\") is a symbiotic relationship between certain kinds of plants and fungi, in which the plant gets all or part of its food from parasitism upon fungi rather than from photosynthesis. A myco-heterotroph is the parasitic plant partner in this relationship. Myco-heterotrophy is considered a kind of cheating relationship and myco-heterotrophs are sometimes informally referred to as \"mycorrhizal cheaters\". This relationship is sometimes referred to as mycotrophy, though this term is also used for plants that engage in mutualistic mycorrhizal relationships.\n\nFull (or obligate) myco-heterotrophy exists when a non-photosynthetic plant (a plant largely lacking in chlorophyll or otherwise lacking a functional photosystem) gets all of its food from the fungi that it parasitizes. Partial (or facultative) myco-heterotrophy exists when a plant is capable of photosynthesis, but parasitizes fungi as a supplementary food supply. There are also plants, such as some orchid species, that are non-photosynthetic and obligately myco-heterotrophic for part of their life cycle, and photosynthetic and facultatively myco-heterotrophic or non-myco-heterotrophic for the rest of their life cycle. Not all non-photosynthetic or \"\" plants are myco-heterotrophic – some non-photosynthetic plants like dodder directly parasitize the vascular tissue of other plants.\n\nIn the past, non-photosynthetic plants were mistakenly thought to get food by breaking down organic matter in a manner similar to saprotrophic fungi. Such plants were therefore called \"saprophytes\". It is now known that these plants are not physiologically capable of directly breaking down organic matter and that in order to get food, non-photosynthetic plants must engage in parasitism, either through myco-heterotrophy or direct parasitism of other plants.\n\nThe interface between the plant and fungal partners in this association is between the roots of the plant and the mycelium of the fungus. Myco-heterotrophy therefore closely resembles mycorrhiza (and indeed is thought to have evolved from mycorrhiza), except that in myco-heterotrophy, the flow of carbon is from the fungus to the plant, rather than vice versa.\n\nMost myco-heterotrophs can therefore be seen as ultimately being epiparasites, since they take energy from fungi that in turn get their energy from vascular plants. Indeed, much myco-heterotrophy takes place in the context of common mycorrhizal networks, in which plants use mycorrhizal fungi to exchange carbon and nutrients with other plants. In these systems, myco-heterotrophs play the role of \"mycorrhizal cheaters\", taking carbon from the common network, with no known reward.\n\nIn congruence with older reports, it has been recently shown that some myco-heterotrophic orchids can be supported by saprotrophic fungi, exploiting litter- or wood-decaying fungi. In addition, several green plants (evolutionarily close to myco-heterotrophic species) have been shown to engage in partial myco-heterotrophy, that is, they are able to take carbon from mycorrhizal fungi, in addition to their photosynthetic intake.\n\nMyco-heterotrophs are found among a number of plant groups. All monotropes and non-photosynthetic orchids are full myco-heterotrophs, as is the non-photosynthetic liverwort \"Cryptothallus\". Partial myco-heterotrophy is common in the Gentian family, with a few genera such as \"Voyria\" being fully myco-heterotrophic; in photosynthetic orchids; and in a number of other plant groups. Some ferns and clubmosses have myco-heterotrophic gametophyte stages. The fungi that are parasitized by myco-heterotrophs are typically fungi with large energy reserves to draw on, usually mycorrhizal fungi, though there is some evidence that they may also parasitize parasitic fungi that form extensive mycelial networks, such as \"Armillaria\".\nExamples of fungi parasitized by myco-heterotrophic plants can be found among the ectomycorrhizal, arbuscular mycorrhizal, and orchid mycorrhizal fungi. The great diversity in unrelated plant families with myco-heterotrophic members, as well as the diversity of fungi targeted by myco-heterotrophs, suggests multiple parallel evolution of myco-heterotrophs from mycorrhizal ancestors.\n\n", "id": "5224295", "title": "Myco-heterotrophy"}
{"url": "https://en.wikipedia.org/wiki?curid=9630", "text": "Ecology\n\nEcology (from , \"house\", or \"environment\"; -λογία, \"study of\") is the scientific study of interactions among organisms and their environment. It is an interdisciplinary field that straddles biology, geography, and Earth science. Objects of study include interactions of organisms with each other and with abiotic components of their environment. Topics of interest include the biodiversity, distribution, biomass, and populations of organisms, as well as cooperation and competition within and between species. Ecosystems are dynamically interacting systems of organisms, the communities they make up, and the non-living components of their environment. Ecosystem processes, such as primary production, pedogenesis, nutrient cycling, and niche construction, regulate the flux of energy and matter through an environment. These processes are sustained by organisms with specific life history traits. Biodiversity means the varieties of species, genes, and ecosystems, enhances certain ecosystem services.\n\nEcology is not synonymous with environmentalism, natural history, or environmental science. It overlaps with the closely related sciences of evolutionary biology, genetics, and ethology. An important focus for ecologists is to improve the understanding of how biodiversity affects ecological function. Ecologists seek to explain:\n\n\nEcology has practical applications in conservation biology, wetland management, natural resource management (agroecology, agriculture, forestry, agroforestry, fisheries), city planning (urban ecology), community health, economics, basic and applied science, and human social interaction (human ecology). For example, the \"Circles of Sustainability\" approach treats ecology as more than the environment 'out there'. It is not treated as separate from humans. Organisms (including humans) and resources compose ecosystems which, in turn, maintain biophysical feedback mechanisms that moderate processes acting on living (biotic) and non-living (abiotic) components of the planet. Ecosystems sustain life-supporting functions and produce natural capital like biomass production (food, fuel, fiber, and medicine), the regulation of climate, global biogeochemical cycles, water filtration, soil formation, erosion control, flood protection, and many other natural features of scientific, historical, economic, or intrinsic value.\n\nThe word \"ecology\" (\"Ökologie\") was coined in 1866 by the German scientist Ernst Haeckel. Ecological thought is derivative of established currents in philosophy, particularly from ethics and politics. Ancient Greek philosophers such as Hippocrates and Aristotle laid the foundations of ecology in their studies on natural history. Modern ecology became a much more rigorous science in the late 19th century. Evolutionary concepts relating to adaptation and natural selection became the cornerstones of modern ecological theory.\n\nThe scope of ecology contains a wide array of interacting levels of organization spanning micro-level (e.g., cells) to a planetary scale (e.g., biosphere) phenomena. Ecosystems, for example, contain abiotic resources and interacting life forms (i.e., individual organisms that aggregate into populations which aggregate into distinct ecological communities). Ecosystems are dynamic, they do not always follow a linear successional path, but they are always changing, sometimes rapidly and sometimes so slowly that it can take thousands of years for ecological processes to bring about certain successional stages of a forest. An ecosystem's area can vary greatly, from tiny to vast. A single tree is of little consequence to the classification of a forest ecosystem, but critically relevant to organisms living in and on it. Several generations of an aphid population can exist over the lifespan of a single leaf. Each of those aphids, in turn, support diverse bacterial communities. The nature of connections in ecological communities cannot be explained by knowing the details of each species in isolation, because the emergent pattern is neither revealed nor predicted until the ecosystem is studied as an integrated whole. Some ecological principles, however, do exhibit collective properties where the sum of the components explain the properties of the whole, such as birth rates of a population being equal to the sum of individual births over a designated time frame.\n\nThe scale of ecological dynamics can operate like a closed system, such as aphids migrating on a single tree, while at the same time remain open with regard to broader scale influences, such as atmosphere or climate. Hence, ecologists classify ecosystems hierarchically by analyzing data collected from finer scale units, such as vegetation associations, climate, and soil types, and integrate this information to identify emergent patterns of uniform organization and processes that operate on local to regional, landscape, and chronological scales.\n\nTo structure the study of ecology into a conceptually manageable framework, the biological world is organized into a nested hierarchy, ranging in scale from genes, to cells, to tissues, to organs, to organisms, to species, to populations, to communities, to ecosystems, to biomes, and up to the level of the biosphere. This framework forms a panarchy and exhibits non-linear behaviors; this means that \"effect and cause are disproportionate, so that small changes to critical variables, such as the number of nitrogen fixers, can lead to disproportionate, perhaps irreversible, changes in the system properties.\"\n\nBiodiversity (an abbreviation of \"biological diversity\") describes the diversity of life from genes to ecosystems and spans every level of biological organization. The term has several interpretations, and there are many ways to index, measure, characterize, and represent its complex organization. Biodiversity includes species diversity, ecosystem diversity, and genetic diversity and scientists are interested in the way that this diversity affects the complex ecological processes operating at and among these respective levels. Biodiversity plays an important role in ecosystem services which by definition maintain and improve human quality of life. Conservation priorities and management techniques require different approaches and considerations to address the full ecological scope of biodiversity. Natural capital that supports populations is critical for maintaining ecosystem services and species migration (e.g., riverine fish runs and avian insect control) has been implicated as one mechanism by which those service losses are experienced. An understanding of biodiversity has practical applications for species and ecosystem-level conservation planners as they make management recommendations to consulting firms, governments, and industry.\n\nThe habitat of a species describes the environment over which a species is known to occur and the type of community that is formed as a result. More specifically, \"habitats can be defined as regions in environmental space that are composed of multiple dimensions, each representing a biotic or abiotic environmental variable; that is, any component or characteristic of the environment related directly (e.g. forage biomass and quality) or indirectly (e.g. elevation) to the use of a location by the animal.\" For example, a habitat might be an aquatic or terrestrial environment that can be further categorized as a montane or alpine ecosystem. Habitat shifts provide important evidence of competition in nature where one population changes relative to the habitats that most other individuals of the species occupy. For example, one population of a species of tropical lizards (\"Tropidurus hispidus\") has a flattened body relative to the main populations that live in open savanna. The population that lives in an isolated rock outcrop hides in crevasses where its flattened body offers a selective advantage. Habitat shifts also occur in the developmental life history of amphibians, and in insects that transition from aquatic to terrestrial habitats. Biotope and habitat are sometimes used interchangeably, but the former applies to a community's environment, whereas the latter applies to a species' environment.\n\nAdditionally, some species are ecosystem engineers, altering the environment within a localized region. For instance, beavers manage water levels by building dams which improves their habitat in a landscape.\n\nDefinitions of the niche date back to 1917, but G. Evelyn Hutchinson made conceptual advances in 1957 by introducing a widely adopted definition: \"the set of biotic and abiotic conditions in which a species is able to persist and maintain stable population sizes.\" The ecological niche is a central concept in the ecology of organisms and is sub-divided into the \"fundamental\" and the \"realized\" niche. The fundamental niche is the set of environmental conditions under which a species is able to persist. The realized niche is the set of environmental plus ecological conditions under which a species persists. The Hutchinsonian niche is defined more technically as a \"Euclidean hyperspace whose \"dimensions\" are defined as environmental variables and whose \"size\" is a function of the number of values that the environmental values may assume for which an organism has \"positive fitness\".\"\n\nBiogeographical patterns and range distributions are explained or predicted through knowledge of a species' traits and niche requirements. Species have functional traits that are uniquely adapted to the ecological niche. A trait is a measurable property, phenotype, or characteristic of an organism that may influence its survival. Genes play an important role in the interplay of development and environmental expression of traits. Resident species evolve traits that are fitted to the selection pressures of their local environment. This tends to afford them a competitive advantage and discourages similarly adapted species from having an overlapping geographic range. The competitive exclusion principle states that two species cannot coexist indefinitely by living off the same limiting resource; one will always out-compete the other. When similarly adapted species overlap geographically, closer inspection reveals subtle ecological differences in their habitat or dietary requirements. Some models and empirical studies, however, suggest that disturbances can stabilize the co-evolution and shared niche occupancy of similar species inhabiting species-rich communities. The habitat plus the niche is called the ecotope, which is defined as the full range of environmental and biological variables affecting an entire species.\n\nOrganisms are subject to environmental pressures, but they also modify their habitats. The regulatory feedback between organisms and their environment can affect conditions from local (e.g., a beaver pond) to global scales, over time and even after death, such as decaying logs or silica skeleton deposits from marine organisms. The process and concept of ecosystem engineering is related to niche construction, but the former relates only to the physical modifications of the habitat whereas the latter also considers the evolutionary implications of physical changes to the environment and the feedback this causes on the process of natural selection. Ecosystem engineers are defined as: \"organisms that directly or indirectly modulate the availability of resources to other species, by causing physical state changes in biotic or abiotic materials. In so doing they modify, maintain and create habitats.\"\n\nThe ecosystem engineering concept has stimulated a new appreciation for the influence that organisms have on the ecosystem and evolutionary process. The term \"niche construction\" is more often used in reference to the under-appreciated feedback mechanisms of natural selection imparting forces on the abiotic niche. An example of natural selection through ecosystem engineering occurs in the nests of social insects, including ants, bees, wasps, and termites. There is an emergent homeostasis or homeorhesis in the structure of the nest that regulates, maintains and defends the physiology of the entire colony. Termite mounds, for example, maintain a constant internal temperature through the design of air-conditioning chimneys. The structure of the nests themselves are subject to the forces of natural selection. Moreover, a nest can survive over successive generations, so that progeny inherit both genetic material and a legacy niche that was constructed before their time.\n\nBiomes are larger units of organization that categorize regions of the Earth's ecosystems, mainly according to the structure and composition of vegetation. There are different methods to define the continental boundaries of biomes dominated by different functional types of vegetative communities that are limited in distribution by climate, precipitation, weather and other environmental variables. Biomes include tropical rainforest, temperate broadleaf and mixed forest, temperate deciduous forest, taiga, tundra, hot desert, and polar desert. Other researchers have recently categorized other biomes, such as the human and oceanic microbiomes. To a microbe, the human body is a habitat and a landscape. Microbiomes were discovered largely through advances in molecular genetics, which have revealed a hidden richness of microbial diversity on the planet. The oceanic microbiome plays a significant role in the ecological biogeochemistry of the planet's oceans.\n\nThe largest scale of ecological organization is the biosphere: the total sum of ecosystems on the planet. Ecological relationships regulate the flux of energy, nutrients, and climate all the way up to the planetary scale. For example, the dynamic history of the planetary atmosphere's CO and O composition has been affected by the biogenic flux of gases coming from respiration and photosynthesis, with levels fluctuating over time in relation to the ecology and evolution of plants and animals. Ecological theory has also been used to explain self-emergent regulatory phenomena at the planetary scale: for example, the Gaia hypothesis is an example of holism applied in ecological theory. The Gaia hypothesis states that there is an emergent feedback loop generated by the metabolism of living organisms that maintains the core temperature of the Earth and atmospheric conditions within a narrow self-regulating range of tolerance.\n\nUnderstanding traits of individual organisms helps explain patterns and processes at other levels of organization including populations, communities, and ecosystems. Several areas of ecology of evolution that focus on such traits are life history theory, ecophysiology, metabolic theory of ecology, and Ethology. Examples of such traits include features of an organisms life cycle such as age to maturity, life span, or metabolic costs of reproduction. Other traits may be related to structure, such as the spines of a cactus or dorsal spines of a bluegill sunfish, or behaviors such as courtship displays or pair bonding. Other traits include emergent properties that are the result at least in part of interactions with the surrounding environment such as growth rate, resource uptake rate, winter, and deciduous vs. drought deciduous trees and shrubs.\n\nOne set of characteristics relate to body size and temperature. The metabolic theory of ecology provides a predictive qualitative set of relationships between an organism’s body size and temperature and metabolic processes. In general, smaller, warmer organisms have higher metabolic rates and this results in a variety of predictions regarding individual somatic growth rates, reproduction and population growth rates, population size, and resource uptake rates.\n\nThe traits of organisms are subject to change through acclimation, development, and evolution. For this reason, individuals form a shared focus for ecology and for evolutionary ecology.\n\nPopulation ecology studies the dynamics of species populations and how these populations interact with the wider environment. A population consists of individuals of the same species that live, interact, and migrate through the same niche and habitat.\n\nA primary law of population ecology is the Malthusian growth model which states, \"a population will grow (or decline) exponentially as long as the environment experienced by all individuals in the population remains constant.\" Simplified population models usually start with four variables: death, birth, immigration, and emigration.\n\nAn example of an introductory population model describes a closed population, such as on an island, where immigration and emigration does not take place. Hypotheses are evaluated with reference to a null hypothesis which states that random processes create the observed data. In these island models, the rate of population change is described by:\n\nwhere \"N\" is the total number of individuals in the population, \"b\" and \"d\" are the per capita rates of birth and death respectively, and \"r\" is the per capita rate of population change.\n\nUsing these modelling techniques, Malthus' population principle of growth was later transformed into a model known as the logistic equation:\n\nwhere \"N\" is the number of individuals measured as biomass density, \"a\" is the maximum per-capita rate of change, and \"K\" is the carrying capacity of the population. The formula states that the rate of change in population size (\"dN/dT\") is equal to growth (\"aN\") that is limited by carrying capacity (1 – \"N\"/\"K\").\n\nPopulation ecology builds upon these introductory models to further understand demographic processes in real study populations. Commonly used types of data include life history, fecundity, and survivorship, and these are analysed using mathematical techniques such as matrix algebra. The information is used for managing wildlife stocks and setting harvest quotas. In cases where basic models are insufficient, ecologists may adopt different kinds of statistical methods, such as the Akaike information criterion, or use models that can become mathematically complex as \"several competing hypotheses are simultaneously confronted with the data.\"\n\nThe concept of metapopulations was defined in 1969 as \"a population of populations which go extinct locally and recolonize\". Metapopulation ecology is another statistical approach that is often used in conservation research. Metapopulation models simplify the landscape into patches of varying levels of quality, and metapopulations are linked by the migratory behaviours of organisms. Animal migration is set apart from other kinds of movement; because, it involves the seasonal departure and return of individuals from a habitat. Migration is also a population-level phenomenon, as with the migration routes followed by plants as they occupied northern post-glacial environments. Plant ecologists use pollen records that accumulate and stratify in wetlands to reconstruct the timing of plant migration and dispersal relative to historic and contemporary climates. These migration routes involved an expansion of the range as plant populations expanded from one area to another. There is a larger taxonomy of movement, such as commuting, foraging, territorial behaviour, stasis, and ranging. Dispersal is usually distinguished from migration; because, it involves the one way permanent movement of individuals from their birth population into another population.\n\nIn metapopulation terminology, migrating individuals are classed as emigrants (when they leave a region) or immigrants (when they enter a region), and sites are classed either as sources or sinks. A site is a generic term that refers to places where ecologists sample populations, such as ponds or defined sampling areas in a forest. Source patches are productive sites that generate a seasonal supply of juveniles that migrate to other patch locations. Sink patches are unproductive sites that only receive migrants; the population at the site will disappear unless rescued by an adjacent source patch or environmental conditions become more favourable. Metapopulation models examine patch dynamics over time to answer potential questions about spatial and demographic ecology. The ecology of metapopulations is a dynamic process of extinction and colonization. Small patches of lower quality (i.e., sinks) are maintained or rescued by a seasonal influx of new immigrants. A dynamic metapopulation structure evolves from year to year, where some patches are sinks in dry years and are sources when conditions are more favourable. Ecologists use a mixture of computer models and field studies to explain metapopulation structure.\n\nCommunity ecology is the study of the interactions among a collections of species that inhabit the same geographic area. Community ecologists study the determinants of patterns and processes for two or more interacting species. Research in community ecology might measure species diversity in grasslands in relation to soil fertility. It might also include the analysis of predator-prey dynamics, competition among similar plant species, or mutualistic interactions between crabs and corals.\n\nEcosystems may be habitats within biomes that form an integrated whole and a dynamically responsive system having both physical and biological complexes. Ecosystem ecology is the science of determining the fluxes of materials (e.g. carbon, phosphorus) between different pools (e.g., tree biomass, soil organic material). Ecosystem ecologist attempt to determine the underlying causes of these fluxes. Research in ecosystem ecology might measure primary production (g C/m^2) in a wetland in relation to decomposition and consumption rates (g C/m^2/y). This requires an understanding of the community connections between plants (i.e., primary producers) and the decomposers (e.g., fungi and bacteria),\n\nThe underlying concept of ecosystem can be traced back to 1864 in the published work of George Perkins Marsh (\"Man and Nature\"). Within an ecosystem, organisms are linked to the physical and biological components of their environment to which they are adapted. Ecosystems are complex adaptive systems where the interaction of life processes form self-organizing patterns across different scales of time and space. Ecosystems are broadly categorized as terrestrial, freshwater, atmospheric, or marine. Differences stem from the nature of the unique physical environments that shapes the biodiversity within each. A more recent addition to ecosystem ecology are technoecosystems, which are affected by or primarily the result of human activity.\n\nA food web is the archetypal ecological network. Plants capture solar energy and use it to synthesize simple sugars during photosynthesis. As plants grow, they accumulate nutrients and are eaten by grazing herbivores, and the energy is transferred through a chain of organisms by consumption. The simplified linear feeding pathways that move from a basal trophic species to a top consumer is called the food chain. The larger interlocking pattern of food chains in an ecological community creates a complex food web. Food webs are a type of concept map or a heuristic device that is used to illustrate and study pathways of energy and material flows.\n\nFood webs are often limited relative to the real world. Complete empirical measurements are generally restricted to a specific habitat, such as a cave or a pond, and principles gleaned from food web microcosm studies are extrapolated to larger systems. Feeding relations require extensive investigations into the gut contents of organisms, which can be difficult to decipher, or stable isotopes can be used to trace the flow of nutrient diets and energy through a food web. Despite these limitations, food webs remain a valuable tool in understanding community ecosystems.\n\nFood webs exhibit principles of ecological emergence through the nature of trophic relationships: some species have many weak feeding links (e.g., omnivores) while some are more specialized with fewer stronger feeding links (e.g., primary predators). Theoretical and empirical studies identify non-random emergent patterns of few strong and many weak linkages that explain how ecological communities remain stable over time. Food webs are composed of subgroups where members in a community are linked by strong interactions, and the weak interactions occur between these subgroups. This increases food web stability. Step by step lines or relations are drawn until a web of life is illustrated.\n\nA trophic level (from Greek \"troph\", τροφή, trophē, meaning \"food\" or \"feeding\") is \"a group of organisms acquiring a considerable majority of its energy from the adjacent level nearer the abiotic source.\" Links in food webs primarily connect feeding relations or trophism among species. Biodiversity within ecosystems can be organized into trophic pyramids, in which the vertical dimension represents feeding relations that become further removed from the base of the food chain up toward top predators, and the horizontal dimension represents the abundance or biomass at each level. When the relative abundance or biomass of each species is sorted into its respective trophic level, they naturally sort into a 'pyramid of numbers'.\n\nSpecies are broadly categorized as autotrophs (or primary producers), heterotrophs (or consumers), and Detritivores (or decomposers). Autotrophs are organisms that produce their own food (production is greater than respiration) by photosynthesis or chemosynthesis. Heterotrophs are organisms that must feed on others for nourishment and energy (respiration exceeds production). Heterotrophs can be further sub-divided into different functional groups, including primary consumers (strict herbivores), secondary consumers (carnivorous predators that feed exclusively on herbivores), and tertiary consumers (predators that feed on a mix of herbivores and predators). Omnivores do not fit neatly into a functional category because they eat both plant and animal tissues. It has been suggested that omnivores have a greater functional influence as predators, because compared to herbivores, they are relatively inefficient at grazing.\n\nTrophic levels are part of the holistic or complex systems view of ecosystems. Each trophic level contains unrelated species that are grouped together because they share common ecological functions, giving a macroscopic view of the system. While the notion of trophic levels provides insight into energy flow and top-down control within food webs, it is troubled by the prevalence of omnivory in real ecosystems. This has led some ecologists to \"reiterate that the notion that species clearly aggregate into discrete, homogeneous trophic levels is fiction.\" Nonetheless, recent studies have shown that real trophic levels do exist, but \"above the herbivore trophic level, food webs are better characterized as a tangled web of omnivores.\"\nA keystone species is a species that is connected to a disproportionately large number of other species in the food-web. Keystone species have lower levels of biomass in the trophic pyramid relative to the importance of their role. The many connections that a keystone species holds means that it maintains the organization and structure of entire communities. The loss of a keystone species results in a range of dramatic cascading effects that alters trophic dynamics, other food web connections, and can cause the extinction of other species.\n\nSea otters (\"Enhydra lutris\") are commonly cited as an example of a keystone species; because, they limit the density of sea urchins that feed on kelp. If sea otters are removed from the system, the urchins graze until the kelp beds disappear, and this has a dramatic effect on community structure. Hunting of sea otters, for example, is thought to have led indirectly to the extinction of the Steller's sea cow (\"Hydrodamalis gigas\"). While the keystone species concept has been used extensively as a conservation tool, it has been criticized for being poorly defined from an operational stance. It is difficult to experimentally determine what species may hold a keystone role in each ecosystem. Furthermore, food web theory suggests that keystone species may not be common, so it is unclear how generally the keystone species model can be applied.\n\nComplexity is understood as a large computational effort needed to piece together numerous interacting parts exceeding the iterative memory capacity of the human mind. Global patterns of biological diversity are complex. This biocomplexity stems from the interplay among ecological processes that operate and influence patterns at different scales that grade into each other, such as transitional areas or ecotones spanning landscapes. Complexity stems from the interplay among levels of biological organization as energy, and matter is integrated into larger units that superimpose onto the smaller parts. \"What were wholes on one level become parts on a higher one.\" Small scale patterns do not necessarily explain large scale phenomena, otherwise captured in the expression (coined by Aristotle) 'the sum is greater than the parts'.\n\n\"Complexity in ecology is of at least six distinct types: spatial, temporal, structural, process, behavioral, and geometric.\" From these principles, ecologists have identified emergent and self-organizing phenomena that operate at different environmental scales of influence, ranging from molecular to planetary, and these require different explanations at each integrative level. Ecological complexity relates to the dynamic resilience of ecosystems that transition to multiple shifting steady-states directed by random fluctuations of history. Long-term ecological studies provide important track records to better understand the complexity and resilience of ecosystems over longer temporal and broader spatial scales. These studies are managed by the International Long Term Ecological Network (LTER). The longest experiment in existence is the Park Grass Experiment, which was initiated in 1856. Another example is the Hubbard Brook study, which has been in operation since 1960.\n\nHolism remains a critical part of the theoretical foundation in contemporary ecological studies. Holism addresses the biological organization of life that self-organizes into layers of emergent whole systems that function according to non-reducible properties. This means that higher order patterns of a whole functional system, such as an ecosystem, cannot be predicted or understood by a simple summation of the parts. \"New properties emerge because the components interact, not because the basic nature of the components is changed.\"\n\nEcological studies are necessarily holistic as opposed to reductionistic. Holism has three scientific meanings or uses that identify with ecology: 1) the mechanistic complexity of ecosystems, 2) the practical description of patterns in quantitative reductionist terms where correlations may be identified but nothing is understood about the causal relations without reference to the whole system, which leads to 3) a metaphysical hierarchy whereby the causal relations of larger systems are understood without reference to the smaller parts. Scientific holism differs from mysticism that has appropriated the same term. An example of metaphysical holism is identified in the trend of increased exterior thickness in shells of different species. The reason for a thickness increase can be understood through reference to principles of natural selection via predation without need to reference or understand the biomolecular properties of the exterior shells.\n\nEcology and evolutionary biology are considered sister disciplines of the life sciences. Natural selection, life history, development, adaptation, populations, and inheritance are examples of concepts that thread equally into ecological and evolutionary theory. Morphological, behavioural, and genetic traits, for example, can be mapped onto evolutionary trees to study the historical development of a species in relation to their functions and roles in different ecological circumstances. In this framework, the analytical tools of ecologists and evolutionists overlap as they organize, classify, and investigate life through common systematic principals, such as phylogenetics or the Linnaean system of taxonomy. The two disciplines often appear together, such as in the title of the journal \"Trends in Ecology and Evolution\". There is no sharp boundary separating ecology from evolution, and they differ more in their areas of applied focus. Both disciplines discover and explain emergent and unique properties and processes operating across different spatial or temporal scales of organization. While the boundary between ecology and evolution is not always clear, ecologists study the abiotic and biotic factors that influence evolutionary processes, and evolution can be rapid, occurring on ecological timescales as short as one generation.\n\nAll organisms can exhibit behaviours. Even plants express complex behaviour, including memory and communication. Behavioural ecology is the study of an organism's behaviour in its environment and its ecological and evolutionary implications. Ethology is the study of observable movement or behaviour in animals. This could include investigations of motile sperm of plants, mobile phytoplankton, zooplankton swimming toward the female egg, the cultivation of fungi by weevils, the mating dance of a salamander, or social gatherings of amoeba.\n\nAdaptation is the central unifying concept in behavioural ecology. Behaviours can be recorded as traits and inherited in much the same way that eye and hair colour can. Behaviours can evolve by means of natural selection as adaptive traits conferring functional utilities that increases reproductive fitness.\n\nPredator-prey interactions are an introductory concept into food-web studies as well as behavioural ecology. Prey species can exhibit different kinds of behavioural adaptations to predators, such as avoid, flee, or defend. Many prey species are faced with multiple predators that differ in the degree of danger posed. To be adapted to their environment and face predatory threats, organisms must balance their energy budgets as they invest in different aspects of their life history, such as growth, feeding, mating, socializing, or modifying their habitat. Hypotheses posited in behavioural ecology are generally based on adaptive principles of conservation, optimization, or efficiency. For example, \"[t]he threat-sensitive predator avoidance hypothesis predicts that prey should assess the degree of threat posed by different predators and match their behaviour according to current levels of risk\" or \"[t]he optimal flight initiation distance occurs where expected postencounter fitness is maximized, which depends on the prey's initial fitness, benefits obtainable by not fleeing, energetic escape costs, and expected fitness loss due to predation risk.\"\n\nElaborate sexual displays and posturing are encountered in the behavioural ecology of animals. The birds-of-paradise, for example, sing and display elaborate ornaments during courtship. These displays serve a dual purpose of signalling healthy or well-adapted individuals and desirable genes. The displays are driven by sexual selection as an advertisement of quality of traits among suitors.\n\nCognitive ecology integrates theory and observations from evolutionary ecology and neurobiology, primarily cognitive science, in order to understand the effect that animal interaction with their habitat has on their cognitive systems and how those systems restrict behavior within an ecological and evolutionary framework. \"Until recently, however, cognitive scientists have not paid sufficient attention to the fundamental fact that cognitive traits evolved under particular natural settings. With consideration of the selection pressure on cognition, cognitive ecology can contribute intellectual coherence to the multidisciplinary study of cognition.\" As a study involving the 'coupling' or interactions between organism and environment, cognitive ecology is closely related to enactivism, a field based upon the view that \"...we must see the organism and environment as bound together in reciprocal specification and selection...\".\n\nSocial ecological behaviours are notable in the social insects, slime moulds, social spiders, human society, and naked mole-rats where eusocialism has evolved. Social behaviours include reciprocally beneficial behaviours among kin and nest mates and evolve from kin and group selection. Kin selection explains altruism through genetic relationships, whereby an altruistic behaviour leading to death is rewarded by the survival of genetic copies distributed among surviving relatives. The social insects, including ants, bees, and wasps are most famously studied for this type of relationship because the male drones are clones that share the same genetic make-up as every other male in the colony. In contrast, group selectionists find examples of altruism among non-genetic relatives and explain this through selection acting on the group; whereby, it becomes selectively advantageous for groups if their members express altruistic behaviours to one another. Groups with predominantly altruistic members beat groups with predominantly selfish members.\n\nEcological interactions can be classified broadly into a host and an associate relationship. A host is any entity that harbours another that is called the associate. Relationships within a species that are mutually or reciprocally beneficial are called mutualisms. Examples of mutualism include fungus-growing ants employing agricultural symbiosis, bacteria living in the guts of insects and other organisms, the fig wasp and yucca moth pollination complex, lichens with fungi and photosynthetic algae, and corals with photosynthetic algae. If there is a physical connection between host and associate, the relationship is called symbiosis. Approximately 60% of all plants, for example, have a symbiotic relationship with arbuscular mycorrhizal fungi living in their roots forming an exchange network of carbohydrates for mineral nutrients.\n\nIndirect mutualisms occur where the organisms live apart. For example, trees living in the equatorial regions of the planet supply oxygen into the atmosphere that sustains species living in distant polar regions of the planet. This relationship is called commensalism; because, many others receive the benefits of clean air at no cost or harm to trees supplying the oxygen. If the associate benefits while the host suffers, the relationship is called parasitism. Although parasites impose a cost to their host (e.g., via damage to their reproductive organs or propagules, denying the services of a beneficial partner), their net effect on host fitness is not necessarily negative and, thus, becomes difficult to forecast. Co-evolution is also driven by competition among species or among members of the same species under the banner of reciprocal antagonism, such as grasses competing for growth space. The Red Queen Hypothesis, for example, posits that parasites track down and specialize on the locally common genetic defense systems of its host that drives the evolution of sexual reproduction to diversify the genetic constituency of populations responding to the antagonistic pressure.\n\nBiogeography (an amalgamation of \"biology\" and \"geography\") is the comparative study of the geographic distribution of organisms and the corresponding evolution of their traits in space and time. The \"Journal of Biogeography\" was established in 1974. Biogeography and ecology share many of their disciplinary roots. For example, the theory of island biogeography, published by the Robert MacArthur and Edward O. Wilson in 1967 is considered one of the fundamentals of ecological theory.\n\nBiogeography has a long history in the natural sciences concerning the spatial distribution of plants and animals. Ecology and evolution provide the explanatory context for biogeographical studies. Biogeographical patterns result from ecological processes that influence range distributions, such as migration and dispersal. and from historical processes that split populations or species into different areas. The biogeographic processes that result in the natural splitting of species explains much of the modern distribution of the Earth's biota. The splitting of lineages in a species is called vicariance biogeography and it is a sub-discipline of biogeography. There are also practical applications in the field of biogeography concerning ecological systems and processes. For example, the range and distribution of biodiversity and invasive species responding to climate change is a serious concern and active area of research in the context of global warming.\n\nA population ecology concept is r/K selection theory, one of the first predictive models in ecology used to explain life-history evolution. The premise behind the r/K selection model is that natural selection pressures change according to population density. For example, when an island is first colonized, density of individuals is low. The initial increase in population size is not limited by competition, leaving an abundance of available resources for rapid population growth. These early phases of population growth experience \"density-independent\" forces of natural selection, which is called \"r\"-selection. As the population becomes more crowded, it approaches the island's carrying capacity, thus forcing individuals to compete more heavily for fewer available resources. Under crowded conditions, the population experiences density-dependent forces of natural selection, called \"K\"-selection.\n\nIn the \"r/K\"-selection model, the first variable \"r\" is the intrinsic rate of natural increase in population size and the second variable \"K\" is the carrying capacity of a population. Different species evolve different life-history strategies spanning a continuum between these two selective forces. An \"r\"-selected species is one that has high birth rates, low levels of parental investment, and high rates of mortality before individuals reach maturity. Evolution favours high rates of fecundity in \"r\"-selected species. Many kinds of insects and invasive species exhibit \"r\"-selected characteristics. In contrast, a \"K\"-selected species has low rates of fecundity, high levels of parental investment in the young, and low rates of mortality as individuals mature. Humans and elephants are examples of species exhibiting \"K\"-selected characteristics, including longevity and efficiency in the conversion of more resources into fewer offspring.\n\nThe important relationship between ecology and genetic inheritance predates modern techniques for molecular analysis. Molecular ecological research became more feasible with the development of rapid and accessible genetic technologies, such as the polymerase chain reaction (PCR). The rise of molecular technologies and influx of research questions into this new ecological field resulted in the publication \"Molecular Ecology\" in 1992. Molecular ecology uses various analytical techniques to study genes in an evolutionary and ecological context. In 1994, John Avise also played a leading role in this area of science with the publication of his book, \"Molecular Markers, Natural History and Evolution\". Newer technologies opened a wave of genetic analysis into organisms once difficult to study from an ecological or evolutionary standpoint, such as bacteria, fungi, and nematodes. Molecular ecology engendered a new research paradigm for investigating ecological questions considered otherwise intractable. Molecular investigations revealed previously obscured details in the tiny intricacies of nature and improved resolution into probing questions about behavioural and biogeographical ecology. For example, molecular ecology revealed promiscuous sexual behaviour and multiple male partners in tree swallows previously thought to be socially monogamous. In a biogeographical context, the marriage between genetics, ecology, and evolution resulted in a new sub-discipline called phylogeography.\n\nEcology is as much a biological science as it is a human science. Human ecology is an interdisciplinary investigation into the ecology of our species. \"Human ecology may be defined: (1) from a bioecological standpoint as the study of man as the ecological dominant in plant and animal communities and systems; (2) from a bioecological standpoint as simply another animal affecting and being affected by his physical environment; and (3) as a human being, somehow different from animal life in general, interacting with physical and modified environments in a distinctive and creative way. A truly interdisciplinary human ecology will most likely address itself to all three.\" The term was formally introduced in 1921, but many sociologists, geographers, psychologists, and other disciplines were interested in human relations to natural systems centuries prior, especially in the late 19th century.\n\nThe ecological complexities human beings are facing through the technological transformation of the planetary biome has brought on the Anthropocene. The unique set of circumstances has generated the need for a new unifying science called coupled human and natural systems that builds upon, but moves beyond the field of human ecology. Ecosystems tie into human societies through the critical and all encompassing life-supporting functions they sustain. In recognition of these functions and the incapability of traditional economic valuation methods to see the value in ecosystems, there has been a surge of interest in social-natural capital, which provides the means to put a value on the stock and use of information and materials stemming from ecosystem goods and services. Ecosystems produce, regulate, maintain, and supply services of critical necessity and beneficial to human health (cognitive and physiological), economies, and they even provide an information or reference function as a living library giving opportunities for science and cognitive development in children engaged in the complexity of the natural world. Ecosystems relate importantly to human ecology as they are the ultimate base foundation of global economics as every commodity, and the capacity for exchange ultimately stems from the ecosystems on Earth.\n\nEcology is an employed science of restoration, repairing disturbed sites through human intervention, in natural resource management, and in environmental impact assessments. Edward O. Wilson predicted in 1992 that the 21st century \"will be the era of restoration in ecology\". Ecological science has boomed in the industrial investment of restoring ecosystems and their processes in abandoned sites after disturbance. Natural resource managers, in forestry, for example, employ ecologists to develop, adapt, and implement ecosystem based methods into the planning, operation, and restoration phases of land-use. Ecological science is used in the methods of sustainable harvesting, disease, and fire outbreak management, in fisheries stock management, for integrating land-use with protected areas and communities, and conservation in complex geo-political landscapes.\n\nThe environment of ecosystems includes both physical parameters and biotic attributes. It is dynamically interlinked, and contains resources for organisms at any time throughout their life cycle. Like ecology, the term environment has different conceptual meanings and overlaps with the concept of nature. Environment \"includes the physical world, the social world of human relations and the built world of human creation.\" The physical environment is external to the level of biological organization under investigation, including abiotic factors such as temperature, radiation, light, chemistry, climate and geology. The biotic environment includes genes, cells, organisms, members of the same species (conspecifics) and other species that share a habitat.\n\nThe distinction between external and internal environments, however, is an abstraction parsing life and environment into units or facts that are inseparable in reality. There is an interpenetration of cause and effect between the environment and life. The laws of thermodynamics, for example, apply to ecology by means of its physical state. With an understanding of metabolic and thermodynamic principles, a complete accounting of energy and material flow can be traced through an ecosystem. In this way, the environmental and ecological relations are studied through reference to conceptually manageable and isolated material parts. After the effective environmental components are understood through reference to their causes; however, they conceptually link back together as an integrated whole, or \"holocoenotic\" system as it was once called. This is known as the dialectical approach to ecology. The dialectical approach examines the parts, but integrates the organism and the environment into a dynamic whole (or umwelt). Change in one ecological or environmental factor can concurrently affect the dynamic state of an entire ecosystem.\n\nEcosystems are regularly confronted with natural environmental variations and disturbances over time and geographic space. A disturbance is any process that removes biomass from a community, such as a fire, flood, drought, or predation. Disturbances occur over vastly different ranges in terms of magnitudes as well as distances and time periods, and are both the cause and product of natural fluctuations in death rates, species assemblages, and biomass densities within an ecological community. These disturbances create places of renewal where new directions emerge from the patchwork of natural experimentation and opportunity. Ecological resilience is a cornerstone theory in ecosystem management. Biodiversity fuels the resilience of ecosystems acting as a kind of regenerative insurance.\n\nThe Earth was formed approximately 4.5 billion years ago. As it cooled and a crust and oceans formed, its atmosphere transformed from being dominated by hydrogen to one composed mostly of methane and ammonia. Over the next billion years, the metabolic activity of life transformed the atmosphere into a mixture of carbon dioxide, nitrogen, and water vapor. These gases changed the way that light from the sun hit the Earth's surface and greenhouse effects trapped heat. There were untapped sources of free energy within the mixture of reducing and oxidizing gasses that set the stage for primitive ecosystems to evolve and, in turn, the atmosphere also evolved.\n\nThroughout history, the Earth's atmosphere and biogeochemical cycles have been in a dynamic equilibrium with planetary ecosystems. The history is characterized by periods of significant transformation followed by millions of years of stability. The evolution of the earliest organisms, likely anaerobic methanogen microbes, started the process by converting atmospheric hydrogen into methane (4H + CO → CH + 2HO). Anoxygenic photosynthesis reduced hydrogen concentrations and increased atmospheric methane, by converting hydrogen sulfide into water or other sulfur compounds (for example, 2HS + CO + h\"v\" → CHO + HO + 2S). Early forms of fermentation also increased levels of atmospheric methane. The transition to an oxygen-dominant atmosphere (the \"Great Oxidation\") did not begin until approximately 2.4–2.3 billion years ago, but photosynthetic processes started 0.3 to 1 billion years prior.\n\nThe biology of life operates within a certain range of temperatures. Heat is a form of energy that regulates temperature. Heat affects growth rates, activity, behaviour, and primary production. Temperature is largely dependent on the incidence of solar radiation. The latitudinal and longitudinal spatial variation of temperature greatly affects climates and consequently the distribution of biodiversity and levels of primary production in different ecosystems or biomes across the planet. Heat and temperature relate importantly to metabolic activity. Poikilotherms, for example, have a body temperature that is largely regulated and dependent on the temperature of the external environment. In contrast, homeotherms regulate their internal body temperature by expending metabolic energy.\n\nThere is a relationship between light, primary production, and ecological energy budgets. Sunlight is the primary input of energy into the planet's ecosystems. Light is composed of electromagnetic energy of different wavelengths. Radiant energy from the sun generates heat, provides photons of light measured as active energy in the chemical reactions of life, and also acts as a catalyst for genetic mutation. Plants, algae, and some bacteria absorb light and assimilate the energy through photosynthesis. Organisms capable of assimilating energy by photosynthesis or through inorganic fixation of HS are autotrophs. Autotrophs — responsible for primary production — assimilate light energy which becomes metabolically stored as potential energy in the form of biochemical enthalpic bonds.\n\nDiffusion of carbon dioxide and oxygen is approximately 10,000 times slower in water than in air. When soils are flooded, they quickly lose oxygen, becoming hypoxic (an environment with O concentration below 2 mg/liter) and eventually completely anoxic where anaerobic bacteria thrive among the roots. Water also influences the intensity and spectral composition of light as it reflects off the water surface and submerged particles. Aquatic plants exhibit a wide variety of morphological and physiological adaptations that allow them to survive, compete, and diversify in these environments. For example, their roots and stems contain large air spaces (aerenchyma) that regulate the efficient transportation of gases (for example, CO and O) used in respiration and photosynthesis. Salt water plants (halophytes) have additional specialized adaptations, such as the development of special organs for shedding salt and osmoregulating their internal salt (NaCl) concentrations, to live in estuarine, brackish, or oceanic environments. Anaerobic soil microorganisms in aquatic environments use nitrate, manganese ions, ferric ions, sulfate, carbon dioxide, and some organic compounds; other microorganisms are facultative anaerobes and use oxygen during respiration when the soil becomes drier. The activity of soil microorganisms and the chemistry of the water reduces the oxidation-reduction potentials of the water. Carbon dioxide, for example, is reduced to methane (CH) by methanogenic bacteria. The physiology of fish is also specially adapted to compensate for environmental salt levels through osmoregulation. Their gills form electrochemical gradients that mediate salt excretion in salt water and uptake in fresh water.\n\nThe shape and energy of the land is significantly affected by gravitational forces. On a large scale, the distribution of gravitational forces on the earth is uneven and influences the shape and movement of tectonic plates as well as influencing geomorphic processes such as orogeny and erosion. These forces govern many of the geophysical properties and distributions of ecological biomes across the Earth. On the organismal scale, gravitational forces provide directional cues for plant and fungal growth (gravitropism), orientation cues for animal migrations, and influence the biomechanics and size of animals. Ecological traits, such as allocation of biomass in trees during growth are subject to mechanical failure as gravitational forces influence the position and structure of branches and leaves. The cardiovascular systems of animals are functionally adapted to overcome pressure and gravitational forces that change according to the features of organisms (e.g., height, size, shape), their behaviour (e.g., diving, running, flying), and the habitat occupied (e.g., water, hot deserts, cold tundra).\n\nClimatic and osmotic pressure places physiological constraints on organisms, especially those that fly and respire at high altitudes, or dive to deep ocean depths. These constraints influence vertical limits of ecosystems in the biosphere, as organisms are physiologically sensitive and adapted to atmospheric and osmotic water pressure differences. For example, oxygen levels decrease with decreasing pressure and are a limiting factor for life at higher altitudes. Water transportation by plants is another important ecophysiological process affected by osmotic pressure gradients. Water pressure in the depths of oceans requires that organisms adapt to these conditions. For example, diving animals such as whales, dolphins, and seals are specially adapted to deal with changes in sound due to water pressure differences. Differences between hagfish species provide another example of adaptation to deep-sea pressure through specialized protein adaptations.\n\nTurbulent forces in air and water affect the environment and ecosystem distribution, form and dynamics. On a planetary scale, ecosystems are affected by circulation patterns in the global trade winds. Wind power and the turbulent forces it creates can influence heat, nutrient, and biochemical profiles of ecosystems. For example, wind running over the surface of a lake creates turbulence, mixing the water column and influencing the environmental profile to create thermally layered zones, affecting how fish, algae, and other parts of the aquatic ecosystem are structured. Wind speed and turbulence also influence evapotranspiration rates and energy budgets in plants and animals. Wind speed, temperature and moisture content can vary as winds travel across different land features and elevations. For example, the westerlies come into contact with the coastal and interior mountains of western North America to produce a rain shadow on the leeward side of the mountain. The air expands and moisture condenses as the winds increase in elevation; this is called orographic lift and can cause precipitation. This environmental process produces spatial divisions in biodiversity, as species adapted to wetter conditions are range-restricted to the coastal mountain valleys and unable to migrate across the xeric ecosystems (e.g., of the Columbia Basin in western North America) to intermix with sister lineages that are segregated to the interior mountain systems.\n\nPlants convert carbon dioxide into biomass and emit oxygen into the atmosphere. By approximately 350 million years ago (the end of the Devonian period), photosynthesis had brought the concentration of atmospheric oxygen above 17%, which allowed combustion to occur. Fire releases CO and converts fuel into ash and tar. Fire is a significant ecological parameter that raises many issues pertaining to its control and suppression. While the issue of fire in relation to ecology and plants has been recognized for a long time, Charles Cooper brought attention to the issue of forest fires in relation to the ecology of forest fire suppression and management in the 1960s.\n\nNative North Americans were among the first to influence fire regimes by controlling their spread near their homes or by lighting fires to stimulate the production of herbaceous foods and basketry materials. Fire creates a heterogeneous ecosystem age and canopy structure, and the altered soil nutrient supply and cleared canopy structure opens new ecological niches for seedling establishment. Most ecosystems are adapted to natural fire cycles. Plants, for example, are equipped with a variety of adaptations to deal with forest fires. Some species (e.g., \"Pinus halepensis\") cannot germinate until after their seeds have lived through a fire or been exposed to certain compounds from smoke. Environmentally triggered germination of seeds is called serotiny. Fire plays a major role in the persistence and resilience of ecosystems.\n\nSoil is the living top layer of mineral and organic dirt that covers the surface of the planet. It is the chief organizing centre of most ecosystem functions, and it is of critical importance in agricultural science and ecology. The decomposition of dead organic matter (for example, leaves on the forest floor), results in soils containing minerals and nutrients that feed into plant production. The whole of the planet's soil ecosystems is called the pedosphere where a large biomass of the Earth's biodiversity organizes into trophic levels. Invertebrates that feed and shred larger leaves, for example, create smaller bits for smaller organisms in the feeding chain. Collectively, these organisms are the detritivores that regulate soil formation. Tree roots, fungi, bacteria, worms, ants, beetles, centipedes, spiders, mammals, birds, reptiles, amphibians, and other less familiar creatures all work to create the trophic web of life in soil ecosystems. Soils form composite phenotypes where inorganic matter is enveloped into the physiology of a whole community. As organisms feed and migrate through soils they physically displace materials, an ecological process called bioturbation. This aerates soils and stimulates heterotrophic growth and production. Soil microorganisms are influenced by and feed back into the trophic dynamics of the ecosystem. No single axis of causality can be discerned to segregate the biological from geomorphological systems in soils. Paleoecological studies of soils places the origin for bioturbation to a time before the Cambrian period. Other events, such as the evolution of trees and the colonization of land in the Devonian period played a significant role in the early development of ecological trophism in soils.\n\nEcologists study and measure nutrient budgets to understand how these materials are regulated, flow, and recycled through the environment. This research has led to an understanding that there is global feedback between ecosystems and the physical parameters of this planet, including minerals, soil, pH, ions, water, and atmospheric gases. Six major elements (hydrogen, carbon, nitrogen, oxygen, sulfur, and phosphorus; H, C, N, O, S, and P) form the constitution of all biological macromolecules and feed into the Earth's geochemical processes. From the smallest scale of biology, the combined effect of billions upon billions of ecological processes amplify and ultimately regulate the biogeochemical cycles of the Earth. Understanding the relations and cycles mediated between these elements and their ecological pathways has significant bearing toward understanding global biogeochemistry.\n\nThe ecology of global carbon budgets gives one example of the linkage between biodiversity and biogeochemistry. It is estimated that the Earth's oceans hold 40,000 gigatonnes (Gt) of carbon, that vegetation and soil hold 2070 Gt, and that fossil fuel emissions are 6.3 Gt carbon per year. There have been major restructurings in these global carbon budgets during the Earth's history, regulated to a large extent by the ecology of the land. For example, through the early-mid Eocene volcanic outgassing, the oxidation of methane stored in wetlands, and seafloor gases increased atmospheric CO (carbon dioxide) concentrations to levels as high as 3500 ppm.\n\nIn the Oligocene, from twenty-five to thirty-two million years ago, there was another significant restructuring of the global carbon cycle as grasses evolved a new mechanism of photosynthesis, C photosynthesis, and expanded their ranges. This new pathway evolved in response to the drop in atmospheric CO concentrations below 550 ppm. The relative abundance and distribution of biodiversity alters the dynamics between organisms and their environment such that ecosystems can be both cause and effect in relation to climate change. Human-driven modifications to the planet's ecosystems (e.g., disturbance, biodiversity loss, agriculture) contributes to rising atmospheric greenhouse gas levels. Transformation of the global carbon cycle in the next century is projected to raise planetary temperatures, lead to more extreme fluctuations in weather, alter species distributions, and increase extinction rates. The effect of global warming is already being registered in melting glaciers, melting mountain ice caps, and rising sea levels. Consequently, species distributions are changing along waterfronts and in continental areas where migration patterns and breeding grounds are tracking the prevailing shifts in climate. Large sections of permafrost are also melting to create a new mosaic of flooded areas having increased rates of soil decomposition activity that raises methane (CH) emissions. There is concern over increases in atmospheric methane in the context of the global carbon cycle, because methane is a greenhouse gas that is 23 times more effective at absorbing long-wave radiation than CO on a 100-year time scale. Hence, there is a relationship between global warming, decomposition and respiration in soils and wetlands producing significant climate feedbacks and globally altered biogeochemical cycles.\n\nEcology has a complex origin, due in large part to its interdisciplinary nature. Ancient Greek philosophers such as Hippocrates and Aristotle were among the first to record observations on natural history. However, they viewed life in terms of essentialism, where species were conceptualized as static unchanging things while varieties were seen as aberrations of an idealized type. This contrasts against the modern understanding of ecological theory where varieties are viewed as the real phenomena of interest and having a role in the origins of adaptations by means of natural selection. Early conceptions of ecology, such as a balance and regulation in nature can be traced to Herodotus (died \"c\". 425 BC), who described one of the earliest accounts of mutualism in his observation of \"natural dentistry\". Basking Nile crocodiles, he noted, would open their mouths to give sandpipers safe access to pluck leeches out, giving nutrition to the sandpiper and oral hygiene for the crocodile. Aristotle was an early influence on the philosophical development of ecology. He and his student Theophrastus made extensive observations on plant and animal migrations, biogeography, physiology, and on their behaviour, giving an early analogue to the modern concept of an ecological niche.\n\nEcological concepts such as food chains, population regulation, and productivity were first developed in the 1700s, through the published works of microscopist Antoni van Leeuwenhoek (1632–1723) and botanist Richard Bradley (1688?–1732). Biogeographer Alexander von Humboldt (1769–1859) was an early pioneer in ecological thinking and was among the first to recognize ecological gradients, where species are replaced or altered in form along environmental gradients, such as a cline forming along a rise in elevation. Humboldt drew inspiration from Isaac Newton as he developed a form of \"terrestrial physics\". In Newtonian fashion, he brought a scientific exactitude for measurement into natural history and even alluded to concepts that are the foundation of a modern ecological law on species-to-area relationships. Natural historians, such as Humboldt, James Hutton, and Jean-Baptiste Lamarck (among others) laid the foundations of the modern ecological sciences. The term \"ecology\" () is of a more recent origin and was first coined by the German biologist Ernst Haeckel in his book \"Generelle Morphologie der Organismen\" (1866). Haeckel was a zoologist, artist, writer, and later in life a professor of comparative anatomy.\n\nOpinions differ on who was the founder of modern ecological theory. Some mark Haeckel's definition as the beginning; others say it was Eugenius Warming with the writing of Oecology of Plants: An Introduction to the Study of Plant Communities (1895), or Carl Linnaeus' principles on the economy of nature that matured in the early 18th century. Linnaeus founded an early branch of ecology that he called the economy of nature. His works influenced Charles Darwin, who adopted Linnaeus' phrase on the \"economy or polity of nature\" in \"The Origin of Species\". Linnaeus was the first to frame the balance of nature as a testable hypothesis. Haeckel, who admired Darwin's work, defined ecology in reference to the economy of nature, which has led some to question whether ecology and the economy of nature are synonymous.\n\nFrom Aristotle until Darwin, the natural world was predominantly considered static and unchanging. Prior to \"The Origin of Species\", there was little appreciation or understanding of the dynamic and reciprocal relations between organisms, their adaptations, and the environment. An exception is the 1789 publication \"Natural History of Selborne\" by Gilbert White (1720–1793), considered by some to be one of the earliest texts on ecology. While Charles Darwin is mainly noted for his treatise on evolution, he was one of the founders of soil ecology, and he made note of the first ecological experiment in \"The Origin of Species\". Evolutionary theory changed the way that researchers approached the ecological sciences.\n\nModern ecology is a young science that first attracted substantial scientific attention toward the end of the 19th century (around the same time that evolutionary studies were gaining scientific interest). The scientist Ellen Swallow Richards may have first introduced the term \"oekology\" (which eventually morphed into home economics) in the U.S. as early 1892.\n\nIn the early 20th century, ecology transitioned from a more descriptive form of natural history to a more analytical form of \"scientific natural history\". Frederic Clements published the first American ecology book in 1905, presenting the idea of plant communities as a superorganism. This publication launched a debate between ecological holism and individualism that lasted until the 1970s. Clements' superorganism concept proposed that ecosystems progress through regular and determined stages of seral development that are analogous to the developmental stages of an organism. The Clementsian paradigm was challenged by Henry Gleason, who stated that ecological communities develop from the unique and coincidental association of individual organisms. This perceptual shift placed the focus back onto the life histories of individual organisms and how this relates to the development of community associations.\n\nThe Clementsian superorganism theory was an overextended application of an idealistic form of holism. The term \"holism\" was coined in 1926 by Jan Christiaan Smuts, a South African general and polarizing historical figure who was inspired by Clements' superorganism concept. Around the same time, Charles Elton pioneered the concept of food chains in his classical book \"Animal Ecology\". Elton defined ecological relations using concepts of food chains, food cycles, and food size, and described numerical relations among different functional groups and their relative abundance. Elton's 'food cycle' was replaced by 'food web' in a subsequent ecological text. Alfred J. Lotka brought in many theoretical concepts applying thermodynamic principles to ecology.\n\nIn 1942, Raymond Lindeman wrote a landmark paper on the trophic dynamics of ecology, which was published posthumously after initially being rejected for its theoretical emphasis. Trophic dynamics became the foundation for much of the work to follow on energy and material flow through ecosystems. Robert MacArthur advanced mathematical theory, predictions, and tests in ecology in the 1950s, which inspired a resurgent school of theoretical mathematical ecologists. Ecology also has developed through contributions from other nations, including Russia's Vladimir Vernadsky and his founding of the biosphere concept in the 1920s and Japan's Kinji Imanishi and his concepts of harmony in nature and habitat segregation in the 1950s. Scientific recognition of contributions to ecology from non-English-speaking cultures is hampered by language and translation barriers.\n\nEcology surged in popular and scientific interest during the 1960–1970s environmental movement. There are strong historical and scientific ties between ecology, environmental management, and protection. The historical emphasis and poetic naturalistic writings advocating the protection of wild places by notable ecologists in the history of conservation biology, such as Aldo Leopold and Arthur Tansley, have been seen as far removed from urban centres where, it is claimed, the concentration of pollution and environmental degradation is located. Palamar (2008) notes an overshadowing by mainstream environmentalism of pioneering women in the early 1900s who fought for urban health ecology (then called euthenics) and brought about changes in environmental legislation. Women such as Ellen Swallow Richards and Julia Lathrop, among others, were precursors to the more popularized environmental movements after the 1950s.\n\nIn 1962, marine biologist and ecologist Rachel Carson's book \"Silent Spring\" helped to mobilize the environmental movement by alerting the public to toxic pesticides, such as DDT, bioaccumulating in the environment. Carson used ecological science to link the release of environmental toxins to human and ecosystem health. Since then, ecologists have worked to bridge their understanding of the degradation of the planet's ecosystems with environmental politics, law, restoration, and natural resources management.\n\n\n\n", "id": "9630", "title": "Ecology"}
{"url": "https://en.wikipedia.org/wiki?curid=644152", "text": "Environmental gradient\n\nAn environmental gradient is a gradual change in abiotic factors through space (or time). Environmental gradients can be related to factors such as altitude, temperature, depth, ocean proximity and soil humidity.\n\nSpecies abundances usually change along environmental gradients in a more or less predictive way. However, the species abundance along an environmental gradient is not only determined by the abiotic factor but, also by the change in the biotic interactions, like competition, along the environmental gradient.\n\nAt an ecotone, species abundances change relatively quickly compared to the environmental gradient.\n\nThe species distribution along environmental gradients has been studied intensively due to large databases of species presence data (e.g. GBIF)\n\nEnvironmental Gradients are linked to Connectivity and natural disturbance when considering river systems. A river restoration scheme must consider all of these factors before undertaking a program as these three factors are what leads to a larger biodiversity.\n\nEach species are not found in every type of habitat or in every part of the world. Within the environment there are multiple factors which affects organisms. The organisms in the polar region can not survive the climate at the equator.\n\nHuisman–Olff–Fresco models describe unimodal species responses over an environmental gradient.\n\n\n", "id": "644152", "title": "Environmental gradient"}
{"url": "https://en.wikipedia.org/wiki?curid=26956160", "text": "Priority effect\n\nIn ecology, a priority effect is the impact that a particular species can have on community development due to prior arrival at a site.\n\nThere are two basic types: \"inhibitory priority effects\" occur when a species that arrives first at a site negatively impacts a species that arrives later by reducing the availability of space or resources. \"Facilitative priority effects\" occur when a species that arrives first at a site alters abiotic or biotic conditions in ways that positively impact a species arriving later. Priority effects are a central and pervasive element of ecological community development. These effects have important implications for natural systems as well as ecological restoration efforts.\n\nEarly in the 20th century, Frederic Clements and other plant ecologists suggested that ecological communities develop in a linear, directional manner towards a final, stable end-point: the climax community. Clements indicated that a site's climax community would reflect local climate. He conceptualized the climax community as a \"superorganism\" that followed a defined developmental sequence.\n\nEarly ecological succession theory maintained that the directional shifts from one stage of succession to the next were induced by the plants themselves. In this sense, succession theory implicitly recognized priority effects; the prior arrival of certain species had important impacts on future community composition. At the same time, the climax concept implied that species shifts were predetermined. A given species would always appear at the same point during the development of the climax community, and always have the same impact on community development.\n\nThis static view of priority effects remained essentially unchanged by the concept of patch dynamics, which was introduced by Alex Watt in 1947. Watt conceived of plant communities as dynamic \"mechanisms\" that followed predetermined succession cycles. Although Watt questioned the idea of a stable endpoint to community development, he seemed to agree with Clements that each particular species had a predetermined role to play in community development. They viewed succession as a process driven by facilitation, in which each species made local conditions more suitable for another species.\n\nIn 1926, Henry Gleason presented an alternative hypothesis in which plants were conceptualized as individuals rather than components of a superorganism. Gleason suggested that the distribution of various species across the landscape reflected species-specific dispersal limitations and environmental requirements rather than predetermined associations among species. Gleason set the stage for future research on priority effects by explaining that initially identical ponds colonized by different species could develop through succession into very different communities. Thus, Gleason contested the idea of a predetermined climax community and recognized that different colonizing species could produce alternative trajectories of community development.\n\nFrank Egler (1954) built on Gleason's hypothesis by developing the Initial Floristic Composition model to describe community development in abandoned agricultural fields. According to this model, the set of species present in a field immediately after abandonment had strong influences on community development and final community composition. Although rooted in succession theory, this approach foreshadowed the development of alternative stable state and community assembly theory.\n\nIn the 1970s, it was suggested that natural communities could be characterized by multiple or alternative stable states. In accordance with the conclusions of Gleason and Egler, multiple stable state models indicated that the same environment could support several different combinations of species. Theorists argued that historical context could play a central role in determining which stable state would be present at any given time. Robert May explained, \"If there is a unique stable state, historical accidents are unimportant; if there are many alternative locally stable states, historical accidents can be of overriding significance.\"\n\nThe development of assembly theory followed from the emergence of alternative stable state theory. Assembly theory explains community development processes in the context of multiple stable states. It asks why a particular type of community developed when other stable community types were possible. In contrast to succession theory, assembly theory was developed largely by animal ecologists and explicitly incorporated historical context.\n\nIn one of the first models based on this theory, Jared Diamond (1975) developed quantitative \"assembly rules\" to predict avian community composition on an archipelago. Although the idea of deterministic community assembly quickly drew criticism, the assembly approach, which emphasized historical contingency and multiple stable states, continued to gain support. Drake (1991) used an assembly model to demonstrate that different community types would result from different sequences of species invasions. In Drake’s model, early invaders had major impacts on the invasion success of species that arrived later. Other modeling studies suggested that priority effects may be especially important when invasion frequency is low enough to allow species to become established before replacement, or when other factors that could drive assembly (e.g., competition, abiotic stress) are relatively unimportant. In a 1999 review, Belyea and Lancaster described three basic determinants of community assembly: dispersal constraints, environmental constraints, and internal dynamics. They identified priority effects as a manifestation of the interaction between dispersal constraints and internal dynamics.\n\nOn January 25, 2007, a search of the ISI Web of Science citation index using the key word \"priority effect*\" returned 65 ecology-related studies. The first study to explicitly mention priority effects was published in 1983. Although early research focused on animals and aquatic systems, more recent studies have begun to examine terrestrial and plant-based priority effects. Inhibitory priority effects have been documented more frequently than facilitative priority effects. Priority effects among species within the same trophic level and functional group, or guild, have been documented more frequently than effects across trophic levels or guilds. Studies indicate that both abiotic (e.g. resource availability) and biotic (e.g. predation) factors can affect the strength of priority effects.\n\nMost of the earliest empirical evidence for priority effects came from studies on aquatic animals. Sutherland (1974) found that final community composition varied depending on the initial order of larval recruitment in a community of small marine organisms (sponges, tunicates, hydroids, and other species). Shulman (1983) and Almany (2003) found strong priority effects among coral reef fish. The former study found that prior establishment by a territorial damselfish reduced establishment rates of other fish. The authors also identified cross-trophic priority effects; prior establishment by a predator fish reduced establishment rates of prey fishes.\n\nIn the late 1980s, several studies examined priority effects in marine microcosms. Robinson and Dickerson (1987) found that priority effects were important in some cases, but suggested, \"Being the first to invade a habitat does not guarantee success; there must be sufficient time for the early colonist to increase its population size for it to pre-empt further colonization.\" Robinson and Edgemon (1988) later developed 54 communities of phytoplankton species by varying invasion order, rate, and timing. They found that although invasion order (priority effects) could explain a small fraction of the resulting variation in community composition, most of the variation was explained by changes in invasion rate and invasion timing. These studies indicate that priority effects may not be the only or the most important historical factor affecting the trajectory of community development.\n\nIn a striking example of cross-trophic priority effects, Hart (1992) found that priority effects explain the maintenance of two alternate stable states in stream ecosystems. While a macroalga is dominant in some patches, sessile grazers maintain a \"lawn\" of small microalgae in others. If the sessile grazers colonize a patch first, they exclude the macroalga, and vice versa.\n\nIn two of the most commonly cited empirical studies on priority effects, Alford and Wilbur documented inhibitory and facilitative priority effects among and toad larvae in experimental ponds. They found that hatchlings of a toad species (\"Bufo americanus\") exhibited higher growth and survivorship when introduced to a pond before those of a frog species (\"Rana sphenocephala\"). The frog larvae, however, did best when introduced after the toad larvae. Thus, prior establishment by the toad species facilitated the frog species, while prior establishment by the frog species inhibited the toad species. Studies on tree frogs have also documented both types of priority effect. Morin (1987) also observed that priority effects became less important in the presence of a predatory salamander. He hypothesized that predation mediated priority effects by reducing competition between frog species. Studies on larval insects and frogs in water-filled tree holes and stumps found that abiotic factors such as space, resource availability, and toxin levels can also be important in mediating priority effects.\n\nTerrestrial studies on priority effects are rare. The aforementioned ISI Web of Science search retrieved only 19 studies on fully terrestrial organisms, and all of these studies were published during or after 1993. Most studies have focused on arthropods or grassland plant species. In a lab experiment, Shorrocks and Bingley (1994) showed that prior arrival increased survivorship for two species of fruit flies; each fly species had inhibitory impacts on the other. A 1996 field study on desert spiders by Ehmann and MacMahon showed that the presence of species from one spider guild reduced establishment of spiders from a different guild. More recently, Palmer (2003) demonstrated that priority effects allowed a competitively subordinate ant species to avoid exclusion by a competitively dominant species. If the competitively subordinate ants were able to colonize first, they altered their host tree’s morphology in ways that made it less suitable for other ant species. This study was especially important because it was able to identify a mechanism driving observed priority effects.\n\nWith the exception of an early study exploring the facilitative effects of litter deposition, studies that explicitly addressed terrestrial plant priority effects began to appear in the literature around the year 2000. A study on two species of introduced grasses in Hawaiian woodlands found that the species with inferior competitive abilities may be able to persist through priority effects. At least three studies have come to similar conclusions about the coexistence of native and exotic grasses in California grassland ecosystems. If given time to establish, native species can successfully inhibit the establishment of exotics. Authors of the various studies attributed the prevalence of exotic grasses in California to the low seed production and relatively poor dispersal ability of native species.\n\nAlthough many studies have documented priority effects, the persistence of these effects over time often remains unclear. Young(2001) indicated that both convergence (in which \"communities proceed towards a predisturbance state regardless of historical conditions\") and divergence (in which historical factors continue to affect the long-term trajectory of community development) are present in nature. Among studies of priority effects, both trends seem to have been observed. Fukami (2005) argued that a community could be both convergent and divergent at different levels of community organization. The authors studied experimentally-assembled plant communities and found that while the identities of individual species remained unique across different community replicates, species traits generally became more similar.\n\nSome studies indicate that priority effects can occur across guilds or trophic levels. Such priority effects could have dramatic impacts on community composition and food web structure. Even intra-guild priority effects could have important consequences at multiple trophic levels if the affected species are associated with unique predator or prey species. Consider, for example, a plant species that is eaten by a host-specific herbivore. Priority effects that influence the ability of the plant species to establish would indirectly affect the establishment success of the associated herbivore. Theoretical models have described cyclical assembly dynamics in which species associated with different suites of predators are able to repeatedly replace one another.\n\nIn situations where two species are introduced at the same time, spatial aggregation of a species' propagules could cause priority effects by initially reducing interspecific competition. Aggregation during recruitment and establishment could allow inferior competitors to coexist with or even displace competitive dominants over the long-term. Several modeling efforts have begun to examine the implications of spatial priority effects for species coexistence. Rejmanek (2002) suggested that only 10 empirical studies examining intraspecific aggregation had been published by 2002.\n\nThe literature on priority effects is currently growing in both depth and breadth. A few studies have begun to explore the mechanisms driving observed priority effects. Moreover, although past studies focused on a small subset of species, recent papers indicate that priority effects may be important for a wide range of organisms, including fungi, birds, lizards, and salamanders.\n\nPriority effects have important implications for ecological restoration. In many systems, information about priority effects can help practitioners identify cost-effective strategies for improving the survival and persistence of certain species, especially species of inferior competitive ability. For example, in a study on the restoration of native Californian grasses and forbs, Lulow (2004) found that forbs could not establish in plots where she had previously planted bunchgrasses. When bunchgrasses were added to plots where forbs had already been growing for a year, forbs were able to coexist with grasses for at least 3–4 years. Lulow’s results suggested that planting forbs before grasses might improve forb persistence in this system.\n", "id": "26956160", "title": "Priority effect"}
{"url": "https://en.wikipedia.org/wiki?curid=50049", "text": "Subarctic climate\n\nThe subarctic climate (also called subpolar climate, subalpine climate, or boreal climate) is a climate characterised by long, usually very cold winters, and short, cool to mild summers. It is found on large landmasses, away from the moderating effects of an ocean, generally at latitudes from 50° to 70°N poleward of the humid continental climates. These climates represent Köppen climate classification \"Dfc\", \"Dwc\", \"Dsc\", \"Dfd\", \"Dwd\" and \"Dsd\". In very small areas at high altitudes around the Mediterranean Basin, Iran, Kyrgyzstan, Tajikistan, Turkey, Alaska and other parts of the northwestern United States (Eastern Washington, Eastern Oregon and Idaho) the climate is classified as \"Dsc\" with a dry summer climate, such as in Seneca, Oregon.\n\nThis type of climate offers some of the most extreme seasonal temperature variations found on the planet: in winter, temperatures can drop to and in summer, the temperature may exceed . However, the summers are short; no more than three months of the year (but at least one month) must have a 24-hour average temperature of at least to fall into this category of climate and the coldest month should average below . Record low temperatures can approach .\nWith 5–7 consecutive months where the average temperature is below freezing, all moisture in the soil and subsoil freezes solidly to depths of many feet. Summer warmth is insufficient to thaw more than a few surface feet, so permafrost prevails under most areas not near the southern boundary of this climate zone. Seasonal thaw penetrates from , depending on latitude, aspect, and type of ground. Some northern areas with subarctic climates located near oceans (southern Alaska, the northern fringe of Europe, Sakhalin Oblast and Kamchatka Oblast), have milder winters and no permafrost, and are more suited for farming unless precipitation is excessive. The frost-free season is very short, varying from about 45 to 100 days at most, and a freeze can occur during any month in many areas.\n\nMost subarctic climates have very little precipitation, typically no more than over an entire year. Away from the coasts, precipitation occurs mostly in the warmer months, while in coastal areas with subarctic climates the heaviest precipitation is usually during the autumn months when the relative warmth of sea vis-à-vis land is greatest. Low precipitation, by the standards of more temperate regions with longer summers and warmer winters, is typically sufficient in view of the very low evapotranspiration to allow a water-logged terrain in many areas of subarctic climate and to permit snow cover during winter.\n\nA notable exception to this pattern is that subarctic climates occurring at high altitudes in otherwise temperate regions have extremely high precipitation due to orographic lift. Mount Washington, with temperatures typical of a subarctic climate, receives an average rain-equivalent of of precipitation per year. Coastal areas of Khabarovsk Krai also have much higher precipitation in summer due to orographic influences (up to in July in some areas), whilst the mountainous Kamchatka peninsula and Sakhalin island are even wetter since orographic moisture is not confined to the warmer months and creates large glaciers in Kamchatka. Labrador, in eastern Canada, is similarly wet throughout the year due to the semi-permanent Icelandic Low and can receive up to of rainfall equivalent per year, creating a snow cover of up to that does not melt until June.\n\nVegetation in regions with subarctic climates is generally of low diversity, as only hardy species can survive the long winters and make use of the short summers. Trees are mostly limited to conifers, as few broadleaved trees are able to survive the very low temperatures in winter. This type of forest is also known as taiga, a term which is sometimes applied to the climate found therein as well. Even though the diversity may be low, numbers are high, and the taiga (boreal) forest is the largest forest biome on the planet, with most of the forests located in Russia and Canada. The process by which plants become acclimated to cold temperatures is called hardening.\n\nAgricultural potential is generally poor, due to the natural infertility of soils and the prevalence of swamps and lakes left by departing ice sheets, and short growing seasons prohibit all but the hardiest of crops. (Despite the short season, the long summer days at such latitudes do permit some agriculture.) In some areas, ice has scoured rock surfaces bare, entirely stripping off the overburden. Elsewhere rock basins have been formed and stream courses dammed, creating countless lakes.\n\nThe \"Dfc\" climate, by far the most common subarctic type, is found in the following areas:\n\nIn parts of East Asia, like China, the Siberian High makes the winters colder than places like Scandinavia or Alaska interior but extremely dry (typically with around of rainfall equivalent per month) that snow cover is very limited, creating a \"Dwc\" climate in:\n\nFurther north in Siberia, continentality increases so much that winters can be exceptionally severe, averaging below , even though the hottest month still averages more than . This creates \"Dfd\", \"Dwd\" and \"Dsd\" climates.\n\nThe Southern Hemisphere, which has no large landmasses in the upper-middle latitudes that can have both the short but well-defined summers and severe winters that characterize this climate, has very few locations with this climate. One example is parts of the Snowy Mountains in Australia, although they're more alpine than true subarctic.\n\nShould one go poleward or even toward a polar sea, one finds that the warmest month has an average temperature of less than , and the subarctic climate grades into a tundra climate even less suitable for trees. Equatorward or toward a lower altitude, this climate grades into the humid continental climates with longer summers (and usually less-severe winters); in a few locations close to a temperate sea (as in North Norway and southern Alaska), this climate can grade into a short-summer version of an oceanic climate, the subpolar oceanic climate, as the sea is approached. In China and Mongolia, as one moves southwestwards or towards lower altitudes, temperatures increase but precipitation is so low that the subarctic climate grades into a cold semi-arid climate.\n\n", "id": "50049", "title": "Subarctic climate"}
{"url": "https://en.wikipedia.org/wiki?curid=3114516", "text": "Hutchinson's ratio\n\nThe Hutchinson's ratio is the ratio of the size differences between similar species when they were living together as compared to when they were isolated. It is named after G. Evelyn Hutchinson who concluded that various key attributes in species varied according to the ratio of 1:1.1 to 1:1.4.\n\n", "id": "3114516", "title": "Hutchinson's ratio"}
{"url": "https://en.wikipedia.org/wiki?curid=29302590", "text": "Plant cover\n\nThe abundances of plant species are often measured by plant cover, i.e. the relative area covered by different plant species in a small plot. Plant cover is not biased by the size and distributions of individuals, and is an important and often measured characteristic of the composition of plant communities. Plant cover data may be used to classify the studied plant community into a vegetation type, to test different ecological hypothesis on plant abundance, and in gradient studies, where the effects of different environmental gradients on the abundance of specific plant species are investigated.\n\nThe most common way to measure plant cover in herbal plant communities, is to make a visual assessment of the relative area covered by the different species in a small plot (see quadrat). The visually assessed cover of a plant species is then recorded as a continuous variable between 0 and 1, or divided into interval classes as an ordinal variable. An alternative methodology, called the pin-point method (or point-intercept method), has also been widely employed.\n\nIn a pin-point analysis, a frame with a fixed grid pattern is placed randomly above the vegetation, and a thin pin is inserted vertically through one of the grid points into the vegetation. The different species touched by the pin are recorded at each insertion. The cover of plant species \"k\" in a\nplot, formula_1, is now assumed to be proportional to the number of “hits” by the pin,\n\nformula_2,\n\nwhere formula_3 is the number of pins that hit species \"k\" out of a total of \"n\" pins. Since a single pin in multi-species plant communities often will hit more than a single species, the sum of the plant cover of the different species may be larger than unity when estimated by the pin-point method. The sum of the estimated plant cover is expected to increase with the number of plant species in a plot and with increasing 3-dimensional structuring of the plants in the community. Plant cover data obtained by the pin-point method may be modelled by a generalised binomial distribution (or Pólya–Eggenberger distribution).\n\n", "id": "29302590", "title": "Plant cover"}
{"url": "https://en.wikipedia.org/wiki?curid=30155658", "text": "Ecological urbanism\n\nThe ecological urbanism project draws from ecology to inspire an urbanism that is more socially inclusive and sensitive to the environment, as well as less ideologically driven, than green urbanism or sustainable urbanism. In many ways, ecological urbanism is an evolution of, and a critique of, Landscape Urbanism arguing for a more holistic approach to the design and management of cities. The term appeared first in 1998 as \"EcoUrbanism\" in a book by Architect and Planner Miguel Ruano, who defined it as \"the development of multi-dimensional sustainable human communities within harmonious and balanced built environments\". The term was used later in April 2003 at a conference at the University of Oregon, and again in 2006 in a paper by Jeffrey Hou. The phrase was used by Mohsen Mostafavi in 2007 in \"Intervention Architecture\" and in a lecture at the Canadian Centre for Architecture, ecological urbanism as a project was largely started at Harvard University Graduate School of Design, with a conference, and exhibition, and book.\n\nArguing for a \"new ethics and aesthetics of the urban,\" the 656-page \"Ecological Urbanism\" book, edited by Mohsen Mostafavi with Gareth Doherty, was published in May 2010 by Lars Müller Publishers (). The book follows the conference, and exhibition, held at the GSD in 2009. The book has a long list of contributors, including Rem Koolhaas, Homi K. Bhabha, Mitchell Joachim, Andrea Branzi, and about 130 others. A blog during the conference is part of the book. According to \"Architecture Today\", the book is \"one of the few books that recognises and articulates how, if this systems-based approach is to be successful, it needs to design, integrate and express complex systems and social processes in ways that are fundamentally humane.\" The book has been reviewed and cited in many publications, including [\"Metropolis Magazine\"], \"The Journal of Landscape Architecture\", and Cities magazine. Events and discussions on the book have been held at the 2010 Venice Biennale, the Storefront for Art and Architecture in New York, and at the Van Alen Institute in New York.\n\nIn his introduction to the \"Ecological Urbanism\", \"Why Ecological Urbanism? Why Now?\", extracted in \"Topos: The International Review of Landscape Architecture and Urban Design\", Mostafavi asks: \"Increased numbers of people and cities go hand in hand with a greater exploitation of the world’s limited resources. Every year, more cities are feeling the devastating impacts of this situation. What are we to do? What means do we have as designers to address this challenging reality?\n\nJeb Brugmann in his book \"Welcome to the Urban Revolution: How Cities Are Changing the World\" (Bloomsbury Press, 2009) says we need to become \"masters of a stable, just, and ecological urbanism.\" For Brugmann, \"The first step towards ecological urbanism is increasing the energy and nutrient productivity within the city, but the only way to move sufficiently from extractive mode to a sustainable productive mode is to think, design, and develop at the scale of the City.\"\n\nThere have been a number of recent conferences and lectures on the project of ecological urbanism, including: The New Aesthetics and Ecological Urbanism at Peking University in October 2010, New Zealand Institute of Landscape Architects Spring Lecture Series: Ecological Urbanism: A Prospectus for the Super City, in October 2010. The University of Washington’s urban initiative included a seminar on Now Urbanism and talks \"on Ecological Urbanism, Ecological Design for Healthy Cities, Networked Urbanism, and America’s War on Immigrants.” Eco-Urbanism: towards sustainable city living, was hosted by Nottingham University at the Shanghai Expo in August 2010.\n\nIn addition to courses at the GSD in 2008 and 2011, there have been courses on ecological urbanism at the Bergen School of Architecture, Oslo School of Architecture and Design, and Yale University. It is on numerous course syllabi, including Advanced Design Theories 2010 at Florida International University. Arizona State University expanded on the subject with a lecture by Charles Anderson, ASLA. Anderson stated that \"ecology is concerned with the relationships between all organisms and the environment. Together and coupled with aesthetic and expressionist design principles, they form the foundation for urban design.\"\n\nEcological urbanism has been criticized as an idea that is loosely defined from a set of flashy projects. These are expensive schemes with a commercial and esthetic purpose that satisfy a local or regional ambition to invest in ecology or sustainability without posing a more globally applicable approach. A true merger of landscape architecture with the field of Urban Ecology lacks. From this criticism Frederick Steiner introduced landscape ecological urbanism as an approach that can include the field of urban ecology and Wybe Kuitert has shown how such integrative planning and management of the city should rely on analysis. Discerning the potential quality of wild nature in the city is a first step to see how new urban ecology might be developed. Potential vegetation maps for a city are the tool to this end.\n\nEcological Urbanism is explained as a successor to Landscape Urbanism without the difference between the two approaches, and the terms used in the new approach, being defined. Jason King sees it as an inadequately explained addition to a list of 61 other 'Fill-in-the-blank Urbanisms'. Tom Turner welcomes landscape and ecological urbanism as 'the most significant contributions to landscape design theory since the landscape architecture profession was launched in the mid-nineteenth century' but is 'unpersuaded by the change of name' \n", "id": "30155658", "title": "Ecological urbanism"}
{"url": "https://en.wikipedia.org/wiki?curid=20599992", "text": "Agroecological restoration\n\nAgroecological restoration is the practice of re-integrating natural systems into agriculture in order to maximize sustainability, ecosystem services, and biodiversity. This is one example of a way to apply the principles of agroecology to an agricultural system.\n\nFarms cannot be restored to a purely natural state because of the negative economic impact on farmers, but returning processes, such as pest control to nature with the method of intercropping, allows a farm to be more ecologically sustainable and, at the same time, economically viable. Agroecological restoration works toward this balance of sustainability and economic viability because conventional farming is not sustainable over the long run without the integration of natural systems and because the use of land for agriculture has been a driving force in creating the present world biodiversity crisis. Its efforts are complementary to, rather than a substitute for, biological conservation.\n\"...biodiversity is just as important on farms and in fields as it is in deep river valleys or mountain cloud forests.\"\nFAO, 15 October 2004\n\nAgriculture creates a conflict over the use of land between wildlife and humans. Though the domestication of crop plants occurred 10,000 years ago, a 500% increase in the amount of pasture and crop land over the last three hundred years has led to the rapid loss of natural habitats. In recent years, the world community acknowledged the value of biodiversity in treaties, such as the 1992 landmark Convention on Biological Diversity.\n\nThe reintegration of agricultural systems into more natural systems will result in decreased yield and produce a more complex system, but there will be considerable gains in biodiversity and ecosystem services.\n\nThe Food and Agriculture Organization of the United Nations estimates that more than 40% of earth’s land surface is currently used for agriculture. And because so much land has been converted to agriculture, habitat loss is recognized as the driving force in biodiversity loss (FAO). This biodiversity loss often occurred in two steps, as in the American Midwest, with the introduction of mixed farming carried out on small farms and then with the widespread use of mechanized farming and monoculture beginning after World War II. The decline in farmland biodiversity can now be traced to changes in farming practices and increased agricultural intensity.\n\nHeterogeneity (here, the diversity or complexity of the landscape) has been shown to be associated with species diversity. For example, the abundance of butterflies has been found to increase with heterogeneity. One important part of maintaining heterogeneity in the spaces between different fields is made up of habitat that is not cropped, such as grass margins and strips, scrub along field boundaries, woodland, ponds, and fallow land. These seemingly unimportant pieces of land are crucial for the biodiversity of a farm. The presence of field margins benefits many different taxa: the plants attract herbivorous insects, will which attract certain species of birds and those birds will attract their natural predators. Also, the cover provided by the no cropped habitat allows the species that need a large range to move across the landscape.\n\nIn the absence of cover, species face a landscape in which their habitat is greatly fragmented. The isolation of a species to a small habitat that it can’t safely wander from can create a genetic bottleneck, decreasing the resilience of the particular population, and be another factor leading to the decline of the total population of the species. Monoculture, the practice of producing a single crop over a wide area, causes fragmentation. In conventional farming, monoculture, such as with rotations of corn and soybean crops planted in alternating growing seasons, is used so that very high yields can be produced. After the mechanization of farming, monoculture became a standard practice in corn-beans rotation, and had broad implications for the long-term sustainability and biodiversity of farms. Whereas organic fertilizers, had kept the soil’s nutrients fixed to the ecosystem, the introduction of monoculture removed the nutrients and farmers compensated for that loss by using inorganic fertilizers. It is estimated that humans have doubled the rate of nitrogen input into the nitrogen cycle, mostly since 1975. As a result, the biological processes that controlled the way crops used the nutrients changed and the leached nitrogen from farmland soils has become a source of pollution.\n\nOrganic farming is defined in different legal terms by different nations, but its main distinction from conventional farming is that it prohibits the use of synthetic chemicals in crop and livestock production. Often, it also includes diverse crop rotations and provides non-cropped habitat for insects that provide ecosystem services, such as pest control and pollination. However, it is merely encouraged that organic farmers follow those kinds of wildlife friendly practices, and as a result there is a great difference between the ecosystem services that similarly sized but distinctly managed organic farms provide. A recent review of the 76 studies concerning the relationship between biodiversity and organic farming listed three practices associated with organic farming that accounted for the higher biodiversity counts found in organic farms as compared to conventional farms. \n\"1. \"Prohibition/reduced use of chemical pesticides and inorganic fertilizers\" is likely to have a positive impact through the removal of both direct and indirect negative effects on arable plants, invertebrates and vertebrates.\n2. \"Sympathetic management of non-crop habitats and field margins\" can enhance diversity and abundance of arable plants, invertebrates, birds and mammals.\n3. \"Preservation of mixed farming\" is likely to positively impact farmland biodiversity through the provision of greater habitat heterogeneity at a variety of temporal and spatial scales within the landscape.\"\n\n", "id": "20599992", "title": "Agroecological restoration"}
{"url": "https://en.wikipedia.org/wiki?curid=17303574", "text": "Ecological network\n\nAn ecological network is a representation of the biotic interactions in an ecosystem, in which species (nodes) are connected by pairwise interactions (links). These interactions can be trophic or symbiotic. Ecological networks are used to describe and compare the structures of real ecosystems, while network models are used to investigate the effects of network structure on properties such as ecosystem stability.\n\nHistorically, research into ecological networks developed from descriptions of trophic relationships in aquatic food webs; however, recent work has expanded to look at other food webs as well as webs of mutualists. Results of this work have identified several important properties of ecological networks.\n\nComplexity ([linkage density): the average number of links per species. Explaining the observed high levels of complexity in ecosystems has been one of the main challenges and motivations for ecological network analysis, since early theory predicted that complexity should lead to instability.\n\nConnectance: the proportion of possible links between species that are realized (links/species). In food webs, the level of connectance is related to the statistical distribution of the links per species. The distribution of links changes from (partial) power-law to exponential to uniform as the level of connectance increases. The observed values of connectance in empirical food webs appear to be accountable for by constraints on an organisms diet breadth driven by optimal foraging behaviour.This links the structure of these ecological networks to the behaviour of individual organisms.\n\nDegree distribution: the degree distribution of an ecological network is the cumulative distribution for the number of links each species has. The degree distributions of food webs have been found to display the same universal functional form. The degree distribution can be split into its two component parts, links to a species' prey (aka. in degree) and links to a species' predators (aka- out degree). Both the in degree and out degree distributions display their own universal functional forms. As there is a faster decay of the out-degree distribution than the in degree distribution we can expect that on average in a food web a species will have more in links than out links.\n\nClustering: the proportion of species that are directly linked to a focal species. A focal species in the middle of a cluster may be a keystone species, and its loss could have large effects on the network.\n\nCompartmentalization: the division of the network into relatively independent sub-networks. Some ecological networks have been observed to be compartmentalized by body size and by spatial location. Evidence also exists which suggests that compartmentilization in food webs appears to result from patterns of species' diet contiguity and adaptive foraging \n\nNestedness: the degree to which species with few links have a sub-set of the links of other species, rather than a different set of links. In highly nested networks, guilds of species that share an ecological niche contain both generalists (species with many links) and specialists (species with few links, all shared with the generalists). In mutualistic networks, nestedness is often asymmetrical, with specialists of one guild linked to the generalists of the partner guild. The level of nestedness is determined not by species features but overall network depictors (e.g. network size and connectance) and can be predicted by a dynamic adaptive model with species rewiring to maximize individual fitness or the fitness of the whole community.\n\nNetwork motif: Motifs are unique sub-graphs composed of n-nodes found embedded in a network. For instance there exist thirteen unique motif structures containing three species, some of these correspond to familiar interaction modules studied by population ecologists such as food chains, apparent competition, or intraguild predation. Studies investigating motif structures of ecological networks, by examining patterns of under/over representation of certain motifs compared to a random graph, have found that food webs have particular motif structures \n\nTrophic coherence: The tendency of species to specialise on particular trophic levels leads to food webs displaying a significant degree of order in their trophic structure, known as \"trophic coherence\", which in turn has important effects on properties such as stability and prevalence of cycles.\n\nThe relationship between ecosystem complexity and stability is a major topic of interest in ecology. Use of ecological networks makes it possible to analyze the effects of the network properties described above on the stability of an ecosystem. Ecosystem complexity was once thought to reduce stability by enabling the effects of disturbances, such as species loss or species invasion, to spread and amplify through the network. However, other characteristics of network structure have been identified that reduce the spread of indirect effects and thus enhance ecosystem stability. The relationship between complexity and stability can even be inverted in food webs with sufficient trophic coherence, so that increases in biodiversity would make a community more stable rather than less.\n\nInteraction strength may decrease with the number of links between species, damping the effects of any disturbance and cascading extinctions are less likely in compartmentalized networks, as effects of species losses are limited to the original compartment. Furthermore, as long as the most connected species are unlikely to go extinct, network persistence increases with connectance and nestedness. No consensus on the links between network nestedness and community stability in mutualistic species has however been reached among several investigations in recent years. Recent findings suggest that a trade-off between different types of stability may exist. The nested structure of mutualisitic networks was shown to promote the capacity of species to persist under increasingly harsh circumstances. Most likely, because the nested structure of mutualistic networks helps species to indirectly support each other when circumstances are harsh. This indirect facilitation helps species to survive, but it also means that under harsh circumstances one species cannot survive without the support of the other. As circumstances become increasingly harsh, a tipping point may therefore be passed at which the populations of a large number of species may collapse simultaneously.\n\nAdditional applications of ecological networks include exploration of how the community context affects pairwise interactions. The community of species in an ecosystem is expected to affect both the ecological interaction and coevolution of pairs of species. Related, spatial applications are being developed for studying metapopulations, epidemiology, and the evolution of cooperation. In these cases, networks of habitat patches (metapopulations) or individuals (epidemiology, social behavior), make it possible to explore the effects of spatial heterogeneity.\n\n\n\n", "id": "17303574", "title": "Ecological network"}
{"url": "https://en.wikipedia.org/wiki?curid=14700754", "text": "Eltonian niche\n\nThe Eltonian niche is an ecological niche that emphasizes the functional attributes of animals and their corresponding trophic position. This was the definition Eugene Odum popularized in his analogy of the niche of a species with its profession in the ecosystem as opposed to the habitat being its address. The definition is attributed to Charles Elton in his 1927 now classic book \"Animal Ecology\". Elton used the two African Rhinoceros species to exemplify the definition. The White Rhinoceros has broad (wide, hence its name) mouthparts, which are efficient in harvesting grass, while the Black Rhinoceros has narrow pointed lips enabling it to feed selectively on the foliage of thorny bushes.\n\nGrinellian niche\n", "id": "14700754", "title": "Eltonian niche"}
{"url": "https://en.wikipedia.org/wiki?curid=1881089", "text": "Historical ecology\n\nHistorical ecology is a research program that focuses on the interactions between humans and their environment over long-term periods of time, typically over the course of centuries. In order to carry out this work, historical ecologists synthesize long-series data collected by practitioners in diverse fields. Rather than concentrating on one specific event, historical ecology aims to study and understand this interaction across both time and space in order to gain a full understanding of its cumulative effects. Through this interplay, humans adapt to \"and\" shape the environment, continuously contributing to landscape transformation. Historical ecologists recognize that humans have had world-wide influences, impact landscape in dissimilar ways which increase or decrease species diversity, and that a holistic perspective is critical to be able to understand that system.\n\nPiecing together landscapes requires a sometimes difficult union between natural and social sciences, close attention to geographic and temporal scales, a knowledge of the range of human ecological complexity, and the presentation of findings in a way that is useful to researchers in many fields. Those tasks require theory and methods drawn from geography, biology, ecology, history, sociology, anthropology, and other disciplines. Common methods include historical research, climatological reconstructions, plant and animal surveys, archaeological excavations, ethnographic interviews, and landscape reconstructions.\n\nThe discipline has several sites of origins by researchers who shared a common interest in the problem of ecology and history, but with a diversity of approaches. Edward Smith Deevey, Jr. used the term in the 1960s to describe a methodology that had been in long development. Deevey wished to bring together the practices of \"general ecology\" which was studied in an experimental laboratory, with a \"historical ecology\" which relied on evidence collected through fieldwork. For example, Deevey used radiocarbon dating to reconcile biologists’ successions of plants and animals with the sequences of material culture and sites discovered by archaeologists.\n\nIn the 1980s, members of the history department at the University of Arkansas at Little Rock organized a lecture series entitled \"Historical Ecology: Essays on Environment and Social Change\" The authors noted the public’s concerns with pollution and dwindling natural resources, and they began a dialogue between researchers with specialties which spanned the social sciences. The papers highlighted the importance of understanding social and political structures, personal identities, perceptions of nature, and the multiplicity of solutions for environmental problems.\n\nThe emergence of historical ecology as a coherent discipline was driven by a number of long-term research projects in historical ecology of tropical, temperate and arctic environments:\n\nE.S. Deevey's Historical Ecology of the Maya Project (1973-1984) was carried out by archaeologists and biologists who combined data from lake sediments, settlement patterns, and material from excavations in the central Petén District of Guatemala to refute the hypotheses that a collapse of Mayan urban areas was instigated by faltering food production.\n\nCarole L. Crumley's Burgundian Landscape Project (1974–present) is carried out by a multidisciplinary research team aimed at identifying the multiple factors which have contributed to the long-term durability of the agricultural economy of Burgundy, France.\n\nThomas H. McGovern's Inuit-Norse Project (1976–present) uses archaeology, environmental reconstruction, and textual analysis to examine the changing ecology of Nordic colonizers and indigenous peoples in Greenland, Iceland, Faeroes, and Shetland.\n\nIn recent years the approaches to historical ecology have been expanded to include coastal and marine environments:\n\nStellwagen Bank National Marine Sanctuary Project (1984–present) examines Massachusetts, USA cod fishing in the 17th through 19th centuries through historical records.\n\nFlorida Keys Coral Reef Eco-region Project (1990–present) researchers at the Scripps Institute of Oceanography are examining archival records including natural history descriptions, maps and charts, family and personal papers, and state and colonial records in order to understand the impact of over-fishing and habitat loss in the Florida Keys, USA which contains the third largest coral reef in the world.\n\nMonterey Bay National Marine Sanctuary Historical Ecology (2008–present) seeks to collect relevant historical data on fishing, whaling, and trade of the furs of aquatic animals in order form a baseline for environmental restorations of the California, USA coast.\n\nHistorical ecology is interdisciplinary in principle; at the same time, it borrows heavily from the rich intellectual history of environmental anthropology. Western scholars have known since the time of Plato that the history of environmental changes cannot be separated from human history. Several ideas have been used to describe human interaction with the environment, the first of which is the concept of the Great Chain of Being, or inherent design in nature. In this, all forms of life are ordered, with Humanity as the highest being, due to its knowledge and ability to modify nature. This lends to the concept of another nature, a manmade nature, which involves design or modification by humans, as opposed to design inherent in nature.\n\nInterest in environmental transformation continued to increase in the 18th, 19th, and 20th centuries, resulting in a series of new intellectual approaches. One of these approaches was environmental determinism, developed by geographer Friedrich Ratzel. This view held that it is not social conditions, but environmental conditions, which determine the culture of a population. Ratzsel also viewed humans as restricted by nature, for their behaviors are limited to and defined by their environment. A later approach was the historical viewpoint of Franz Boas which refuted environmental determinism, claiming that it is not nature, but specifics of history, that shape human cultures. This approach recognized that although the environment may place limitations on societies, every environment will impact each culture differently. Julian Steward's cultural ecology is considered a fusion of environmental determinism and Boas' historical approach. Steward felt it was neither nature nor culture that had the most impact on a population, but instead, the mode of subsistence used in a given environment.\n\nAnthropologist Roy Rappaport introduced the field of ecological anthropology in a deliberate attempt to move away from cultural ecology. Studies in ecological anthropology borrow heavily from the natural sciences, in particular, the concept of the ecosystem from systems ecology. In this approach, also called systems theory, ecosystems are seen as self-regulating, and as returning to a state of equilibrium. This theory views human populations as static and as acting in harmony with the environment.\n\nThe revisions of anthropologist Eric Wolf and others are especially pertinent to the development of historical ecology. These revisions and related critiques of environmental anthropology undertook to take into account the temporal and spatial dimensions of history and cultures, rather than continuing to view populations as static. These critiques led to the development of historical ecology by revealing the need to consider the historical, cultural, and evolutionary nature of landscapes and societies. Thus, historical ecology as a research program developed to allow for the examination of all types of societies, simple or complex, and their interactions with the environment over space and time.\n\nIn historical ecology, the landscape is defined as an area of interaction between human culture and the non-human environment. The landscape is a perpetually changing, physical manifestation of history. Historical ecology revises the notion of the ecosystem and replaces it with the landscape. While an ecosystem is static and cyclic, a landscape is historical. While the ecosystem concept views the environment as always trying to return to a state of equilibrium, the landscape concept considers \"landscape transformation\" to be a process of evolution. Landscapes do not return to a state of equilibrium, but are palimpsests of successive disturbances over time. The use of \"landscape\" instead of \"ecosystem\" as the core unit of analysis lies at the heart of historical ecology.\nVarious individuals and schools of thought have informed the idea of the landscape as historical ecologists conceive of it. The Old English words \"landskift\", \"landscipe\" or \"landscaef\" refer to environments that have been altered by humans. As this etymology demonstrates, landscapes have been conceived of as related to human culture since at least the 5th century CE. Cultural and historical geographers have had a more recent influence. They adopted this idea from nineteenth-century German architects, gardeners, and landscape painters in Europe, Australia, and North America. Landscapes are not only physical objects, but also \"forms of knowledge\". Landscapes have cultural meanings, for example, the sacredness in many cultures of burial grounds. This recognition of landscapes as forms of knowledge is central to historical ecology, which studies landscapes from an anthropocentric perspective.\n\nThe idea of the cultural landscape is directly attributed to American geographer Carl Sauer. Sauer's theories developed as a critique of environmental determinism, which was a popular theory in the early twentieth century. Sauer's pioneering 1925 paper \"The Morphology of Landscape\" is now fundamental to many disciplines and defines the domain. In this, the term landscape is used in a geographical sense to mean an arbitrarily selected section of reality; morphology means the conceptual and methodological processes for altering it. Hence to Sauer, wherever humans lived and impacted the environment, landscapes with determinate histories resulted.\n\nThe perception of the landscape in historical ecology differs from other disciplines, such as landscape ecology. Landscape ecologists often attribute the depletion of biodiversity to human disturbance. Historical ecologists recognize that this is not always true. These changes are due to multiple factors that contribute to the ever-changing landscape. Landscape ecology still focuses on areas defined as ecosystems. In this, the ecosystem perpetually returns to a state of equilibrium. In contrast, historical ecologists view the landscape as perpetually changing. Landscape ecologists view noncyclical human events and natural disasters as external influences, while historical ecologists view disturbances as an integral part of the landscape's history. It is this integration of the concept of disturbance and history that allows for landscape to be viewed as palimpsests, representing successive layers of change, rather than as static entities.\n\nHistorical ecologists recognize that landscapes undergo continuous alteration over time and these modifications are part of that landscape's history. Historical ecology recognizes that there is a primary and a secondary succession that occurs in the landscape. These successions should be understood without a preconceived bias against humanity. Landscape transformations are ecological successions driven by human impacts. Primary landscape transformations occur when human activity results in a complete turnover of species and major substrate modifications in certain habitats while secondary landscape transformations involve human-induced changes in species proportions. The stages of landscape transformation demonstrate the history of a landscape. These stages can be brought on by humans or natural causes. Parts of the Amazon rainforest exhibit different stages of landscape transformation such as the impact of indigenous slash-and-burn horticulture on plant species compositions. Such landscape transformation does not inherently reduce biodiversity or harm the environment. There are many cases in which human-mediated disturbance increases biodiversity as landscapes transform over time.\n\nHistorical ecology challenges the very notion of a pristine landscape, such as virgin rainforests. The idea that the landscape of the New World was uninhabited and unchanged by those groups that did inhabit it was fundamental to the justifications of colonialism. Thus, perceptions of landscape have profound consequences on the histories of societies and their interactions with the environment. All landscapes have been altered by various organisms and mechanisms prior to human existence on Earth. Humans have always transformed the landscapes they inhabit, however, and today there are no landscapes on Earth that have not been affected by humans in some way.\n\nHuman alterations have occurred in different phases, including the period prior to industrialization. These changes have been studied through the archeological record of modern humans and their history. The evidence that classless societies, like foragers and trekkers, were able to change a landscape was a breakthrough in historical ecology and anthropology as a whole. Using an approach that combines history, ecology, and anthropology, a landscape's history can be observed and deduced through the traces of the various mechanisms that have altered it, anthropogenic or otherwise. Understanding the unique nature of every landscape, in addition to relations among landscapes, and the forms which comprise the landscape, is key to understanding historical ecology.\n\n\"Homo sapiens\" have interacted with the environment throughout history, generating a long-lasting influence on landscapes worldwide. Humans sometimes actively change their landscapes, while at other times their actions alter landscapes through secondary effects. These changes are called human-mediated disturbances, and are effected through various mechanisms. These mechanisms vary; they may be detrimental in some cases, but advantageous in others.\n\nBoth destructive and at times constructive, anthropogenic fire is the most immediately visible human-mediated disturbance, and without it, many landscapes would become denatured. Humans have practiced controlled burns of forests globally for thousands of years, shaping landscapes in order to better fit their needs. They burned vegetation and forests to create space for crops, sometimes resulting in higher levels of species diversity. Today, in the absence of indigenous populations who once practiced controlled burns (most notably in North America and Australia), naturally ignited wildfires have increased. In addition, there has been destabilization of \"ecosystem after ecosystem, and there is good documentation to suggest fire exclusion by Europeans has led to floral and faunal extinctions.\"\n\nBiological invasions and the spread of pathogens and diseases are two mechanisms that spread both inadvertently and purposefully. Biological invasions begin with introductions of foreign species or biota into an already existing environment. They can be spread by stowaways on ships or even as weapons in warfare. In some cases a new species may wreak havoc on a landscape, causing the loss of native species and destruction of the landscape. In other cases, the new species may fill a previously empty niche, and play a positive role. The spread of new pathogens, viruses, and diseases rarely have any positive effects; new pathogens and viruses sometimes destroy populations lacking immunities to those diseases. Some pathogens have the ability to transfer from one species to another, and may be spread as a secondary effect of a biological invasion.\n\nOther mechanisms of human-mediated disturbances include water management and soil management. In Mediterranean Europe, these have been recognized as ways of landscape alteration since the Roman Empire. Cicero noted that through fertilization, irrigation, and other activities, humans had essentially created a second world. At present, fertilization yields larger, more productive harvests of crops, but also has had adverse effects on many landscapes, such as decreasing the diversity of plant species and adding pollutants to soils.\n\nAnthropogenic fire is a mechanism of human-mediated disturbance, defined within historical ecology as a means of altering the landscape in a way that better suits human needs. The most common form of anthropogenic fire is controlled burns, or broadcast burning, which people have employed for thousands of years. Forest fires and burning tend to carry negative connotations, yet controlled burns can have a favorable impact on landscape diversity, formation, and protection.\n\nBroadcast burning alters the biota of a landscape. The immediate effect of a forest fire is a decrease in diversity. This negative impact associated with broadcast burning, however, is only temporary. Cycles of burning will allow the landscape to gradually increase in diversity. The time required for this change is dependent on the intensity, frequency, timing, and size of the controlled burns. After a few cycles, however, diversity increases. The adaptation to fire has shaped many of Earth's landscapes.\nIn addition to fostering diversity, controlled burns have helped change landscapes. These changes can range from grasslands to woodlands, from prairies or forest-steppes, to scrubland to forest. Whatever the case, these transformations increase diversity and engender landscapes more suitable to human needs, creating patches rich in utilitarian and natural resources.\n\nIn addition to increasing diversity of landscapes, broadcast burning can militate against catastrophic wildfires. Forest fires gained a negative connotation because of cultural references to uncontrolled fires that take lives and destroy homes and properties. Controlled burns can decrease the risk of wildfires through the regular burning of undergrowth that would otherwise fuel rampant burning. Broadcast burning has helped to fireproof landscapes by burning off undergrowth and using up potential fuel, leaving little or no chance for a wildfire to be sparked by lightning.\n\nOf all of the mechanisms of human-mediated disturbances, anthropogenic fire has become one of great interest to ecologists, geographers, soil scientists, and anthropologists alike. By studying the effects of anthropogenic fires, anthropologists have been able to identify landscape uses and requirements of past cultures. Ecologists became interested in the study of anthropogenic fire as to utilize methods from previous cultures to develop policies for regular burning. Geographers and soil scientists are interested in the utility of anthropic soils caused by burning in the past. The interest in anthropogenic fire came about in the wake of the Industrial Revolution. This time period included a mass migration from rural to urban areas, which decreased controlled burning in the countryside. This led to an increase in the frequency and strength of wildfires, thus initiating a need to develop proper prevention methods. Historical ecology focuses on the impact on landscapes through human-mediated disturbances, once such being anthropogenic fire. It is a fusion of ecological, geographical, anthropological, and pedological interests.\n\nBiological invasions are composed of exotic biota that enter a landscape and replace species with which they share similarities in structure and ecological function. Because they multiply and grow quickly, invasive species can eliminate or greatly reduce existing flora and fauna by various mechanisms, such as direct competitive exclusion. Invasive species typically spread at a faster rate when they have no natural predators or when they fill an empty niche. These invasions often occur in a historical context and are classified as a type of human-mediated disturbance called human-mediated invasions.\n\nInvasive species can be transported intentionally or accidentally. Many invasive species originate in shipping areas from where they are unintentionally transported to their new location. Sometimes human populations intentionally introduce species into new landscapes to serve various purposes, ranging from decoration to erosion control. These species can later become invasive and dramatically modify the landscape. It is important to note that not all exotic species are invasive; in fact, the majority of newly introduced species never become invasive. Humans have on their migrations through the ages taken along plants of agricultural and medicinal value, so that the modern distribution of such favored species is a clear mapping of the routes they have traveled and the places they have settled.\n\nOne example of an invasive species that has had a significant impact on the landscape is the gypsy moth (\"Lymantria dispar\"). The foliage-feeding gypsy moth is originally from temperate Eurasia; it was intentionally brought to the United States by an entomologist in 1869. Many specimens escaped from captivity and have since changed the ecology of deciduous and coniferous forests in North America by defoliation. This has led not only to the loss of wildlife habitat, but also other forest services, such as carbon sequestration and nutrient cycling. After its initial introduction, the continued accidental transport of its larvae across North America has contributed to its population explosion.\n\nRegardless of the medium of introduction, biological invasions have a considerable effect on the landscape. The goal of eliminating invasive species is not new; Plato wrote about the benefits of biotic and landscape diversity centuries ago. However, the notion of eliminating invasive species is difficult to define because there is no canonical length of time that a species must exist in a specific environment until it is no longer classified as invasive. European forestry defines plants as being archaeotypes if they existed in Europe before 1500 and neophytes if they arrived after 1500. This classification is still arbitrary and some species have unknown origins while others have become such key components of their landscape that they are best understood as keystone species. As a result, their removal would have an enormous impact on the landscape, but not necessarily cause a return to conditions that existed before the invasion.\n\nA clear relationship between nature and people is expressed through human disease. Infectious disease can thus be seen as another example of human-mediated disturbance as humans are hosts for infectious diseases. Historically, evidence of epidemic diseases is associated with the beginnings of agriculture and sedentary communities. Previously, human populations were too small and mobile for most infections to become established as chronic diseases. Permanent settlements, due to agriculture, allowed for more inter-community interaction, enabling infections to develop as specifically human pathogens.\n\nHolistic and interdisciplinary approaches to the study of human disease have revealed a reciprocal relationship between humans and parasites. The variety of parasites found within the human body often reflects the diversity of the environment in which that individual resides. For instance, Bushmen and Australian Aborigines have half as many intestinal parasites as African and Malaysian hunter-gatherers living in a species-rich tropical rainforest. Infectious diseases can be either chronic or acute, and epidemic or endemic, impacting the population in any given community to different extents. Thus, human-mediated disturbance can either increase or decrease species diversity in a landscape, causing a corresponding change in pathogenic diversity.\n\nHistorical ecologists postulate that landscape transformations have occurred throughout history, even before the dawn of western civilization. Human-mediated disturbances are predated by soil erosion and animals damming waterways which contributed to waterway transformations. Landscapes, in turn, were altered by waterway transformation. Historical ecology views the effects of human-mediated disturbances on waterway transformation as both subtle and drastic occurrences. Waterways have been modified by humans through the building of irrigation canals, expanding or narrowing waterways, and multiple other adjustments done for agricultural or transportation usage.\n\nThe evidence for past and present agricultural use of wetlands in Mesoamerica suggests an evolutionary sequence of landscape and waterway alteration. Pre-Columbian, indigenous agriculturalists developed capabilities with which to raise crops under a wide range of ecological conditions, giving rise to a multiplicity of altered, cultivated landscapes. The effects of waterway transformation were particularly evident in Mesoamerica, where agricultural practices ranged from swiddening to multicropped hydraulically transformed wetlands.\n\nHistorical ecologists view the Amazon basin landscape as cultural and embodying social labor. The Amazon River has been altered by the local population for crop growth and water transportation. Previous research failed to account for human interaction with the Amazon landscape. Recent research, however, has demonstrated that the landscape has been manipulated by its indigenous population over time. The continual, natural shifting of rivers, however, often masked the human disturbances in the course of rivers. As a result, the indigenous populations in the Amazon are often overlooked for their ability to alter the land and the river.\n\nHowever, waterway transformation has been successfully identified in the Amazon landscape. Clark Erickson observes that pre-Hispanic savanna peoples of the Bolivian Amazon built an anthropogenic landscape through the construction of raised fields, large settlement mounds, and earthen causeways. Erickson, on the basis of location, form, patterning, associations and ethnographic analogy, identified a particular form of earthwork, the zigzag structure, as fish weirs in the savanna of Baures, Bolivia. The artificial zigzag structures were raised from the adjacent savanna and served as a means to harvest the fish who used them to migrate and spawn.\n\nFurther evidence of waterway transformation is found in Igarapé Guariba in Brazil. It is an area in the Amazon basin where people have intervened in nature to change rivers and streams with dramatic results. Researcher Hugh Raffles notes that British naturalists Henry Walter Bates and Alfred Russel Wallace noted waterway transformation as they sailed through a canal close to the town of Igarapé-Miri in 1848. Archival materials identifies that it had been dug out by slaves. In his studies he notes an abundance of documentary and anecdotal evidence which supports landscape transformation by the manipulation of waterways. Transformation continues in more recent times as noted when in 1961, a group of villagers from Igarapé Guariba cut a canal about two miles (3 km) long across fields thick with tall papyrus grass and into dense tropical rain forest. The narrow canal and the stream that flowed into it have since formed a full-fledged river more than six hundred yards wide at its mouth, and the landscape in this part of the northern Brazilian state of Amapá was dramatically transformed.\n\nIn general, with an increase in global population growth, comes an increase in the anthropogenic transformation of waterways. The Sumerians had created extensive irrigations by 4000 BC. As the population increased in the 3,000 years of agriculture, the ditches and canals increased in number. By the early 1900s, ditching, dredging, and diking had become common practice. This led to an increase in erosion which impacted the landscapes. Human activities have affected the natural role of rivers and its communal value. These changes in waterways have impacted the floodplains, natural tidal patterns, and the surrounding land.\n\nThe importance of understanding such transformation is it provides a more accurate understanding to long-standing popular and academic insights of the Amazon, as well as other ecological settings, as places where indigenous populations have dealt with the forces of nature. Ecological landscapes have been portrayed as an environment, not a society. Recent studies supported by historical ecologists, however, understand that ecological landscape like the Amazon are biocultural, rather than simply natural and provide for a greater understanding of anthropogenic transformation of both waterways and landscapes.\n\nSoil management, or direct human interaction with the soil, is another mechanism of anthropogenic change studied by historical ecologists. Soil management can take place through rearranging soils, altering drainage patterns, and building large earthen formations. Consistent with the basic premises of historical ecology, it is recognized that anthropogenic soil management practices can have both positive and negative effects on local biodiversity. Some agricultural practices have led to organically and chemically impoverished soils. In the North American Midwest, industrial agriculture has led to a loss in topsoil. Salinization of the Euphrates River has occurred due to ancient Mesopotamian irrigation, and detrimental amounts of zinc have been deposited in the New Caliber River of Nigeria. Elsewhere, soil management practices may not have any effect on soil fertility. The iconic mounds of the Hopewell Indians built in the Ohio River valley likely served a religious or ceremonial purpose, and show little evidence of changing soil fertility in the landscape.\n\nThe case of soil management in the Neotropics (including the Amazon) is a classic example of beneficial results of human-mediated disturbance. In this area, prehistoric peoples altered the texture and chemical composition of natural soils. The altered black and brown earths, known as Amazon Dark Earths, or Terra preta, are actually much more fertile than unaltered surrounding soils. Furthermore, the increased soil fertility improves the results of agriculture. Terra preta is characterized by the presence of charcoal in high concentrations, along with pottery shards and organic residues from plants, animal bones, and feces. It is also shows increased levels of nutrients such as nitrogen, phosphorus, calcium, zinc, and manganese; along with high levels of microorganic activity. It is now accepted that these soils are a product of a labor-intensive technique termed slash-and-char. In contrast to the commonly known slash-and-burn technique, this uses a lower temperature burn that produces more charcoal than ashes. Research shows these soils were created by human activity between 9000 and 2500 years ago. Contemporary local farmers actively seek out and sell this dark earth, which covers around 10% of the Amazon basin. Harvesting Terra preta does not deplete it however, for it has the ability to regenerate at the rate of one centimeter per year by sequestering more carbon.\nInterest in and the study of Amazon dark earths was advanced with the work of Wim Sombroek. Sombroek's interest in soil fertility came from his childhood. He was born in the Netherlands and lived through the Dutch famine of 1944. His family subsided on a small plot of land that had been maintained and improved for generations. Sombroek's father, in turn, improved the land by sowing it with the ash and cinders from their home. Sombroek came across Terra preta in the 1950s and it reminded him of the soil from his childhood, inspiring him to study it further. Soil biologist from the University of Kansas William W. Woods is also a major figure in Terra preta research. Woods has made several key discoveries and his comprehensive bibliography on the subject doubles in size every decade.\n\nGlobally, forests are well known for having greater biodiversity than nearby savannas or grasslands. Thus, the creation of ‘forest islands’ in multiple locations can be considered a positive result of human activity. This is evident in the otherwise uniform savannas of Guinea and central Brazil that are punctured by scattered clumps of trees. These clumps are the result of generations of intense resource management. Earth works and mounds formed by humans, such as the Ibibate mound complex in the Llanos de Mojos in Bolivia, are examples of built environments that have undergone landscape transformation and provide habitats for a greater number of species than the surrounding wetland areas. The forest islands in the Bolivian Amazon not only increase the local plant species diversity, but also enhance subsistence possibilities for the local people.\n\nHistorical ecology involves an understanding of multiple fields of study such as archaeology and cultural history as well as ecological processes, species diversity, natural variability, and the impact of human-mediated disturbances. Having a broad understanding of landscapes allows historical ecology to be applied to various disciplines. Studying past relationships between humans and landscapes can successfully aid land managers by helping develop holistic, environmentally rational, and historically accurate plans of action. As summarized in the postulates of historical ecology, humans play significant roles in the creation and destruction of landscapes as well as in ecosystem function. Through experience, many indigenous societies learned how to effectively alter their landscapes and biotic distributions. Modern societies, seeking to curtail the magnitude of their effects on the landscape, can use historical ecology to promote sustainability by learning from the past. Farmers in the Amazon region, for example, now utilize nutrient-rich terra preta to increase crop yields much like the indigenous societies that lived long before them.\n\nHistorical ecology can also aid in the goals of other fields of study. Conservation biology recognizes different types of land management processes, each attempting to maintain the landscape and biota in their present form. Restoration ecology restores sites to former function, structure, and components of biological diversity through active modification of the landscapes. Reclamation deals with shifting a degraded ecosystem back toward a higher value or use, but not necessarily to its original state. Replacement of an ecosystem would create an entirely new one. Revegetation involves new additions of biota into a landscape, not limited to the original inhabitants of an area. Each method can be enriched by the application of historical ecology and the past knowledge it supplies. The interdisciplinary nature of historical ecology would permit conservation biologists to create more effective and efficient landscape improvements. Reclamation and revegetation can use a historical perspective to determine what biota will be able to sustain large populations without threatening native biota of the landscape.\n\nA tropical forest in particular needs to be studied extensively because it is a highly diverse, heterogeneous setting. Historical ecology can use archaeological sites within this setting to study past successes and failures of indigenous peoples. The use of swidden fires in Laos is an example of historical ecology as used by current land managers in policy-making. Swidden fires were originally considered a source of habitat degradation. This conclusion led the Laos government to discourage farmers from using swidden fires as a farming technique. However, recent research has found that swidden fires were practiced historically in Laos and were not, in fact, the source of degradation. Similar research revealed that habitat degradation originated from a population increase after the Vietnam War. The greater volume of people compelled the government to put pressure on farmers for increased agricultural production. Land managers no longer automatically eliminate the use of swidden fires, but rather the number of swidden fires that are set for government-sponsored agricultural purposes.\n\nThe San Francisco Estuary Institute also uses historical ecology to study human impacts on the California landscape to guide environmental management. A study of the wetlands of Elkhorn Slough near Monterey, California, sought to enhance conservation and restoration activities. By using historical data such as maps, charts, and aerial photographs, researchers were able to trace habitat change to built structures that had negatively altered the tidal flow into the estuaries dating from the early 1900s. The study further suggested using techniques that \"imitate the complex structure of natural tidal wetlands and maintain connectivity with intact wetland habitats as well as with adjoining subtidal and upland habitats.\"\n\n", "id": "1881089", "title": "Historical ecology"}
{"url": "https://en.wikipedia.org/wiki?curid=24755469", "text": "Island ecology\n\nIsland ecology is the study of island organisms and their interactions with each other and the environment. Islands account for nearly 1/6 of earth’s total land area, yet the ecology of island ecosystems is vastly different from that of mainland communities. Their isolation and high availability of empty niches leads to increased speciation. As a result, island ecosystems comprise 30% of the world’s biodiversity hotspots, 50% of marine tropical diversity, and some of the most unusual and rare species. Many species still remain unknown.\n\nThe diversity of species on islands is highly impacted by human activities such as deforestation and introduction of exotic species. In response, ecologists and managers are directing attention towards conservation and restoration of island species. Because they are simple systems, islands provide an opportunity to study processes of extinction that can be extrapolated to larger ecosystems.\n\nIslands are attractive sites for ecological research because they provide clear examples of evolution in action. They show interesting patterns of colonization, adaptation, and speciation.\n\nIslands are surrounded by water, and may or may not exist as part of a continental land mass. Oceanic islands arise due to volcanic activity or reef growth, and usually subside over time due to erosion and changing sea levels. When islands emerge, they undergo the process of ecological succession as species colonize the island (see theory of island biogeography). New species cannot immigrate via land, and instead must arrive via air, water, or wind. As a result, organisms with high dispersal capabilities, such as plants and birds, are much more common on islands than are poorly dispersing taxa like mammals. However, some mammals are present on islands, presumably from swimming or riding on natural “rafts” that are washed away from the mainland.\n\nOf the species that arrive, only some will be able to survive and establish populations. As a result, islands have fewer species than mainland habitats. Island populations are small and exhibit low genetic variability (see founder effect), but are isolated from the predators and competitors that they initially evolved with. This can lead to a process called ecological release, where a species is released from its ancestral community interactions and then colonizes new niches.\n\nIn response to these changing ecological pressures, island species can become much more docile than their mainland counterparts, and may grow larger (see island gigantism) or smaller (see island dwarfism). Some of these unique adaptations are reflected in charismatic island species such as the giant tortoise, Komodo dragon, or pygmy mammoths. \n\nOther adaptations to life on islands include increased poikilothermy, relaxed anti-predator behavior, and reduced sexual selection in animals, and loss of herbivore defenses and reduced dispersal in plants.\n\nThe formation of new islands and their isolation from the mainland provides many unoccupied niches for species to adapt to. Since immigration of predators and competitors is limited, many organisms are able to persist in these new niches. This results in a high occurrence of endemism, where species are unique to a localized area. For example, 50% of endemic bird areas are found on islands.\n\nEndemism is often the result of adaptive radiation. Adaptive radiation is when a single species colonizes an area and rapidly diversifies to fill all of the available niches. A common example is the assemblage of finch species documented by Charles Darwin in the Galapagos Islands. Darwin’s finches exhibited adaptive radiation by evolving different beak sizes to exploit the diversity of seeds present on the different islands. \n\nBecause the distributions of these populations are limited by their island habitats, they tend to have fewer individuals than their mainland counterparts and lower genetic variation. This, along with the behavioral and ecological factors mentioned above, makes island species more vulnerable to extinction.\n\nThe continued survival of species on islands depends on factors such as natural selection, genetic variation, natural disturbances (hurricanes, volcanic eruptions) and human-caused disturbances (introduced species, habitat loss). Human-caused disturbances tend to be the greatest cause of mortality, and understanding the causes of extinction facilitates conservation efforts.\n\nThe movement of humans to islands has led to rapid extinction of native island species either from hunting, habitat destruction, or introduced species.\n\nMany large animals on islands have been hunted to extinction by humans. A well-known example is the dodo, once found on the island of Mauritius. It evolved to become large, flightless and docile, and was subsequently driven to extinction by humans and introduced predators.\n\nThe depletion of natural resources can have dramatic effects on island ecology. On Easter Island, the depletion of the forest by humans not only resulted in widespread loss of species, but also the collapse of the island civilization. Today there are over 500 million people on islands, all dependent on local resources either directly (traditional use) or indirectly (ecotourism revenue). Population growth and development result in heavy deforestation, pollution, and over-exploitation. Overharvesting of ocean fauna is particularly troubling as yields of coral reef fish species are an important food source for island populations.\n\nHumans have contributed to globalization and decreased effective isolation of island communities, allowing for invasion of exotic species. This can have a profound effect on the native species. In Guam, the introduced brown tree snake ate nearly all of the native vertebrate species to extinction. Feral cats and dogs have also greatly diminished native vertebrate populations on islands, through both predation and disease. Introduced ungulates are another major threat, as they graze on native vegetation and can destroy entire forests. Exotic grasses can out-compete native understory species and increase the risk of fire. Lastly, social insects such as ants also cause major problems.\n\nGlobal warming is emerging as a strong cause of species loss on islands. This can be due to sea level rise, intrusion of salt water into freshwater habitats, or species inability to adapt to increasing temperatures and extreme weather events. Plant species are particularly susceptible. In more isolated areas, such as the Southern Ocean Islands, indirect effects such as invasive species and global warming can play a greater role in influencing populations than overexploitation, pollution and habitat loss.\n\nHuman activities and the introduction of non-native species often cause trophic cascades, where direct effects on one species result in indirect effects on other species in the food web. An example is on Santa Cruz Island of the California Channel Islands, where DDT poisoning reduced bald eagle populations. This, along with an abundance of introduced feral pigs for prey, allowed golden eagles to colonize the island and replace bald eagles. However, the golden eagles also ate native island foxes. Fox population levels decreased to near extinction, while skunk populations increased due to relaxed competition with foxes.\n\nSince island ecosystems are self-contained, it should be possible to mitigate many of the threats to species. Ecologists and managers are working together to prioritize areas for conservation and to quickly design and implement action plans. Not everything can be put into a reserve, so it is important to first compile pertinent information and prioritize areas of concern. Once an area has been chosen, managers must then acquire ownership and gain support. Local experts and indigenous populations should also be involved in this process. Having clearly defined goals will facilitate the many necessary interactions between people and agencies. Once a reserve is in place, managers can then practice adaptive management and do continued community education. \n\nOn land, island conservation focuses on the protection of species and their habitat. In some cases, conservation can be integrated with agricultural production. For example, the \"Acacia koa\" plantations and wooded pastures in Hawaii are anthropogenically altered ecosystems, yet allow connectivity between forest fragments and thus maintain higher diversity than would open pasture. Other directions include habitat restoration, and eradication of introduced predators, ungulates, and exotic plants (via hunting, removal or biological control).\n\nIn marine ecosystems, there has been increasing establishment of “no-take” reserves. This allows for reestablishment of native species, and also augmentation of commercially harvested species. However, in both terrestrial and marine systems, these actions are expensive and do not always result in the desired outcomes. For example, some non-natives become keystone species and their removal can cause more harm than good to the ecosystem. To be more effective, managers of island ecosystems should share information and learn from each other’s mistakes. \n\nIsland conservation tends to focus on preservation of individual species and their habitats. However, many ecologists caution that ecological and evolutionary processes should be conserved as well. The conservation of island communities as a whole is closely linked to restoration. \n\nActive restoration on islands can be done for both animal species (translocations, induced breeding) and plant species (reforestation). Creating goals for restoration can be challenging because it is often impossible to restore the ecosystem to its “historic” or “normal” state, if that state can even be clearly defined. Restoration is never complete, as ecological communities are always in a state of change.\n\nAs resource depletion is a major issue on islands, the needs of human populations must also be taken into account. On many islands, scientists and managers are studying traditional practices of indigenous populations as potential conservation solutions. In some cases, limited-take systems that serve the community may provide a better alternative to fully closed protected areas, if there are not enough resources for proper enforcement. Public education plays an important role.\n\n\n", "id": "24755469", "title": "Island ecology"}
{"url": "https://en.wikipedia.org/wiki?curid=6327216", "text": "Pocosin\n\nPocosin is a type of palustrine wetland with deep, acidic, sandy, peat soils. Groundwater saturates the soil except during brief seasonal dry spells and during prolonged droughts. Pocosin soils are nutrient-deficient (oligotrophic), especially in phosphorus.\n\nPocosins occur in the southern portions of the Atlantic coastal plain of North America, spanning from southeastern Virginia, through North Carolina, and into South Carolina. However, the majority of pocosins are found in North Carolina. They occupy poorly drained higher ground between streams and floodplains. Seeps cause the inundation. There are often perched water tables underlying pocosins.\n\nShrub vegetation is common. Pocosins are sometimes called \"shrub bogs\". Pond pines (\"Pinus serotina\") dominate pocosin forests, but loblolly pine (\"Pinus taeda\") and longleaf pine (\"Pinus palustris\") are also associated with pocosins. Additionally, pocosins are home to rare and threatened plant species including Venus flytrap (\"Dionaea muscipula\") and sweet pitcher plant (\"Sarracenia rubra\").\n\nA distinction is sometimes made between short pocosins, which have shorter trees (less than ), deeper peat, and fewer soil nutrients, and tall pocosins, which have taller trees (greater than ), shallow peat, and more nutrient-rich soil. Where soil saturation is less frequent and peat depths shallower, pocosins transition into pine flatwoods. A loose definition of \"pocosin\" can include all shrub and forest bogs, as well as stands of Atlantic White Cedar (\"Chamaecyparis thyoides\") and loblolly pine on the Atlantic coastal plain. A stricter definition (promulgated by A. W. Kuchler) restricts pocosins to shrubby \"short pocosins\" and pond pine-forested \"tall pocosins\".\n\nPocosins are formed by the accumulation of organic matter, resembling black muck, that is built up over thousands of years. This accumulation of material causes the area to be highly acidic and nutrient-deficient. The thickness of the organic buildup varies depending on one's location within the pocosin. Near the edges the buildup can be several inches thick but toward the center it can be up to several feet thick. Vegetation on the pocosin varies throughout. At the edges more pond pine is found with an abundance of titi, zenobia (a shrub unique to pocosins), and greenbrier vines. Closer to the center thin, stunted trees are typically found however fewer shrubs and vines are present.\n\nPocosins are very important for birds living in cold climates during the winter months and migrate southward. The abundance of various types of available berries draws birds from colder areas. \n\nPocosin ecosystems are fire-adapted (pyrophytic). Pond pines exhibit serotiny, such that wildfire can create a pond pine seedbed in the soil. Wildfires in pocosins tend to be intense, sometimes burning deep into the peat, resulting in small lakes and ponds.\n\nWildfires occurring about once a decade tend to cause pond pines to dominate over other trees, and cane (\"Arundinaria\") rather than shrubs to dominate the understory. More frequent fires result in a pyrophytic shrub understory. Annual fires prevent shrub growth and thin the pond pine forest cover, creating a flooded savanna with grass, sedge, and herb groundcover.\n\nThe word \"pocosin\" comes from an Eastern Algonquian word meaning \"swamp-on-a-hill\", however, a more accurate description of a pocosin would be a “raised bog”. The city of Poquoson, Virginia, located in the coastal plain of Virginia (see Tidewater region of Virginia), derives its name from this geographic feature.\n\n", "id": "6327216", "title": "Pocosin"}
{"url": "https://en.wikipedia.org/wiki?curid=30389209", "text": "Extinction debt\n\nIn ecology, extinction debt is the future extinction of species due to events in the past. Extinction debt occurs because of time delays between impacts on a species, such as destruction of habitat, and the species' ultimate disappearance. For instance, long-lived trees may survive for many years even after reproduction of new trees has become impossible, and thus they may be committed to extinction. Technically, extinction debt generally refers to the \"number of species\" in an area likely to become extinct, rather than the prospects of any one species, but colloquially it refers to any occurrence of delayed extinction.\n\nExtinction debt may be local or global, but most examples are local as these are easier to observe and model. It is most likely to be found in long-lived species and species with very specific habitat requirements (specialists). Extinction debt has important implications for conservation, as it implies that species may become extinct due to past habitat destruction, even if continued impacts cease, and that current reserves may not be sufficient to maintain the species that occupy them. Interventions such as habitat restoration may reverse extinction debt.\n\n\"Immigration credit\" is the corollary to extinction debt. It refers to the number of species likely to immigrate to an area after an event such as the restoration of an ecosystem.\n\nThe term \"extinction debt\" was first used in 1994 in a paper by David Tilman, Robert May, Clarence Lehman and Martin Nowak, although Jared Diamond used the term \"relaxation time\" to describe a similar phenomenon in 1972.\n\nExtinction debt is also known by the terms dead clade walking, and survival without recovery when referring to the species affected. The phrase \"dead clade walking\" was coined by David Jablonski as early as 2001 as a reference to \"Dead Man Walking\", a film whose title is based on American prison slang for a condemned prisoner's last walk to the execution chamber. \"Dead clade walking\" has since appeared in other scientists' writings about the aftermaths of mass extinctions.\n\nIn discussions of threats to biodiversity, extinction debt is analogous to the \"climate commitment\" in climate change, which states that inertia will cause the earth to continue to warm for centuries even if no more greenhouse gasses are emitted. Similarly, the current extinction may continue long after human impacts on species halt.\n\nJablonski recognized at least four patterns in the fossil record following mass extinctions: (1) unbroken continuity (large-scale patterns continuing with little disruption), (2) continuity with setbacks (patterns disturbed by the extinction event but soon continuing on the previous trajectory), (3) survival without recovery or \"dead clade walking\" (a group's dwindling to extinction or minor ecological niches), and (4) unbridled diversification (an increase in diversity and species richness, as in the mammals following the end-Cretaceous extinction event).\n\nExtinction debt is caused by many of the same drivers as extinction. The most well-known drivers of extinction debt are habitat fragmentation and habitat destruction. These cause extinction debt by reducing the ability of species to persist via immigration to new habitats. Under equilibrium conditions, species may become extinct in one habitat patch, yet continues to survive because it can disperse to other patches. However, as other patches have been destroyed or rendered inaccessible due to fragmentation, this \"insurance\" effect is reduced and the species may ultimately become extinct.\n\nPollution may also cause extinction debt by reducing a species' birth rate or increasing its death rate so that its population slowly declines. Extinction debts may be caused by invasive species or by climate change.\n\nExtinction debt may also occur due to the loss of mutualist species. In New Zealand, the local extinction of several species of pollinating birds in 1870 has caused a long-term reduction in the reproduction of the shrub species \"Rhabdothamnus solandri\", which requires these birds to produce seeds. However, as the plant is slow-growing and long-lived, its populations persist.\n\nJablonski found that the extinction rate of marine invertebrates was significantly higher in the stage (major subdivision of an epoch – typically 2–10 million years' duration) following a mass extinction than in the stages preceding the mass extinction. His analysis focused on marine molluscs since they constitute the most abundant group of fossils and are therefore the least likely to produce sampling errors. Jablonski suggested that two possible explanations deserved further study:\n\nThe time to \"payoff\" of extinction debt can be very long. Islands that lost habitat at the end of the last ice age 10,000 years ago still appear to be losing species as a result. It has been shown that some bryozoans, a type of microscopic marine organism, became extinct due to the volcanic rise of the Isthmus of Panama. This event cut off the flow of nutrients from the Pacific Ocean to the Caribbean 3–4.5 million years ago. While bryozoan populations dropped severely at this time, extinction of these species took another 1–2 million years.\n\nExtinction debts incurred due to human actions have shorter timescales. Local extinction of birds from rainforest fragmentation occurs over years or decades, while plants in fragmented grasslands show debts lasting 50 to 100 years. Tree species in fragmented temperate forests have debts lasting 200 years or more.\n\nTilman et al. demonstrated that extinction debt could occur using a mathematical ecosystem model of species metapopulations. Metapopulations are multiple populations of a species that live in separate habitat patches or islands but interact via immigration between the patches. In this model, species persist via a balance between random local extinctions in patches and colonization of new patches. Tilman et al. al used this model to predict that species would persist long after they no longer had sufficient habitat to support them. When used to estimate extinction debts of tropical tree species, the model predicted debts lasting 50–400 years.\n\nOne of the assumptions underlying the original extinction debt model was a trade-off between species' competitive ability and colonization ability. That is, a species that competes well against other species, and is more likely to become dominant in an area, is less likely to colonize new habitats due to evolutionary trade-offs . One of the implications of this assumption is that better competitors, which may even be more common than other species, are more likely to become extinct than rarer, less competitive, better dispersing species. This has been one of the more controversial components of the model, as there is little evidence for this trade-off in many ecosystems, and in many empirical studies dominant competitors were least likely species to become extinct. A later modification of the model showed that these trade-off assumptions may be relaxed, but need to exist partially, in order for the theory to work.\n\nFurther theoretical work has shown that extinction debt can occur under many different circumstances, driven by different mechanisms and under different model assumptions. The original model predicted extinction debt as a result of habitat destruction in a system of small, isolated habitats such as islands. Later models showed that extinction debt could occur in systems where habitat destruction occurs in small areas within a large area of habitat, as in slash-and-burn agriculture in forests, and could also occur due to decreased growth of species from pollutants. Predicted patterns of extinction debt differ between models, though. For instance, habitat destruction resembling slash-and-burn agriculture is thought to affect rare species rather than poor colonizers. Models that incorporate stochasticity, or random fluctuation in populations, show extinction debt occurring over different time scales than classic models.\n\nMost recently, extinction debts have been estimated through the use models derived from neutral theory. Neutral theory has very different assumptions than the metapopulation models described above. It predicts that the abundance and distribution of species can be predicted entirely through random processes, without considering the traits of individual species. As extinction debt arises in models under such different assumptions, it is robust to different kinds of models. Models derived from neutral theory have successfully predicted extinction times for a number of bird species, but perform poorly at both very small and very large spatial scales.\n\nMathematical models have also shown that extinction debt will last longer if it occurs in response to large habitat impacts (as the system will move farther from equilibrium), and if species are long-lived. Also, species just below their extinction threshold, that is, just below the population level or habitat occupancy levels required sustain their population, will have long-term extinction debts. Finally, extinction debts are predicted to last longer in landscapes with a few large patches of habitat, rather than many small ones.\n\nExtinction debt is difficult to detect and measure. Processes that drive extinction debt are inherently slow and highly variable (noisy), and it is difficult to locate or count the very small populations of near-extinct species. Because of these issues, most measures of extinction debt have a great deal of uncertainty.\n\nDue to the logistical and ethical difficulties of inciting extinction debt, there are few studies of extinction debt in controlled experiments. However, experiments of insects living on moss habitats demonstrated that extinction debt occurs after habitat destruction. In these experiments, it took 6–12 months for species to die out following the destruction of habitat.\n\nExtinction debts that reach equilibrium in relatively short time scales (years to decades) can be observed via measuring the change in species numbers in the time following an impact on habitat. For instance, in the Amazon rainforest, researchers have measured the rate at which bird species disappear after forest is cut down. As even short-term extinction debts can take years to decades to reach equilibrium, though, such studies take many years and good data are rare.\n\nMost studies of extinction debt compare species numbers with habitat patterns from the past and habitat patterns in the present. If the present populations of species are more closely related to past habitat patterns than present, extinction debt is a likely explanation. The magnitude of extinction debt (i.e., number of species likely to become extinct) can not be estimated by this method.\n\nIf one has information on species populations from the past in addition to the present, the magnitude of extinction debt can be estimated. One can use the relationship between species and habitat from the past to predict the number of species expected in the present. The difference between this estimate and the actual number of species is the extinction debt.\n\nThis method requires the assumption that in the past species and their habitat were in equilibrium, which is often unknown. Also, a common relationship used to equate habitat and species number is the species-area curve, but as the species-area curve arises from very different mechanisms than those in metapopulation based models, extinction debts measured in this way may not conform with metapopulation models' predictions. The relationship between habitat and species number can also be represented by much more complex models that simulate the behavior of many species independently.\n\nIf data on past species numbers or habitat are not available, species debt can also be estimated by comparing two different habitats: one which is mostly intact, and another which has had areas cleared and is smaller and more fragmented. One can then measure the relationship of species with the condition of habitat in the intact habitat, and, assuming this represents equilibrium, use it to predict the number of species in the cleared habitat. If this prediction is lower than the actual number of species in the cleared habitat, then the difference represents extinction debt. This method requires many of the same assumptions as methods comparing the past and present.\n\nStudies of European grasslands show evidence of extinction debt through both comparisons with the past and between present-day systems with different levels of human impacts. The species diversity of grasslands in Sweden appears to be a remnant of more connected landscapes present 50 to 100 years ago. In alvar grasslands in Estonia that have lost area since the 1930s, 17-70% of species are estimated to be committed to extinction. However, studies of similar grasslands in Belgium, where similar impacts have occurred, show no evidence of extinction debt. This may be due to differences in the scale of measurement or the level of specialization of grass species.\n\nForests in Vlaams-Brabant, Belgium, show evidence of extinction debt remaining from deforestation that occurred between 1775 and 1900. Detailed modeling of species behavior, based on similar forests in England that did not experience deforestation, showed that long-lived and slow-growing species were more common than equilibrium models would predict, indicating that their presence was due to lingering extinction debt.\n\nIn Sweden, some species of lichens show an extinction debt in fragments of ancient forest. However, species of lichens that are habitat generalists, rather than specialists, do not.\n\nExtinction debt has been found among species of butterflies living in the grasslands on Saaremaa and Muhu - islands off the western coast of Estonia. Butterfly species distributions on these islands are better explained by the habitat in the past than current habitats.\n\nOn the islands of the Azores Archipelago, more than 95% of native forests have been destroyed in the past 600 years. As a result, more than half of arthropods on these islands are believed to be committed to extinction, with many islands likely to lose more than 90% of species.\n\n80-90% of extinction from past deforestation in the Amazon has yet to occur, based on modeling based on species-area relationships. Local extinctions of approximately 6 species are expected in each 2500 km region by 2050 due to past deforestation. Birds in the Amazon rain forest continued to become extinct locally for 12 years following logging that broke up contiguous forest into smaller fragments. The extinction rate slowed, however, as forest regrew in the spaces in between habitat fragments.\n\nCountries in Africa are estimated to have, on average, a local extinction debt of 30% for forest-dwelling primates. That is, they are expected to have 30% of their forest primate species to become extinct in the future due to loss of forest habitat. The time scale for these extinctions has not been estimated.\n\nBased on historical species-area relationships, Hungary currently has approximately nine more species of raptors than are thought to be able to be supported by current nature reserves.\n\nThe existence of extinction debt in many different ecosystems has important implications for conservation. It implies that in the absence of further habitat destruction or other environmental impacts, many species are still likely to become extinct. Protection of existing habitats may not be sufficient to protect species from extinction. However, the long time scales of extinction debt may allow for habitat restoration in order to prevent extinction, as occurred in the slowing of extinction in Amazon forest birds above. In another example, it has been found that grizzly bears in very small reserves in the Rocky Mountains are likely to become extinct, but this finding allows the modification of reserve networks to better support their populations.\n\nThe extinction debt concept may require revision of the value of land for species conservation, as the number of species currently present in a habitat may not be a good measure of the habitat's ability to support species (see carrying capacity) in the future. As extinction debt may last longest near extinction thresholds, it may be hardest to detect the threat of extinction for species that conservation could benefit the most.\n\nEconomic analyses have shown that including extinction in management decision-making process changes decision outcomes, as the decision to destroy habitat changes conservation value in the future as well as the present. It is estimated that in Costa Rica, ongoing extinction debt may cost between $88 million and $467 million.\n\n", "id": "30389209", "title": "Extinction debt"}
{"url": "https://en.wikipedia.org/wiki?curid=21474906", "text": "Traditional ecological knowledge\n\nTraditional ecological knowledge (TEK) describes aboriginal, indigenous, or other forms of traditional knowledges regarding sustainability of local resources. TEK has become a field of study in anthropology, and refers to \"a cumulative body of knowledge, belief, and practice, evolving by accumulation of TEK and handed down through generations through traditional songs, stories and beliefs. [It concerns] the relationship of living beings (including human) with their traditional groups and with their environment.\" Such knowledge is commonly used in natural resource management as a substitute for baseline environmental data to measure changes over time in remote regions that have little recorded scientific data.\n\nThe use of traditional knowledge in this field in management and science is controversial since methods of acquiring and accumulating the knowledge, although often including forms of empirical research and experimentation, differ from those used to create and validate scientific ecological knowledge . Non-tribal government agencies, such as the United States Environmental Protection Agency have established integration programs with some tribal governments in order to utilize TEK in environmental plans and climate change tracking.\n\nThere is a debate whether Indigenous populations retain an intellectual property right over traditional knowledge and whether use of this knowledge requires prior permission and license. This is especially complicated because TEK is most frequently preserved as oral tradition and as such may lack objectively confirmed documentation. Ironically, those same methods that might resolve the issue of documentation compromise the very nature of traditional knowledge.\n\nTraditional knowledge is often used to sustain local populations and maintain resources necessary for survival. However, it can be weakened or invalidated in the context of rapid climate change, environmental impact, or other situations in which significant alterations of ecosystems render it weak or obsolete.\n\nTEK can also be referred to as traditional environmental knowledge which emphasizes the different components and interactions of the environment. More specifically it contains the knowledge of species of both animals and plants, and biophysical characteristics of the environment through space and time. However Traditional Ecological Knowledge and Traditional Environmental Knowledge can be used interchangeably due to the nature of both terms being synonymous where both emphasize the cultural relations with the environment and non-human relations with animals.\n\nThe earliest systematic studies of traditional ecological knowledge were conducted in anthropology. Ecological knowledge was studied through the lens of ethnoecology, \"an approach that focuses on the conceptions of ecological relationships held by a people or a culture,\" in understanding how systems of knowledge were developed by a given culture. Harold Colyer Conklin, an American anthropologist who pioneered the study of ethnoscience, took the lead in documenting indigenous ways of understanding the natural world. Conklin and others documented how traditional peoples, such as Philippine horticulturists, displayed remarkable and exceptionally detailed knowledge about the natural history of places where they resided. Direct involvement in gathering, fashioning products from, and using local plants and animals created a scheme in which the biological world and the cultural world were tightly intertwined. Although the field of TEK began with documentation of lists of species used by different indigenous groups and their \"taxonomies of plants, animals, and later, of other environmental features such as soils,\" the shift from documentation to consideration of functional relationships and mechanisms gave rise to the field as it is recognized today. In emphasizing the study of adaptive processes, which argues that social organization itself is an ecological adaptational response by a group to its local environment, human-nature relations and the practical techniques on which these relationships and culture depended, the field of TEK could analyze a broad range of questions related to cultural ecology and ecological anthropology, .\n\nBy the mid 1980s a growing body of literature on traditional ecological knowledge documented both the environmental knowledge held by diverse indigenous peoples and their ecological relations. The studies included examining \"cultivation and biodiversity conservation in tropical ecosystems, and traditional knowledge and management systems in coastal fisheries and lagoons, semi-arid areas, and the Arctic.\" What these studies illustrated was that a variety of \"traditional peoples had their own understandings of ecological relationships and distinct traditions of resource management.\" The rise of traditional ecological knowledge at this time led to international recognition of its potential applications in resource management practices and sustainable development. The 1987 report by the World Commission on Environment and Development reflects the consensus at the time. The report points out that the successes of the 20th century (decreases in infant mortality, increases in life expectancy, increases in literacy, and global food production) have given rise to trends that have caused environmental decay \"in an ever more polluted world among ever decreasing resources.\" Hope, however, existed for traditional lifestyles. The report declared that tribal and indigenous peoples had lifestyles that could provide modern societies with lessons in the management of resources in complex forest, mountain, and dryland ecosystems.\n\nFulvio Mazzocchi of the Italian National Research Council's Institute of Atmospheric Pollution contrasts traditional knowledge from scientific knowledge as follows:\n\nThe aspects of traditional ecological knowledge provide different typologies in how it is utilized and understood. These are good indicators in how it is used from different perspectives and how they are interconnected, providing more emphasis on \"cooperative management to better identify areas of difference and convergence when attempting to bring two ways of thinking and knowing together.\"\n\nThe first aspect of traditional ecological knowledge incorporates the factual, specific observations generated by recognition, naming, and classification of discrete components of the environment. This aspect is about understanding the interrelationship with species and their surrounding environment. It is also a set of both empirical observations and information emphasizing the aspects of animals and their behavior, and habitat, and the physical characteristics of species, and animal abundance. This type of \"empirical knowledge consists of a set of generalized observations conducted over a long period of time and reinforced by accounts of other TEK holders.\"\n\nThe second aspect refers to the ethical and sustainable use of resources in regards to management systems. This is achieved through strategic planning to ensure resource conservation. More specifically this face involves dealing with pest management, resource conversion, multiple cropping patterns, and methods for estimating the state of resources. A lot of ignorance toward traditional ecological knowledge is at the fault of management, these people are used to growing up in a more modern advanced system, they tend to ignore it.\n\nThe third face refers to time dimension aspect of traditional ecological knowledge, focusing on the past and current uses of the environment transmitted through oral history. Oral history is also used to transmit cultural heritage through generation to generation to maintain the sense of family and community.\n\nThe fourth face refers to value statements and connections between the belief system and the organization of facts. In regards to TEK it refers to environmental ethics that keeps exploitative abilities in check. This face also refers to the expression of values concerning the relationship with the habitats of species and their surrounding environment - the human-relationship environment.\n\nThe fifth face refers to the role of language and images of the past giving life to culture. The relationship between Aboriginals (original inhabitants) and their environment are vital to sustaining the cultural components that define them. This face reflects the stories, values, and social relations that reside in places as contributing to the survival, reproduction, and evolution of aboriginal cultures, and identities. It also stresses \"the restorative benefits of cultural landscapes as places for renewal\"\n\nThis aspect is a culturally based cosmology that is the foundation of the other aspects. The combination relates to the assumptions and beliefs about how things work, and explains the way in which things are connected, and gives principles that regulate human-animal relations and the role of humans in the world. From an anthropological perspective, cosmology attempts to understand the human-animal relationship and how these directly influence social relationships, obligations toward community members, and management practices.\n\nEcosystem management is a multifaceted and holistic approach to natural resource management. It incorporates both science and traditional ecological knowledge to collect data from long term measures that science cannot. This is achieved by scientists and researchers collaborating with Indigenous peoples through a consensus decision-making process while meeting the socioeconomic, political and cultural needs of current and future generations.\n\nThe U.S. Environmental Protection Agency was one of the first federal agencies to develop formal policies detailing how it would collaborate with tribal governments and acknowledge tribal interests in enacting its programs \"to protect human health and the environment.\" In recognizing tribal peoples connection to the environment the EPA has sought to develop environmental programs that integrate traditional ecological knowledge into the \"agency's environmental science, policy, and decision-making processes.\"\n\nAlthough TEK is not currently recognized as an important component of mainstream environmental decision making, scientists are working on developing core science competency programs that align with TEK and promote self-sufficiency and determination.\n\nIn November 2000, U.S. President Bill Clinton issued Executive Order 13175, which required federal departments and agencies to consult with Indian Tribal governments in the development of policies that would have Tribal implications. Tribal Implications are defined by the EPA as having \"substantial direct effects on one or more Indian tribes, on the relationship between the federal government and Indian tribes, or on the distribution of power and responsibilities between the federal government and Indian tribes.\" As a Federal agency of the U.S. government, the EPA was required to establish a set of standards for the consultation process. As its initial response, the agency developed a set of standards that would allow for meaningful communication and coordination between the agency and tribal officials prior to the agency taking actions or implementing decisions that may affect tribes. The standards also designated EPA consultation contacts to promote consistency and coordination of the consultation process, and established management oversight and reporting to ensure accountability and transparency.\n\nOne form of consultation has been EPA Tribal Councils. In 2000, the EPA's Office of Research and Development formed the EPA Tribal Science Council. The council, made up of representatives from tribes across the nation, is meant to provide a structure for tribal involvement in EPA's science efforts, and serve as a vehicle through which EPA may gain an understanding of the scientific issues that are of highest priority to tribes at a national level. The Council also offers tribes an opportunity to influence EPA’s scientific agenda by raising these priority issues to an EPA-wide group.\n\nOf importance for tribal members at the initial gathering of the EPA Tribal Science Council was the inherent differences in tribal traditional lifeways and western science. These lifeways include \"spiritual, emotional, physical, and mental connections to the environment; connections which are based on intrinsic, immeasurable values\"; and an understanding that the earth’s resources will provide everything necessary for human survival.\n\nThe EPA's Tribal Science Council, however, was meant to act as a meeting place where both groups could \"share information that may contribute to environmental protection for all peoples with neither culture relinquishing its identity.\" In an effort to protect TTL the Council identified subsitence as a critical area for investigation. The EPA-Tribal Science Council defined subsistence as: the \"relationships between people and their surrounding environment, a way of living. Subsistence involves an intrinsic spiritual connection to the earth, and includes an understanding that the earth’s resources will provide everything necessary for human survival. People who subsist from the earth’s basic resources remain connected to those resources, living within the circle of life. Subsistence is about living in a way that will ensure the integrity of the earth’s resources for the beneficial use of generations to come.\" Because TTL or TEK is specific to a location and includes the relationships between plants and animals, and the relationship of living beings to the environment, acknowledgment of subsitence as a priority allows for the knowledge and practices of TTL to be protected. For example, as part of their deliberation regarding subsistence, the Council agreed to identify resource contamination as “the most critical tribal science issue at this time.” Because tribal people with subsistence lifestyles rely the environment for traditional techniques of farming, hunting. fishing, forestry, and medicines, and ceremonies, contaminants disproportionately impact tribal peoples and jeopardizes their TTL. As the EPA Council stated, \"Tribal subsistence consumption rates are typically many times higher than those of the general population, making the direct impact of resource contamination a much more immediate concern.\" As native peoples struggle with tainted resources, the Council has made progress in investigating its impacts.\n\nDespite such efforts, there are still barriers to progress within the EPA-Tribal Science Council. For example, one obstacle has been the nature of TTL. Tribal Traditional Lifeways are passed down orally, from person to person, generation to generation, whereas western science relies on the written word, communicated through academic and literate transmission. Endeavors to bring together western scientists and tribal people have also been hindered by Native American's perceptions that scientific analysis are put in a metaphorical “black box” that shuts out tribal input. Regardless, the EPA has recognized the ability of indigenous knowledge to advance scientific understanding and provide new information and perspectives that may benefit the environment and human health.\n\nThe integration of TTL into the EPA's risk assessment paradigm is one example of how the EPA-Tribal Science Council has been able to enact change in EPA culture. The risk assessment paradigm is an \"organizing framework for the scientific analysis of the potential for harmful impacts to human health and the environment as a result of exposure to contaminants or other environmental stressors.\" Risk assessment has been used by the EPA to establish \"clean-up levels at hazardous waste sites, water quality and air quality criteria, fish advisories, and bans or restricted uses for pesticides and other toxic chemicals.\" Tribal people are concerned, however, that current risk assessment methodologies do not afford complete value to tribal culture, values, and/or life ways. The Tribal Science Council seeks to incorporate TTL into exposure assumptions existent in the EPA risk assessment model. A long-term goal for the EPA’s Tribal Science Council, however, is a complete shift in decision-making assessments from risk to preserving a healthy people and environment. As stated above, tribal people do not accept a separation of the human and ecological condition when they characterize risk. Through EPA initiated seminar, workshops, and projects, tribes have been able to engage in dialogue about the integration of Tribal Traditional Lifeways into EPA risk assessment and decision-making. This has occurred in a number of ways: inclusion of unique tribal cultural activities such as native basketry, the importance of salmon and other fishes, native plant medicine, consumption of large amounts of fish and game, and sweat lodges as exposures for estimating potential risk to people or to communities. Although these types of tribal specific activities may be included in EPA's risk assessment, there is no assurance that they will be included nor is there consistency in how they may be applied at different sites across the country.\n\nIn July 2014, the EPA announced its “Policy on Environmental Justice for Working with Federally Recognized Tribes and Indigenous Peoples,\" setting forth its principles for programs related to federally recognized tribes and indigenous peoples in order to \"support the fair and effective implementation of federal environmental laws, and provide protection from disproportionate impacts and significant risks to human health and the environment.\" Among the 17 principles were #3 (\"The EPA works to understand definitions of human health and the environment from the perspective of federally recognized tribes, indigenous peoples throughout the United States, and others living in Indian country\"); #6 (\"The EPA encourages, as appropriate and to the extent practicable and permitted by law, the integration of traditional ecological knowledge into the agency’s environmental science, policy, and decision-making processes, to understand and address environmental justice concerns and facilitate program implementation\"); and #7 (\"The EPA considers confidentiality concerns regarding information on sacred sites, cultural resources, and other traditional knowledge, as permitted by law.\"). While this policy identifies guidelines and procedures for the EPA in regards to environmental justice principles as they relate to tribes and indigenous peoples, the agency noted that they are in no way applicable as rules or regulations. They cannot be applied to particular situations nor change or substitute any law, regulation, or any other legally-binding requirement and is not legally enforceable.\n\nIn some areas, environmental degradation has led to a decline in traditional ecological knowledge. For example, at the Aamjiwnaang community of Anishnaabe First Nations people in Sarnia, Ontario, Canada, residents suffer from a \"noticeable decrease in male birth ratio ..., which residents attribute to their proximity to petrochemical plants\":\n\nTraditional ecological knowledge provides information about climate change across generations and geography of the actual residents in the area. Traditional ecological knowledge emphasizes and makes the information about the health and interactions of the environment the center of the information it carries. Climate change affects traditional ecological knowledge in the forms of the indigenous people’s identity and the way they live their lives.\n\nThe rising temperature poses as threats for ecosystems because it harms the livelihoods of certain tree and plant species. The combination of the rise in temperatures and change in precipitation levels affects plant growth locations. Climate change has wiped out much of the salmonids and acorns which make up a significant portion of the Karuk people's food. The increase in temperatures has stunted the wild rice's ability to grow and that has a negative influence on the Anishinaabe people's lifestyle. The Ojibwe people are also affected by the rising temperature's effect on rice growth.\n\nThe warming also affects insects and animals. The change in temperatures can affect many aspects from the times that insects emerge throughout the year to the changes in the habitats of animals throughout seasonal changes. In Maine, the loss of certain habitats and the increase in temperatures, especially in the colder seasons, encourages the survival of ticks that harm the moose population.\n\nAs the temperature gets hotter, wild fires become more likely. Not only are different aspects of the environment are affected, but together, the health of the ecosystem is affected by climate change and so the environmental resources available to the indigenous people can change in the amount available and the quality of the resources.\n\nThe Navajo Nation peoples in the Southwestern United States are victims to the pollution in the air. Climate change increases chances for droughts which lead to the dangers of airborne dust to be picked up from the ground.\n\nAs sea ice levels decrease, Alaska Native peoples experience changes in their daily lives; fishing, transportation, social and economic aspects of their lives become more unsafe. The Native peoples residing on the Gulf and West Coasts are affected by the rising sea temperatures because that makes the fish and shellfish, that they rely on for food and cultural activities, more susceptible to contamination. The defrosting of soil has caused damages to buildings and roadways. Water contamination becomes exacerbated as clean water resources dwindle.\n\nClimate changes undermine the daily lives of the Native peoples on many levels. For example, to immediately deal with these conditions, the indigenous people adjust when they harvest and what they harvest and also adjust their resource use. Climate change can change the accuracy of the information of traditional ecological knowledge. The indigenous people have relied deeply on indicators in nature to plan activities and even for short- term weather predictions. As a result of even more increasing unfavorable conditions, the indigenous people relocate to find other ways to survive. As a result, there is a loss of cultural ties to the lands they once resided on and there is also a loss to the traditional ecological knowledge they had with the land there. Climate change adaptations not properly structured or implemented can harm the indigenous people's rights.\n\nThe EPA has mentioned that it would take traditional ecological knowledge into consideration in planning adaptations to climate change. The National Resource Conservation Service of the United States Department of Agriculture has used methods of the indigenous people to combat climate change conditions.\n\nIn one study, villagers of Savoonga and Shaktoolik, Alaska reported that over the last twenty years of their lives, the weather has become more difficult to predict, the colder season has shortened, there is more difficulty in predicting the amount of plants available for harvests, there are differences in animal migrations, there are more sightings of new species than before, and the activities of hunting and gathering have become not as predictable nor occur as often due to more limited availability to do so. The residents saw a noticeable change in their climate which also affected their livelihoods. The plants and animals are not as consistent with their availability which affects the residents' hunting and gathering because there is not as much to hunt or gather. The appearance of new species of plants and animals is also a physical and nutritional safety concern because they are not traditionally part of the land.\n\n\n\n", "id": "21474906", "title": "Traditional ecological knowledge"}
{"url": "https://en.wikipedia.org/wiki?curid=30509934", "text": "Ecological fitting\n\nEcological fitting is \"the process whereby organisms colonize and persist in novel environments, use novel resources or form novel associations with other species as a result of the suites of traits that they carry at the time they encounter the novel condition.” \nIt can be understood as a situation in which a species' interactions with its biotic and abiotic environment seem to indicate a history of coevolution, when in actuality the relevant traits evolved in response to a different set of biotic and abiotic conditions. The simplest form of ecological fitting is resource tracking, in which an organism continues to exploit the same resources, but in a new host or environment. In this framework, the organism occupies a multidimensional operative environment defined by the conditions in which it can persist, similar to the idea of the Hutchinsonian niche. In this case, a species can colonize new environments (e.g. an area with the same temperature and water regime) and/or form new species interactions (e.g. a parasite infecting a new host) which can lead to the misinterpretation of the relationship as coevolution, although the organism has not evolved and is continuing to exploit the same resources it always has. The more strict definition of ecological fitting requires that a species encounter an environment or host outside of its original operative environment and obtain realized fitness based on traits developed in previous environments that are now co-opted for a new purpose. This strict form of ecological fitting can also be expressed either as colonization of new habitat or the formation of new species interactions.\n\nThe evolutionary ecologist Dr. Daniel Janzen began to explicate the idea of ecological fitting with a 1980 paper that observed that many instances of ecological interactions were inferred to be the result of coevolution when this was not necessarily the case, and encouraged ecologists to use the term coevolution more strictly. He observed that the existing defense traits of plants were likely produced by co-evolution with herbivores or parasites that no longer co-occurred with the plants, but that these traits were continuing to protect the plants against new attacks.\nHe expanded this idea in a 1985 paper written while visiting Santa Rosa National Park in Costa Rica. While there, he observed that almost all of the species in the park occupied large geographic ranges, and despite the heterogeneity of habitats across these ranges, individuals were mostly identical across locations, indicating that little local adaptation had taken place. He described the cyclical life history pattern he believed responsible for this pattern: a species begins as a small population occupying a small area with little genetic variation, but then over the course of a few generations grows to occupy a large area, either because of the emergence of a genotype successful over a wider range, or because of the removal of a geographic barrier. This large interconnected population is now subject to many contradictory selection pressures and thus remains evolutionarily static until a disturbance separates populations, restarting the cycle. This cyclic life history pattern is dependent on three premises: that the ancestral range of most species is smaller than the ones now occupied, that biological communities have porous borders and are thus subject to invasion, and that species possess robust genotypes that allow them to colonize new habitats without evolution. Thus, many biological communities may be made up of organisms that despite their complex biological interactions have very little evolutionary history with each other.\n\nEcological fitting represents a contrasting view to, and null hypothesis for, the hypothesis that current species interactions are evidence of coevolution. Coevolution occurs when each species in a relationship imposes evolutionary selection on the other(s). Examples could include mutualisms or predator-prey systems. The traditional view of plant-insect, host-parasite, and other tightly associated species, explained by Ehrlich & Raven (1964) defines coevolution as the primary mechanism for these associations In his 1980 paper, Janzen gives a response to these adaptationist explanations of why a phenotype or species might exist in a particular environment, and expressed his concern with what he perceived as an overuse of coevolutionary explanations for current species associations. He stated that it would be difficult to distinguish between coevolution and ecological fitting, leading ecologists to potentially spurious explanations of current species associations. It is difficult to determine whether a close relationship is the result of coevolution or of ecological fitting because ecological fitting is a sorting process in which only associations that 'fit', or increase fitness (biology), will be maintained. When trying to determine which process is at work in a particular interaction, it is important to remember that species can only come into contact through biotic expansion and ecological fitting, followed by adaptation or coevolution. Thus, both processes are important in shaping interactions and communities.\n\nEcological fitting can occur by a variety of mechanisms, and can help to explain some ecological phenomena. Resource tracking can help to explain the parasite paradox: that parasites are specialists with narrow environmental ranges, which would encourage host fidelity, yet scientists commonly observe parasite shifts onto novel hosts, both in the phylogenetic record and in ecological time. Ecological fitting can explain the frequency of this phenomenon: similar to the expansion phase of the cyclic life cycle described by Janzen, a species undergoes taxon pulses, usually in a time of ecological disturbance, and expands its range, disperses, and colonizes new areas. For parasite-host, insect-plant, or plant-pollinator associations, this colonization is facilitated by the organism tracking an ancestral resource, and not tracking a particular species. The probability of this is increased when the tracked resource is widespread, or when specialization on a certain resource is a shared trait among distantly related species. This resource tracking has been demonstrated for both insect-plant and parasite-host systems in which sister species are capable of surviving on each other's hosts, even if they were never associated in nature.\n\nWhen operating under the more strict definition of ecological fitting, in which traits must be exapted for a new purpose, several mechanisms could be operating. Phenotypic plasticity, in which an organism changes phenotype in response to environmental variables, allows for individuals with existing genotypes to obtain fitness in novel conditions without adaptation occurring. Correlated trait evolution can encourage ecological fitting when direct selection on one trait causes a correlated change in another, potentially creating a phenotype that is pre-adapted to possible future conditions. Phylogenetic conservatism is the latent retention of genetic changes from past conditions: for instance, historical exposure to a certain host may predispose it to colonization in the future. Finally, fixed traits such as body size may lead to entirely different biotic interactions in different environments, e.g. pollinators visiting different sets of flowers.\n\nStudies of introduced species can provide some of the best evidence for ecological fitting, because species invasions represent natural experiments testing how a new species fits into a community. Invasion ecology teaches us that changes in geographic range can occur quickly, as is required by the Janzen model for ecological fitting, and ecological fitting provides an important mechanism whereby new species can fit into an existing community without adaptation. These natural experiments have often shown that communities dominated by invasive species, such as those on Ascension Island, can be as diverse and complex as native communities. Additionally, phylogenetic studies show evidence for ecological fitting when lineages of the associated species do not correlate over evolutionary time; that is, if host-parasite or other interactions are as tightly coevolved as was previously believed, parasites should not be switching to unrelated hosts. This kind of host switching has been shown many times: in insect-plant relationships where oligophagy in locusts manifests itself on distantly related plants, plant-disperser relationships among Mediterranean birds, plant-pollinator relationships between hummingbirds and Heliconia flowers, and for parasite-host associations ranging from flatworms in frogs to parasitic worms in primates or in trout. Another study examined the time required for sugarcane, \"Saccharum officinarum\", to accumulate diverse arthropod pest communities. It determined that time did not influence pest species richness, indicating that host-parasite associations were forming in ecological, not evolutionary, time.\n\nThe human-made cloud forest on Green Mountain, Ascension Island represents an example of how unrelated and unassociated plant species can form a functioning ecosystem without a shared evolutionary history. 19th-century accounts of the island, including that of Charles Darwin on his expedition aboard the Beagle, described the rocky island as destitute and bare. Plants were brought to the island by colonists, but the most important change occurred in 1843 with the terraforming of Green Mountain by botanist Joseph Dalton Hooker, who recommended planting trees on Green Mountain and vegetation on the slopes to encourage deeper soils. Plants were regularly sent from England until, in the 1920s, the mountain was green and verdant, and could be described as a functioning cloud forest. Although some of the species likely were introduced together because of their coevolutionary relationships, the overwhelming mechanism governing relationships is clearly ecological fitting. The system has changed dramatically and even provides ecosystem services such as carbon sequestration, all as a result of ecological fitting. This is important in the light of climate change for two reasons: species ranges may be shifting dramatically, and ecological fitting is an important mechanism for the construction of communities over ecological time, and it shows that human-made systems could be integral in the mitigation of climate change.\n\nEcological fitting can influence species diversity either by promoting diversification through genetic drift, or by maintaining evolutionary stasis through gene flow. Research has shown that ecological fitting can result in parasite assemblages that are just as diverse as those created over evolutionary time, indicating the importance of ecological factors for biodiversity. Ecological fitting can contribute to 3 types of evolutionary transition. The first is simple ecological fitting, in which organisms track resources to form novel species interactions and increase individual fitness. The second is a shift from an organism's ancestral ecology to a derived ecology, or a more true form of ecological fitting: traits are exapted from their original purpose to increase fitness. Finally, a more dramatic form involves the creation of new evolutionary arenas, requiring morphological or ecological changes to gain fitness under new conditions. Any of these processes can promote speciation or diversification under the right circumstances. Each form of ecological fitting can encourage speciation only if the population is sufficiently isolated from other populations to prevent gene flow from swamping local adaptation to newly formed species associations. Host-plant or other specialized relationships have been previously regarded as an evolutionary 'dead-end' because they seem to limit diversity, but they can actually promote it according to coevolutionary theory. Insects that feed on plants induce them to develop new defense mechanisms, which frees them from herbivory. In this new adaptive zone, or ecospace, plant clades can undergo evolutionary radiation, in which diversification of the clade occurs quickly due to adaptive change. The herbivorous insects may eventually succeed in adapting to the plants' defenses, and would also be capable of diversifying, in the absence of competition by other herbivorous insects. Thus, species associations can lead to rapid diversification of both lineages and contribute to overall community diversity.\n\nEcological fitting can also maintain populations in stasis, influencing diversity by limiting it. If populations are well connected through gene flow, local adaptation may not be able to occur (known as antagonistic gene flow), or the well-connected population could evolve as a whole without speciation occurring. The Geographic Mosaic of Coevolution theory can help to explain this: it suggests that coevolution or speciation of a species occurs across a wide geographic scale, rather than at the level of populations, so that populations experiencing selection for a particular trait affect gene frequencies across the geographic region due to gene flow. Populations of a species interact with different species in different parts of its range, so populations may be experiencing a small sub-set of the interactions to which the species as a whole is adapted. This is based on three premises: there is an environmental and biotic interaction mosaic affecting fitness in different areas, there are certain areas where species are more coevolved than others, and that there is mixing of allele frequencies and traits between the regions to create more homogeneous populations. Thus, depending on connectivity of populations and strength of selection pressure in different arenas, a widespread population can coevolve with another species, or individual populations can specialize, potentially resulting in diversification.\n\nEcological fitting can explain aspects of species associations and community assembly, as well as invasion ecology. It is another mechanism, in addition to coevolution and in situ evolution (in which new phenotypes evolve and travel sympatrically), that can explain the creation and maintenance of species associations within a community. The phenomenon of ecological fitting helps to weigh in on some of the great debates in community ecology. The Clementisian school of community ecology, based on the work of Frederic Clements, a plant ecologist who studied ecological succession, holds that communities are constructed by deterministic processes that assemble a 'superorganism' from the individual species present. With the removal or exchange of a species, the community would be unstable. On the other hand, the Gleasonian view, promoted by Henry Gleason, who was also a plant ecologist studying successional communities, is more individualistic and emphasizes the role of random processes such as dispersal in community assembly. The Clementsian view would emphasize coevolution and strict niche fidelity as a major factor structuring communities, also known as the niche-assembly perspective, whereas the Gleasonian, or dispersal assembly view emphasizes neutral and historical processes, including ecological fitting. These views of community assembly raise the question: do species continue stable relationships over time, or do all individuals represent \"asymmetrical pegs in square holes\"? Some of these question can be answered through phylogenetic studies, which can determine when certain traits arose, and thus whether species interactions and community assembly occurs primarily through coevolution or through dispersal and ecological fitting. Support exists for each, indicating that each has a varied role to play, depending on the community and on historical factors.\n\nA field of recent importance for the application of ecological fitting is that of emerging infectious disease: infectious diseases that have emerged or increased incidence in the last 20 years, as a result of evolution, range expansion, or ecological changes. Climate change represents an ecological perturbation that induces range and phenological shifts in many species, which can encourage parasite transmission and host switching without any evolutionary change occurring. When species begin to infect host species with which they were not previously associated, it may be the result of ecological fitting. Even organisms with complex life histories can switch hosts as long as the resource required by each life stage is phylogenetically conserved and geographically widespread, meaning that it is difficult to predict based on life history complexity or other external factors. This has been used to explain the mysterious appearance of the bullfrog lung trematode \"Haematoloechus floedae\" in Costa Rican leopard frogs, even though bullfrogs do not and have never occurred in this area. When emerging infectious disease is the result of ecological fitting and host specificity is loose, then recurrent host shifts are likely to occur and the difficult task of building a predictive framework for management is necessary.\n\n\n", "id": "30509934", "title": "Ecological fitting"}
{"url": "https://en.wikipedia.org/wiki?curid=4986999", "text": "Shadow biosphere\n\nA shadow biosphere is a hypothetical microbial biosphere of Earth that uses radically different biochemical and molecular processes than currently known life. Although life on Earth is relatively well-studied, the shadow biosphere may still remain unnoticed because the exploration of the microbial world targets primarily the biochemistry of the macro-organisms. The term was coined by Carol Cleland and Shelley Copley in 2005.\n\nSteven A. Benner, Alonso Ricardo, and Matthew A. Carrigan, biochemists at the University of Florida, argued that if organisms based on RNA once existed, they might still be alive today, unnoticed because they don't contain ribosomes, which are usually used to detect living organisms. They suggest searching for them in environments that are low in sulfur, environments that are spatially constrained (for example, minerals with pores smaller than one micrometre), or environments that cycle between extreme hot and cold.\n\nOther proposed candidates for a shadow biosphere include organisms using different suites of amino acids in their proteins or different molecular units (e.g., bases or sugars) in their nucleic acids, having a chirality opposite of ours, using some of the non-standard amino acids, or using arsenic instead of phosphorus. Carol Cleland, a philosopher of science at the University of Colorado (Boulder), argues that desert varnish, whose status as living or nonliving has been debated since the time of Darwin, should be investigated as a potential candidate for a shadow biosphere.\n\nThe idea of a shadow biosphere is not widely accepted in biochemistry, and methods used by proponents and conclusions drawn from experiments that purport to show evidence of shadow biospheres have been criticized. For example, evidence that once seemed to support arsenic as a substitute for phosphorus in DNA could have resulted from lab or field contamination, and DNA that includes arsenic is chemically unstable.\n\n", "id": "4986999", "title": "Shadow biosphere"}
{"url": "https://en.wikipedia.org/wiki?curid=31180783", "text": "Biochore\n\nA biochore is a subdivision of the biosphere consisting of biotopes that resemble one another and thus are colonized by similar vegetation.\n", "id": "31180783", "title": "Biochore"}
{"url": "https://en.wikipedia.org/wiki?curid=623501", "text": "Forb\n\nA forb (sometimes spelled phorb) is an herbaceous flowering plant that is not a graminoid (grasses, sedges and rushes). The term is used in biology and in vegetation ecology, especially in relation to grasslands and understory.\n\n\"Forb\" is derived from the Greek φορβή (\"phorbḗ\"), \"pasture\" or \"fodder\". The spelling \"phorb\" is sometimes used, and in older usage this sometimes includes graminids and other plants currently not regarded as forbs.\n\nForbs are members of a guild – a group of plant species with broadly similar growth form. In certain contexts in ecology, guild membership may often be more important than the taxonomic relationships between organisms.\n\nIn addition to its use in ecology, the term \"forb\" may be used for subdividing popular guides to wildflowers, distinguishing them from other categories such as grasses, sedges, shrubs, and trees.\n\nSome examples of forbs are clover, sunflower, daylily, and milkweed.\n\n\n", "id": "623501", "title": "Forb"}
{"url": "https://en.wikipedia.org/wiki?curid=3913867", "text": "Optimal virulence\n\nOptimal virulence is a concept relating to the ecology of hosts and parasites. One definition of virulence is the host's parasite-induced loss of fitness. The parasite's fitness is determined by its success in transmitting offsprings to other hosts. At one time, the consensus was that over time, virulence moderated and parasitic relationships evolved toward symbiosis. This view has been challenged. A pathogen that is too restrained will lose out in competition to a more aggressive strain that diverts more host resources to its own reproduction. However, the host, being the parasite's resource and habitat in a way, suffers from this higher virulence. This might induce faster host death, and act against the parasite's fitness by reducing probability to encounter another host (killing the host too fast to allow for transmission). Thus, there is a natural force providing pressure on the parasite to \"self-limit\" virulence. \nThe idea is, then, that there exists an equilibrium point of virulence, where parasite's fitness is highest. Any movement on the virulence axis, towards higher or lower virulence, will result in lower fitness for the parasite, and thus will be selected against.\n\nAccording to evolutionary medicine, virulence increases with horizontal transmission (between non-relatives) and decreases with vertical transmission (from parent to child).\n\nPaul W. Ewald has explored the relationship between virulence and mode of transmission. He came to the conclusion that virulence tends to remain especially high in waterborne and vector-borne infections, such as cholera and Dengue. Cholera is spread through sewage and Dengue through mosquitos. In the case of respiratory infections, the pathogen depends on an ambulatory host to survive. It must spare the host long enough to find a new host. Water- or vector-borne transmission circumvents the need for a mobile host. Ewald is convinced that the crowding of trench warfare provided an easy route to transmission that explains the virulence of the 1918 influenza pandemic. In crowded conditions the time to find a new host is minimal.\n\nOther epidemiologists have expanded on the idea of a tradeoff between costs and benefits of virulence. One factor is the time or distance between potential hosts. Airplane travel, crowded factory farms and urbanization have all been suggested as possible sources of virulence. Another factor is the presence of multiple infections in a single host leading to increased competition among pathogens. In this scenario, the host can survive only as long as it resists the most virulent strains. The advantage of a low virulence strategy becomes moot. Multiple infections can also result in gene swapping among pathogens, increasing the likelihood of lethal combinations.\n\nThere are three main hypotheses about why a pathogen evolves as it does. These three models help to explain the life history strategies of parasites, including reproduction, migration within the host, virulence, etc. The three hypotheses are the Trade-Off Hypothesis, the Short-Sighted Evolution Hypothesis, and the Coincidental Evolution Hypothesis. All of these offer ultimate explanations for virulence in pathogens.\n\nAt one time, some biologists argued that pathogens would tend to evolve toward ever decreasing virulence because the death of the host (or even serious disability) is ultimately harmful to the pathogen living inside. For example, if the host dies, the pathogen population inside may die out entirely. Therefore, it was believed that less virulent pathogens that allowed the host to move around and interact with other hosts should have greater success reproducing and dispersing.\n\nBut this is not necessarily the case. Pathogen strains that kill the host can increase in frequency as long as the pathogen can transmit itself to a new host, whether before or after the host dies. The evolution of virulence in pathogens is a balance between the costs and benefits of virulence to the pathogen. For example, Mackinnon and Read (2004) and Paul et al. (2004) studied the malaria parasite using a rodent and chicken model respectively and found that there was trade-off between transmission success and virulence as defined by host mortality.\n\nShort-sighted evolution suggests that the traits that increase reproduction rate and transmission to a new host will rise to high frequency within the pathogen population. These traits include the ability to reproduce sooner, reproduce faster, reproduce in higher numbers, live longer, survive against antibodies, or survive in parts of the body the pathogen does not normally infiltrate. These traits typically arise due to mutations, which occur more frequently in pathogen populations than in host populations, due to the pathogens' rapid generation time and immense numbers. After only a few generations, the mutations that enhance rapid reproduction or dispersal will increase in frequency. The same mutations that enhance the reproduction and dispersal of the pathogen also enhance its virulence in the host, causing much harm (disease and death). If the pathogen's virulence kills the host and interferes with its own transmission to a new host, virulence will be selected against. But as long as transmission continues despite the virulence, virulent pathogens will have the advantage. So, for example, virulence often increases within families, where transmission from one host to the next is likely, no matter how sick the host. Similarly, in crowded conditions such as refugee camps, virulence tends to increase over time since new hosts cannot escape the likelihood of infection.\n\nSome forms of pathogenic virulence did not co-evolve with the host. For example, tetanus is caused by the soil bacterium \"Clostridium tetani\". After \"C. tetani\" bacteria enter a human wound, the bacteria may grow and divide rapidly, even though the human body is not their normal habitat. While dividing, \"C. tetani\" produce a neurotoxin that is lethal to humans. But it is selection in the bacterium's normal life cycle in the soil that leads it to produce this toxin, not any evolution with a human host. The bacterium finds itself inside a human instead of in the soil by mere happenstance. We can say that the neurotoxin is not directed at the human host.\n\nMore generally, the virulence of many pathogens in humans may not be a target of selection itself, but rather an accidental by-product of selection that operates on other traits, as is the case with antagonistic pleiotropy\n\nA potential for virulence exists whenever a pathogen invades a new environment, host or tissue. The new host is likely to be poorly adapted to the intruder, either because it has not built up an immunological defense or because of a fortuitous vulnerability. In times of change, natural selection favors mutations that exploit the new host more effectively than the founder strain, providing an opportunity for virulence to erupt.\n\nHost susceptibility contributes to virulence. Once transmission occurs, the pathogen must establish an infection to continue. The more competent the host immune system, the less chance there is for the parasite to survive. It may require multiple transmission events to find a suitably vulnerable host. During this time, the invader is dependent upon the survival of its current host. For this reason virulence thrives in a community with prevalent immune dysfunction and poor nutrition. Virulence weakens in a healthy population and as hosts acquire resistance. Good hygiene, nutrition and sanitation are all effective strategies against virulence.\n\n", "id": "3913867", "title": "Optimal virulence"}
{"url": "https://en.wikipedia.org/wiki?curid=306064", "text": "Ecosophy\n\nEcosophy or ecophilosophy (a portmanteau of ecological philosophy) is a philosophy of ecological harmony or equilibrium. The term was coined by the Norwegian father of deep ecology, Arne Næss, and French post-Marxist philosopher and psychoanalyst Félix Guattari.\n\nNaess defined ecosophy in the following way:\n\nWhile a professor at University of Oslo in 1972, Arne Næss, introduced the terms \"deep ecology movement\" and \"ecosophy\" into environmental literature. Naess based his article on a talk he gave in Bucharest in 1972 at the Third World Future Research Conference. As Drengson notes in \"Ecophilosophy, Ecosophy and the Deep Ecology Movement: An Overview\", \"In his talk Næss discussed the longer-range background of the ecology movement and its connection with respect for Nature and the inherent worth of other beings.\" Naess's view of humans as an integral part of a \"total-field image\" of Nature contrasts with the alternative (and more anthropocentric) construction of ecosophy outlined by Guattari.\n\nThe term ecological wisdom, synonymous with ecosophy, was introduced by Næss in 1973. The concept has become one of the foundations of the deep ecology movement. All expressions of values by Green Parties list ecological wisdom as a key value—it was one of the original Four Pillars of the Green Party and is often considered the most basic value of these parties. It is also often associated with indigenous religion and cultural practices. In its political context, it is necessarily not as easily defined as ecological health or scientific ecology concepts.\n\nEcosophy also refers to a field of practice introduced by psychoanalyst, poststructuralist philosopher and political activist Félix Guattari. In part Guattari's use of the term demarcates what he observes as the necessity for the proponents of social liberation whose struggles in the 20th century were dominated by the paradigm of social revolution and Marxism to embed their arguments within an ecological framework which understands the interconnections of social and environmental spheres.\n\nGuattari holds that traditional environmentalist perspectives obscure the complexity of the relationship between humans and their natural environment through its maintenance of the dualistic separation of human (cultural) and nonhuman (natural) systems; he envisions ecosophy as a new field with a monistic and pluralistic approach to such study. Ecology in the Guattarian sense, then, is a study of complex phenomena, including human subjectivity, the environment, and social relations, all of which are intimately interconnected. Despite this emphasis on interconnection, throughout his individual writings and more famous collaborations with Gilles Deleuze, Guattari has resisted calls for holism, preferring to emphasize heterogeneity and difference, synthesizing assemblages and multiplicities in order to trace rhizomatic structures rather than creating unified and holistic structures.\n\nGuattari's concept of the three interacting and interdependent ecologies of mind, society, and environment stems from the outline of the three ecologies presented in \"Steps to an Ecology of Mind\", a collection of writings by cyberneticist Gregory Bateson.\n\n\n\n", "id": "306064", "title": "Ecosophy"}
{"url": "https://en.wikipedia.org/wiki?curid=1868978", "text": "SLOSS debate\n\nThe SLOSS debate was a debate in ecology and conservation biology during the 1970s and 1980s as to whether a single large or several small (SLOSS) reserves were a superior means of conserving biodiversity in a fragmented habitat.\n\nIn 1975 Jared Diamond suggested some \"rules\" for the design of protected areas, based on Robert MacArthur and E. O. Wilson's book \"The Theory of Island Biogeography\". One of his suggestions was that a single large reserve was preferable to several smaller reserves whose total areas were equal to the larger.\n\nSince species richness increases with habitat area, a larger block of habitat would support more species than any of the smaller blocks. This idea was popularised by many other ecologists, and has been incorporated into most standard textbooks in conservation biology, and was used in real-world conservation planning. This idea was challenged by Wilson's former student Daniel Simberloff who pointed out that this idea relied on the assumption that smaller reserves had a \"nested\" species composition - it assumed that each larger reserve had all the species presented in any smaller reserve. If the smaller reserves had unshared species, then it was possible that two smaller reserves could have more species than a single large reserve.\n\nSimberloff and Abele expanded their argument in subsequent paper in the journal \"The American Naturalist\" stating neither ecological theory nor empirical data exist to support the hypothesis that subdividing a nature reserve would increase extinction rates, basically negating Diamond as well as MacArthur and Wilson. Bruce A. Wilcox and Dennis D. Murphy responded with a key paper \"Conservation strategy - effects of fragmentation on extinction\" pointing out flaws in their argument while providing a comprehensive definition of habitat fragmentation. Wilcox and Murphy also argued that habitat fragmentation is probably the major threat to the loss of global biological diversity.\n\nThis helped set the stage for fragmentation research as an important area of conservation biology. The SLOSS debate ensued as to the extent to which smaller reserves shared species with one another, leading to the development of \"nested subset theory\" by Bruce Patterson and Wirt Atmar in the 1980s and to the establishment of the Biological Dynamics of Forest Fragments Project (BDFFP) near Manaus, Brazil in 1979 by Thomas Lovejoy and Richard Bierregaard. In the field of metapopulation ecology, modelling works suggest that the SLOSS debate should be refined and cannot be solved without explicit spatial consideration of dispersal and environmental dynamics. In particular, a large number of small patches may be optimal to long-term species persistence only if the species range increases with the number of patches.\n\n\n", "id": "1868978", "title": "SLOSS debate"}
{"url": "https://en.wikipedia.org/wiki?curid=31037820", "text": "Hutchinson's rule\n\nThe observation that the trophic structures (i.e. mouths) of sympatric congeneric species generally vary by a factor of ~1.3. This variation presumably leads to niche differentiation, allowing coexistence of multiple similar species in the same habitat, by partitioning food resources. The rule's legitimacy has been questioned, as other categories of objects also exhibit size ratios of roughly 1.3.\n", "id": "31037820", "title": "Hutchinson's rule"}
{"url": "https://en.wikipedia.org/wiki?curid=208303", "text": "Primary production\n\nIn ecology, primary production is the synthesis of organic compounds from atmospheric or aqueous carbon dioxide. It principally occurs through the process of photosynthesis, which uses light as its source of energy, but it also occurs through chemosynthesis, which uses the oxidation or reduction of inorganic chemical compounds as its source of energy. Almost all life on Earth relies directly or indirectly on primary production. The organisms responsible for primary production are known as \"primary producers\" or autotrophs, and form the base of the food chain. In terrestrial ecoregions, these are mainly plants, while in aquatic ecoregions algae predominate in this role. Ecologists distinguish primary production as either \"net\" or \"gross\", the former accounting for losses to processes such as cellular respiration, the latter not.\n\nPrimary production is the production of chemical energy in organic compounds by living organisms. The main source of this energy is sunlight but a minute fraction of primary production is driven by lithotrophic organisms using the chemical energy of inorganic molecules.\n\nRegardless of its source, this energy is used to synthesize complex organic molecules from simpler inorganic compounds such as carbon dioxide (CO) and water (HO). The following two equations are simplified representations of photosynthesis (top) and (one form of) chemosynthesis (bottom):\n\nIn both cases, the end point is a polymer of reduced carbohydrate, (CHO), typically molecules such as glucose or other sugars. These relatively simple molecules may be then used to further synthesise more complicated molecules, including proteins, complex carbohydrates, lipids, and nucleic acids, or be respired to perform work. Consumption of primary producers by heterotrophic organisms, such as animals, then transfers these organic molecules (and the energy stored within them) up the food web, fueling all of the Earth's living systems.\n\n\"Gross primary production\" (GPP) is the amount of chemical energy as biomass that primary producers create in a given length of time. (GPP is sometimes confused with Gross Primary \"productivity\", which is the rate at which photosynthesis or chemosynthesis occurs.) Some fraction of this fixed energy is used by primary producers for cellular respiration and maintenance of existing tissues (i.e., \"growth respiration\" and \"maintenance respiration\"). The remaining fixed energy (i.e., mass of photosynthate) is referred to as \"net primary production\" (NPP).\n\nNet primary production is the rate at which all the plants in an ecosystem produce net useful chemical energy; it is equal to the difference between the rate at which the plants in an ecosystem produce useful chemical energy (GPP) and the rate at which they use some of that energy during respiration. Some net primary production goes toward growth and reproduction of primary producers, while some is consumed by herbivores.\n\nBoth gross and net primary production are in units of mass per unit area per unit time interval. In terrestrial ecosystems, mass of carbon per unit area per year (g C m yr) is most often used as the unit of measurement.\n\nOn the land, almost all primary production is now performed by vascular plants, with a small fraction coming from algae and non-vascular plants such as mosses and liverworts. Before the evolution of vascular plants, non-vascular plants likely played a more significant role. Primary production on land is a function of many factors, but principally local hydrology and temperature (the latter covaries to an extent with light, specifically photosynthetically active radiation (PAR), the source of energy for photosynthesis). While plants cover much of the Earth's surface, they are strongly curtailed wherever temperatures are too extreme or where necessary plant resources (principally water and PAR) are limiting, such as deserts or polar regions.\n\nWater is \"consumed\" in plants by the processes of photosynthesis (see above) and transpiration. The latter process (which is responsible for about 90% of water use) is driven by the evaporation of water from the leaves of plants. Transpiration allows plants to transport water and mineral nutrients from the soil to growth regions, and also cools the plant. Diffusion of water vapour out of a leaf, the force that drives transpiration, is regulated by structures known as stomata. These structure also regulate the diffusion of carbon dioxide from the atmosphere into the leaf, such that decreasing water loss (by partially closing stomata) also decreases carbon dioxide gain. Certain plants use alternative forms of photosynthesis, called Crassulacean acid metabolism (CAM) and C4. These employ physiological and anatomical adaptations to increase water-use efficiency and allow increased primary production to take place under conditions that would normally limit carbon fixation by C3 plants (the majority of plant species).\n\nIn a reversal of the pattern on land, in the oceans, almost all photosynthesis is performed by algae, with a small fraction contributed by vascular plants and other groups. Algae encompass a diverse range of organisms, ranging from single floating cells to attached seaweeds. They include photoautotrophs from a variety of groups. Eubacteria are important photosynthetizers in both oceanic and terrestrial ecosystems, and while some archaea are phototrophic, none are known to utilise oxygen-evolving photosynthesis. A number of eukaryotes are significant contributors to primary production in the ocean, including green algae, brown algae and red algae, and a diverse group of unicellular groups. Vascular plants are also represented in the ocean by groups such as the seagrasses.\n\nUnlike terrestrial ecosystems, the majority of primary production in the ocean is performed by free-living microscopic organisms called phytoplankton. Larger autotrophs, such as the seagrasses and macroalgae (seaweeds) are generally confined to the littoral zone and adjacent shallow waters, where they can attach to the underlying substrate but still be within the photic zone. There are exceptions, such as \"Sargassum\", but the vast majority of free-floating production takes place within microscopic organisms.\n\nThe factors limiting primary production in the ocean are also very different from those on land. The availability of water, obviously, is not an issue (though its salinity can be). Similarly, temperature, while affecting metabolic rates (see Q), ranges less widely in the ocean than on land because the heat capacity of seawater buffers temperature changes, and the formation of sea ice insulates it at lower temperatures. However, the availability of light, the source of energy for photosynthesis, and mineral nutrients, the building blocks for new growth, play crucial roles in regulating primary production in the ocean. Available Earth System Models suggest that ongoing ocean bio-geochemical changes could trigger reductions in ocean NPP between 3% and 10% of current values depending on the emissions scenario.\n\nThe sunlit zone of the ocean is called the photic zone (or euphotic zone). This is a relatively thin layer (10–100 m) near the ocean's surface where there is sufficient light for photosynthesis to occur. For practical purposes, the thickness of the photic zone is typically defined by the depth at which light reaches 1% of its surface value. Light is attenuated down the water column by its absorption or scattering by the water itself, and by dissolved or particulate material within it (including phytoplankton).\n\nNet photosynthesis in the water column is determined by the interaction between the photic zone and the mixed layer. Turbulent mixing by wind energy at the ocean's surface homogenises the water column vertically until the turbulence dissipates (creating the aforementioned mixed layer). The deeper the mixed layer, the lower the average amount of light intercepted by phytoplankton within it. The mixed layer can vary from being shallower than the photic zone, to being much deeper than the photic zone. When it is much deeper than the photic zone, this results in phytoplankton spending too much time in the dark for net growth to occur. The maximum depth of the mixed layer in which net growth can occur is called the critical depth. As long as there are adequate nutrients available, net primary production occurs whenever the mixed layer is shallower than the critical depth.\n\nBoth the magnitude of wind mixing and the availability of light at the ocean's surface are affected across a range of space- and time-scales. The most characteristic of these is the seasonal cycle (caused by the consequences of the Earth's axial tilt), although wind magnitudes additionally have strong spatial components. Consequently, primary production in temperate regions such as the North Atlantic is highly seasonal, varying with both incident light at the water's surface (reduced in winter) and the degree of mixing (increased in winter). In tropical regions, such as the gyres in the middle of the major basins, light may only vary slightly across the year, and mixing may only occur episodically, such as during large storms or hurricanes.\n\nMixing also plays an important role in the limitation of primary production by nutrients. Inorganic nutrients, such as nitrate, phosphate and silicic acid are necessary for phytoplankton to synthesise their cells and cellular machinery. Because of gravitational sinking of particulate material (such as plankton, dead or fecal material), nutrients are constantly lost from the photic zone, and are only replenished by mixing or upwelling of deeper water. This is exacerbated where summertime solar heating and reduced winds increases vertical stratification and leads to a strong thermocline, since this makes it more difficult for wind mixing to entrain deeper water. Consequently, between mixing events, primary production (and the resulting processes that leads to sinking particulate material) constantly acts to consume nutrients in the mixed layer, and in many regions this leads to nutrient exhaustion and decreased mixed layer production in the summer (even in the presence of abundant light). However, as long as the photic zone is deep enough, primary production may continue below the mixed layer where light-limited growth rates mean that nutrients are often more abundant.\n\nAnother factor relatively recently discovered to play a significant role in oceanic primary production is the micronutrient iron. This is used as a cofactor in enzymes involved in processes such as nitrate reduction and nitrogen fixation. A major source of iron to the oceans is dust from the Earth's deserts, picked up and delivered by the wind as aeolian dust.\n\nIn regions of the ocean that are distant from deserts or that are not reached by dust-carrying winds (for example, the Southern and North Pacific oceans), the lack of iron can severely limit the amount of primary production that can occur. These areas are sometimes known as HNLC (High-Nutrient, Low-Chlorophyll) regions, because the scarcity of iron both limits phytoplankton growth and leaves a surplus of other nutrients. Some scientists have suggested introducing iron to these areas as a means of increasing primary productivity and sequestering carbon dioxide from the atmosphere.\n\nThe methods for measurement of primary production vary depending on whether gross vs net production is the desired measure, and whether terrestrial or aquatic systems are the focus. Gross production is almost always harder to measure than net, because of respiration, which is a continuous and ongoing process that consumes some of the products of primary production (i.e. sugars) before they can be accurately measured. Also, terrestrial ecosystems are generally more difficult because a substantial proportion of total productivity is shunted to below-ground organs and tissues, where it is logistically difficult to measure. Shallow water aquatic systems can also face this problem.\n\nScale also greatly affects measurement techniques. The rate of carbon assimilation in plant tissues, organs, whole plants, or plankton samples can be quantified by biochemically based techniques, but these techniques are decidedly inappropriate for large scale terrestrial field situations. There, net primary production is almost always the desired variable, and estimation techniques involve various methods of estimating dry-weight biomass changes over time. Biomass estimates are often converted to an energy measure, such as kilocalories, by an empirically determined conversion factor.\n\nIn terrestrial ecosystems, researchers generally measure net primary production (NPP). Although its definition is straightforward, field measurements used to estimate productivity vary according to investigator and biome. Field estimates rarely account for below ground productivity, herbivory, turnover, litterfall, volatile organic compounds, root exudates, and allocation to symbiotic microorganisms. Biomass based NPP estimates result in underestimation of NPP due to incomplete accounting of these components. However, many field measurements correlate well to NPP. There are a number of comprehensive reviews of the field methods used to estimate NPP. Estimates of ecosystem respiration, the total carbon dioxide produced by the ecosystem, can also be made with gas flux measurements.\n\nThe major unaccounted pool is belowground productivity, especially production and turnover of roots. Belowground components of NPP are difficult to measure. BNPP (below-ground NPP) is often estimated based on a ratio of ANPP:BNPP (above-ground NPP:below-ground NPP) rather than direct measurements.\n\nGross primary production can be estimated from measurements of net ecosystem exchange (NEE) of carbon dioxide made by the eddy covariance technique. During night, this technique measures all components of ecosystem respiration. This respiration is scaled to day-time values and further subtracted from NEE.\n\nMost frequently, peak standing biomass is assumed to measure NPP. In systems with persistent standing litter, live biomass is commonly reported. Measures of peak biomass are more reliable if the system is predominantly annuals. However, perennial measurements could be reliable if there were a synchronous phenology driven by a strong seasonal climate. These methods may underestimate ANPP in grasslands by as much as 2 (temperate) to 4 (tropical) fold. Repeated measures of standing live and dead biomass provide more accurate estimates of all grasslands, particularly those with large turnover, rapid decomposition, and interspecific variation in timing of peak biomass. Wetland productivity (marshes and fens) is similarly measured. In Europe, annual mowing makes the annual biomass increment of wetlands evident.\n\nMethods used to measure forest productivity are more diverse than those of grasslands. Biomass increment based on stand specific allometry plus litterfall is considered a suitable although incomplete accounting of above-ground net primary production (ANPP). Field measurements used as a proxy for ANPP include annual litterfall, diameter or basal area increment (DBH or BAI), and volume increment.\n\nIn aquatic systems, primary production is typically measured using one of six main techniques:\n\nThe technique developed by Gaarder and Gran uses variations in the concentration of oxygen under different experimental conditions to infer gross primary production. Typically, three identical transparent vessels are filled with sample water and stoppered. The first is analysed immediately and used to determine the initial oxygen concentration; usually this is done by performing a Winkler titration. The other two vessels are incubated, one each in under light and darkened. After a fixed period of time, the experiment ends, and the oxygen concentration in both vessels is measured. As photosynthesis has not taken place in the dark vessel, it provides a measure of ecosystem respiration. The light vessel permits both photosynthesis and respiration, so provides a measure of net photosynthesis (i.e. oxygen production via photosynthesis subtract oxygen consumption by respiration). Gross primary production is then obtained by adding oxygen consumption in the dark vessel to net oxygen production in the light vessel.\n\nThe technique of using C incorporation (added as labelled NaCO) to infer primary production is most commonly used today because it is sensitive, and can be used in all ocean environments. As C is radioactive (via beta decay), it is relatively straightforward to measure its incorporation in organic material using devices such as scintillation counters.\n\nDepending upon the incubation time chosen, net or gross primary production can be estimated. Gross primary production is best estimated using relatively short incubation times (1 hour or less), since the loss of incorporated C (by respiration and organic material excretion / exudation) will be more limited. Net primary production is the fraction of gross production remaining after these loss processes have consumed some of the fixed carbon.\n\nLoss processes can range between 10-60% of incorporated C according to the incubation period, ambient environmental conditions (especially temperature) and the experimental species used. Aside from those caused by the physiology of the experimental subject itself, potential losses due to the activity of consumers also need to be considered. This is particularly true in experiments making use of natural assemblages of microscopic autotrophs, where it is not possible to isolate them from their consumers.\n\nThe methods based on stable isotopes and O/Ar ratios have the advantage of providing estimates of respiration rates in the light without the need of incubations in the dark. Among them, the method of the triple oxygen isotopes and O/Ar have the additional advantage of not needing incubations in closed containers and O/Ar can even be measured continuously at sea using equilibrator inlet mass spectrometry (EIMS) or a membrane inlet mass spectrometry (MIMS). However, if results relevant to the carbon cycle are desired, it is probably better to rely on methods based on carbon (and not oxygen) isotopes. It is important to notice that the method based on carbon stable isotopes is not simply an adaptation of the classic C method, but an entirely different approach that does not suffer from the problem of lack of account of carbon recycling during photosynthesis.\n\nAs primary production in the biosphere is an important part of the carbon cycle, estimating it at the global scale is important in Earth system science. However, quantifying primary production at this scale is difficult because of the range of habitats on Earth, and because of the impact of weather events (availability of sunlight, water) on its variability. Using satellite-derived estimates of the Normalized Difference Vegetation Index (NDVI) for terrestrial habitats and sea-surface chlorophyll for the oceans, it is estimated that the total (photoautotrophic) primary production for the Earth was 104.9 Gt C yr. Of this, 56.4 Gt C yr (53.8%), was the product of terrestrial organisms, while the remaining 48.5 Gt C yr, was accounted for by oceanic production.\n\nScaling ecosystem-level GPP estimations based on eddy covariance measurements of net ecosystem exchange (see above) to regional and global values using spatial details of different predictor variables, such as climate variables and remotely sensed fAPAR or LAI led to a terrestrial gross primary production of 123±8 Gt carbon (NOT carbon dioxide) per year during 1998-2005 \n\nIn areal terms, it was estimated that land production was approximately 426 g C m yr (excluding areas with permanent ice cover), while that for the oceans was 140 g C m yr. Another significant difference between the land and the oceans lies in their standing stocks - while accounting for almost half of total production, oceanic autotrophs only account for about 0.2% of the total biomass.\n\nPrimary productivity can be estimated by a variety of proxies. One that has particular relevance to the geological record is Barium, whose concentration in marine sediments rises in line with primary productivity at the surface.\n\nHuman societies are part of the Earth's NPP cycle, but exert a disproportionate influence in it. In 1996, Josep Garí designed a new indicator of sustainable development based precisely on the estimation of the human appropriation of NPP: he coined it \"HANPP\" (Human Appropriation of Net Primary Production) and introduced it at the inaugural conference of the European Society for Ecological Economics. HANPP has since been further developed and widely applied in research on ecological economics as well as in policy analysis for sustainability. HANPP represents a proxy of the human impact on Nature and can be applied to different geographical scales and also globally.\n\nThe extensive degree of human use of the Planet's resources, mostly via land use, results in various levels of impact on \"actual NPP\" (NPP). Although in some regions, such as the Nile valley, irrigation has resulted in a considerable increase in primary production, in most of the Planet there us a notable trend of \"NPP reduction due to land changes\" (ΔNPP) of 9.6% across global land-mass. In addition to this, end consumption by people raises the total HANPP to 23.8% of \"potential vegetation\" (NPP). It is estimated that, in 2000, 34% of the Earth's ice-free land area (12% cropland; 22% pasture) was devoted to human agriculture. This disproportionate amount reduces the energy available to other species, having a marked impact on biodiversity, flows of carbon, water and energy, and ecosystem services, and scientists have questioned how large this fraction can be before these services begin to break down. Reductions in NPP are also expected in the ocean as a result of ongoing climate change, potentially impacting marine ecosystems and goods and services that the oceans provide \n\n", "id": "208303", "title": "Primary production"}
{"url": "https://en.wikipedia.org/wiki?curid=30773", "text": "Theoretical ecology\n\nTheoretical ecology is the scientific discipline devoted to the study of ecological systems using theoretical methods such as simple conceptual models, mathematical models, computational simulations, and advanced data analysis. Effective models improve understanding of the natural world by revealing how the dynamics of species populations are often based on fundamental biological conditions and processes. Further, the field aims to unify a diverse range of empirical observations by assuming that common, mechanistic processes generate observable phenomena across species and ecological environments. Based on biologically realistic assumptions, theoretical ecologists are able to uncover novel, non-intuitive insights about natural processes. Theoretical results are often verified by empirical and observational studies, revealing the power of theoretical methods in both predicting and understanding the noisy, diverse biological world.\n\nThe field is broad and includes foundations in applied mathematics, computer science, biology, statistical physics, genetics, chemistry, evolution, and conservation biology. Theoretical ecology aims to explain a diverse range of phenomena in the life sciences, such as population growth and dynamics, fisheries, competition, evolutionary theory, epidemiology, animal behavior and group dynamics, food webs, ecosystems, spatial ecology, and the effects of climate change.\n\nTheoretical ecology has further benefited from the advent of fast computing power, allowing the analysis and visualization of large-scale computational simulations of ecological phenomena. Importantly, these modern tools provide quantitative predictions about the effects of human induced environmental change on a diverse variety of ecological phenomena, such as: species invasions, climate change, the effect of fishing and hunting on food network stability, and the global carbon cycle.\n\nAs in most other sciences, mathematical models form the foundation of modern ecological theory.\n\nEcological models can be deterministic or stochastic.\n\n\nSpecies can be modelled in continuous or discrete time.\n\n\nModels are often used to describe real ecological reproduction processes of single or multiple species.\nThese can be modelled using stochastic branching processes. Examples are the dynamics of interacting populations (predation competition and mutualism), which, depending on the species of interest, may best be modeled over either continuous or discrete time. Other examples of such models may be found in the field of mathematical epidemiology where the dynamic relationships that are to be modeled are host–pathogen interactions.\n\nBifurcation theory is used to illustrate how small changes in parameter values can give rise to dramatically different long run outcomes, a mathematical fact that may be used to explain drastic ecological differences that come about in qualitatively very similar systems. Logistic maps are polynomial mappings, and are often cited as providing archetypal examples of how chaotic behaviour can arise from very simple non-linear dynamical equations. The maps were popularized in a seminal 1976 paper by the theoretical ecologist Robert May. The difference equation is intended to capture the two effects of reproduction and starvation.\n\nIn 1930, R.A. Fisher published his classic \"The Genetical Theory of Natural Selection\", which introduced the idea that frequency-dependent fitness brings a strategic aspect to evolution, where the payoffs to a particular organism, arising from the interplay of all of the relevant organisms, are the number of this organism' s viable offspring. In 1961, Richard Lewontin applied game theory to evolutionary biology in his \"Evolution and the Theory of Games\",\nfollowed closely by John Maynard Smith, who in his seminal 1972 paper, “Game Theory and the Evolution of Fighting\", defined the concept of the evolutionarily stable strategy.\n\nBecause ecological systems are typically nonlinear, they often cannot be solved analytically and in order to obtain sensible results, nonlinear, stochastic and computational techniques must be used. One class of computational models that is becoming increasingly popular are the agent-based models. These models can simulate the actions and interactions of multiple, heterogeneous, organisms where more traditional, analytical techniques are inadequate. Applied theoretical ecology yields results which are used in the real world. For example, optimal harvesting theory draws on optimization techniques developed in economics, computer science and operations research, and is widely used in fisheries.\n\nPopulation ecology is a sub-field of ecology that deals with the dynamics of species populations and how these populations interact with the environment. It is the study of how the population sizes of species living together in groups change over time and space, and was one of the first aspects of ecology to be studied and modelled mathematically.\n\nThe most basic way of modeling population dynamics is to assume that the rate of growth of a population depends only upon the population size at that time and the per capita growth rate of the organism. In other words, if the number of individuals in a population at a time t, is N(t), then the rate of population growth is given by:\nwhere r is the per capita growth rate, or the intrinsic growth rate of the organism. It can also be described as r = b-d, where b and d are the per capita time-invariant birth and death rates, respectively. This first order linear differential equation can be solved to yield the solution\na trajectory known as Malthusian growth, after Thomas Malthus, who first described its dynamics in 1798. A population experiencing Malthusian growth follows an exponential curve, where N(0) is the initial population size. The population grows when r > 0, and declines when r < 0. The model is most applicable in cases where a few organisms have begun a colony and are rapidly growing without any limitations or restrictions impeding their growth (e.g. bacteria inoculated in rich media).\n\nThe exponential growth model makes a number of assumptions, many of which often do not hold. For example, many factors affect the intrinsic growth rate and is often not time-invariant. A simple modification of the exponential growth is to assume that the intrinsic growth rate varies with population size. This is reasonable: the larger the population size, the fewer resources available, which can result in a lower birth rate and higher death rate. Hence, we can replace the time-invariant r with r’(t) = (b –a*N(t)) – (d + c*N(t)), where a and c are constants that modulate birth and death rates in a population dependent manner (e.g. intraspecific competition). Both a and c will depend on other environmental factors which, we can for now, assume to be constant in this approximated model. The differential equation is now:\nThis can be rewritten as:\nwhere r = b-d and K = (b-d)/(a+c).\n\nThe biological significance of K becomes apparent when stabilities of the equilibria of the system are considered. The constant K is the carrying capacity of the population. The equilibria of the system are N = 0 and N = K. If the system is linearized, it can be seen that N = 0 is an unstable equilibrium while K is a stable equilibrium.\n\nAnother assumption of the exponential growth model is that all individuals within a population are identical and have the same probabilities of surviving and of reproducing. This is not a valid assumption for species with complex life histories. The exponential growth model can be modified to account for this, by tracking the number of individuals in different age classes (e.g. one-, two-, and three-year-olds) or different stage classes (juveniles, sub-adults, and adults) separately, and allowing individuals in each group to have their own survival and reproduction rates.\nThe general form of this model is\nwhere N is a vector of the number of individuals in each class at time \"t\" and L is a matrix that contains the survival probability and fecundity for each class. The matrix L is referred to as the Leslie matrix for age-structured models, and as the Lefkovitch matrix for stage-structured models.\n\nIf parameter values in L are estimated from demographic data on a specific population, a structured model can then be used to predict whether this population is expected to grow or decline in the long-term, and what the expected age distribution within the population will be. This has been done for a number of species including loggerhead sea turtles and right whales.\n\nAn ecological community is a group of trophically similar, sympatric species that actually or potentially compete in a local area for the same or similar resources. Interactions between these species form the first steps in analyzing more complex dynamics of ecosystems. These interactions shape the distribution and dynamics of species. Of these interactions, predation is one of the most widespread population activities.\nTaken in its most general sense, predation comprises predator–prey, host–pathogen, and host–parasitoid interactions.\n\nPredator–prey interactions exhibit natural oscillations in the populations of both predator and the prey. In 1925, the American mathematician Alfred J. Lotka developed simple equations for predator–prey interactions in his book on biomathematics. The following year, the Italian mathematician Vito Volterra, made a statistical analysis of fish catches in the Adriatic and independently developed the same equations. It is one of the earliest and most recognised ecological models, known as the Lotka-Volterra model:\n\nwhere N is the prey and P is the predator population sizes, r is the rate for prey growth, taken to be exponential in the absence of any predators, α is the prey mortality rate for per-capita predation (also called ‘attack rate’), c is the efficiency of conversion from prey to predator, and d is the exponential death rate for predators in the absence of any prey.\n\nVolterra originally used the model to explain fluctuations in fish and shark populations after fishing was curtailed during the First World War. However, the equations have subsequently been applied more generally. Other examples of these models include the Lotka-Volterra model of the snowshoe hare and Canadian lynx in North America, any infectious disease modeling such as the recent outbreak of SARS\n\nand biological control of California red scale by the introduction of its parasitoid, \"Aphytis melinus\"\n\nA credible, simple alternative to the Lotka-Volterra predator–prey model and their common prey dependent generalizations is the ratio dependent or Arditi-Ginzburg model. The two are the extremes of the spectrum of predator interference models. According to the authors of the alternative view, the data show that true interactions in nature are so far from the Lotka–Volterra extreme on the interference spectrum that the model can simply be discounted as wrong. They are much closer to the ratio-dependent extreme, so if a simple model is needed one can use the Arditi–Ginzburg model as the first approximation.\n\nThe second interaction, that of host and pathogen, differs from predator–prey interactions in that pathogens are much smaller, have much faster generation times, and require a host to reproduce. Therefore, only the host population is tracked in host–pathogen models. Compartmental models that categorize host population into groups such as susceptible, infected, and recovered (SIR) are commonly used.\n\nThe third interaction, that of host and parasitoid, can be analyzed by the Nicholson-Bailey model, which differs from Lotka-Volterra and SIR models in that it is discrete in time. This model, like that of Lotka-Volterra, tracks both populations explicitly. Typically, in its general form, it states:\nwhere f(N, P) describes the probability of infection (typically, Poisson distribution), λ is the per-capita growth rate of hosts in the absence of parasitoids, and c is the conversion efficiency, as in the Lotka-Volterra model.\n\nIn studies of the populations of two species, the Lotka-Volterra system of equations has been extensively used to describe dynamics of behavior between two species, N and N. Examples include relations between \"D. discoiderum\" and \"E. coli\",\nas well as theoretical analysis of the behavior of the system.\nThe r coefficients give a “base” growth rate to each species, while K coefficients correspond to the carrying capacity. What can really change the dynamics of a system, however are the α terms. These describe the nature of the relationship between the two species. When α is negative, it means that N has a negative effect on N, by competing with it, preying on it, or any number of other possibilities. When α is positive, however, it means that N has a positive effect on N, through some kind of mutualistic interaction between the two.\nWhen both α and α are negative, the relationship is described as competitive. In this case, each species detracts from the other, potentially over competition for scarce resources.\nWhen both α and α are positive, the relationship becomes one of mutualism. In this case, each species provides a benefit to the other, such that the presence of one aids the population growth of the other.\n\nUnified neutral theory is a hypothesis proposed by Stephen Hubbell in 2001. The hypothesis aims to explain the diversity and relative abundance of species in ecological communities, although like other neutral theories in ecology, Hubbell's hypothesis assumes that the differences between members of an ecological community of trophically similar species are \"neutral,\" or irrelevant to their success. Neutrality means that at a given trophic level in a food web, species are equivalent in birth rates, death rates, dispersal rates and speciation rates, when measured on a per-capita basis. This implies that biodiversity arises at random, as each species follows a random walk. This can be considered a null hypothesis to niche theory. The hypothesis has sparked controversy, and some authors consider it a more complex version of other null models that fit the data better.\n\nUnder unified neutral theory, complex ecological interactions are permitted among individuals of an ecological community (such as competition and cooperation), providing all individuals obey the same rules. Asymmetric phenomena such as parasitism and predation are ruled out by the terms of reference; but cooperative strategies such as swarming, and negative interaction such as competing for limited food or light are allowed, so long as all individuals behave the same way. The theory makes predictions that have implications for the management of biodiversity, especially the management of rare species. It predicts the existence of a fundamental biodiversity constant, conventionally written \"θ\", that appears to govern species richness on a wide variety of spatial and temporal scales.\n\nHubbell built on earlier neutral concepts, including MacArthur & Wilson's theory of island biogeography and Gould's concepts of symmetry and null models.\n\nBiogeography is the study of the distribution of species in space and time. It aims to reveal where organisms live, at what abundance, and why they are (or are not) found in a certain geographical area.\n\nBiogeography is most keenly observed on islands, which has led to the development of the subdiscipline of island biogeography. These habitats are often a more manageable areas of study because they are more condensed than larger ecosystems on the mainland. In 1967, Robert MacArthur and E.O. Wilson published \"The Theory of Island Biogeography\". This showed that the species richness in an area could be predicted in terms of factors such as habitat area, immigration rate and extinction rate. The theory is considered one of the fundamentals of ecological theory. The application of island biogeography theory to habitat fragments spurred the development of the fields of conservation biology and landscape ecology.\n\nA population ecology concept is r/K selection theory, one of the first predictive models in ecology used to explain life-history evolution. The premise behind the r/K selection model is that natural selection pressures change according to population density. For example, when an island is first colonized, density of individuals is low. The initial increase in population size is not limited by competition, leaving an abundance of available resources for rapid population growth. These early phases of population growth experience \"density-independent\" forces of natural selection, which is called \"r\"-selection. As the population becomes more crowded, it approaches the island's carrying capacity, thus forcing individuals to compete more heavily for fewer available resources. Under crowded conditions, the population experiences density-dependent forces of natural selection, called \"K\"-selection.\n\nSpatial analysis of ecological systems often reveals that assumptions that are valid for spatially homogenous populations – and indeed, intuitive – may no longer be valid when migratory subpopulations moving from one patch to another are considered. In a simple one-species formulation, a subpopulation may occupy a patch, move from one patch to another empty patch, or die out leaving an empty patch behind. In such a case, the proportion of occupied patches may be represented as\nwhere m is the rate of colonization, and e is the rate of extinction. In this model, if e < m, the steady state value of p is 1 – (e/m) while in the other case, all the patches will eventually be left empty. This model may be made more complex by addition of another species in several different ways, including but not limited to game theoretic approaches, predator–prey interactions, etc. We will consider here an extension of the previous one-species system for simplicity. Let us denote the proportion of patches occupied by the first population as p, and that by the second as p. Then,\nIn this case, if e is too high, p and p will be zero at steady state. However, when the rate of extinction is moderate, p and p can stably coexist. The steady state value of p is given by\n(p* may be inferred by symmetry).\nIt is interesting to note that if e is zero, the dynamics of the system favor the species that is better at colonizing (i.e. has the higher m value). This leads to a very important result in theoretical ecology known as the Intermediate Disturbance Hypothesis, where the biodiversity (the number of species that coexist in the population) is maximized when the disturbance (of which e is a proxy here) is not too high or too low, but at intermediate levels.\n\nThe form of the differential equations used in this simplistic modelling approach can be modified. For example:\n\nThe model can also be extended to combinations of the four possible linear or non-linear dependencies of colonization and extinction on p are described in more detail in.\n\nIntroducing new elements, whether biotic or abiotic, into ecosystems can be disruptive. In some cases, it leads to ecological collapse, trophic cascades and the death of many species within the ecosystem. The abstract notion of ecological health attempts to measure the robustness and recovery capacity for an ecosystem; i.e. how far the ecosystem is away from its steady state. Often, however, ecosystems rebound from a disruptive agent. The difference between collapse or rebound depends on the toxicity of the introduced element and the resiliency of the original ecosystem.\n\nIf ecosystems are governed primarily by stochastic processes, through which its subsequent state would be determined by both predictable and random actions, they may be more resilient to sudden change than each species individually. In the absence of a balance of nature, the species composition of ecosystems would undergo shifts that would depend on the nature of the change, but entire ecological collapse would probably be infrequent events. In 1997, Robert Ulanowicz used information theory tools to describe the structure of ecosystems, emphasizing mutual information (correlations) in studied systems. Drawing on this methodology and prior observations of complex ecosystems, Ulanowicz depicts approaches to determining the stress levels on ecosystems and predicting system reactions to defined types of alteration in their settings (such as increased or reduced energy flow, and eutrophication.\n\nEcopath is a free ecosystem modelling software suite, initially developed by NOAA, and widely used in fisheries management as a tool for modelling and visualising the complex relationships that exist in real world marine ecosystems.\n\nFood webs provide a framework within which a complex network of predator–prey interactions can be organised. A food web model is a network of food chains. Each food chain starts with a primary producer or autotroph, an organism, such as a plant, which is able to manufacture its own food. Next in the chain is an organism that feeds on the primary producer, and the chain continues in this way as a string of successive predators. The organisms in each chain are grouped into trophic levels, based on how many links they are removed from the primary producers. The length of the chain, or trophic level, is a measure of the number of species encountered as energy or nutrients move from plants to top predators. Food energy flows from one organism to the next and to the next and so on, with some energy being lost at each level. At a given trophic level there may be one species or a group of species with the same predators and prey.\n\nIn 1927, Charles Elton published an influential synthesis on the use of food webs, which resulted in them becoming a central concept in ecology. In 1966, interest in food webs increased after Robert Paine's experimental and descriptive study of intertidal shores, suggesting that food web complexity was key to maintaining species diversity and ecological stability. Many theoretical ecologists, including Sir Robert May and Stuart Pimm, were prompted by this discovery and others to examine the mathematical properties of food webs. According to their analyses, complex food webs should be less stable than simple food webs. The apparent paradox between the complexity of food webs observed in nature and the mathematical fragility of food web models is currently an area of intensive study and debate. The paradox may be due partially to conceptual differences between persistence of a food web and equilibrial stability of a food web.\n\nSystems ecology can be seen as an application of general systems theory to ecology. It takes a holistic and interdisciplinary approach to the study of ecological systems, and particularly ecosystems. Systems ecology is especially concerned with the way the functioning of ecosystems can be influenced by human interventions. Like other fields in theoretical ecology, it uses and extends concepts from thermodynamics and develops other macroscopic descriptions of complex systems. It also takes account of the energy flows through the different trophic levels in the ecological networks. In systems ecology the principles of ecosystem energy flows are considered formally analogous to the principles of energetics. Systems ecology also considers the external influence of ecological economics, which usually is not otherwise considered in ecosystem ecology. For the most part, systems ecology is a subfield of ecosystem ecology.\n\nThis is the study of how \"the environment, both physical and biological, interacts with the physiology of an organism. It includes the effects of climate and nutrients on physiological processes in both plants and animals, and has a particular focus on how physiological processes scale with organism size\".\n\nSwarm behaviour is a collective behaviour exhibited by animals of similar size which aggregate together, perhaps milling about the same spot or perhaps migrating in some direction. Swarm behaviour is commonly exhibited by insects, but it also occurs in the flocking of birds, the schooling of fish and the herd behaviour of quadrupeds. It is a complex emergent behaviour that occurs when individual agents follow simple behavioral rules.\n\nRecently, a number of mathematical models have been discovered which explain many aspects of the emergent behaviour. Swarm algorithms follow a Lagrangian approach or an Eulerian approach. The Eulerian approach views the swarm as a field, working with the density of the swarm and deriving mean field properties. It is a hydrodynamic approach, and can be useful for modelling the overall dynamics of large swarms. However, most models work with the Lagrangian approach, which is an agent-based model following the individual agents (points or particles) that make up the swarm. Individual particle models can follow information on heading and spacing that is lost in the Eulerian approach. Examples include ant colony optimization, self-propelled particles and particle swarm optimization\n\nThe British biologist Alfred Russel Wallace is best known for independently proposing a theory of evolution due to natural selection that prompted Charles Darwin to publish his own theory. In his famous 1858 paper, Wallace proposed natural selection as a kind of feedback mechanism which keeps species and varieties adapted to their environment.\n\n\"The action of this principle is exactly like that of the centrifugal governor of the steam engine, which checks and corrects any irregularities almost before they become evident; and in like manner no unbalanced deficiency in the animal kingdom can ever reach any conspicuous magnitude, because it would make itself felt at the very first step, by rendering existence difficult and extinction almost sure soon to follow.\"\n\nThe cybernetician and anthropologist Gregory Bateson observed in the 1970s that, though writing it only as an example, Wallace had \"probably said the most powerful thing that’d been said in the 19th Century\". Subsequently, the connection between natural selection and systems theory has become an area of active research.\n\nIn contrast to previous ecological theories which considered floods to be catastrophic events, the river flood pulse concept argues that the annual flood pulse is the most important aspect and the most biologically productive feature of a river's ecosystem.\n\nTheoretical ecology draws on pioneering work done by G. Evelyn Hutchinson and his students. Brothers H.T. Odum and E.P. Odum are generally recognised as the founders of modern theoretical ecology. Robert MacArthur brought theory to community ecology. Daniel Simberloff was the student of E.O. Wilson, with whom MacArthur collaborated on \"The Theory of Island Biogeography\", a seminal work in the development of theoretical ecology.\n\nSimberloff added statistical rigour to experimental ecology and was a key figure in the SLOSS debate, about whether it is preferable to protect a single large or several small reserves. This resulted in the supporters of Jared Diamond's community assembly rules defending their ideas through Neutral Model Analysis. Simberloff also played a key role in the (still ongoing) debate on the utility of corridors for connecting isolated reserves.\n\nStephen Hubbell and Michael Rosenzweig combined theoretical and practical elements into works that extended MacArthur and Wilson's Island Biogeography Theory - Hubbell with his Unified Neutral Theory of Biodiversity and Biogeography and Rosenzweig with his Species Diversity in Space and Time.\n\nA tentative distinction can be made between mathematical ecologists, ecologists who apply mathematics to ecological problems, and mathematicians who develop the mathematics itself that arises out of ecological problems.\n\nSome notable theoretical ecologists can be found in these categories:\n\n\n", "id": "30773", "title": "Theoretical ecology"}
{"url": "https://en.wikipedia.org/wiki?curid=31834667", "text": "Commodification of nature\n\nThe commodification of nature is an area of research within critical environmental studies that is concerned with the ways in which natural entities and processes are made exchangeable through the market, and the implications thereof.\n\nDrawing upon the work of Karl Marx, Karl Polanyi, James O’Connor and David Harvey, this area of work is normative and critical, based in Marxist geography and political ecology. Theorists use a commodification framing in order to contest the perspectives of \"market environmentalism,\" which sees marketization as a solution to environmental degradation. The environment has been a key site of conflict between proponents of the expansion of market norms, relations and modes of governance and those who oppose such expansion. Critics emphasize the contradictions and undesirable physical and ethical consequences brought about by the commodification of natural resources (as inputs to production and products) and processes (environmental services or conditions).\n\nMost researchers who employ a commodification of nature framing invoke a Marxian conceptualization of commodities as \"objects produced for sale on the market\" that embody both use and exchange value. Commodification itself is a process by which goods and services not produced for sale are converted into an exchangeable form. It involves multiple elements, including privatization, alienation, individuation, abstraction, valuation and displacement.\n\nAs capitalism expands in breadth and depth, more and more things previously external to the system become “internalized,” including entities and processes that are usually considered \"natural.\" Nature, as a concept, however, is very difficult to define, with many layers of meaning, including external environments as well as humans themselves. Political ecology and other critical conceptions draw upon strands within Marxist geography that see nature as \"socially produced,\" with no neat boundary separating the \"social\" from the \"natural.\" Still, the commodification of entities and processes that are considered natural is viewed as a \"special case\" based on nature’s biophysical materiality, which \"shape[es] and condition[s] trajectories of commodification.\"\n\nThe commodification of nature has its origins in the rise of capitalism. In England and later elsewhere, \"enclosure\" involved attacks upon and eventual near-elimination of the commons—a long, contested and frequently violent process Marx referred to as \"primitive accumulation.\"\n\nClassical liberalism, the ideological aspect of this process, was closely bound to questions of the environment. Privatization was presented as \"more conducive to the careful stewardship of natural resources than the commons\" by thinkers like Bentham, Locke and Malthus. The neo-Malthusian discourse of Garrett Hardin’s \"Tragedy of the Commons\" (1968) parallels this perspective, reconceptualizing public goods as \"scarce commodities\" requiring either privatization or strong state control.\n\nEcology Against Capitalism\n\nAs Foster points out in \"Ecology Against Capitalism\", the environment is not a commodity (such as most things are treated in capitalism) but it is rather the biosphere that sustains all life that we know of. However, it is important to note that in our society, it is treated as a capitalistic value. For example, a price is put on lumber in a certain forest or the quality of water in a river or stream, or the minerals that are available under ground. These ways of putting a price on the ecosystem tend to forget to put a price on exploiting it. This can cause more damage to an ecosystem if the externalities for business are not taken into consideration. One way to fix this problem is taxes that will increase the cost of environmental damage. For example, a carbon tax would help society get off of fossil fuels and go towards renewables much faster. This is one step that many scientists and experts agree needs to happen in order to transition away from fossil fuels and delay or even prevent man made climate change. Deregulation of governmental programs such as the EPA, and other environmental organizations may be good for business, but it doesn't serve the people who must live on a more polluted earth.\n\nMarxists define capitalism as a socio-economic system whose central goal is the accumulation of more wealth through the production and exchange of commodities. While the commodity form is not unique to capitalism, in it economic production is motivated increasingly by exchange. Competition provides constant pressure for innovation and growth in a \"restless and unstable process,\" making the system expansionary and \"tendentially all-encompassing.\"\n\nThrough market globalization, the tendency Marx described in the \"Communist Manifesto\" in which \"[t]he need of a constantly expanding market for its products chases the bourgeoisie over the entire surface of the globe,\" capitalism converts nature into \"an appendage of the production process.\" As Neil Smith argues, \"[n]o part of the earth’s surface, the atmosphere, the oceans, the geological substratum, or the biological superstratum are immune from transformation by capital.\"\n\nSince the late 1980s, an ideology of “market environmentalism” has gained prominence within environmental policy. Such a perspective is based in neoclassical economic theory, which sees degradation as a result of the absence of prices in environmental goods. Market environmentalism gained widespread acceptance through the rise of neoliberalism, an approach to human affairs in which the \"free market\" is given priority and money-mediated relations are seen as the best way to deliver services.\n\nA neoliberal approach constructs nature as a \"world currency,\" valued in international markets and given \"the opportunity to earn its own right to survive.\" This \"selling nature to save it\" approach requires economic valuation — either indirectly, as with cost-benefit analysis and contingent valuation, or through direct commodification.\n\nWhile commodification efforts are propelled in large part by private firms seeking new areas of investment and avenues for the circulation of capital, there are also explicit policy prescriptions for privatization and market exchange of resources, production byproducts and processes as the best means to rationally manage and conserve the environment.\n\nThe commodification of nature occurs through two distinct \"moments\" as capitalization \"stretches\" its reach to include greater distances of space and time, and \"deepens\" to penetrate into more types of goods and services. External nature becomes an \"accumulation strategy\" for capital, through traditional examples like mining and agriculture as well as new \"commodity frontiers\" in bioprospecting and ecotourism.\n\nDavid Harvey sees this as \"the wholesale commodification of nature in all its forms,\" a \"new wave of ‘enclosing the commons’\" that employs environmentalism in the service of the rapid expansion of capitalism. This \"accumulation by dispossession\" releases assets at very low or zero cost, providing immediate profitability and counteracting overaccumulation.\n\nAt the most abstract level, commodification is a process through which qualitatively different things are made equivalent and exchangeable through the medium of money. By taking on a general quality of exchange value, they become commensurable. Commodification turns on this apparent dissolution of qualitative difference and its “renegotiation,” as commodities are standardized in order to maintain a constant identity across space and time.\n\nCommodity status is not something intrinsic to a natural entity, but is rather an assigned quality, brought about through an active process. The conversion of a whole class of goods or services necessitates changes in the way nature is conceptualized and discursively represented.\n\nThere is no \"single path\" to commodification. Noel Castree stresses that commodification in fact involves several interrelated aspects, or \"relational moments,\" that should not be confused or conflated as they can be employed independently of each other.\n\nPrivatization is the assigning of legal title to an entity or process. A commodity needs to be owned, either by an individual or a group, in order to be traded. Privatization of natural entities can entail enclosure or the representation thereof (as with intellectual property rights), and represents a shift in social relations, changing rights of access, use and disposal as things move from communally-, state- or unowned modes into private hands.\n\nAlienability is the capacity of a given commodity to be separated, physically and morally, from its seller. If a commodity is not alienable, it cannot be exchanged and is thus shielded from the market. For example, human organs might be privatized (owned by their bearer) but very rarely would they be considered alienable.\n\nIndividuation is the representational and physical act of separating a commodity from its supporting context through legal and/or material boundaries. This could involve \"splitting\" an ecosystem into legally-defined and tradable property rights to specific services or resources.\n\nAbstraction is the assimilation of a given thing into a broader type or process, the transformation of particular things into classes. Through \"functional abstraction\", \"wetlands\" are constructed as a generic category despite the uniqueness of physical sites and different gasses and activities are equated through carbon markets. Through \"spatial abstraction\" things in one place are treated as the same as things located elsewhere so that both can form part of the same market.\n\nValuation is the manifestation of all expressions of worth (aesthetic, practical, ethical, \"et cetera\") through a single exchange value. Monetization is thus foundational to capitalism, rendering things commensurable and exchangeable, allowing for the separation of production, circulation and consumption over great gulfs of time and space.\n\nDisplacement involves something appearing as \"something other than itself.\" Commodities might be better thought of as \"socio-natural relations\" than reified as things \"in and of themselves,\" but through spatio-temporal separation of producers and consumers, the histories and relations of commodities become obscured. This is Marx’s commodity fetishism, the \"making invisible\" of the social relationships and embeddedness of production.\n\nCritics see environmental degradation as stemming from these processes of commodification, and generally include at least implicit criticism of one or more aspect. There appear to be three broad \"problem areas\" from which the commodification of nature is critiqued: \"practical\", in terms of whether or not nature can be properly made into a commodity; \"moral\", in terms of the ethical implications of commodification; and \"consequential\", in terms of the effects of commodification on nature itself.\n\nMuch of the literature relates commodification of nature to the issue of materiality—the significance of biophysical properties and context. The qualitative differences of a heterogeneous biophysical world are seen to be analytically and practically significant, sources of unpredictability and resistance to human intention that also shape and provide opportunities for capital circulation and accumulation.\n\nThe tangible non-human world thus affects the construction of social and economic relations and practice, inscribing ecology in the dynamics of capital. While some \"natures\" are readily subsumed by capitalism, others \"resist\" complete commodification, displaying a form of \"agency.\" The ecological characteristics of marine fish, for example, affect the forms that privatization, industry structure and regulation can take. Water, also, does not commodify easily due to its physical properties, which leads to differentiation in its governing institutions.\n\nThe demarcation and pricing of nature-based commodities is thus problematic. Divisibility and exclusion are difficult, as it is often not possible to draw clean property rights around environmental services or resources. Likewise, pricing is a problem as many species, landscapes and services are unique or otherwise irreplaceable and incommensurable. Their monetary values are thus in many ways arbitrary, as they do not follow changes in quality or quantity but rather social preference, failing to convey \"real\" ecological value or reasons for conservation.\n\nA single monetary value also denies the multiplicity of values which could be attributed to nature — non-monetary systems of cultural and social importance. The environment can express relations between generations as a sort of heritage. Livelihood, territorial rights and \"sacredness\" poorly translate into prices, and dividing a communal-social value — a forest, for instance — into private property rights can undermine the relations and identity of a community.\n\nNeoliberal policies have been implicated in greatly altered patterns of access and use. Markets generally deal poorly with issues of procedural fairness and equitable distribution, and critics see commodification as producing greater levels of inequality in power and participation while reinforcing existing vulnerabilities. Ecosystem benefits might be considered \"normative public goods\" — even when commodified, there is a sense that individuals \"ought\" to not be excluded from access. When water privatization prices people out, for instance, a sense of use rights inspires protest. While neoliberal approaches are often presented as neutral or objective, they disguise highly political approaches to resources and the interests and power of certain actors.\n\nThrough commodification, natural entities and services become vehicles for the realization of profit, subject to the pressures of the market where efficiency overrides other concerns. With climate commodities, the profit motive incentivizes buyers and sellers to ignore the steady erosion of the climate mitigation goal. Market exchange is \"reason-blind,\" but without rational assessment of different strategies and the ecological importance of particular natural entities, commodification cannot effectively deliver on conservation.\n\nHarvey thus declares that there is something \"inherently anti-ecological\" about capitalist commodification. It ignores and simplifies complex relations, obscuring origins and narrowing things to a single service or standard unit. The treatment of things as the same for a particular end — either profit or a single utility — leads to a homogenization and simplification of the biophysical. As governments and private firms seek to maximize carbon content for emissions markets, they invest preferably in tree plantations over complex forest ecosystems, eliminating species diversity, density and resulting in domino effects on processes such as water flow.\n\nThe neglect of relational aspects also ignores the emergent and embedded character of ecosystem functions. Components are frequently dependent on each other and the result of interactions between biotic and non-biotic factors across space and at multiple levels. Alienation and individuation may thus be counterproductive to the provision of ecosystem services, and veils human perception of what an ecosystem is and how it functions—and consequently how to best conserve and repair it. John Bellamy Foster argues that neglect of such relational aspects is a result of economic reductionism. This reductionism leads to an inefficiency in promoting biodiversity since as ecosystems are simplified into more basic commodities they can no longer support as diverse a set of organisms as they could precommodification. This creates a concern that the commodification of nature lends itself toward undermining biodiversity through its pursuit of attaching a value to nature.\n\nKarl Polanyi voiced this concern when addressing the concept of treating nature as a commodity. If nature were treated as a commodity it would be concentrated down to its base parts and destroyed. Polanyi highlighted many of the concerns that contemporary environmentalists have by noting that nature's commodification would lead to its pollution, overuse, and eventually imperil human life \n\nWhen confronted with natural \"barriers to accumulation,\" capitalists attempt to overcome them through technical and social innovation. This often involves the modification of nature to fit the needs of production and exchange, allowing for fuller realization of profits. Nature is \"subsumed\" to capitalist accumulation, losing its \"independent\" capacity and approaching \"the archetype of a ‘pure’ commodity.\"\n\nHowever, as nature becomes \"rationalized\" and internalized, increasing the control of capitalists over exchange, production and distribution, a new contradiction emerges. Capitalist penetration into natural commodities can never be complete, because a certain amount of production, by definition, takes place prior to human intervention. Because natural entities and processes do not require capital or labor to be produced, and their social, cultural and/or ecological value \"exceeds\" the market value placed upon them, they are considered pseudo- or fictitious commodities. This basic fictitiousness is the origin of the material contradictions that arise when natural commodities are treated \"as if\" they were \"true\" commodities, as completely privatizable, alienable, separable, \"et cetera\".\n\nMany scholars believe that ecology and capitalism are against one another regarding climate change. As environmental economics is a relatively new field of study, and capitalism a significantly older economic system, radical change of current capitalist systems is highly unlikely while internalization of natural resources into the economy is much more feasible. John Bellamy Foster believes that commodification of nature might be more dangerous than the impending danger of climate change and ecologic disaster. Foster fears that commodification of nature might lead to an system that favors economy over ecology (endangering natural resources) and promote a form of neocolonialism that acknowledges the elements of capitalism, globalization, and cultural imperialism, but disregards the idea of colonialism altogether.\n\nAs fictitious commodities with origins outside of capitalist production, the value of nature, counter to the neoclassical assumption, \"cannot\" be fully accounted for in monetary terms, and there is a resultant tendency toward the overexploitation and \"underproduction\" of nature.\n\nNatural entities that are commodified are subjected to the competitive drive for accumulation. Capitalism is \"ecologically irrational,\" with a systematic tendency to overexploit its natural resource base. At the same time, what O’Connor terms the \"conditions of production\" (all the phenomena upon which capitalism depends but is unable to produce itself, including environmental conditions and processes) are subjected to indiscriminate degradation as they \"cannot\" be fully commodified. This is the \"second contradiction\" of capitalism, between the relations and forces of production and its conditions. Capitalism undermines its own production system, \"producing its own scarcity.\"\n\nRecruiting nature into relations of capitalist exchange \"incites a good deal of push back,\" as these entities and services \"matter a great deal to ordinary people.\" Social needs compete politically for access and control of an increasingly commodified nature, and as price is insufficient to resolve these competing claims, counter-movements emerge, expressing the \"crisis tendencies\" of capitalist nature through socio-political struggles over representation and access.\n\nProtest movements, transnational coalitions, instances of alternative practices and counter-discourses all fall within a broad tent of resistance struggles to \"reclaim the commons.\" This can be seen as Polanyi’s \"double movement,\" in which tendencies toward and against market coordination interact, based in a rejection of the treatment of the environment as alienable market goods.\n\nWhile there are numerous natural resources that are being capitalized upon all across the world, there are several more notable examples of commodification of nature. The following examples are some that are either more prevalent or larger in scale and scope.\n\nEmissions trading, commonly referred to as cap and trade, embodies commodification of nature in that it allows for the trade of pollution and emissions within a given limit for a specific environment. Rather than simply outright prohibiting or allowing pollution and other various negative externalities, cap and trade essentially permits members of an industry to buy and sell units of emission with a maximum set for the industry as a whole.\n\nWhile there are various outlooks on whether emissions trading is effective in cutting emissions or pollution, it is pertinent to understand that this concept takes a company or individual's emissions and presents them as something that can be bought or sold on a specialized market.\n\nAs capitalism has spread in leaps and bounds, so too has its reach on previously universal resources; one such resource is drinking water. As more and more people struggle to find access to clean water, a major economic industry has formed in response, striving to provide this resource to consumers.\n\nWater, a fundamental resource to human survival, now is a multibillion dollar industry. Essentially what this means is that something that used to be completely free and public has been taken and turned into a privatized service. One modern example of water commodification is the current conflict going on in Flint, Michigan.\n\nAs petroleum has begun to be used for fuel and other various mechanical and transportation uses, the demand for the natural resource has skyrocketed. As a result, an economic industry has formed that completely revolves around the extraction and sale of the resource. By extension, many other industries also rely on the resource such as the automotive industry or anyone that relies on transportation for their business.\n\nOil is just one of many natural resources being taken from the environment to be sold in markets of various size and influence across the globe. What sets this resource apart from others, however, is that so many other industries are reliant upon oil that it has become one of the most sought after resources across the world.\n\n\nNotable contemporary studies concerning the commodification of nature include:\n\n", "id": "31834667", "title": "Commodification of nature"}
{"url": "https://en.wikipedia.org/wiki?curid=12731840", "text": "Nectar robbing\n\nNectar robbing is a foraging behavior utilized by some organisms that feed on floral nectar. \"Nectar robbers\" usually feed from holes bitten in flowers, rather than by entering through the flowers' natural openings. Often, nectar robbers avoid contact with the floral reproductive structures, and therefore do not facilitate plant reproduction via pollination. Because many species that act as pollinators also act as nectar robbers, nectar robbing is considered to be a form of exploitation of plant-pollinator mutualism.\n\nNectar robbers vary greatly in species diversity and include species of carpenter bees, bumblebees, stingless \"Trigona\" bees, solitary bees, wasps, ants, hummingbirds, passerine birds, and flowerpiercer birds. Nectar robbing mammals include a fruit bat and a squirrel which robs nectar from the ginger plant.\n\nRecords of nectar robbing in nature date back at least to 1793 when German naturalist Christian Konrad Sprengel observed bumblebees perforating flowers. Charles Darwin observed bumblebees stealing nectar from flowers in 1859.\n\nNectar robbing is specifically the behavior of consuming nectar from a perforation (robbing hole) in the floral tissue rather than from the floral opening. There are two main types of nectar robbing: primary robbing, which requires that the nectar forager perforates the floral tissues itself, and secondary robbing, which is foraging from a robbing hole created by a primary robber. The term \"floral larceny\" has been proposed to include the entire suite of foraging behaviors for floral rewards that can potentially disrupt pollination. They include \"nectar theft\" (floral visits that remove nectar from the floral opening without pollinating the flower), and \"base working\" (removing nectar from in between petals, which generally bypasses floral reproductive structures).\n\nPollination systems are mostly mutualistic, meaning that the plant benefits from the pollinator's transport of male gametes and the pollinator benefits from a reward, such as pollen or nectar. As nectar robbers receive the rewards without direct contact with the reproductive parts of the flower, their behaviour is easily assumed to be cheating. However, the effect of robbery on the plant is sometimes neutral or even positive. For example, the proboscis of \"E. elvina\" does not come in contact with the reproductive parts of the flower in \"C. ovandensis,\" but this does not lead to significant reduction in fruit-set of the plant. In an another example, when 80 percent of the flowers in a study site were robbed and the robbers did not pollinate, neither the seed nor fruit set were negatively affected.\n\nThe effect of floral-nectar robbing on plant fitness depends on several issues. Firstly, nectar robbers such as carpenter bees, bumble bees and some birds can pollinate flowers. Pollination may take place when the body of the robber contacts the reproductive parts of the plant while it robs, or during pollen collection which some bees practice in concert with nectar robbing. The impact of \"Trigona\" bees (e.g. \"Trigona ferricauda\") on a plant is almost always negative, probably because their aggressive territorial behaviour effectively evicts legitimate pollinators. Nectar robbers may change the behaviour of legitimate pollinators in other ways, such as by reducing the amount of nectar available. This may force pollinators to visit more flowers in their nectar foraging. The increased number of flowers visited and longer flight distances increase pollen flow and outcrossing, which is beneficial for the plant because it lessens inbreeding depression. This requires a robber's not completely consuming all of a flower's nectar. When a robber consumes all of a flower's nectar, legitimate pollinators may avoid the flower, resulting in a negative effect on plant fitness.\n\nThe response of different species of legitimate pollinators also varies. Some species, like the bumble bees \"Bombus appositus\" or \"B. occidentalis\" and many species of nectar-feeding birds can distinguish between robbed and unrobbed plants and minimize their energy cost of foraging by avoiding heavily robbed flowers. Pollinating birds may be better at this than insects, because of their higher sensory capability. The ways that bees distinguish between robbed and unrobbed flowers have not been studied, but they have been thought to be related to the damage on petal tissue after robbery or changes in nectar quality. \"Xylocopa varipuncta\" steals nectar through a slit they make in the base of the petals. If nectar robbing severely reduces the success of legitimate pollinators they may be able to switch to other nectar sources.\n\nNectar robbing, especially by birds, can damage the reproductive parts of a flower and thus diminish the fitness of a plant. In this case, the effect of robbery on a plant is direct. A good example of an indirect effect is the change in the behaviour of a legitimate pollinator, which either increases or decreases the fitness of a plant. There are both primary and secondary nectar robbers. Secondary robbers are those (e.g. flies and bees) that take advantage of the holes made by primary robbers.\n\nThe effect of robbing is positive if the robber also pollinates or increases the pollination by the legitimate pollinator, and negative if the robber damages the reproductive parts of a plant or reduces pollination success, either by competing with the legitimate pollinator or by lessening the attractiveness of the flower. Distinguishing between a legitimate pollinator and a nectar robber can be difficult.\n\nPollination systems cause coevolution, as in the close relationships between figs and fig wasps as well as yuccas and yucca moths. If nectar robbers have an effect (direct or indirect) on a plant or pollinator fitness, they are part of the coevolution process. Where nectar robbing is detrimental to the plant, a plant species might evolve to minimize the traits that attract the robbers or develop some type of protective mechanism to hinder them. Another option is to try to neutralize negative effects of nectar robbers. Nectar robbers are adapted for more efficient nectar robbing: for instance, hummingbirds and \"Diglossa\" flowerpiercers have serrated bills that are thought to aid them in incising flower tissue for nectar robbing.\n\nNectar robbers may only get food in illegitimate ways because of the mismatch between the morphologies of their mouthparts and the floral structure; or they may rob nectar as a more energy-saving way to get nectar from flowers.\n\nIt is not completely clear how pollination mutualisms persist in the presence of cheating nectar robbers. Nevertheless, as exploitation is not always harmful for the plant, the relationship may be able to endure some cheating. Mutualism may simply confer a higher payoff than nectar robbing.\n\nEven though there has not been much research on the defences evolved in plants against nectar robbers, the adaptations have been assumed not to rise from traits used in interactions between plants and herbivores (especially florivores). Some defences may have evolved through traits originally referred to pollination. Defences against nectar robbers have been thought to include toxins and secondary compounds, escape in time or space, physical barriers and indirect defences.\n\nToxins and secondary compounds are likely to act as a defence against nectar robbing because they are often found in floral nectar or petal tissue. There is some evidence that secondary compounds in nectar only affect nectar robbers and not the pollinators. One example is a plant called \"Catalpa speciosa\" which produces nectar containing iridoid glycosides that deter nectar-thieving ants but not legitimate bee pollinators. Low sugar concentration in nectar may also deter nectar robbers without deterring pollinators because dilute nectar does not yield net energy profits for robbers.\n\nIf robbers and pollinators forage at different times of day, plants may produce nectar according to the active period of a legitimate pollinator. This is an example of a defence by escaping in time. Another way to use time in defence is to flower only for one day as a tropical shrub \"Pavonia dasypetala\" does to avoid the robbing Trigona bees. Escaping in space refers to a situation in which plant avoids being robbed by growing in a certain location like next to a plant which is more attractive to the robbers.\n\nThe last two methods of protection are physical barriers and indirect defence like symbionts. Tightly packed flowers and unfavourably sized corolla tubes, bract liquid moats and toughness of the corolla or sepal are barriers for some nectar robbers. A good example of an indirect defence is to attract symbiotic predators (like ants) by nectar or other rewards to scare away the robbers.\n\nThe term 'resistance' refers to the plant's ability to live and reproduce in spite of nectar robbers. This may happen, for example, by compensating the lost nectar by producing more. With the help of defence and resistance, mutualisms can persist even in the presence of cheaters.\n", "id": "12731840", "title": "Nectar robbing"}
{"url": "https://en.wikipedia.org/wiki?curid=31950486", "text": "Aeroecology\n\nAeroecology is the discipline for studying how airborne life forms utilize and interact with other biotic and abiotic components of the lower atmosphere. The aerosphere is viewed as habitat and the way that organisms respond to and take advantage of the dynamic aeroscape has relevance to the ecology, evolution, and conservation of many of the world's bird, bat, insect, and plant species.\n\nThe interactions and properties in the aerosphere, the zone that is closest to the Earth's surface, provide selective pressures that influence the size and shape of organisms, their behavioral, sensory, metabolic, and respiratory functions. In contrast to organisms that spend their entire lives on land or in water, organisms that use the aerosphere are almost immediately affected by changing conditions such as winds, air density, oxygen concentrations, precipitation, air temperature, sunlight, polarized light, moonlight, and geomagnetic and gravitational forces.\n\nAeroecology has relied upon traditional ecological field studies such as direct observation or detection of organisms flying overhead (e.g., moon watching, thermal cameras, or bioacoustics). However, the field has been greatly advanced by the inclusion of remotely sensed data, in particular Doppler weather radar or NEXRAD. In March 2012, an international and interdisciplinary Radar Aeroecology Workshop was held at the National Weather Center on the University of Oklahoma campus in Norman, OK, USA. Experts in the fields of ecology and meteorology discussed how various radar technologies could be applied to aeroecological questions. Aeroecology research groups at both the University of Oklahoma and the University of Delaware continue to advance the development and integration of remotely sensed data to quantify, qualify, and track biological utilization of the lower aerosphere.\n\nIn the traditional sense, aeroecology has been limited to observations taken from the ground of biological organisms occupying the airspace above. This may include near-surface foraging behavior or moon-watching passage migrants using human observers equipped with optics. With the advent and adoption of technologies such as thermographic cameras, marine radar, and NEXRAD to aeroecological studies, the ability to detect and track sufficiently large animals in the aerospere was revolutionized.\n\nAeroecological studies using weather radar were pioneered by Dr. Sidney A. Gauthreaux during his graduate studies at Louisiana State University and later as a professor at Clemson University. His initial work with radar images produced by the WSR-57 network revealed much about the trans-Gulf of Mexico arrivals and departures of Neotropical migratory birds.\n\nRadar beams will reflect off sufficiently dense objects, such as water droplets, airplane fuselages, or flying animals. The reflectance of the object will depend upon its radar cross-section, which is dictated by the size, shape, and material composition of the object. Weather radar reflectivity data represents the sum reflectivity of all objects within the sampled airspace and therefore is a generalization of the amount of rain or, for aeroecological purposes, the abundance of animals in that volume of air. Aeroecologists use the term \"bioscatter\" to describe radar reflectance from biological objects.\n\nWeather radars are capable of detecting Doppler shift in returning waveforms. This information is used to extrapolate a mean relative velocity for all objects within the sampled airspace. Aeroecologists have used this information to distinguish among objects drifting with the wind (particulates such as dust, seeds, or pollen), from objects moving slightly faster/angular to the wind (e.g., insects), and objects moving at least 5–6 m/s faster than and/or moving against the predominant direction of the wind (e.g., birds and bats).\n\nAn upgrade of weather radars to allow dual polarization of the radar beam promises to provide greater characterization and discrimination of airborne targets. For aeroecology this promises to allow better capability to distinguish migrating birds from insects, weather, or suspended particulates. Ratios of horizontal versus vertical beam reflectivity and Doppler shift also hold much potential for gauging discrepancies between the orientation of birds relative to their realized movement paths, providing the means to assess drift compensation among migratory birds.\n\n", "id": "31950486", "title": "Aeroecology"}
{"url": "https://en.wikipedia.org/wiki?curid=31352483", "text": "Soundscape ecology\n\nThe term soundscape ecology, first appeared in the \"Handbook for Acoustic Ecology\", Barry Truax Ed., in 1978. It focuses on the study of the effects of the acoustic environment on the physical and behavioral characteristics of those organisms living within it. It has occasionally been used, sometimes interchangeably, with the term, acoustic ecology. Soundscape ecologists also study the relationships between the three basic sources of sound that comprise the soundscape: those generated by organisms are referred to as the biophony; those from non-biological natural categories are classified as the geophony, and those produced by humans, the anthropophony. Increasingly soundscapes are dominated by a sub-set of anthropophony (sometimes referred to in older, more archaic terminology as \"anthropogenic noise\"), or technophony, the overwhelming presence of electro-mechanical noise. This sub-class of noise pollution or disturbance may produce a negative effect on a wide range of organisms. Variations in soundscapes as a result of natural phenomena and/or human endeavor may have wide-ranging ecological effects as many organisms have evolved to respond to acoustic cues that emanate primarily from undisturbed habitats. Soundscape ecologists use recording devices, audio tools, and elements of traditional ecological and acoustic analyses to study soundscape structure. Soundscape ecology has deepened current understandings of ecological issues and established profound visceral connections to ecological data. The preservation of natural soundscapes is now a recognized conservation goal.\n\nSoundscape ecology is the bio- and geo-acoustic branch of ecology that studies acoustic signatures from whatever source within a landscape (the soundscape). The soundscape of a given region can be viewed as the sum of three separate sound sources: Geophony is the first sound heard on earth. Non-biological in nature, it consists of the effect of wind in trees or grasses, water flowing in a stream, waves at an ocean or lake shoreline, and movement of the earth. Biophony is a term introduced by soundscape ecologist, Bernie Krause, who in 1998, first began to express the soundscape in terms of its acoustic sources. The biophony refers to the collective acoustic signatures generated by all sound-producing organisms in a given habitat at a given moment. It includes vocalizations that are used for conspecific communication in some cases. Anthropophony is another term introduced by Bernie Krause along with colleague, Stuart Gage. It represents human sources from heavily populated urban regions usually contains information that was intentionally produced for communication with a sound receiver. The expression in various combinations of these acoustic features across space and time generate unique soundscapes.\n\nSoundscape ecologists seek to investigate the structure of soundscapes, explain how they are generated, and study how organisms interrelate acoustically. A number of hypotheses have been proposed to explain the structure of soundscapes, particularly elements of biophony. For instance, an ecological theory known as the acoustic adaptation hypothesis predicts that acoustic signals of animals are altered in different physical environments in order to maximize their propagation through the habitat. In addition, acoustic signals from organisms may be under selective pressure to minimize their frequency (pitch) overlap with other auditory features of the environment. This acoustic niche hypothesis is analogous to the classical ecological concept of niche partitioning. It suggests that acoustic signals in the environment should display frequency partitioning as a result of selection acting to maximize the effectiveness of intraspecific communication for different species. Observations of frequency differentiation among insects, birds, and anurans support the acoustic niche hypothesis. Organisms may also partition their vocalization frequencies to avoid overlap with pervasive geophonic sounds. For example, territorial communication in some frog species takes place partially in the high frequency ultrasonic spectrum. This communication method represents an evolutionary adaptation to the frogs' riparian habitat where running water produces constant low frequency sound. Invasive species that introduce new sounds into soundscapes can disrupt acoustic niche partitioning in native communities, a process known as biophonic invasion. Although adaptation to acoustic niches may explain the frequency structure of soundscapes, spatial variation in sound is likely to be generated by environmental gradients in altitude, latitude, or habitat disturbance. These gradients may alter the relative contributions of biophony, geophony, and anthrophony to the soundscape. For example, when compared with unaltered habitats, regions with high levels of urban land-use are likely to have increased levels of anthrophony and decreased physical and organismal sound sources. Soundscapes typically exhibit temporal patterns, with daily and seasonal cycles being particularly prominent. These patterns are often generated by the communities of organisms that contribute to biophony. For example, birds chorus heavily at dawn and dusk while anurans call primarily at night; the timing of these vocalization events may have evolved to minimize temporal overlap with other elements of the soundscape.\n\nAs an academic discipline, soundscape ecology shares some characteristics with other fields of inquiry but is also distinct from them in significant ways. For instance, acoustic ecology is also concerned with the study of multiple sound sources. However, acoustic ecology, which derives from the founding work of R. Murray Schafer and Barry Truax, primarily focuses on human perception of soundscapes. Soundscape ecology seeks a broader perspective by considering soundscape effects on communities of living organisms, human and Other, and the potential interactions between sounds in the environment. Compared to soundscape ecology, the discipline of bioacoustics tends to have a narrower interest in individual species’ physiological and behavioral mechanisms of auditory communication. Soundscape ecology also borrows heavily from some concepts in landscape ecology, which focuses on ecological patterns and processes occurring over multiple spatial scales. Landscapes may directly influence soundscapes as some organisms use physical features of their habitat to alter their vocalizations. For example, baboons and other animals exploit specific habitats to generate echoes of the sounds they produce.\n\nThe function and importance of sound in the environment may not be fully appreciated unless one adopts an organismal perspective on sound perception, and, in this way, soundscape ecology is also informed by sensory ecology. Sensory ecology focuses on understanding the sensory systems of organisms and the biological function of information obtained from these systems. In many cases, humans must acknowledge that sensory modalities and information used by other organisms may not be obvious from an anthropocentric viewpoint. This perspective has already highlighted many instances where organisms rely heavily on sound cues generated within their natural environments to perform important biological functions. For example, a broad range of crustaceans are known to respond to biophony generated around coral reefs. Species that must settle on reefs to complete their developmental cycle are attracted to reef noise while pelagic and nocturnal crustaceans are repelled by the same acoustic signal, presumably as a mechanism to avoid predation (predator densities are high in reef habitats). Similarly, juvenile fish may use biophony as a navigational cue to locate their natal reefs. Other species’ movement patterns are influenced by geophony, as in the case of the reed frog which is known to disperse away from the sound of fire. In addition, a variety of bird and mammal species use auditory cues, such as movement noise, in order to locate prey. Disturbances created by periods of environmental noise may also be exploited by some animals while foraging. For example, insects that prey on spiders concentrate foraging activities during episodes of environmental noise to avoid detection by their prey. These examples demonstrate that many organisms are highly capable of extracting information from soundscapes.\n\nAcoustic information describing the environment is the primary data required in soundscape ecology studies. Technological advances have provided improved methods for the collection of such data. Automated recording systems allow for temporally replicated samples of soundscapes to be gathered with relative ease. Data collected from such equipment can be extracted to generate a visual representation of the soundscape in the form of a spectrogram. Spectrograms provide information on a number of sound properties that may be subject to quantitative analysis. The vertical axis of a spectrogram indicates the frequency of a sound while the horizontal axis displays the time scale over which sounds were recorded. In addition, spectrograms display the amplitude of sound, a measure of sound intensity. Ecological indices traditionally used with species-level data, such as diversity and evenness, have been adapted for use with acoustic metrics. These measures provide a method of comparing soundscapes across time or space. For example, automated recording devices have been used to gather acoustic data in different landscapes across yearlong time scales, and diversity metrics were employed to evaluate daily and seasonal fluctuations in soundscapes across sites. Spatial patterns of sound may also be studied using tools familiar to landscape ecologists such as geographic information systems (GIS). Finally, recorded samples of the soundscape can provide proxy measures for biodiversity inventories in cases where other sampling methods are impractical or inefficient. These techniques may be especially important for the study of rare or elusive species that are especially difficult to monitor in other ways.\n\nAlthough soundscape ecology has only recently been defined as an independent academic discipline (it was first described in 2011 and formalized at the first meeting of the International Society of Ecoacoustics, held in Paris in 2014), many earlier ecological investigations have incorporated elements of soundscape ecology theory. For instance, a large body of work has focused on documenting the effects of anthropophony on wildlife. Anthropophony (the uncontrolled version, is often used synonymously with noise pollution) can emanate from a variety of sources, including transportation networks or industry, and may represent a pervasive disturbance to natural systems even in seemingly remote regions such as national parks. A major effect of noise is the masking of organismal acoustic signals that contain information. Against a noisy background, organisms may have trouble perceiving sounds that are important for intraspecific communication, foraging, predator recognition, or a variety of other ecological functions. In this way, anthropogenic noise may represent a soundscape interaction wherein increased anthropophony interferes with biophonic processes. The negative effects of anthropogenic noise impact a wide variety of taxa including fish, amphibians, birds, and mammals. In addition to interfering with ecologically important sounds, anthropophony can also directly affect the biological systems of organisms. Noise exposure, which may be perceived as a threat, can lead to physiological changes. For example, noise can increase levels of stress hormones, impair cognition, reduce immune function, and induce DNA damage. Although much of the research on anthropogenic noise has focused on behavioral and population-level responses to noise disturbance, these molecular and cellular systems may prove promising areas for future work.\n\nBirds have been used as study organisms in much of the research concerning wildlife responses to anthropogenic noise, and the resulting literature documents many effects that are relevant to other taxa affected by anthropophony. Birds may be particularly sensitive to noise pollution given that they rely heavily on acoustic signals for intraspecific communication. Indeed, a wide range of studies demonstrate that birds use altered songs in noisy environments. Research on great tits in an urban environment revealed that male birds inhabiting noisy territories tended to use higher frequency sounds in their songs. Presumably these higher-pitched songs allow male birds to be heard above anthropogenic noise, which tends to have high energy in the lower frequency range thereby masking sounds in that spectra. A follow-up study of multiple populations confirmed that great tits in urban areas sing with an increased minimum frequency relative to forest-dwelling birds. In addition, this study suggests that noisy urban habitats host birds that use shorter songs but repeat them more rapidly. In contrast to frequency modulations, birds may simply increase the amplitude (loudness) of their songs to decrease masking in environments with elevated noise. Experimental work and field observations show that these song alterations may be the result of behavioral plasticity rather than evolutionary adaptations to noise (i.e., birds actively change their song repertoire depending on the acoustic conditions they experience). In fact, avian vocal adjustments to anthropogenic noise are unlikely to be the products of evolutionary change simply because high noise levels are a relatively recent selection pressure. However, not all bird species adjust their songs to improve communication in noisy environments, which may limit their ability to occupy habitats subject to anthropogenic noise. In some species, individual birds establish a relatively rigid vocal repertoire when they are young, and these sorts of developmental constraints may limit their ability to make vocal adjustments later in life. Thus, species that do not or cannot modify their songs may be particularly sensitive to habitat degradation as a result of noise pollution.\n\nEven among birds that are able to alter their songs to be better heard in environments inundated with anthropophony, these behavioral changes may have important fitness consequences. In the great tit, for example, there is a tradeoff between signal strength and signal detection that depends on song frequency. Male birds that include more low frequency sounds in their song repertoire experience better sexual fidelity from their mates which results in increased reproductive success. However, low frequency sounds tend to be masked when anthropogenic noise is present, and high frequency songs are more effective at eliciting female responses under these conditions. Birds may therefore experience competing selective pressures in habitats with high levels of anthropogenic noise: pressure to call more at lower frequencies in order to improve signal strength and secure good mates versus opposing pressure to sing at higher frequencies in order to ensure that calls are detected against a background of anthrophony. In addition, use of certain vocalizations, including high amplitude sounds that reduce masking in noisy environments, may impose energetic costs that reduce fitness. Because of the reproductive trade-offs and other stresses they impose on some birds, noisy habitats may represent ecological traps, habitats in which individuals have reduced fitness yet are colonized at rates greater than or equal to other habitats.\n\nAnthropophony may ultimately have population- or community-level impacts on avian fauna. One study focusing on community composition found that habitats exposed to anthropophony hosted fewer bird species than regions without noise, but both areas had similar numbers of nests. In fact, nests in noisy habitats had higher survival than those laid in control habitats, presumably because noisy environments hosted fewer western scrub jays which are major nest predators of other birds. Thus, anthropophony can have negative effects on local species diversity, but the species capable of coping with noise disturbance may actually benefit from the exclusion of negative species interactions in those areas. Other experiments suggest that noise pollution has the potential to affect avian mating systems by altering the strength of pair bonds. When exposed to high amplitude environmental noise in a laboratory setting, zebra finches, a monogamous species, show a decreased preference for their mated partners. Similarly, male reed buntings in quiet environments are more likely to be part of a mated pair than males in noisy locations. Such effects may ultimately result in reduced reproductive output of birds subject to high levels of environmental noise.\n\nThe discipline of conservation biology has traditionally been concerned with the preservation of biodiversity and the habitats that organisms are dependent upon. However, soundscape ecology encourages biologists to consider natural soundscapes as resources worthy of conservation efforts. Soundscapes that come from relatively untrammeled habitats have value for wildlife as demonstrated by the numerous negative effects of anthropogenic noise on various species. Organisms that use acoustic cues generated by their prey may be particularly impacted by human-altered soundscapes. In this situation, the (unintentional) senders of the acoustic signals will have no incentive to compensate for masking imposed by anthropogenic sound. In addition, natural soundscapes can have benefits for human wellbeing and may help generate a distinct sense of place, connecting people to the environment and providing unique aesthetic experiences. Because of the various values inherent in natural soundscapes, they may be considered ecosystem services that are provisioned by intact, functioning ecosystems. Targets for soundscape conservation may include soundscapes necessary for the persistence of threatened wildlife, soundscapes that are themselves being severely altered by anthrophony, and soundscapes that represent unique places or cultural values. Some governments and management agencies have begun to consider preservation of natural soundscapes as an environmental priority. In the United States, the National Park Service's Natural Sounds and Night Skies Division is working to protect natural and cultural soundscapes.\n\n", "id": "31352483", "title": "Soundscape ecology"}
{"url": "https://en.wikipedia.org/wiki?curid=32078809", "text": "Trophic species\n\nTrophic species are a group of organisms that are aggregated according to their common trophic (feeding) positions in a food web or food chain. Trophic species have identical prey and a shared set of predators in the food web. This means that members of a trophic species share many of the same kinds of ecological functions. The idea of trophic species was first devised by Joel Cohen and Frederick Briand in 1984 to redefine assessment of the ratio of predators to prey within a food web. The category may include species of plant, animal, a combination of plant and animal, and biological stages of an organism. The reassessment grouped similar species according to habit rather than genetics. This resulted in a ratio of predator to prey in food webs is generally 1:1. By assigning groups in a trophic manner, relationships are linear in scale. This allows for predicting the proportion of different trophic links in a community food web.\n", "id": "32078809", "title": "Trophic species"}
{"url": "https://en.wikipedia.org/wiki?curid=14456919", "text": "Pleuston\n\nPleuston are the organisms that live in the thin surface layer existing at the air-water interface of a body of water as their habitat. Examples include some cyanobacteria, some gastropods, the ferns \"Azolla\" and \"Salvinia\" and the seed plants \"Lemna\", \"Wolffia\", \"Pistia\", \"Eichhornia crassipes\" and \"Hydrocharis\". Some fungi and fungi-like protists may be also found.\n\nThe term \"Neuston\" is used either:\n\nNeustons, broadly defined, are made up of some species of fish (see flying fish), beetles (see whirligig beetle), protozoans, bacteria and spiders (see fishing spider and diving bell spider). Collembola in the genera Podura and Sminthurides are almost exclusively neustonic, while Hypogastrura species often aggregate on pond surfaces. A water strider, \"Gerris\", is a common example of an insect that supports its weight on water's surface tension. By extension, the term may also refer to non-organismal floating aggregations (see, \"e.g.\", Great Pacific Garbage Patch).\n\nPlankton (organisms that float or drift within the water) are distinguished from nekton (organisms that swim, powerfully, in the water), and benthos (organisms on the bottom of a body of water).\n", "id": "14456919", "title": "Pleuston"}
{"url": "https://en.wikipedia.org/wiki?curid=32301719", "text": "Reverse ecology\n\nReverse ecology refers to the use of genomics to study ecology with no \"a priori\" assumptions about the organism(s) under consideration. The term was suggested in 2007 by Matthew Rockman during a conference on ecological genomics in Christchurch, New Zealand. Rockman was drawing an analogy to the term reverse genetics in which gene function is studied by comparing the phenotypic effects of different genetic sequences of that gene. Most researchers employing reverse ecology make use of some sort of population genomics methodology. This requires that a genome scan is performed on multiple individuals from at least two populations in order to identify genomic regions or sites that show signs of selection. These genome scans usually utilize single nucleotide polymorphism (SNP) markers, though use of microsatellites can work as well (with reduced resolution).\n\nReverse ecology has been used by researchers to understand environments and other ecological traits of organisms on Earth using genomic approaches. By examining the genes of bacteria, scientists are able to reconstruct what the organisms' environments are like today, or even from millions of years ago. The data could help us understand key events in the history of life on Earth. In 2010, researchers presented a technique to carry out reverse ecology to infer a bacteria's living temperature-range conditions based on the GC content of certain genomic regions.\n\nIn 2011, researchers at the University of California, Berkeley were able to demonstrate that one can determine an organism's adaptive traits by looking first at its genome and checking for variations across a population.\n\n", "id": "32301719", "title": "Reverse ecology"}
{"url": "https://en.wikipedia.org/wiki?curid=12201781", "text": "Ecological competence\n\nEcological competence is the ability of an organism, often a pathogen, to survive and compete in new habitats. In the case of plant pathogens, it is also their ability to survive between growing seasons. For example, peanut clump virus can survive in the spores of its fungal vector until a new growing season begins and it can proceed to infect its primary host again. If a pathogen does not have ecological competence it is likely to become extinct. \n\n", "id": "12201781", "title": "Ecological competence"}
{"url": "https://en.wikipedia.org/wiki?curid=4457559", "text": "Ecospirituality\n\nEcospirituality connects the science of ecology with spirituality. It brings together religion and environmental activism. Ecospirituality has been defined as \"a manifestation of the spiritual connection between human beings and the environment.\" The new millennium and the modern ecological crisis has created a need for environmentally based religion and spirituality. Ecospirituality is understood by some practitioners and scholars as one result of people wanting to free themselves from a consumeristic and materialistic society. Ecospirituality has been critiqued for being an umbrella term for concepts such as deep ecology, ecofeminism, and nature religion.\n\nProponents may come from a range of faiths including: Islam; Christianity (Catholicism, Evangelicalism and Orthodox Christianity); Judaism; Buddhism and Indigenous traditions. Although many of their practices and beliefs may differ, a central claim is that there is \"a spiritual dimension to our present ecological crisis.\" According to the environmentalist Sister Virginia Jones, \"Eco-spirituality is about helping people experience 'the holy' in the natural world and to recognize their relationship as human beings to all creation.\n\nEcospirituality has been influenced by the ideas of deep ecology, which is characterized by \"recognition of the inherent value of all living beings and the use of this view in shaping environmental policies\" Similarly to ecopsychology, it refers to the connections between the science of ecology and the study of psychology. 'Earth-based' spirituality is another term related to ecospirituality; it is associated with pagan religious traditions and the work of prominent ecofeminist, Starhawk. Ecospirituality refers to the intertwining of intuition and bodily awareness pertaining to a relational view between human beings and the planet.\n\nEcospirituality finds its history in the relationship between spirituality and the environment. Some scholars say it \"flows from an understanding of cosmology or the story of the origin of the universe.\" There are multiple origin stories about how the spiritual relationship with people and the environment began. In Native America philosophy, there are many unique stories of how spirituality came to be. A common theme in a number of them is the discussion of a Great Spirit that lives within the universe and the earth represents its presence.\n\nEcospirituality has also sprung from a reaction to the Western world's materialism and consumerism, characterized by ecotheologian Thomas Berry as a \"crisis of cosmology.\" Scholars have argued that \"the modern perspective is based on science and focused on the human self with everything else being outside, resulting in the demise of the metaphysical world and the disenchantment with the cosmos.\" Therefore, ecospirituality originates as a rebuttal to the emphasis on the material as well as Western separation from the environment, where the environment is regarded as a set of material resources with primarily instrumental value.\n\nEcospirituality became popularized due to a need for a reconceptualization of the human relationship with the environment. Terms such as environmental crisis, ecological crisis, climate change, global warming all refer to an ongoing global issue that needs to be addressed. Generally the ecological crisis is referring to the destruction of the earth’s ecosystem. What this encompasses is a highly controversial debate in scientific and political spheres. Globally we are faced with pollution of our basic needs (air, and water) as well as the depletion of important resources, most notably food resources.\n\nAnnette Van Schalkwyk refers to the environmental crisis as “man-made”. It is arguably the result of a “mechanistic and capitalistic world view”. Whether it is man-made, or as some argue, a natural occurrence, humans are not helping. Pollution and depletion of resources play a major role in the ecological crisis. Bringing religion into the ecological crisis is controversial due to the divide between religion and science. Ecospirituality is prepared to acknowledge science, and work in tandem with religion to frame the environment as a sacred entity in need of protection.\n\nMary Evelyn Tucker notes the importance of religion and ecology connecting with sustainability. Due to the environmental crisis, perceptions of sustainability are changing. Religion and ecology, and the way people experience ecospirituality, could contribute to this changing definition of sustainability.\n\nEcospirituality has been studied by academics in order to understand a clearer definition of what individuals label as ecospirituality and the framework in which they create this definition. One study focused on holistic nurses, who themselves characterize their profession as having a fundamentally spiritual nature and a sense of the importance of the environment. Researchers performed a phenomenological study where they assessed the nurses' ecospiritual consciousness. For the purpose of their study, they defined ecospiritual consciousness as \"accessing a deep awareness of one's ecospiritual relationship.\" They then narrowed down their findings to the five principles of ecospiritual consciousness, which are: tending, dwelling, reverence, connectedness, and sentience.\nAnother study looked at medical effects of ecospirituality by having patients with cardiovascular disease practice \"environmental meditation\" and log regular journal entries about their experiences. Researchers started out with the research question of, \"\"What is the essence of the experience of ecospirituality meditation in patients with CVD?\"\" CVD is an acronym for cardiovascular disease. From analyzing journal entries of participants, researchers abstracted four major themes of ecospirituality meditation: entering a new time zone, environmental reawakening, finding a new rhythm, and the creation of a healing environment.\nThis research was driven by the goal of raising awareness among healthcare professionals about ecospirituality and the medical importance of both self and environmental consciousness. Anecdotal evidence showed a decrease in blood pressure. However, the psychological benefits of environmental meditation were the main focus for the researchers.\n\nDark Green Religion is one way in which people, both secular and religious, connect with nature on a spiritual level. Bron Taylor defines Dark Green Religion as \"religion that considers nature to be sacred, imbued by intrinsic value, and worthy of reverent care\" in his book \"Dark Green Religion: Nature Spirituality and the Planetary Future.\" \nNature religion is an overarching term of which Dark Green Religion is a part of. A key part of Dark Green Religion is the \"depth of its consideration of nature.\" \nDark Green Religion differs from Green Religion. Green Religion claims that it is a religious obligation for humans to be environmental stewards, while Dark Green Religion is a movement that simply holds nature as valuable and sacred.\nSpiritual types of Dark Green Religion include Naturalistic and Supernaturalistic forms of Animism and of Gaianism. The diverse views within Dark Green Religion are not without the idea that the earth is sacred and worthy of care. The perceptions of Dark Green Religion are global and flexible. Taylor's use of the word 'Dark' gestures toward these negative possibilities. According to Taylor, Dark Green Religion has the possibility to \"inspire the emergence of a global, civic, earth religion.\" Dark Green, Green and Nature Religions are arguably all a part of ecospirituality. The term ecospirituality is versatile and overarching.\n\nThe umbrella term \"ecospirituality\" covers the feminist theology called Ecofeminism. The term ecofeminism was first coined by the French writer Françoise D'Eaubonne in her book, \"Le Féminisme ou la Mort\" in order to name the connection between the patriarchal subjugation of women and the destruction of nature. In it, she argues that women have different ways of seeing and relating to the world than men. These differences can give rise alternative insights on interactions between humans and the natural world when women's perspectives are considered. The suppression and control of woman and the natural world are connected. On the ecofeminist view, women are controlled because they are thought to be closer to primitive nature. By understanding the connection between femininity and nature and by exploring feminine ways of seeing and relating, ecofeminism asserts that humans can realize positive ways of interacting with the natural world and with each other.\n\nA significant figure in Christian ecofeminism is Rosemary Radford Ruether. Ruether argues that feminism and ecology share a common vision, even though they use different languages. In her work, \"Gaia and God: An Ecofeminist Theology of Earth Healing\" Ruether provides three recommendations on ways to move forward with repairing and \"healing\" the ecological crisis. The first recommendation is that \"the ecological crisis needs to be seen not just as a crisis in the health of nonhuman ecosystems, polluted water, contaminated skies, threatened climate change, deforestation, extinction of species, important as all these realities are. Rather one needs to see the interconnections between the impoverishment of the earth and the impoverishment of human groups, even as others are enriching themselves to excess.\" The second recommendation is that \"a healed ecosystem – humans, animals, land, air, and water together – needs to be understood as requiring a new way of life, not just a few adjustments here and there.\" The third and final recommendation is that the need for a new vision is necessary: \"one needs to nurture the emergence of a new planetary vision and communal ethic that can knit together people across religions and cultures. There is rightly much dismay at the role that religions are playing in right-wing politics and even internecine violence today. But we need also to recognize the emergence of new configurations of inter-religious relations.\"\n\nAccording to Ivone Gebara, in Latin America, particularly in Christian Churches in Brazil, it is difficult to be a feminist, but more difficult to be an ecofeminist. Gebara explains ecology as one of the \"deepest concerns of feminism and ecology as having a deep resonance or a political and anthropolocial consequence from a feminist perspective.\" Gebara believes that it is the task of different groups of Latin American women to \"provide a new order of meaning including marginalized people.\" This task is both challenging and political. Gebara says: \"We can choose the life of the planet and the respect of all living beings or we choose to die by our own bad decisions.\"\n\nPaganism is a nature-based religion that exists in a multitude of forms. There is no official doctrine or sacred text that structures its practice. Due to its lack of structure, many Pagans believe that it should be used as a tool to combat the current ecological crisis because it is flexible and can adapt to the environment's needs. Ecospirituality advocates contend that an ecology-based religion that focuses on the nurturing and healing of the earth is necessary in modernity. As paganism is already based in nature worship, many believe it would be a useful starting point for ecospirituality. In fact, neopagan revivals have seen the emergence of pagan communities that are more earth-focused. They may build their rituals around advocacy for a sustainable lifestyle and emphasize complete interconnectedness with the earth. Paganism understands divine figures to exist not as transcendent beings, but as immanent beings in the present realm, meaning that their divine figures exist within each of us, and within nature. Many pagans believe in \"interconnectedness\" among all living beings, which allows them to foster moments of self-reflection before acting. These pagan ideals coincide with ecospirituality because pagans understand the environment to be part of the divine realm and part of their inner self. Therefore, in their view, harming the environment directly affects their wellbeing. Pagans have already recognized the importance of incorporating environmental ideologies with their own religious beliefs. The Dragon Environmental Network is a pagan community based in the UK. They are committed to practicing \"eco-magic\" with the intention of recognizing the earth as sacred and divine. Their four goals are as follows:\nPaganism combines religion with environmental activism. Pagans organize protests, campaigns, and petitions with the environment in mind while staying true to their religious beliefs. Bron Taylor, argues that their core Pagan beliefs greatly improves their environmental activism. Additionally, the Pagan community has recently released a statement on the ecological crisis. It explains that Pagans lead lives that foster “harmony with the rhythms of our great Earth\" and that they view the Earth as their equal in stating “we are neither above nor separate from the rest of nature”. It states that we are part of a web of life, and are fully interconnected with the biosphere. This connection to all living beings is seen as spiritual and sacred. And in turn it provides a framework that Pagans can use to combine their religious beliefs with environmental activism. It calls for a return to ancient understandings of the earth by listening to ancient wisdom. It asks Pagans to practice their religion in all aspects of their lives in order to give the Earth room to heal. The statement concludes by stating “building a truly sustainable culture means transforming the systems of domination and exploitation that threaten our future into systems of symbiotic partnership that support our ecosystems”.\n\nMost Christian theology has centered on the doctrine of creation. According to Elizabeth Johnson, in recent years, this has led to growing ecological awareness among Christians. The logic of this stance is rooted in the theological idea that since God created the world freely, it has an intrinsic value and is worthy of our respect and care. In 1990, Pope John Paul II wrote a letter on ecological issues. He concluded the letter with a discussion of Christian belief and how it should lead to ethical care of the earth. He ended the letter with the principle \"respect for life and the dignity of human person must extend also to the rest of creation.\"\n\nThe doctrines of Christ that Christians follow also have the potential for ecological spirituality for they support interpretations that are consistent with ecospirituality. According to Elizabeth Johnson, Jesus' view of the Kingdom of God included earthly wellbeing. According to Thomas Berry, Christians recognize a need for an Earth Ethic. The Ecumenical Patriarch Bartholomew, leader of the Greek Orthodox Church, has organized major religion and science symposia on water issues across Europe, the Amazon River and Greenland. He has issued statements – including a joint statement with John Paul II in 2002 – calling destruction of the environment \"ecological sin.\" Bishop Malone, president of the National Conference of Catholic Bishops has said: \"The Church stands in need of a new symbolic and affective system through which to proclaim the Gospel to the modern world.\" In the ecotheology of the late Thomas Berry, he argues that Christians often fail to realize that both their social and religious wellbeing depend on the wellbeing of Earth. Earth provides sustenance for physical, imaginative and emotions, and religious wellbeing. In Thomas Berry's view, the Christian future will depend on the ability of Christians to assume their responsibility for Earth's fate. An example of such responsibility-taking can be seen in the founding of an association called \"Sisters of Earth,\" which is made up of nuns and laywomen. This network of women from diverse religious communities is significant, both for the movement of general concern for the natural world and for the religious life in Christian contexts.\n\nMany teachings in Hinduism are intertwined with the ethics of ecospirituality in their stress on environmental wellbeing. The Hindu text called the \"Taittariya Upanishad\" refers to creation as offspring of the Supreme Power, \"paramatman\". Thus, the environment is related to something that is divine and therefore deserves respect. Since the late 1980s when the negative effects of mass industrialization were becoming popularized, India instituted administrative policies to deal with environmental conservation. These policies were rooted in the ways that the Hindu religion is tied to the land.\n\nIn the Hindu text \"Vajur Veda\" (32.10), God is described as being present in all living things, further reinforcing the need to show respect for creation. Passages such as this lead some Hindus to become vegetarian and to affirm a broader type of ecospiritual connection to the Earth. \"Vishnu Purana\" 3.8.15. states that, \"God, Kesava, is pleased with a person who does not harm or destroy other non-speaking creatures or animals.\" This notion is tied in with the Hindu concept of karma. Karma means that the pain caused to other living things will come back to you through the process of reincarnation.\n\nEcospirituality can also be seen in the \"Prithivi Sukta\" which is a \"Hymn to Mother Earth.\" In this text, the Earth is humanized into a spiritual being to which humans have familial ties. Through ecospirituality, the notion of praising and viewing the Earth in this way brings about its strong connections to Hinduism.\n\nContemporary Jaina fatih is “inherently ecofriendly.” In terms of the ecological crisis, Jains are “quite self-conscious of the ecological implications of their core teachings.”\n\nJain teachings center on five vows that lead to reverse the flow of or release karma. One of these vows is ahimsa or non-violence. Ahimsa “is said to contain the key to advancement along the spiritual path (sreni). This requires abstaining from harm to any being that possesses more than one sense” The principles of the Jaina tradition are rooted in environmental practices. The Jaina connection to nature is conducive to ecospirituality.\n\nSome scholars argue that while looking at the scriptural sources of Islam, you can see it is an ecologically orientated religion. Looking at textual sources of Islam, the shari'a preach a number of environmentally focused guidelines to push environmentalism, in particular, \"maintenance of preserves, distribution of water, and the development of virgin lands.\" Much of Muslim environmentalism is a result of the Qur'anic stress of stewardship which is explained through the Arabic concept \"khilafa\". A quote translated from the \"hadith\" states, \"verily, this world is sweet and appealing, and Allah placed you as vice-regents thereinl he will see what you do.\" Within the Islamic faith, there is a set importance to following the messages set forth in scripture, therefore the environmentalism spoken through them has led to a spirituality around the environment. This spirituality can also be seen with Qur'anic concept of \"tawhid\", which translates to unity. Many Muslim environmentalists see this meaning spiritually as \"all-inclusive\" when in relation to the Earth.\n\nA majority of Muslim writers draw attention to the environmental crisis as a direct result of social injustice. Many argue that the problem is not that, \"humans as a species are destroying the balance of nation, but rather that \"some\" humans are taking more than their share.\" Muslim environmentalists such as Fazlun Khalid, Yasin Dutton, Omar Vadillo, and Hashim Dockrat have drawn a correlation between the capitalist nature of the global economy to being un-Islamic and essentiality leading to ecological crisis.\n\nThe issues of environmental degradation are especially important to Muslims as majority of Muslims live in developing countries where they see the effects of the ecological crisis on a daily basis. This has led to conferences discussing Islam and the environment to take place in Iran and Saudi Arabia as well as the introduction of environmental nongovernmental organizations.\n\nBuddhism has been around for hundreds of years, however with the modern knowledge on topics such as global warming, many Buddhist scholars have looked back at how Buddhist teaching would respond to the environmental crisis and created what is called Green Buddhism. One of the key players in this introduction was Gary Snyder who brought to light where Buddhist practice and ecological thinking intertwine. Green Buddhism made waves in the 1980s when they publicly address the ecological crisis to create awareness and in 1989 when the Dalai Lama won a Noble Peace Prize for the proposed introduction of Tibet as an ecological reserve. Buddhism has been open to working with other world religions to combat the environment crisis seen at an international conference for Buddhist-Christian studies that addressed the environment. Although Green Buddhism has not commented much on technical issues such as air and water pollution, they use their spirituality to focus heavily on \"rich resources for immediate application in food ethics, animal rights, and consumerism.\"\n\n", "id": "4457559", "title": "Ecospirituality"}
{"url": "https://en.wikipedia.org/wiki?curid=33257107", "text": "Ecosemiotics\n\nEcosemiotics is a branch of semiotics in its intersection with human ecology that studies the sign relations established by culture, which deal with other living beings, communities, and landscapes.\n\nThe field was initiated by Winfried Nöth and Kalevi Kull.\n\nThe central focus of ecosemiotics concerns the role of concepts (sign-based models people have) in designing and changing the environment. Ecosemiotics includes (or largely overlaps) with semiotics of landscape.\n\n\n\n", "id": "33257107", "title": "Ecosemiotics"}
{"url": "https://en.wikipedia.org/wiki?curid=33910664", "text": "Lithoprotection\n\nLithoprotection is a term introduced in 2001 by Armenian biologist Tigran Tadevosyan as the name to the phenomenon where rock cover of a habitat diversifies local wildlife.\n\nThe word \"lithoprotection\" originates from the Greek root \"lithos\", meaning \"stone\", and the Latin root \"protectus\", meaning \"to cover\".\n\nOriginally an existence of a lithoprotection had been proposed based on observations of increased plant and animal diversity in habitats with rock cover compared to habitats without rock cover in the same conditions of an arid climate and steep slopes (Safarian, 1960; Tadevosyan, 2001). To explain this phenomenon, the author compared the life forms of plants, and the body sizes and escape strategies of animals inhabiting habitats with and without rock cover (Tadevosyan, 2001 - 2002). His conclusion was that many groups of vascular plants, including trees, shrubs, succulents, ferns, and moss species, linked to rocky substrates because they require higher than an area's average soil humidity, sometimes being shaded by a solid piece of rock, as well as strong attachment to the substrate. On the other hand, many relatively large animals (including larger lizards, snakes, some mammals and many bird species) need habitats with a dense network of shelters created by crevices and spaces between rocks in order survive overheating and predation. Thus, due to its ability to prevent the evaporation of humidity from the soil, to catch the seeds of plants, to hold trees and shrubs securely to the ground and to serve as a network of efficient shelters for many animals and shade-loving plants, rock cover lithoprotection is being considered as a protective element of a habitat biodiversity.\n\nManaging lithoprotection may be used as a measure of managing wildlife. Removal of a lithoprotection by cleaning an area of stone and rocks is a common practice in an urban landscape development. Because a lack of lithoprotection is equal to decreased biodiversity, this practice can be considered one of the core mechanisms of biodiversity loss in urban landscapes. Adding lithoprotection in contrary typically attracts wildlife and helps diversify and maintain biodiversity of a landscape (Tadevosyan, 2001). Bright examples of artificial use of lithoprotection are attractive rockaries, Japanese rock garden and other elements of a garden design.\n", "id": "33910664", "title": "Lithoprotection"}
{"url": "https://en.wikipedia.org/wiki?curid=19468941", "text": "Balance of nature\n\nThe balance of nature is a theory that proposes that ecological systems are usually in a stable equilibrium or homeostasis, which is to say that a small change in some particular parameter (the size of a particular population, for example) will be corrected by some negative feedback that will bring the parameter back to its original \"point of balance\" with the rest of the system. It may apply where populations depend on each other, for example in predator/prey systems, or relationships between herbivores and their food source. It is also sometimes applied to the relationship between the Earth's ecosystem, the composition of the atmosphere, and the world's weather.\n\nThe Gaia hypothesis is a balance of nature-based theory that suggests that the Earth and its ecology may act as co-ordinated systems in order to maintain the balance of nature.\n\nThe theory that nature is permanently in balance has been largely discredited by scientists working in ecology, as it has been found that chaotic changes in population levels are common, but nevertheless the idea continues to be popular in the general public. During the later half of the twentieth century the theory was superseded by catastrophe theory and chaos theory.\n\nThe concept that nature maintains its condition is of ancient provenance; Herodotus commented on the wonderful relationship between predator and prey species, which remained in a steady proportion to one another, with predators never excessively consuming their prey populations. The \"balance of nature\" concept once ruled ecological research, as well as once governing the management of natural resources. This led to a doctrine popular among some conservationists that nature was best left to its own devices, and that human intervention into it was by definition unacceptable. The validity of a \"balance of nature\" was already questioned in the early 1900s, but the general abandonment of the theory by scientists working in ecology only happened in the last quarter of that century when studies showed that it did not match what could be observed among plant and animal populations.\n\nPredator-prey populations tend to show chaotic behavior within limits, where the sizes of populations change in a way that may appear random, but is in fact obeying deterministic laws based only on the relationship between a population and its food source illustrated by the Lotka–Volterra equation. An experimental example of this was shown in an eight-year study on small Baltic Sea creatures such as plankton, which were isolated from the rest of the ocean. Each member of the food web was shown to take turns multiplying and declining, even though the scientists kept the outside conditions constant. An article in the journal \"Nature\" stated; \"Advanced mathematical techniques proved the indisputable presence of chaos in this food web ... short-term prediction is possible, but long-term prediction is not.\"\n\nAlthough some conservationist organizations argue that human activity is incompatible with a balanced ecosystem, there are numerous examples in history showing that several modern day habitats originate from human activity: some of Latin America's rain forests owe their existence to humans planting and transplanting them, while the abundance of grazing animals in the Serengeti plain of Africa is thought by some ecologists to be partly due to human-set fires that created savanna habitats.\n\nPossibly one of the best examples of an ecosystem fundamentally modified by human activity can be observed as a consequence of the Australian Aboriginal practice of \"Fire-stick farming\". The legacy of this practice over long periods has resulted in forests being converted to grasslands capable of sustaining larger populations of faunal prey, particularly in the northern and western regions of the continent. So thorough has been the effect of these deliberate regular burnings that many plant and tree species from affected regions have now completely adapted to the annual fire regime in that they require the passage of a fire before their seeds will even germinate.\n\nDespite being discredited among ecologists, the theory is widely held to be true by the general public, with one authority calling it an \"enduring myth\". At least in Midwestern America, the \"balance of nature\" idea was shown to be widely held by both science majors and the general student population. In a study at the University of Patras, educational sciences students were asked to reason about the future of ecosystems which suffered human-driven disturbances. Subjects agreed that it was very likely for the ecosystems to fully recover their initial state, referring to either a 'recovery process' which restores the initial 'balance', or specific 'recovery mechanisms' as an ecosystem's inherent characteristic. In a 2017 study, Ampatzidis and Ergazaki discuss the learning objectives and design criteria that a learning environment for non-biology major students should meet to support them challenge the \"balance of nature\" idea.\n\n", "id": "19468941", "title": "Balance of nature"}
{"url": "https://en.wikipedia.org/wiki?curid=2272402", "text": "Natural region\n\nA natural region is a basic geographic unit. Usually it is a region which is distinguished by its common natural features of geography, geology, and climate. \n\nFrom the ecological point of view, the naturally occurring flora and fauna of the region are likely to be influenced by its geographical and geological factors, such as soil and water availability, in a significant manner. Thus most natural regions are homogeneous ecosystems. Human impact can be an important factor in the shaping and destiny of a particular natural region.\n\nThe concept \"natural region\" may refer to a small, well defined area, or to a large basic geographical unit, like the vast boreal forest region. The term may also be used generically, like in alpine tundra, or specifically to refer to a particular place.\n\nThe term is particularly useful where there is no corresponding or coterminous official region. The Fens of eastern England, the Thai highlands, and the Pays de Bray in Normandy, are examples of this. Others might include regions with particular geological characteristics, like badlands, such as the Bardenas Reales, an upland massif of acidic rock, or The Burren, in Ireland.\n\n\n", "id": "2272402", "title": "Natural region"}
{"url": "https://en.wikipedia.org/wiki?curid=6867899", "text": "Phytotelma\n\nPhytotelma (plural phytotelmata) is a small water-filled cavity in a terrestrial plant. The water accumulated within these plants may serve as the habitat for associated fauna and flora. Often the faunae associated with phytotelmata are unique. Some species also are of great practical significance; for example, immature stages of some mosquitoes, such as some \"Anopheles\" and \"Aedes\" species that are important disease vectors, develop in phytotelmata.\n\nA rich literature in German summarised by Thienemann (1954) developed many aspects of phytotelm biology. Reviews of the subject by Kitching (1971) and Maguire (1971) introduced the concept of phytotelmata to English-speaking readers. A multi-authored book edited by Frank and Lounibos (1983) dealt in 11 chapters with classification of phytotelmata, and with phytotelmata provided by bamboo internodes, banana leaf axils, bromeliad leaf axils, \"Nepenthes\" pitchers, \"Sarracenia\" pitchers, tree holes, and \"Heliconia\" flower bracts.\n\nA classification of phytotelmata by Kitching (2000) recognizes five principal types: bromeliad tanks, certain carnivorous plants such as pitcher plants, water-filled tree hollows, bamboo internodes, and axil water (collected at the base of leaves, petals or bracts); it concentrated on food webs. A review by Greeney (2001) identified seven forms: tree holes, leaf axils, flowers, modified leaves, fallen vegetative parts (e.g. leaves or bracts), fallen fruit husks, and stem rots.\n\nThe word \"phytotelma\" derives from the ancient Greek roots \"phyto-\", meaning 'plant', and \"telma\", meaning 'pond'. Thus, the correct singular is \"phytotelma\".\n\nThe term was coined by L. Varga in 1928.\n\nThe correct pronunciation is \"phytotēlma\" and \"phytotēlmata\" because of the Greek origin (the stressed vowels are here written as \"ē\"). \n\n", "id": "6867899", "title": "Phytotelma"}
{"url": "https://en.wikipedia.org/wiki?curid=34983797", "text": "Taylor's law\n\nTaylor's law (also known as Taylor's power law) is an empirical law in ecology that relates the variance of the number of individuals of a species per unit area of habitat to the corresponding mean by a power law relationship. It is named after the ecologist who first proposed it in 1961, Lionel Roy Taylor (1924–2007). Taylor's original name for this relationship was the law of the mean.\n\nThis law was originally defined for ecological systems, specifically to assess the spatial clustering of organisms. For a population count \"Y\" with mean \"µ\" and variance var(\"Y\"), Taylor’s law is written,\n\nwhere \"a\" and \"b\" are both positive constants. Taylor proposed this relationship in 1961, suggesting that the exponent \"b\" be considered a species specific index of aggregation. This power law has subsequently been confirmed for many hundreds of species.\n\nTaylor’s law has also been applied to assess the time dependent changes of population distributions. Related variance to mean power laws have also been demonstrated in several non-ecological systems: \n\nThe first use of a double log-log plot was by Reynolds in 1879 on thermal aerodynamics. Pareto used a similar plot to study the proportion of a population and their income.\nThe term \"variance\" was coined by Fisher in 1918.\n\nFisher in 1921 proposed the equation\n\nformula_2\n\nNeyman studied the relationship between the sample mean and variance in 1926. Barlett proposed a relationship between the sample mean and variance in 1936\n\nformula_2\n\nSmith in 1938 while studying crop yields proposed a relationship similar to Taylor's. This relationship was\n\nwhere \"V\" is the variance of yield for plots of \"x\" units, \"V\" is the variance of yield per unit area and \"x\" is the size of plots. The slope (\"b\") is the index of heterogeneity. The value of \"b\" in this relationship lies between 0 and 1. Where the yield are highly correlated \"b\" tends to 0; when they are uncorrelated \"b\" tends to 1.\n\nBliss in 1941, Fracker and Brischle in 1941 and Hayman & Lowe in 1961 also described what is now known as Taylor's law, but in the context of data from single species.\n\nL.R. Taylor (1924–2007) was an English entomologist who worked on the Rothamsted Insect Survey for pest control. His 1961 paper used data from 24 papers published between 1936 and 1960. These papers considered a variety of biological settings: virus lesions, macro-zooplankton, worms and symphylids in soil, insects in soil, on plants and in the air, mites on leaves, ticks on sheep and fish in the sea. In these papers the \"b\" value lay between 1 and 3. Taylor proposed the power law as a general feature of the spatial distribution of these species. He also proposed a mechanistic hypothesis to explain this law. Among the papers cited were those of Bliss and Yates and Finney.\n\nInitial attempts to explain the spatial distribution of animals had been based on approaches like Bartlett’s stochastic population models and the negative binomial distribution that could result from birth-death processes. Taylor’s novel explanation was based the assumption of a balanced migratory and congregatory behavior of animals. His hypothesis was initially qualitative, but as it evolved it became semi-quantitative and was supported by simulations. In proposing that animal behavior was the principal mechanism behind the clustering of organisms, Taylor though appeared to have ignored his own report of clustering seen with tobacco necrosis virus plaques.\n\nFollowing Taylor’s initial publications several alternative hypotheses for the power law were advanced. Hanski proposed a random walk model, modulated by the presumed multiplicative effect of reproduction. Hanski’s model predicted that the power law exponent would be constrained to range closely about the value of 2, which seemed inconsistent with many reported values.\n\nAnderson \"et al\" formulated a simple stochastic birth, death, immigration and emigration model that yielded a quadratic variance function. As a response to this model Taylor argued that such a Markov process would predict that the power law exponent would vary considerably between replicate observations, and that such variability had not been observed.\n\nAbout this time concerns were, however, raised regarding the statistical variability with measurements of the power law exponent, and the possibility that observations of a power law might reflect more mathematical artefact than a mechanistic process. Taylor \"et al\" responded with an additional publication of extensive observations which he claimed refuted Downing’s concerns.\n\nIn addition, Thórarinsson published a detailed critique of the animal behavioral model, noting that Taylor had modified his model several times in response to concerns raised, and that some of these modifications were inconsistent with earlier versions. Thórarinsson also claimed that Taylor confounded animal numbers with density and that Taylor had incorrectly interpreted simulations that had been constructed to demonstrate his models as validation.\n\nKemp reviewed a number of discrete stochastic models based on the negative binomial, Neyman type A, and Polya-Aeppli distributions that with suitable adjustment of parameters could produce a variance to mean power law. Kemp, however, did not explain the parameterizations of his models in mechanistic terms. Other relatively abstract models for Taylor’s law followed.\n\nA number of additional statistical concerns were raised regarding Taylor’s law, based on the difficulty with real data in distinguishing between Taylor’s law and other variance to mean functions, as well the inaccuracy of standard regression methods.\n\nReports also began to accumulate where Taylor’s law had been applied to time series data. Perry showed how simulations based on chaos theory could yield Taylor’s law, and Kilpatrick & Ives provided simulations which showed how interactions between different species might lead to Taylor's law.\n\nOther reports appeared where Taylor’s law had been applied to the spatial distribution of plants and bacterial populations As with the observations of Tobacco necrosis virus mentioned earlier, these observations were not consistent with Taylor’s animal behavioral model.\n\nEarlier it was mentioned that variance to mean power function had been applied to non-ecological systems, under the rubric of Taylor’s law. To provide a more general explanation for the range of manifestations of the power law a hypothesis was proposed based on the Tweedie distributions, a family of probabilistic models that express an inherent power function relationship between the variance and the mean. Details regarding this hypothesis will be provided in the next section.\n\nA further alternative explanation for Taylor's law was proposed by Cohen \"et al\", derived from the Lewontin Cohen growth model. This model was successfully used to describe the spatial and temporal variability of forest populations.\n\nAnother paper by Cohen and Xu that random sampling in blocks where the underling distribution is skewed with the first four moments finite gives rise to Taylor's law. Approximate formulae for the parameters and their variances were also derived. These estimates were tested again data from the Black Rock Forest and found to be in reasonable agreement.\n\nFollowing Taylor’s initial publications several alternative hypotheses for the power law were advanced. Hanski proposed a random walk model, modulated by the presumed multiplicative effect of reproduction. Hanski’s model predicted that the power law exponent would be constrained to range closely about the value of 2, which seemed inconsistent with many reported values. Anderson \"et al\" formulated a simple stochastic birth, death, immigration and emigration model that yielded a quadratic variance function. The Lewontin Cohen growth model. is another proposed explanation. The possibility that observations of a power law might reflect more mathematical artefact than a mechanistic process was raised.\n\nA more general explanation for the range of manifestations of the power law a hypothesis is possible, based on the Tweedie distributions, a family of probabilistic models that express an inherent power function relationship between the variance and the mean. Details regarding this hypothesis will be provided in the next section.\n\nIn the physics literature Taylor’s law has been referred to as \"fluctuation scaling\". Eisler \"et al\", in a further attempt to find a general explanation for fluctuation scaling, proposed a process they called \"impact inhomogeneity\" in which frequent events are associated with larger impacts. In appendix B of the Eisler article, however, the authors noted that the equations for impact inhomogeneity yielded the same mathematical relationships as found with the Tweedie distributions.\n\nAnother group of physicists, Fronczak and Fronczak, derived Taylor’s power law for fluctuation scaling from principles of equilibrium and non-equilibrium statistical physics. Their derivation was based on assumptions of physical quantities like free energy and an external field that caused the clustering of biological organisms. Direct experimental demonstration of these postulated physical quantities in relationship to animal or plant aggregation has yet to be achieved, though. Shortly thereafter, an analysis of Fronczak and Fronczak’s model was presented that showed their equations directly lead to the Tweedie distributions, a finding that suggested that Fronczak and Fronczak had possibly provided a maximum entropy derivation of these distributions.\n\nTaylor's law has been shown to hold for prime numbers not exceeding a given real number. This result has been shown to hold for the first 11 million primes. If the Hardy-Littlewood twin primes conjecture is true then this law also holds for twin primes.\n\nThe law itself is named after the ecologist Lionel Roy Taylor (1924–2007). The name 'Taylor's law' was coined by Southwood in 1966. Taylor's original name for this relationship was the law of the mean\n\nAbout the time that Taylor was substantiating his ecological observations, MCK Tweedie, a British statistician and medical physicist, was investigating a family of probabilistic models that are now known as the Tweedie distributions. As mentioned above, these distributions are all characterized by a variance to mean power law mathematically identical to Taylor’s law.\n\nThe Tweedie distribution most applicable to ecological observations is the compound Poisson-gamma distribution, which represents the sum of \"N\" independent and identically distributed random variables with a gamma distribution where \"N\" is a random variable distributed in accordance with a Poisson distribution. In the additive form its cumulant generating function (CGF) is:\n\nwhere \"κ\"(\"θ\") is the cumulant function,\n\nthe Tweedie exponent\n\n\"s\" is the generating function variable, and \"θ\" and \"λ\" are the canonical and index parameters, respectively.\n\nThese last two parameters are analogous to the scale and shape parameters used in probability theory. The cumulants of this distribution can be determined by successive differentiations of the CGF and then substituting \"s=0\" into the resultant equations. The first and second cumulants are the mean and variance, respectively, and thus the compound Poisson-gamma CGF yields Taylor’s law with the proportionality constant\n\nThe compound Poisson-gamma cumulative distribution function has been verified for limited ecological data through the comparison of the theoretical distribution function with the empirical distribution function. A number of other systems, demonstrating variance to mean power laws related to Taylor’s law, have been similarly tested for the compound Poisson-gamma distribution.\n\nThe main justification for the Tweedie hypothesis rests with the mathematical convergence properties of the Tweedie distributions. The Tweedie convergence theorem requires the Tweedie distributions to act as foci of convergence for a wide range of statistical processes. As a consequence of this convergence theorem, processes based on the sum of multiple independent small jumps will tend to express Taylor’s law and obey a Tweedie distribution. A limit theorem for independent and identically distributed variables, as with the Tweedie convergence theorem, might then be considered as being fundamental relative to the \"ad hoc\" population models, or models proposed on the basis of simulation or approximation.\n\nThis hypothesis remains controversial; more conventional population dynamic approaches seem preferred amongst ecologists, despite the fact that the Tweedie compound Poisson distribution can be directly applied to population dynamic mechanisms.\n\nOne difficulty with the Tweedie hypothesis is that the value of \"b\" does not range between 0 and 1. Values of \"b\" < 1 are rare but have been reported.\n\nIn symbols\n\nwhere \"s\" is the variance of the density of the \"i\"th sample, \"m\" is the mean density of the \"i\"th sample and \"a\" and \"b\" are constants.\n\nIn logarithmic form\n\nTaylor's law is scale invariant. If the unit of measurement is changed by a constant factor \"c\", the exponent (\"b\") remains unchanged.\n\nTo see this let \"y\" = \"cx\". Then\n\nformula_11\n\nformula_12\n\nformula_13\n\nformula_14\n\nTaylor's law expressed in the original variable (\"x\") is\n\nformula_15\n\nand in the rescaled variable (\"y\") it is\n\nformula_16\n\nIt has been shown that Taylor's law is the only relationship between the mean and variance that is scale invariant.\n\nA refinement in the estimation of the slope \"b\" has been proposed by Rayner.\n\nwhere \"r\" is the Pearson moment correlation coefficient between log(\"s\") and log \"m\", \"f\" is the ratio of sample variances in log(\"s\") and log \"m\" and \"φ\" is the ratio of the errors in log(\"s\") and log \"m\".\n\nOrdinary least squares regression assumes that \"φ\" = ∞. This tends to underestimate the value of \"b\" because the estimates of both log(\"s\") and log \"m\" are subject to error.\n\nAn extension of Taylor's law has been proposed by Ferris \"et al\" when multiple samples are taken\n\nwhere \"s\" and \"m\" are the variance and mean respectively, \"b\", \"c\" and \"d\" are constants and \"n\" is the number of samples taken. To date, this proposed extension has not been verified to be as applicable as the original version of Taylor's law.\n\nAn extension to this law for small samples has been proposed by Hanski. For small samples the Poisson variation (\"P\") - the variation that can be ascribed to sampling variation - may be significant. Let \"S\" be the total variance and let \"V\" be the biological (real) variance. Then\n\nAssuming the validity of Taylor's law, we have\n\nBecause in the Poisson distribution the mean equals the variance, we have\n\nThis gives us\n\nThis closely resembles Barlett's original suggestion.\n\nSlope values (\"b\") significantly > 1 indicate clumping of the organisms.\n\nIn Poisson-distributed data, \"b\" = 1. If the population follows a lognormal or gamma distribution, then \"b\" = 2.\n\nFor populations that are experiencing constant per capita environmental variability, the regression of log( variance ) versus log( mean abundance ) should have a line with \"b\" = 2.\n\nMost populations that have been studied have \"b\" < 2 (usually 1.5–1.6) but values of 2 have been reported. Occasionally cases with \"b\" > 2 have been reported. \"b\" values below 1 are uncommon but have also been reported ( \"b\" = 0.93 ).\n\nIt has been suggested that the exponent of the law (\"b\") is proportional to the skewness of the underlying distribution. This proposal has criticised: additional work seems to be indicated.\n\nThe origin of the slope (\"b\") in this regression remains unclear. Two hypotheses have been proposed to explain it. One suggests that \"b\" arises from the species behavior and is a constant for that species. The alternative suggests that it is dependent on the sampled population. Despite the considerable number of studies carried out on this law (over 1000), this question remains open.\n\nIt is known that both \"a\" and \"b\" are subject to change due to age-specific dispersal, mortality and sample unit size.\n\nThis law may be a poor fit if the values are small. For this reason an extension to Taylor's law has been proposed by Hanski which improves the fit of Taylor's law at low densities.\n\nA form of Taylor's law applicable to binary data in clusters (e.q., quadrats) has been proposed. In a binomial distribution, the theoretical variance is\n\nwhere \"(var)\" is the binomial variance, \"n\" is the sample size per cluster, and \"p\" is the proportion of individuals with a trait (such as disease), an estimate of the probability of an individual having that trait.\n\nOne difficulty with binary data is that the mean and variance, in general, have a particular relationship: as the mean proportion of individuals infected increases above 0.5, the variance deceases.\n\nIt is now known that the observed variance \"(var)\" changes as a power function of \"(var)\".\n\nHughes and Madden noted that if the distribution is Poisson, the mean and variance are equal. As this is clearly not the case in many observed proportion samples, they instead assumed a binomial distribution. They replaced the mean in Taylor's law with the binomial variance and then compared this theoretical variance with the observed variance. For binomial data, they showed that \"var = var\" with overdispersion, \"var\" > \"var\".\n\nIn symbols, Hughes and Madden's modification to Tyalor's law was\n\nIn logarithmic form this relationship is\n\nThis latter version is known as the binary power law.\n\nA key step in the derivation of the binary power law by Hughes and Madden was the observation made by Patil and Stiteler that the variance-to-mean ratio used for assessing over-dispersion of unbounded counts in a single sample is actually the ratio of two variances: the observed variance and the theoretical variance for a random distribution. For unbounded counts, the random distribution is the Poisson. Thus, the Taylor power law for a collection of samples can be considered as a relationship between the observed variance and the Poisson variance.\n\nMore broadly, Madden and Hughes considered the power law as the relationship between two variances, the observed variance and the theoretical variance for a random distribution. With binary data, the random distribution is the binomial (not the Poisson). Thus the Taylor power law and the binary power law are two special cases of a general power-law relationships for heterogeneity.\n\nWhen both \"a\" and \"b\" are equal to 1, then a small-scale random spatial pattern is suggested and is best described by the binomial distribution. When \"b\" = 1 and \"a\" > 1, there is over-dispersion (small scale aggregation). When \"b\" is > 1, the degree of aggregation varies with \"p\". Turechek \"et al\" have showed that the binary power law describes numerous data sets in plant pathology. In general, \"b\" is greater than 1 and less than 2.\n\nThe fit of this law has been tested by simulations. These results suggest that rather than a single regression line for the data set, a segmental regression may be a better model for genuinely random distributions. However, this segmentation only occurs for very short-range dispersal distances and large quadrat sizes. The break in the line occurs only at \"p\" very close to 0.\n\nAn extension to this law has been proposed. The original form of this law is symmetrical but it can be extended to an asymmetrical form. Using simulations the symmetrical form fits the data when there is positive correlation of disease status of neighbors. Where there is a negative correlation between the likelihood of neighbours being infected, the asymmetrical version is a better fit to the data.\n\nBecause of the ubiquitous occurrence of Taylor's law in biology it has found a variety of uses some of which are listed here.\n\nIt has been recommended based on simulation studies in applications testing the validity of Taylor's law to a data sample that:\n\n(1) the total number of organisms studied be > 15\n(2) the minimum number of groups of organisms studied be > 5 \n(3) the density of the organisms should vary by at least 2 orders of magnitude within the sample\n\nIt is common assumed (at least initially) that a population is randomly distributed in the environment. If a population is randomly distributed then the mean ( \"m\" ) and variance ( \"s\" ) of the population are equal and the proportion of samples that contain at least one individual ( \"p\" ) is\n\nWhen a species with a clumped pattern is compared with one that is randomly distributed with equal overall densities, p will be less for the species having the clumped distribution pattern. Conversely when comparing a uniformly and a randomly distributed species but at equal overall densities, \"p\" will be greater for the randomly distributed population. This can be graphically tested by plotting \"p\" against \"m\".\n\nWilson and Room developed a binomial model that incorporates Taylor's law. The basic relationship is\n\nwhere the log is taken to the base \"e\".\n\nIncorporating Taylor's law this relationship becomes\n\nThe common dispersion parameter (\"k\") of the negative binomial distribution is\n\nwhere \"m\" is the sample mean and \"s\" is the variance. If 1 / \"k\" is > 0 the population is considered to be aggregated; 1 / \"k\" = 0 ( \"s\" = \"m\" ) the population is considered to be randomly (Poisson) distributed and if 1 / \"k\" is < 0 the population is considered to be uniformly distributed. No comment on the distribution can be made if \"k\" = 0.\n\nWilson and Room assuming that Taylor's law applied to the population gave an alternative estimator for \"k\":\n\nwhere \"a\" and \"b\" are the constants from Taylor's law.\n\nJones using the estimate for \"k\" above along with the relationship Wilson and Room developed for the probability of finding a sample having at least one individual\n\nderived an estimator for the probability of a sample containing \"x\" individuals per sampling unit. Jones's formula is\n\nwhere \"P\"( \"x\" ) is the probability of finding \"x\" individuals per sampling unit, \"k\" is estimated from the Wilon and Room equation and \"m\" is the sample mean. The probability of finding zero individuals \"P\"( 0 ) is estimated with the negative binomial distribution\n\nJones also gives confidence intervals for these probabilities.\n\nwhere \"CI\" is the confidence interval, \"t\" is the critical value taken from the t distribution and \"N\" is the total sample size.\n\nKatz proposed a family of distributions (the Katz family) with 2 parameters ( \"w\", \"w\" ). This family of distributions includes the Bernoulli, Geometric, Pascal and Poisson distributions as special cases. The mean and variance of a Katz distribution are\n\nwhere \"m\" is the mean and \"s\" is the variance of the sample. The parameters can be estimated by the method of moments from which we have\n\nFor a Poisson distribution \"w\" = 0 and \"w\" = \"λ\" the parameter of the Possion distribution. This family of distributions is also sometimes known as the Panjer family of distributions.\n\nThe Katz family is related to the Sundt-Jewel family of distributions:\n\nformula_39\n\nThe only members of the Sundt-Jewel family are the Poisson, binomial, negative binomial (Pascal), extended truncated negative binomial and logarithmic series distributions.\n\nIf the population obeys a Katz distribution then the coefficients of Taylor's law are\n\nKatz also introduced a statistical test\n\nwhere \"J\" is the test statistic, \"s\" is the variance of the sample, \"m\" is the mean of the sample and \"n\" is the sample size. \"J\" is asymptotically normally distributed with a zero mean and unit variance. If the sample is Poisson distributed \"J\" = 0; values of \"J\" < 0 and > 0 indicate under and over dispersion respectively. Overdispersion is often caused by latent heterogeneity - the presence of multiple sub populations within the population the sample is drawn from.\n\nThis statistic is related to the Neyman-Scott statistic\n\nwhich is known to be asymptotically normal and the conditional chi-squared statistic (Poisson dispersion test)\n\nwhich is known to have an asymptotic chi squared distribution with \"n\" − 1 degrees of freedom when the population is Poisson distributed.\n\nIf the population obeys Taylor's law then\n\nIf Taylor's law is assumed to apply it is possible to determine the mean time to local extinction. This model assumes a simple random walk in time and the absence of density dependent population regulation.\n\nLet formula_46 where \"N\" and \"N\" are the population sizes at time \"t\" + 1 and \"t\" respectively and \"r\" is parameter equal to the annual increase (decrease in population). Then\n\nwhere \"var\"( \"r\" ) is the variance of \"r\".\n\nLet \"K\" be a measure of the species abundance (organisms per unit area). Then\n\nwhere T is the mean time to local extinction.\n\nThe probability of extinction by time \"t\" is\n\nIf a population is lognormally distributed then the harmonic mean of the population size (\"H\") is related to the arithmetic mean (\"m\")\n\nGiven that \"H\" must be > 0 for the population to persist then rearranging we have\n\nis the minimum size of population for the species to persist.\n\nThe assumption of a lognormal distribution appears to apply to about half of a sample of 544 species. suggesting that it is at least a plausible assumption.\n\nThe degree of precision (\"D\") is defined to be \"s\" / \"m\" where \"s\" is the standard deviation and \"m\" is the mean. The degree of precision is known as the coefficient of variation in other contexts. In ecology research it is recommended that \"D\" be in the range 10-25%. The desired degree of precision is important in estimating the required sample size where an investigator wishes to test if Taylor's law applies to the data. The required sample size has been estimated for a number of simple distributions but where the population distribution is not known or cannot be assumed more complex formulae may needed to determine the required sample size.\n\nWhere the population is Poisson distributed the sample size (\"n\") needed is\n\nwhere \"t\" is critical level of the t distribution for the type 1 error with the degrees of freedom that the mean (\"m\") was calculated with.\n\nIf the population is distributed as a negative binomial distribution then the required sample size is\n\nwhere \"k\" is the parameter of the negative binomial distribution.\n\nA more general sample size estimator has also been proposed\n\nwhere a and b are derived from Taylor's law.\n\nAn alternative has been proposed by Southwood\n\nwhere \"n\" is the required sample size, \"a\" and \"b\" are the Taylor's law coefficients and \"D\" is the desired degree of precision.\n\nKarandinos proposed two similar estimators for \"n\". The first was modified by Ruesink to incorporate Taylor's law.\n\nwhere \"d\" is the ratio of half the desired confidence interval (\"CI\") to the mean. In symbols\n\nThe second estimator is used in binomial (presence-absence) sampling. The desired sample size (\"n\") is\n\nformula_58\n\nwhere the \"d\" is ratio of half the desired confidence interval to the proportion of sample units with individuals, \"p\" is proportion of samples containing individuals and \"q\" = 1 - \"p\". In symbols\n\nFor binary (presence/absence) sampling, Schulthess \"et al\" modified Karandinos' equation\n\nformula_60\n\nwhere \"N\" is the required sample size, \"p\" is the proportion of units containing the organisms of interest, \"t\" is the chosen level of significance and \"D\" is a parameter derived from Taylor's law.\n\nSequential analysis is a method of statistical analysis where the sample size is not fixed in advance. Instead samples are taken in accordance with a predefined stopping rule. Taylor's law has been used to derive a number of stopping rules.\n\nA formula for fixed precision in serial sampling to test Taylor's law was derived by Green in 1970.\n\nwhere \"T\" is the cumulative sample total, \"D\" is the level of precision, \"n\" is the sample size and \"a\" and \"b\" are obtained from Taylor's law.\n\nAs an aid to pest control Wilson \"et al\" developed a test that incorporated a threshold level where action should be taken. The required sample size is\n\nwhere \"a\" and \"b\" are the Taylor coefficients, || is the absolute value, \"m\" is the sample mean, \"T\" is the threshold level and \"t\" is the critical level of the t distribution. The authors also provided a similar test for binomial (presence-absence) sampling\n\nwhere \"p\" is the probability of finding a sample with pests present and \"q\" = 1 - \"p\".\n\nGreen derived another sampling formula for sequential sampling based on Taylor's law\n\nwhere \"D\" is the degree of precision, \"a\" and \"b\" are the Taylor's law coefficients, \"n\" is the sample size and \"T\" is the total number of individuals sampled.\n\nSerra \"et al\" have proposed a stopping rule based on Taylor's law.\n\nformula_65\n\nwhere \"a\" and \"b\" are the parameters from Taylor's law, \"D\" is the desired level of precision and \"T\" is the total sample size.\n\nSerra \"et al\" also proposed a second stopping rule based on Iwoa's regression\n\nformula_66\n\nwhere \"α\" and \"β\" are the parameters of the regression line, \"D\" is the desired level of precision and \"T\" is the total sample size.\n\nThe authors recommended that \"D\" be set at 0.1 for studies of population dynamics and \"D\" = 0.25 for pest control.\n\nIt is considered to be good practice to estimate at least one additional analysis of aggregation (other than Taylor's law) because the use of only a single index may be misleading. Although a number of other methods for detecting relationships between the variance and mean in biological samples have been proposed, to date none have achieved the popularity of Taylor's law. The most popular analysis used in conjunction with Taylor's law is probably Iowa's Patchiness regression test but all the methods listed here have been used in the literature.\n\nBarlett in 1936 and later Iawo independently in 1968 both proposed an alternative relationship between the variance and the mean. In symbols\n\nwhere \"s\" is the variance in the \"i\"th sample and \"m\" is the mean of the \"i\"th sample\n\nWhen the population follows a negative binomial distribution, \"a\" = 1 and \"b\" = \"k\" (the exponent of the negative binomial distribution).\n\nThis alternative formulation has not been found to be as good a fit as Taylor's law in most studies.\n\nNachman proposed a relationship between the mean density and the proportion of samples with zero counts:\n\nwhere \"p\" is the proportion of the sample with zero counts, \"m\" is the mean density, \"a\" is a scale parameter and \"b\" is a dispersion parameter. If \"a\" = \"b\" = 0 the distribution is random. This relationship is usually tested in its logarithmic form\n\nAllsop used this relationship along with Taylor's law to derive an expression for the proportion of infested units in a sample\n\nformula_70\n\nformula_71\n\nwhere\n\nformula_72\n\nwhere \"D\" is the degree of precision desired, \"z\" is the upper α/2 of the normal distribution, \"a\" and \"b\" are the Taylor's law coefficients, \"c\" and \"d\" are the Nachman coefficients, \"n\" is the sample size and \"N\" is the number of infested units.\n\nBinary sampling is not uncommonly used in ecology. In 1958 Kono and Sugino derived an equation that relates the proportion of samples without individuals to the mean density of the samples.\n\nwhere \"p\" is the proportion of the sample with no individuals, \"m\" is the mean sample density, \"a\" and \"b\" are constants. Like Taylor's law this equation has been found to fit a variety of populations including ones that obey Taylor's law. Unlike the negative binomial distribution this model is independent of the mean density.\n\nThe derivation of this equation is straightforward. Let the proportion of empty units be \"p\" and assume that these are distributed exponentially. Then\n\nformula_74\n\nTaking logs twice and re arranging, we obtain the equation above. This model is the same as that proposed by Nachman.\n\nThe advantage of this model is that it does not require counting the individuals but rather their presence or absence. Counting individuals may not be possible in many cases particularly where insects are the matter of study.\n\n\nThe equation was derived while examining the relationship between the proportion ( \"P\" ) of a series of rice hills infested and the mean severity of infestation ( \"m\" ). The model studied was\n\nwhere \"a\" and \"b\" are empirical constants. Based on this model the constants \"a\" and \"b\" were derived and a table prepared relating the values of \"P\" and \"m\"\n\n\nThe predicted estimates of \"m\" from this equation are subject to bias and it is recommended that the adjusted mean ( \"m\" ) be used instead\n\nwhere \"var\"() is the variance of the sample unit means ( \"m\" ) and \"m\" is the overall mean.\n\nAn alternative adjustment to the mean estimates is\n\nwhere \"MSE\" is the mean square error of the regression.\n\nThis model may also be used to estimate stop lines for enumerative (sequential) sampling. The variance of the estimated means is\n\nwhere\n\nwhere \"MSE\" is the mean square error of the regression, \"α\" and \"β\" are the constant and slope of the regression respectively, \"s\" is the variance of the slope of the regression, \"N\" is the number of points in the regression, \"n\" is the number of sample units and \"p\" is the mean value of p in the regression. The parameters \"a\" and \"b\" are estimated from Taylor's law:\n\nHughes and Madden have proposed testing a similar relationship applicable to binary observations in cluster, where each cluster contains from 0 to n individuals.\n\nwhere \"a\", \"b\" and \"c\" are constants, \"var\" is the observed variance, and p is the proportion of individuals with a trait (such as disease), an estimate of the probability of an individual with a trait. In logarithmic form, this relationship is\n\nIn most cases, it is assumed that \"b = c\", leading to a simple model\n\nThis relationship has been subjected to less extensive testing than Taylor's law. However, it has accurately described over 100 data sets, and there are no published examples reporting that it does not works.\n\nA variant of this equation was proposed by Shiyomi et al. () who suggested testing the regression\n\nwhere \"var\" is the variance, \"a\" and \"b\" are the constants of the regression, \"n\" here is the sample size (not sample per cluster) and \"p\" is the probability of a sample containing at least one individual.\n\nA negative binomial model has also been proposed. The dispersion parameter (\"k\") using the method of moments is \"m\" / ( \"s\" - \"m\" ) and \"p\" is the proportion of samples with counts > 0. The \"s\" used in the calculation of \"k\" are the values predicted by Taylor's law. \"p\" is plotted against 1 - ( \"k\" ( \"k\" + \"m\" ) ) and the fit of the data is visually inspected.\n\nPerry and Taylor have proposed an alternative estimator of \"k\" based on Taylor's law.\n\nA better estimate of the dispersion parameter can be made with the method of maximum likelihood. For the negative binomial it can be estimated from the equation\n\nwhere \"A\" is the total number of samples with more than \"x\" individuals, \"N\" is the total number of individuals, \"x\" is the number of individuals in a sample, \"m\" is the mean number of individuals per sample and \"k\" is the exponent. The value of \"k\" has to be estimated numerically.\n\nGoodness of fit of this model can be tested in a number of ways including using the chi square test. As these may be biased by small samples an alternative is the \"U\" statistic - the difference between the variance expected under the negative binomial distribution and that of the sample. The expected variance of this distribution is \"m\" + \"m\" / \"k\" and\n\nwhere \"s\" is the sample variance, \"m\" is the sample mean and \"k\" is the negative binomial parameter.\n\nThe variance of U is\n\nwhere \"p\" = \"m\" / \"k\", \"q\" = 1 + \"p\", \"R\" = \"p\" / \"q\" and \"N\" is the total number of individuals in the sample. The expected value of \"U\" is 0. For large sample sizes \"U\" is distributed normally.\n\nNote: The negative binomial is actually a family of distributions defined by the relation of the mean to the variance\n\nformula_91\n\nwhere \"a\" and \"p\" are constants. When \"a\" = 0 this defines the Poisson distribution. With \"p\" = 1 and \"p\" = 2, the distribution is known as the NB1 and NB2 distribution respectively.\n\nThis model is a version of that proposed earlier by Barlett.\n\nThe dispersion parameter (\"k\") is\n\nwhere \"m\" is the sample mean and \"s\" is the variance. If \"k\" is > 0 the population is considered to be aggregated; \"k\" = 0 the population is considered to be random; and if \"k\" is < 0 the population is considered to be uniformly distributed.\nSouthwood has recommended regressing \"k\" against the mean and a constant\n\nwhere \"k\" and \"m\" are the dispersion parameter and the mean of the ith sample respectively to test for the existence of a common dispersion parameter (\"k\"). A slope (\"b\") value significantly > 0 indicates the dependence of \"k\" on the mean density.\n\nAn alternative method was proposed by Elliot who suggested plotting ( \"s\" - \"m\" ) against ( \"m\" - \"s\" / \"n\" ). \"k\" is equal to 1/slope of this regression.\n\nThis coefficient (\"C\") is defined as\n\nformula_94\n\nIf the population can be assumed to be distributed in a negative binomial fashion, then \"C\" = 100 (1/\"k\") where \"k\" is the dispersion parameter of the distribution.\n\nThis index (\"I\") is defined as\n\nformula_95\n\nThe usual interpretation of this index is as follows: values of \"I\" < 1, 1, > 1 are taken to mean a uniform distribution, a random distribution or an aggregated distribution.\n\nBecause \"s\" = Σ x - (Σx), the index can also be written\n\nformula_96\n\nIf Taylor's law can be assumed to hold, then\n\nformula_97\n\nLloyd's index of mean crowding (\"IMC\") is the average number of other points contained in the sample unit that contains a randomly chosen point.\n\nwhere \"m\" is the sample mean and \"s\" is the variance.\n\nLloyd's index of patchiness (\"IP\") is\n\nIt is a measure of pattern intensity that is unaffected by thinning (random removal of points). This index was also proposed by Pielou in 1988 and is sometimes known by this name also.\n\nBecause an estimate of the variance of \"IP\" is extremely difficult to estimate from the formula itself, LLyod suggested fitting a negative binomial distribution to the data. This method gives a parameter \"k\"\n\nformula_100\n\nThen\n\nformula_101\n\nwhere \"SE\"(\"IP\") is the standard error of the index of patchiness,\"var\"(\"k\") is the variance of the parameter \"k\" and \"q\" is the number of quadrats sampled..\n\nIf the population obeys Taylor's law then\n\nIwao proposed a patchiness regression to test for clumping\n\nLet\n\n\"y\" here is Lloyd's index of mean crowding. Perform an ordinary least squares regression of \"m\" against \"y\".\n\nIn this regression the value of the slope (\"b\") is an indicator of clumping: the slope = 1 if the data is Poisson-distributed. The constant (\"a\") is the number of individuals that share a unit of habitat at infinitesimal density and may be < 0, 0 or > 0. These values represent regularity, randomness and aggregation of populations in spatial patterns respectively. A value of \"a\" < 1 is taken to mean that the basic unit of the distribution is a single individual.\n\nWhere the statistic \"s\" / \"m\" is not constant it has been recommended to use instead to regress Lloyd's index against \"am\" + \"bm\" where \"a\" and \"b\" are constants.\n\nThe sample size (\"n\") for a given degree of precision (\"D\") for this regression is given by\n\nwhere \"a\" is the constant in this regression, \"b\" is the slope, \"m\" is the mean and \"t\" is the critical value of the t distribution.\n\nIawo has proposed a sequential sampling test based on this regression. The upper and lower limits of this test are based on critical densities m where control of a pest requires action to be taken.\n\nwhere \"N\" and \"N\" are the upper and lower bounds respectively, \"a\" is the constant from the regression, \"b\" is the slope and \"i\" is the number of samples.\n\nKuno has proposed an alternative sequential stopping test also based on this regression.\n\nwhere \"T\" is the total sample size, \"D\" is the degree of precision, \"n\" is the number of samples units, a is the constant and b is the slope from the regression respectively.\n\nKuno's test is subject to the condition that \"n\" ≥ (\"b\" - 1) / \"D\"\n\nParrella and Jones have proposed an alternative but related stop line\n\nformula_109\n\nwhere \"a\" and \"b\" are the parameters from the regression, \"N\" is the maximum number of sampled units and \"n\" is the individual sample size.\n\nMorisita’s index of dispersion ( \"I\" ) is the scaled probability that two points chosen at random from the whole population are in the same sample. Higher values indicate a more clumped distribution.\n\nAn alternative formulation is\n\nwhere \"n\" is the total sample size, \"m\" is the sample mean and \"x\" are the individual values with the sum taken over the whole sample.\nIt is also equal to\n\nwhere \"IMC\" is Lloyd's index of crowding.\n\nThis index is relatively independent of the population density but is affected by the sample size. Values > 1 indicate clumping; values < 1 indicate a uniformity of distribution and a value of 1 indicates a random sample.\n\nMorisita showed that the statistic\n\nis distributed as a chi squared variable with \"n\" - 1 degrees of freedom.\n\nA alternative significance test for this index has been developed for large samples.\n\nwhere \"m\" is the overall sample mean, \"n\" is the number of sample units and \"z\" is the normal distribution abscissa. Significance is tested by comparing the value of \"z\" against the values of the normal distribution.\n\nA function for its calculation is available in the statistical R language. R function\n\nSmith-Gill developed a statistic based on Morisita’s index which is independent of both sample size and population density and bounded by -1 and +1. This statistic is calculated as follows\n\nFirst determine Morisita's index ( \"I\" ) in the usual fashion. Then let \"k\" be the number of units the population was sampled from. Calculate the two critical values\n\nwhere χ is the chi square value for \"n\" - 1 degrees of freedom at the 97.5% and 2.5% levels of confidence.\n\nThe standardised index ( \"I\" ) is then calculated from one of the formulae below\n\nWhen I ≥ M > 1\n\nWhen M > I ≥ 1\n\nWhen 1 > I ≥ M\n\nWhen 1 > M > I\n\n\"I\" ranges between +1 and -1 with 95% confidence intervals of ±0.5. \"I\" has the value of 0 if the pattern is random; if the pattern is uniform, \"I\" < 0 and if the pattern shows aggregation, \"I\" > 0.\n\nSouthwood's index of spatial aggregation (\"k\") is defined as\n\nwhere \"m\" is the mean of the sample and \"m\"* is Lloyd's index of crowding.\n\nFisher's index of dispersion is\n\nThis index may be used to test for over dispersion of the population. It is recommended that in applications n > 5 and that the sample total divided by the number of samples is > 3. In symbols\n\nwhere \"x\" is an individual sample value. The expectation of the index is equal to \"n\" and it is distributed as the chi-square distribution with \"n\" − 1 degrees of freedom when the population is Poisson distributed. It is equal to the scale parameter when the population obeys the gamma distribution.\n\nIt can be applied both to the overall population and to the individual areas sampled individually. The use of this test on the individual sample areas should also include the use of a Bonferroni correction factor.\n\nIf the population obeys Taylor's law then\n\nThe index of cluster size (\"ICS\") was created by David and Moore. Under a random (Poisson) distribution \"ICS\" is expected to equal 0. Positive values indicate a clumped distribution; negative values indicate a uniform distribution.\n\nwhere \"s\" is the variance and \"m\" is the mean.\n\nIf the population obeys Taylor's law\n\nThe \"ICS\" is also equal to Katz's test statistic divided by ( \"n\" / 2 ) where \"n\" is the sample size. It is also related to Clapham's test statistic. It is also sometimes referred to as the clumping index.\n\nGreen’s index (\"GI\") is a modification of the index of cluster size that is independent of \"n\" the number of sample units.\n\nThis index equals 0 if the distribution is random, 1 if it is maximally aggregated and -1 / ( \"nm\" - 1 ) if it is uniform.\n\nThe distribution of Green's index is not currently known so statistical tests have been difficult to devise for it.\n\nIf the population obeys Taylor's law\n\nBinary sampling (presence/absence) is frequently used where it is difficult to obtain accurate counts. The dispersal index (\"D\") is used when the study population is divided into a series of equal samples ( number of units = \"N\": number of units per sample = \"n\": total population size = \"n\" x \"N\" ). The theoretical variance of a sample from a population with a binomial distribution is\n\nwhere \"s\" is the variance, \"n\" is the number of units sampled and \"p\" is the mean proportion of sampling units with at least one individual present. The dispersal index (\"D\") is defined as the ratio of observed variance to the expected variance. In symbols\n\nwhere \"var\" is the observed variance and \"var\" is the expected variance. The expected variance is calculated with the overall mean of the population. Values of \"D\" > 1 are considered to suggest aggregation. \"D\"( \"n\" - 1 ) is distributed as the chi squared variable with \"n\" - 1 degrees of freedom where \"n\" is the number of units sampled.\n\nAn alternative test is the \"C\" test.\n\nwhere \"D\" is the dispersal index, \"n\" is the number of units per sample and \"N\" is the number of samples. C is distributed normally. A statistically significant value of C indicates overdispersion of the population.\n\n\"D\" is also related to intraclass correlation ( ρ ) which is defined as\n\nwhere \"T\" is the number of organisms per sample, \"p\" is the likelihood of the organism having the sought after property (diseased, pest free, \"etc\"), and x is the number of organism in the \"i\"th unit with this property. \"T\" must be the same for all sampled units. In this case with \"n\" constant\n\nIf the data can be fitted with a beta-binomial distribution then\n\nwhere \"θ\" is the parameter of the distribution.\n\nMa has proposed a parameter (\"m\") - the population aggregation critical density - to relate population density to Taylor's law.\n\nformula_135\n\nA number of statistical tests are known that may be of use in applications.\n\nA related statistic suggested by de Oliveria is the difference of the variance and the mean. If the population is Poisson distributed then\n\nwhere \"t\" is the Poisson parameter, \"s\" is the variance, \"m\" is the mean and \"n\" is the sample size. The expected value of \"s\" - \"m\" is zero. This statistic is distributed normally.\n\nIf the Poisson parameter in this equation is estimated by putting \"t\" = \"m\", after a little manipulation this statistic can be written\n\nThis is almost identical to Katz's statistic with ( \"n\" - 1 ) replacing \"n\". Again \"O\" is normally distributed with mean 0 and unit variance for large \"n\".\n\n\nde Oliveria actually suggested that the variance of \"s\" - \"m\" was ( 1 - 2\"t\" + 3\"t\" ) / \"n\" where \"t\" is the Poisson parameter. He suggested that \"t\" could be estimated by putting it equal to the mean (\"m\") of the sample. Further investigation by Bohning showed that this estimate of the variance was incorrect. Bohning's correction is given in the equations above.\n\nIn 1936 Clapham proposed using the ratio of the variance to the mean as a test statistic (the relative variance). In symbols\n\nFor a Possion distribution this ratio equals 1. To test for deviations from this value he proposed testing its value against the chi square distribution with \"n\" degrees of freedom where \"n\" is the number of sample units. The distribution of this statistic was studied further by Blackman who noted that it was approximately normally distributed with a mean of 1 and a variance ( \"V\" ) of\n\nThe derivation of the variance was re analysed by Bartlett who considered it to be\n\nFor large samples these two formulae are in approximate agreement. This test is related to the later Katz's \"J\" statistic.\n\nIf the population obeys Taylor's law then\n\n\nA refinement on this test has also been published These authors noted that this test tends to detect overdispersion at higher scales even when this was not present in the data. They noted that the use of the multinomial distribution may be more appropriate than the use of a Poisson distribution for such data. The statistic \"θ\" is distributed\n\nwhere \"N\" is the number of sample units, \"n\" is the total number of samples examined and \"x\" are the individual data values.\n\nThe expectation and variance of \"θ\" are\n\nFor large \"N\" \"E\"(θ) is approximately 1 and\n\nIf the number of individuals sampled ( \"n\" ) is large this estimate of the variance is in agreement with those derived earlier. However, for smaller samples these latter estimates are more precise and should be used.\n\n", "id": "34983797", "title": "Taylor's law"}
{"url": "https://en.wikipedia.org/wiki?curid=22103162", "text": "Ecoflation\n\nEcoflation (a portmanteau of ecological inflation) is a future scenario in \"Rattling Supply Chains,\" a research report by the World Resources Institute and A.T. Kearney released in November 2008, characterized by natural resources becoming scarcer and sustainability issues become more pressing, with environmental costs increasingly being borne by those responsible. The concept of ecoflation focuses on having environmental externalities of business be the burden of the organization/business responsible, rather than costs being allocated to the public in general. Ecoflation represents more accurate pricing of the true costs associated with business actions\n\n", "id": "22103162", "title": "Ecoflation"}
{"url": "https://en.wikipedia.org/wiki?curid=2488057", "text": "Trophic egg\n\nA trophic egg, in most species that produce them, usually is an unfertilised egg because its function is not reproduction but nutrition; in essence it serves as food for offspring hatched from viable eggs. The production of trophic eggs has been observed in a highly diverse range of species, including fish, amphibians, spiders and insects. The function is not limited to any particular level of parental care, but occurs in sub-social species of insects as well as in Leptodactylus fallax, a species of frog known for its close parental care.\n\nParents of some species deliver trophic eggs directly to their offspring, whereas some other species simply produce the trophic eggs after laying the viable eggs; they then leave the trophic eggs where the viable offspring are likely to find them.\n\nThe mackerel sharks present the most extreme example of proximity between reproductive eggs and trophic eggs; their viable offspring feed on trophic eggs \"in utero\".\n\nDespite the diversity of species and life strategies in which trophic eggs occur, all trophic egg functions are similarly derived from similar ancestral functions, which once amounted to the sacrifice of potential future offspring in order to provide food for the survival of rival (usually earlier) offspring. In more derived examples the trophic eggs are not viable, being neither fertilised, nor even fully formed in some cases, so they do not represent actually potential offspring, although they still represent parental investment corresponding to the amount of food it took to produce them.\n\nTrophic eggs are not always morphologically distinct from normal reproductive eggs; however if there is no physical distinction there tends to be some kind of specialised behaviour in the way that trophic eggs are delivered by the parents.\n\nIn some beetles, trophic eggs are paler in colour and softer in texture than reproductive eggs, with a smoother surface on the chorion. It has also been found that trophic eggs in ants have a less pronounced reticulate pattern on the chorion.\n\nThe morphological differences may arise due to the fact that mothers invest less energy in the production of trophic eggs than viable eggs.\n\nThe behaviour of trophic egg-laying species depends highly on their environment and can be modified via adaptive plasticity in response to environmental variation. The ratio of trophic to viable eggs is determined by the availability of resources, although the absolute number of trophic eggs does not always change.\nThe production of fewer viable eggs ensures that each hatched nymph will have a larger provision of trophic eggs; and therefore give each individual an enhanced chance of survival when external resources are limited. Females can adaptively adjust the egg ratio in response to environmental drivers prior to oviposition.\n\nWhen resources are limited, the presence of trophic eggs greatly increases the maturation and survival rates of offspring. There are some species such as the subsocial burrower bug \"Canthophorus niveimarginatus\" (Heteroptera: Cydnidae) whose offspring cannot survive at all without the provision of trophic eggs. The nymphs starve to death because trophic eggs are the only thing they are able to feed on. However, when other suitable sources of food are plentiful, feeding on trophic eggs has little effect on brood success.\n\nSibling cannibalism, common in many spider species, is not affected by the proportion of trophic eggs, since viable eggs are oviposited and hatch synchronously, before trophic eggs are laid. In the spider \"Amaurobius ferox\", trophic eggs are laid the day after spiderlings emerge from their egg sac. The mother’s reproductive behaviour is modified by the behaviour of her offspring, and their presence inhibits the second generation of eggs from maturing; instead they are released as infertile trophic eggs. Converting the second generation into food for the first ultimately boosts the mother’s reproductive success.\n\nThere are no concrete explanations for the evolution of trophic eggs. The two main conflicting arguments are:\n\nIf they have evolved (and are now distinct) from functionless by-products of failed reproduction, then trophic eggs should be more easily available and provide more nutrients to the offspring than their evolutionary predecessors. There seems to be clear evidence of this adaptation in many species. This can be seen in mothers making an effort to distribute trophic eggs to their offspring; and/or eggs which are specialised for the nutritional needs of the offspring. However, in many species, the two types of egg are indistinguishable. Various hypotheses could potentially be tested to determine whether trophic eggs are indeed an evolved phenotype.\n\nIt has been suggested that trophic egg-laying evolved as a consequence of limited egg size, since larger eggs with more nutrient supply would require the mother to have a larger body size. Thus, the production of more eggs, some of which are not intended to reach maturity. It is relatively simple for the mother to adjust the ratio of fertilised to non-fertilised eggs, in response to environmental conditions.\n\nAn alternative to trophic egg-laying is sibling cannibalism; however this requires the mother to regulate the synchrony of hatching times. However, in this case eggs which are not eaten would continue to develop. If it is difficult for the mother to achieve this synchrony, trophic eggs are a sensible alternative in ensuring that the offspring that hatches will be fed sufficiently.\n\n\n", "id": "2488057", "title": "Trophic egg"}
{"url": "https://en.wikipedia.org/wiki?curid=35150994", "text": "Cover-abundance\n\nCover-abundance is a measure of plant cover, used in phytosociology (or vegetation science). It is based on percentages at the top end, but uses abundance estimates for species with a low cover plant cover. Several scales of cover-abundance are used, e.g. the original 5-point cover scale of Braun-Blanquet or the Domin scale, with finer subdivisions (from simple presence through 10 grades of linked cover-abundance).\n\n", "id": "35150994", "title": "Cover-abundance"}
{"url": "https://en.wikipedia.org/wiki?curid=36027701", "text": "Ecological assessment\n\nEcological assessment (EA) implies the monitoring of ecological resources, to discover the current and changing conditions. EAs are required components of most hazardous waste site investigations. Such assessments, in conjunction with contamination and human health risk assessments, help to evaluate the environmental hazards posed by contaminated sites and to determine remediation requirements.\n\nIn ecological assessment many abiotic and biotic indicators, reflecting the pluralistic components of ecosystems, are used. Reporting on the state of the environment requires that information on separate indicators are integrated into comprehensive yardsticks or indices. EA is extremely complex because of regional and temporal variation in vulnerability of ecosystems and because of limited understanding of ecosystem functioning and health.\n\nEcological indicators are able to\nIdeally the suite of indicators should represent key information about structure, function, and composition of the ecological system.\n\nIn general EA indicators can be divided into abiotic and biotic indicators. Due to the complexity of ecosystems and environmental processes, a set of indicators reflecting the many facets of ecosystems is needed. Chemical, physical, and biological indicators each have specific advantages and disadvantages for monitoring and assessment.\n\nAbiotic indicators, which may give information on the risks or threats from stressors to ecosystems are comparatively well correlated with sources of pollutants and disturbances but may not reflect ecological end points in themselves.\n\nBiotic indicators may reflect end points and may be used to differentiate \"healthy\" from \"sick\" ecosystems. Correlation of biotic indicators with sources of pollutants and other disturbances is relatively difficult due to the complexity of environmental processes and the multitude of potential stressors.\n\nCritical appraisal:\n\nStrategic ecological assessment (SEcA) is required to ensure that proposed new developments are compatible with international obligations to conserve protected habitats and their associated species. In common with all forms of Environmental Impact Assessment, the effectiveness of SEcA depends on the ability to define the proposed action or set of actions and to characterize the receiving environment (baseline conditions). The ability to quantify potential impacts and to estimate their risk of occurrence is strongly dependent on the\nof national data on the distributions of habitats, species and development proposals.\n\nThe U.S. Nature Conservancy has developed Rapid Ecological Assessment (REA), an integrated methodology to provide the multiple scale, up-to-date information required to guide conservation actions. REA relies on analysis of aerial photography, videography, and satellite image data to identify conservation sites and to direct field sampling and research for cost-effective biological and ecological data acquisitions.\n\nThe goal of EA is to understand the structure and function of ecosystems in order to develop improved management options. Furthermore, developing models to predict the response of ecosystems to changes contributes to finding a particular management strategy.\nThe results of the EA will be used to suggest possible improvements of the pollutant´s properties to reduce the potential environmental impacts.\n\n\nThe U.S. Environmental Protection Agency has set a definition for EA. Ecological assessment is a “qualitative or quantitative assessment of the actual or potential effects of a hazardous waste site on plants and animals other than people and domesticated species”. The methodologies used for EA noted down in the Comprehensive Environmental Response, Compensation, and Liability Act (CERCLA)are only vaguely defined. As a result, assessment methods applied by both consultants and regulatory agencies range from qualitative approaches, such as listings of potential biotic receptors at a contaminated site, to fully quantitative approaches that include detailed exposure estimations, quantitative toxicity comparisons, and supplementary biota sampling to evaluate uptake estimates.\n", "id": "36027701", "title": "Ecological assessment"}
{"url": "https://en.wikipedia.org/wiki?curid=3175680", "text": "Generalist and specialist species\n\nA generalist species is able to thrive in a wide variety of environmental conditions and can make use of a variety of different resources (for example, a heterotroph with a varied diet). A specialist species can thrive only in a narrow range of environmental conditions or has a limited diet. Most organisms do not all fit neatly into either group, however. Some species are highly specialized (the most extreme case being monophagy), others less so, and some can tolerate many different environments. In other words, there is a continuum from highly-specialized to broadly-generalist species.\n\nOmnivores are usually generalists. Herbivores are often specialists, but those that eat a variety of plants may be considered generalists. A well-known example of a specialist animal is the koala, which subsists almost entirely on eucalyptus leaves. The raccoon is a generalist because it has a natural range that includes most of North and Central America, and it is omnivorous, eating berries, insects, butterflies (Hackberry Emperor, for example), eggs and small animals. Monophagous organisms feed exclusively, or nearly so, on a single other species.\n\nThe distinction between generalists and specialists is not limited to animals. For example, some plants require a narrow range of temperatures, soil conditions and precipitation to survive while others can tolerate a broader range of conditions. A cactus could be considered a specialist species. It will die during winters at high latitudes or if it receives too much water.\n\nWhen body weight is controlled for, specialist feeders such as insectivores and frugivores have larger home ranges than generalists like some folivores (leaf eaters). Because their food source is less abundant, they need a bigger area for foraging. An example comes from the research of Tim Clutton-Brock, who found that the black and white colobus, a folivore generalist, needs a home range of only 15ha. On the other hand, the more specialized red colobus monkey has a home range of 70 ha, which it requires to find patchy shoots, flowers and fruit.\n\nWhen environmental conditions change, generalists are able to adapt, but specialists tend to fall victim to extinction much more easily. For example, if a species of fish were to go extinct, any specialist parasites would also face extinction. On the other hand, a species with a highly specialized ecological niche is more effective at competing with other organisms. For example, a fish and its parasites are in an evolutionary arms race, a form of co-evolution, in which the fish constantly develops defenses against the parasite, while the parasite in turn evolves adaptations to cope with the specific defenses of its host. This tends to drive the speciation of more specialized species provided conditions remain relatively stable. This involves niche partitioning as new species are formed, and biodiversity is increased.\n\n", "id": "3175680", "title": "Generalist and specialist species"}
{"url": "https://en.wikipedia.org/wiki?curid=32086658", "text": "Nutrient cycle\n\nA nutrient cycle (or ecological recycling) is the movement and exchange of organic and inorganic matter back into the production of matter. unidirectional and noncyclic pathways, whereas the movement of mineral nutrients is cyclic. Mineral cycles include carbon cycle, sulfur cycle, nitrogen cycle, water cycle, phosphorus cycle, oxygen cycle, among others that continually recycle along with other mineral nutrients into productive ecological nutrition. Global biogeochemical cycles\n\nThe nutrient cycle is nature's recycling system. All forms of recycling have feedback loops that uses energy in the process of putting material resources back into use. Recycling in ecology is regulated to a large extent during the process of decomposition. Ecosystems employ biodiversity in the food webs that recycle natural materials, such as mineral nutrients, which includes water. Recycling in natural systems is one of the many ecosystem services that sustain and contribute to the well-being of human societies.\n\nThere is much overlap between the terms for biogeochemical cycle and nutrient cycle. Most textbooks integrate the two and seem to treat them as synonymous terms. However, the terms often appear independently. Nutrient cycle is more often used in direct reference to the idea of an intra-system cycle, where an ecosystem functions as a unit. From a practical point it does not make sense to assess a terrestrial ecosystem by considering the full column of air above it as well as the great depths of Earth below it. While an ecosystem often has no clear boundary, as a working model it is practical to consider the functional community where the bulk of matter and energy transfer occurs. Nutrient cycling occurs in ecosystems that participate in the \"larger biogeochemical cycles of the earth through a system of inputs and outputs.\"\n\nEcosystems are capable of complete recycling. Complete recycling means that 100% of the waste material can be reconstituted indefinitely. This idea was captured by Howard T. Odum when he penned that \"it is thoroughly demonstrated by ecological systems and geological systems that all the chemical elements and many organic substances can be accumulated by living systems from background crustal or oceanic concentrations without limit as to concentration so long as there is available solar or other source of potential energy\" In 1979 Nicholas Georgescu-Roegen proposed a fourth law of entropy stating that complete recycling is impossible. Despite Georgescu-Roegen's extensive intellectual contributions to the science of ecological economics, the fourth law has been rejected in line with observations of ecological recycling. However, some authors state that complete recycling is impossible for technological waste.\n\nEcosystems execute closed loop recycling where demand for the nutrients that adds to the growth of biomass exceeds supply within that system. There are regional and spatial differences in the rates of growth and exchange of materials, where some ecosystems may be in nutrient debt (sinks) where others will have extra supply (sources). These differences relate to climate, topography, and geological history leaving behind different sources of parent material. In terms of a food web, a cycle or loop is defined as \"a directed sequence of one or more links starting from, and ending at, the same species.\" An example of this is the microbial food web in the ocean, where \"bacteria are exploited, and controlled, by protozoa, including heterotrophic microflagellates which are in turn exploited by ciliates. This grazing activity is accompanied by excretion of substances which are in turn used by the bacteria, so that the system more or less operates in a closed circuit.\"\n\nAn example of ecological recycling occurs in the enzymatic digestion of cellulose. \"Cellulose, one of the most abundant organic compounds on Earth, is the major polysaccharide in plants where it is part of the cell walls. Cellulose-degrading enzymes participate in the natural, \"ecological recycling\" of plant material.\" Different ecosystems can vary in their recycling rates of litter, which creates a complex feedback on factors such as the competitive dominance of certain plant species. Different rates and patterns of ecological recycling leaves a legacy of environmental effects with implications for the future evolution of ecosystems.\n\nEcological recycling is common in organic farming, where nutrient management is \"fundamentally different\" compared to agri-business styles of soil management. Organic farms that employ ecosystem recycling to a greater extent support more species (increased levels of biodiversity) and have a different food web structure. Organic agricultural ecosystems rely on the services of biodiversity for the recycling of nutrients through soils instead of relying on the supplementation of synthetic fertilizers. The model for ecological recycling agriculture adheres to the following principals:\n\n\nThe persistent legacy of environmental feedback that is left behind by or as an extension of the ecological actions of organisms is known as niche construction or ecosystem engineering. Many species leave an effect even after their death, such as coral skeletons or the extensive habitat modifications to a wetland by a beaver, whose components are recycled and re-used by descendants and other species living under a different selective regime through the feedback and agency of these legacy effects. Ecosystem engineers can influence nutrient cycling efficiency rates through their actions.\n\nEarthworms, for example, passively and mechanically alter the nature of soil environments. Bodies of dead worms passively contribute mineral nutrients to the soil. The worms also mechanically modify the physical structure of the soil as they crawl about (bioturbation), digest on the moulds of organic matter they pull from the soil litter. These activities transport nutrients into the mineral layers of soil. Worms discard wastes that create worm castings containing undigested materials where bacteria and other decomposers gain access to the nutrients. The earthworm is employed in this process and the production of the ecosystem depends on their capability to create feedback loops in the recycling process.\n\nShellfish are also ecosystem engineers because they: 1) Filter suspended particles from the water column; 2) Remove excess nutrients from coastal bays through denitrification; 3) Serve as natural coastal buffers, absorbing wave energy and reducing erosion from boat wakes, sea level rise and storms; 4) Provide nursery habitat for fish that are valuable to coastal economies.\n\nFungi contribute to nutrient cycling and nutritionally rearrange patches of ecosystem creating niches for other organisms. In that way fungi ingrowing dead wood allow xylophages to grow and develop and xylophages in turn affect dead wood, contributing to wood decomposition and nutrient cycling in the forest floor.\n\nNutrient cycling has a historical foothold in the writings of Charles Darwin in reference to the decomposition actions of earthworms. Darwin wrote about \"the continued Following the Greeks, the idea of a hydrological cycle (water is considered a nutrient) was validated and quantified by Halley in 1687.\n\nIn 1926 Vernadsky coined the term biogeochemistry as a sub-discipline of geochemistry. However, the term nutrient cycle pre-dates biogeochemistry in a pamphlet on silviculture in 1899: \"These demands by no means pass over the fact that at places where sufficient quantities of humus are available and where, in case of continuous decomposition of litter, a stable, nutrient humus is present, considerable quantities of nutrients are also available from the biogenic \"nutrient cycle\" for the standing timber. In 1898 there is a reference to the nitrogen cycle in relation to nitrogen fixing microorganisms. Other uses and variations on the terminology relating to the process of nutrient cycling appear throughout history:\n\n\nWater is also a nutrient. In this context, some authors also refer to precipitation recycling, which \"is the contribution of evaporation within a region to precipitation in that same region.\" These variations on the theme of nutrient cycling continue to be used and all refer to processes that are part of the global biogeochemical cycles. However, authors tend to refer to natural, organic, ecological, or bio-recycling in reference to the work of nature, such as it is used in organic farming or ecological agricultural systems.\n\nAn endless stream of technological waste accumulates in different spatial configurations across the planet and turns into a predator in our soils, our streams, and our oceans. This idea was similarly expressed in 1954 by ecologist Paul Sears: \"We do not know whether to cherish the forest as a source of essential raw materials and other benefits or to remove it for the space it occupies. We expect a river to serve as both vein and artery carrying away waste but bringing usable material in the same channel. Nature long ago discarded the nonsense of carrying poisonous wastes and nutrients in the same vessels.\" Ecologists use population ecology to model contaminants as competitors or predators. Rachel Carson was an ecological pioneer in this area as her book \"Silent Spring\" inspired research into biomagification and brought to the worlds attention the unseen pollutants moving into the food chains of the planet.\n\nIn contrast to the planets natural ecosystems, technology (or technoecosystems) is not reducing its impact on planetary resources. Only 7% of total plastic waste (adding up to millions upon millions of tons) is being recycled by industrial systems; the 93% that never makes it into the industrial recycling stream is presumably \"absorbed\" by natural recycling systems In contrast and over extensive lengths of time (billions of years) ecosystems have maintained a consistent balance with production roughly equaling respiratory consumption rates. The balanced recycling efficiency of nature means that production of decaying waste material has exceeded rates of recyclable consumption into food chains equal to the global stocks of fossilized fuels that escaped the chain of decomposition.\n\nMicroplastics and nanosilver materials flowing and cycling through ecosystems from pollution and discarded technology are among a growing list of emerging ecological concerns. For example, unique assemblages of marine microbes have been found to digest plastic accumulating in the worlds oceans. Discarded technology is absorbed into soils and creates a new class of soils called technosols. Human wastes in the Anthropocene are creating new systems of ecological recycling, novel ecosystems that have to contend with the mercury cycle and other synthetic materials that are streaming into the biodegradation chain. Microorganisms have a significant role in the removal of synthetic organic compounds from the environment empowered by recycling mechanisms that have complex biodegradation pathways. The effect of synthetic materials, such as nanoparticles and microplastics, on ecological recycling systems is listed as one of the major concerns for ecosystem in this century.\n\nRecycling in human industrial systems (or technoecosystems) differs from ecological recycling in scale, complexity, and organization. Industrial recycling systems do not focus on the employment of ecological food webs to recycle waste back into different kinds of marketable goods, but primarily employ people and technodiversity instead. Some researchers have questioned the premise behind these and other kinds of technological solutions under the banner of 'eco-efficiency' are limited in their capability, harmful to ecological processes, and dangerous in their hyped capabilities. Many technoecosystems are competitive and parasitic toward natural ecosystems. Food web or biologically based \"recycling includes metabolic recycling (nutrient recovery, storage, etc.) and ecosystem recycling (leaching and \"in situ\" organic matter mineralization, either in the water column, in the sediment surface, or within the sediment.\"\n\n\n", "id": "32086658", "title": "Nutrient cycle"}
{"url": "https://en.wikipedia.org/wiki?curid=36875918", "text": "Taxonomic impediment\n\nConservationists, ecologists, biodiversity scientists, lawmakers, and many others rely heavily on taxonomic information to manage, conserve, use, and share our biodiversity. The world-wide shortage of this important taxonomic information, the gaps in our taxonomic knowledge, and the shortage of trained taxonomists and curators to fill this need has come to be known as the taxonomic impediment. The importance of the taxonomic impediment was recognized by the Convention on Biological Diversity, signed at the 1992 Rio Earth Summit, and initiatives have occurred that have not yet solved the problem.\nThe greatest contributions of taxonomy to science and humanity are yet to come. Against formidable odds and with minimal funding, equipment, infrastructure, organization and encouragement, taxonomists have discovered, described, and classified nearly 1.8 million species. While increasing attention is being paid to making this substantial amount of accumulated taxonomic information more easily accessible, comparatively little attention has been paid to opening access to the research resources required by taxonomists themselves. Benefits associated with ease of access to museum records (e.g. Global Biodiversity Information Facility) or 'known' species (e.g. Encyclopedia of Life) are seriously restricted when such information is untested for validity or is simply unavailable, as is the case for three-quarters or more of the species on Earth. We act as if taxonomy is done but nothing could be farther from the truth.\n\nThe causes of the current crisis in taxonomy have been ascribed to a loss of perspective in ecology and evolutionary biology as the modern evolutionary synthesis developed during the 1930s and 40s: a conflation of \"pattern with process\", \"confusing the methods and goals of the emerging science of population genetics with those of the established science of taxonomy\", which caused the traditional fundamental taxonomy to be disparaged, and consequently underfunded.\n\nIt is argued that some initiatives that aim to bypass the bottleneck of insufficient taxonomic expertise continue to draw funds away from solving the fundamental problem.\n\n", "id": "36875918", "title": "Taxonomic impediment"}
{"url": "https://en.wikipedia.org/wiki?curid=36908659", "text": "Mountain research\n\nMountain research or \"montology\", traditionally also known as \"orology\" (from Greek \"oros\" ὄρος for 'mountain' and \"logos\" λόγος), is a field of research that regionally concentrates on the Earth's surface's part covered by mountain landscapes.\n\nDifferent approaches have been developed to define \"mountainous\" areas. While some use an altitudinal difference of 300 m inside an area to define that zone as mountainous, others consider differences from 1000 m or more, depending on the areas' latitude. Additionally, some include steepness to define mountain regions, hence excluding high plateaus (e.g. the Andean Altiplano or the Tibetan Plateau), zones often seen to be mountainous. A more pragmatic but useful definition has been proposed by the Italian Statistics Office ISTAT, which classifies municipalities as mountainous\n\n\nThe United Nations Environmental Programme has produced a map of mountain areas worldwide using a combination of criteria, including regions with\n\n\nIn a broader sense, mountain research is considered any research \"in\" mountain regions: for instance disciplinary studies on Himalayan plants, Andean rocks, Alpine cities, or Carpathian people. It is comparable to research that concentrates on the Arctic and Antarctic (polar research) or coasts (coastal research).\n\nIn a narrower sense, mountain research focuses \"on\" mountain regions, their description and the explanation of the human-environment interaction in (positive) and the sustainable development of (normative) these areas. So-defined mountain research is situated at the nexus of natural sciences, social sciences and humanities. Drawing on Alexander von Humboldt's work in the Andean realm, mountain geography and ecology are considered core areas of study; nevertheless important contributions are coming from anthropology, geology, economics, history or spatial planning. In sum, a narrowly defined mountain research applies an interdisciplinary and integrative regional approach. Slaymaker summarizes:\n\nMountain research or \"orology\"—not to be confused with orography—, is sometimes denominated \"montology\". This term stems from Carl Troll's \"mountain geoecology\"—geoecology being Troll's English translation of the German \"Landschaftsökologie\"—and appeared at a meeting in Cambridge, Massachusetts in 1977. Since then, scholars such as Jack D. Ives, Bruno Messerli and Robert E. Rhoades have claimed the development of montology as interdisciplinary mountain research. The term montology was included in the Oxford English Dictionary in 2002. It defines montology as:\n\nOn the one hand, the term \"montology\" received criticism due to the mix of Latin (\"mōns\", pl. \"montēs\") and Greek (\"logos\"). On the other hand, however, this is also the—well accepted—case in several, already established disciplines such as glaciology or sociology.\n\nThe following list includes peer-reviewed journals that have a focus on mountain research and are open to both the natural and the social sciences:\n\n\n\n", "id": "36908659", "title": "Mountain research"}
{"url": "https://en.wikipedia.org/wiki?curid=3008596", "text": "Environmental change\n\nEnvironmental change is a change or disturbance of the environment most often caused by human influences and natural ecological processes. Environmental changes can include any number of things, including natural disasters, human interferences, or animal interaction. Environmental change does not only encompass physical changes, but it can be things like an infestation of invasive species is also environmental changes.\n\n", "id": "3008596", "title": "Environmental change"}
{"url": "https://en.wikipedia.org/wiki?curid=37498273", "text": "Elevational diversity gradient\n\nElevational diversity gradient (EDG) is an ecological pattern where trends in biodiversity occur at different elevations. The EDG states that species richness tends to increase as elevation increases, up to a certain point, creating a \"diversity bulge\" at middle elevations. There have been multiple hypotheses proposed for explaining the EDG, none of which accurately describe the phenomenon in full.\n\nA similar pattern, known as the latitudinal diversity gradient, describes an increase in biodiversity from the poles to the equator. While the EDG generally follows the LDG (i.e., high elevations in tropical regions have greater biodiversity than high elevations in temperate regions), the LDG does not account for elevational changes.\n\nThe first recorded observation of the elevational diversity gradient was by Carl Linnaeus in his treatise \"On the growth of the habitable earth\". In this document, Linnaeus based his predictions on flood geology, assuming most of the world was at one point inundated, leaving only the highest elevations available for terrestrial life. Since, by Linnaeus’ hypothesis, all life was concentrated at high elevations, a higher species diversity would be observed there even as life re-populated lower elevations.\n\nIn 1799, Alexander von Humboldt and Aimé Bonpland described elevational changes along the Andean slopes, noting how climatic changes impacted plant and animal communities. These observations contributed to Leslie R. Holdridge’s \"life zone concept\" (1947). Climatic variables shaping life zones include mean potential temperature, total annual precipitation, and the ratio of mean annual evapotranspiration to mean annual precipitation. These variables, most notably precipitation and temperature, vary along an elevational gradient, resulting in the distribution of different ecosystems.\n\nMuch of the current literature correlates elevational diversity to gradients in single climactic or biotic variables including \"rainfall, temperature, productivity, competition, resource abundance, habitat complexity, or habitat diversity\".\n\nA pattern in species richness is also observed as one moves along an elevational gradient; generally, species richness is thought to decline with increasing elevation. Whether this decline is monotonic or if it assumes different shapes based on the taxa or region being studied is still a topic of debate. In a review of previous studies looking at elevational diversity gradients, Rahbek noted the importance of other factors contributing to the shape of a gradient, distinguishing elevational patterns from those described by the latitudinal diversity gradient.\n\nFor certain taxa and regions, there is a mid elevational peak in species richness. This pattern has received empirical support for small mammals, spiders, ants and plants. Alternatively, microbes have been shown to exhibit not only monotonically decreasing diversity when moving from low to high elevations, but also increasing, hump-shaped, and U-shaped elevational patterns in diversity.\nOne explanation for a mid elevational peak includes mid elevational condensation zones. Under the assumption that natural boundaries can limit species distributions in varying degrees (for example, a mountain can present absolute elevational limits), Collwell and Lees explained the mid domain effect with geometric theory. In the context of a mountain, geometric boundary constraints will naturally result in the increasing overlap of species ranges nearing the midpoint of the mountain. Using vascular epiphytes in Costa Rica, Cardelus et al. (2008) noted that the elevational species richness pattern observed was substantially due to the mid domain effect; there was a bulge in epiphyte species richness at 1000m (The cloud forest).\nThis elevational pattern, however, was less consistent for species with small ranges, suggesting that environmental factors may be more clearly accounted for when constraints on domain boundary are loosened. In cases where geometric models fail to explain the location of the midpoint or the trend in species richness, other explanations need to be explored. An example of this can be seen with microbes, which have been shown to exhibit monotonically decreasing diversity when moving from low to high elevations.\n\nThe mountain-mass effect (also known as the Massenerhebung effect or mass-elevation effect) was proposed in 1904 by A. de Quarvain. This phenomenon recognizes the correlation between mountain mass and the occurrence of physiognomically similar vegetation types; similarity in vegetation type is observed at higher elevations on large mountain masses. Furthermore, under a climatically driven mountain–mass effect, there is a “positive linear trend observed in the elevation of highest diversity with mountain height”. This trend is most evident on isolated mountain peaks.\n\nAnother hypothesis that is cited to explain the upper limit of the elevational diversity gradient is the area hypothesis, which states that larger areas are able to support more species. As elevation increases, total area decreases; thus, there are more species present at middle elevations than high elevations.\n\nHowever, this hypothesis does not account for differences between lowland areas and middle elevations, as lowlands tend to have more area than middle elevations and thus would be expected by this hypothesis to have higher species diversity, an assertion that runs counter to the EDG. Additionally, the area hypothesis does not take climatic conditions or resource availability into account.\n\nThis hypothesis states that diversity increases with increasing rainfall, however the correlation between rainfall and plant diversity varies from region to region. The consistency of rainfall seems to correlate more with species richness than total annual rainfall. Species diversity appears to level off when annual rainfall reaches about 4,000mm, however this could be due to sampling limitations. Rainfall and soil richness affect productivity trends which are also believed to affect diversity. A mid elevation peak is usually seen in mean annual rainfall.\n\nThe resource diversity hypothesis states an increase in diversity can be seen when an increase in the diversity of available resources such as soil and food is present. In this hypothesis diversity increases in an area of higher resource diversity even when resource abundance is constant. However resource diversity, especially pertaining to food, could be a result of other influences, such as rainfall and productivity; as such, it may be inappropriate to consider the resource diversity hypothesis as a mechanism acting independently of other factors influencing diversity gradients.\n\nThe productivity hypothesis states that diversity increases with increased productivity. There is some contradiction to this as other research suggests that after a certain point increasing productivity actually correlates with a decrease in diversity.\n\nIt is generally thought that productivity decreases with an increase in elevation, however there is some research that shows a peak in productivity at mid elevation which may be related to a peak in rainfall within the same area.\n\nThe temperature hypothesis correlates increasing temperature with an increase in species diversity, mainly because of temperature's effect on productivity. However increasing temperatures due to climate change have begun to be linked to the spread of chytrid among frogs in the Tropics. Another concern is that higher-elevation species will become extinct as their ranges become more and more restricted with an increase in temperature. This hypothesis is an important factor in considering the effects of global warming.\n\nThere are conflicting views on the effect of competition on species diversity. Some hold the view that an increase in interspecies competition leads to local extinctions and a decrease in diversity. Others view competition as a means of species specialization and niche partitioning, resulting in increase diversity.\n\nIn other studies the competition between plant species at high elevations has been shown to facilitate the movement of plant species into high stress environments. The competition between plant species leads to hardier species spreading into the high stress environment. These founder species then provide shelter and facilitate the movement of less hardy species into the area. This may result in the movement of plant species up a mountainside.\n\nCurrent research illuminates a variety of mechanisms than can be used to explain elevational diversity gradients. No one factor can be used to explain the present of diversity gradients within and among taxa; in many cases, we must consider more than one hypothesis or mechanism to fully understand a pattern in elevational diversity. The emerging macroecological experiments along environmental gradients (for example, mountain elevation gradients) are an important tool in ecological research because they allow for the disentangling the effects of individual environmental drivers on biodiversity, the independent effects of which are not be easily separated due to their covariance in nature. For instance, microcosm experimental setups in subtropical and subarctic regions (China and Norway, respectively) showed clear segregation of bacterial species along temperature gradients, and interactive effects of temperature and nutrients on biodiversity along mountain elevation gradients. A more expansive research program for mountain biogeography may be extremely beneficial for conservation biologists seeking to understand factors driving biodiversity in known hot spots. Further research and reviews are also needed to address contradictions in the scientific literature, and to identify the extent of interactions between current explanations and hypotheses.\n", "id": "37498273", "title": "Elevational diversity gradient"}
{"url": "https://en.wikipedia.org/wiki?curid=37887483", "text": "Phoslock\n\nPhoslock is the commercial name for a bentonite clay in which the sodium and/or calcium ions are exchanged for lanthanum. The addition of this element allows it to bind with phosphates to form rhabdophane (LaPO4.nH2O) and thereby remove them from the water column. It is used in lake restoration projects as a tool to manage eutrophication and manage algal blooms (specifically cyanobacteria or blue green algae) by reducing phosphorus, one of the major contributing factors to algal growth.\n\nIt was developed in Australia by the CSIRO in the late 1990s by Dr Grant Douglas (US Patent 6350383) as a way of utilising the ability of lanthanum to bind phosphate in freshwater natural aquatic systems. The first large-scale trial took place in January 2000 in the Canning River, Western Australia. More recent CSIRO research has involved the development of a nanoclay hybrid with a demonstrated ability to remove dissolved phosphorus from both natural and wastewaters. \nDuring its development, patenting and commercialisation by CSIRO and subsequent commercial production, Phoslock has been a subject in academic research (,) and has been used globally in lake restoration projects. The largest number of whole lake applications and the most comprehensive pre and post-application monitoring has taken place in Europe, primarily Germany (where it is sold under the tradename Bentophos), the Netherlands and the UK (Official European website )\n", "id": "37887483", "title": "Phoslock"}
{"url": "https://en.wikipedia.org/wiki?curid=3560440", "text": "Ecolinguistics\n\nEcolinguistics, or ecological linguistics, emerged in the 1990s as a new paradigm of linguistic research, one which took into account not only the social context in which language is embedded, but also the ecological contexts in which societies are embedded. Michael Halliday's 1990 paper \"New ways of Meaning: the challenge to applied linguistics\" is often credited as a seminal work which provided the stimulus for linguists to consider the ecological context and consequences of language. Among other things, the challenge that Halliday put forward was to make linguistics relevant to the issues and concerns of the 21st century, particularly the widespread destruction of the ecosystems that life depends on. The main example Halliday gave was that of 'economic growth', describing how 'countless texts repeated daily all around the world contain a simple message: growth is good. Many is better than few, more is better than less, big is better than small, grow is better than shrink', which leads to ecologically destructive consequences. \n\nSince Halliday's initial comments, the field of ecolinguistics has developed in manifold directions, employing a wide range of linguistic frameworks and tools to investigate the linguistic factors at play in both unsustainable societies and genuinely sustaining cultures. The International Ecolinguistics Association, characterizes ecolinguistics in these terms: \n\n\"Ecolinguistics explores the role of language in the life-sustaining interactions of humans, other species and the physical environment. The first aim is to develop linguistic theories which see humans not only as part of society, but also as part of the larger ecosystems that life depends on. The second aim is to show how linguistics can be used to address key ecological issues, from climate change and biodiversity loss to environmental justice.\" \n\nIn this way, the 'eco' of ecolinguistics corresponds to ecology in its literal sense of the relationship of organisms (including humans) with other organisms and the physical environment. This is a sense shared with other ecological humanities disciplines such as ecocriticism and ecopsychology. \n\nThe term 'ecolinguistics' has also been used with a metaphorical sense of 'ecology', for example in 'Linguistic ecology', 'communication ecology' and 'learning ecology' in ways which do not include consideration of other species or the physical environment. This is becoming less prevalent now as ecolingusitics becomes increasingly understood as a form of ecological humanities/social science. \n\nAnother aspect of ecolinguistics is the influence of the natural world on language. In 1996, David Abram's book, \"The Spell of the Sensuous: Perception and Language in a More-than-Human World,\" described how the wider ecology (or 'the more than human world') shapes language in oral cultures (Abram, 1996), helping people attune to their environment. On the other hand, writing has gradually alienated people in literate cultures from the natural world, to the extent that 'our organic atonement to the local earth is thwarted by our ever-increasing intercourse with our own signs' (1996:267). \n\nOverall there are three main areas of interest for ecolinguistics. The first can be described as 'The Ecological Analysis of Language', the second 'Language Diversity', and the third 'The Influence of Ecology on Language'. \n\nThe ecological analysis of language draws on a wide range of linguistic tools including critical discourse analysis, framing theory, cognitive linguistics, identity theory, rhetoric and systemic functional grammar to reveal underlying worldviews or the 'stories we live by'. The stories we live by are cognitive structures in the minds of individuals or across a society (social cognition) which influence how people treat each other, other animals, plants, forests, rivers and the physical environment. The stories are questioned from an ecological perspective with reference to an ecological framework (or ecosophy), and judged to be beneficial in encouraging people to protect the ecosystems that life depends on, or destructive in encouraging behavior which damages those ecosystems. Ecolinguistics attempts to make a practical difference in the world through resisting destructive stories and contributing to the search for new stories to live by (Stibbe 2015). Stories which have been exposed and resisted by ecolinguistics include consumerist stories, stories of unlimited economic growth, advertising stories, stories of intensive farming, and stories which represent nature as a machine or a resource. Using Positive Discourse Analysis, ecolinguistics has also searched for new stories to live by through exploring nature writing, poetry, environmental writing and traditional and indigenous forms of language around the world. \n\nThis form of analysis started with the application of critical discourse analysis to texts about the environment and environmentalism, in order to reveal hidden assumptions and messages and comment on the effectiveness of these in achieving environmental aims (e.g. Harré et al. 1999). It then developed to include analysis of any discourse which has potential consequences for the future of ecosystems, such as neoliberal economic discourse or discursive constructions of consumerism, gender, politics, agriculture and nature (e.g. Goatly 2000). The cognitive approach and the term 'stories we live by' was introduced in Stibbe (2015), which describes eight kinds of story: ideology, framing, metaphor, evaluation, identity, conviction, salience and erasure. Approaches such as environmental communication and ecocriticism have broadly similar aims and techniques to this form of ecolinguistics.\n\nLanguage diversity is part of ecolinguistics because of the relationship between diversity of local languages and biodiversity. This relationship arises because of the ecological wisdom (or cultural adaptation to the environment) that is encoded in local languages. The forces of globalisation and linguistic imperialism are allowing dominant language to spread, and replace these local languages (Nettle and Romaine 2000). This leads to a loss of both sustainable local cultures and the important ecological knowledge contained within their languages. One of the goals of ecolinguistic research is to protect both cultural diversity and the linguistic diversity that supports it (Terralingua 2016, Nettle and Romaine 2000, Harmond 1996, Mühlhaüsler 1995). This research is in line with the United Nations Environment Program's position that: \n\n\"Biodiversity also incorporates human cultural diversity, which can be affected by the same drivers as biodiversity, and which has impacts on the diversity of genes, other species, and ecosystems. (UNEP 2007)\"\n\nNettle and Romaine (2000:166) write that 'Delicate tropical environments in particular must be managed with care and skill. It is indigenous peoples who have the relevant practical knowledge, since they have been successfully making a living in them for hundreds of generations. Much of this detailed knowledge about local ecosystems is encoded in indigenous language and rapidly being lost'. Mühlhaüsler (2003:60) describes how 'The rapid decline in the world's linguistic diversity thus must be regarded with apprehension by those who perceive the interconnection between linguistic and biological diversity'. \n\nOverall, language diversity is part of ecolinguistics because of the correlation between the diversity of language and biological diversity, with the ecological wisdom embedded in local cultures being the link between the two.\n\nAbram's early chapter on \"The Flesh of Language\" examined the contribution of the sensate body—and of the body's ongoing interaction with the earthly terrain—in the emergence of meaningful speech. A longer chapter on \"Animism and the Alphabet\" carefully contrasted the discourse of indigenous, oral cultures with the discourse of literate cultures. For oral cultures, the coherence of spoken language is inseparable from the coherence of the surrounding ecology, from the expressive vitality of the more-than-human terrain. For these peoples \"it is the animate earth that speaks; human speech is but a part of that vaster discourse.\" (p. 179) A subsequent chapter, entitled \"In the Landscape of Language,\" drew examples from a range of divergent oral cultures to show some of the diverse ways that the local, more-than-human terrain informs and influences the discursive speech of oral cultures. Overall, Abram argues that ecology plays a key role in shaping human language in oral cultures, but with writing this role becomes less and less significant. This results in a situation where ‘our organic atonement to the local earth is thwarted by our ever-increasing intercourse with our own signs’ (1996:267). He therefore argues for using language in ways which bring ecology (or the 'more-than-human-world') back into language:\n\n\"there can be no question of simply abandoning literacy, of turning away from all writing. Our task, rather, is that of taking up the written word, with all of its potency, and patiently, carefully, writing language back into the land. Our craft is that of releasing the budded, earthy intelligence of our words, freeing them to respond to the speech of the things themselves - to the green uttering-forth of leaves from the spring branches.\" (Abram 1996:273)\n\nThe International Ecolinguistics Association is an international network of ecolinguists. The website includes a bibliography, online journal (Language & Ecology) and other resources. \n\nThe Stories We Live By is a free online course in ecolinguistics created by the University of Gloucestershire and the International Ecolinguistics Association. \n\nThe Ecolinguistics Website (http://www-gewi.kfunigraz.ac.at/ed/project/ecoling) is an archive website of early ecolinguistics. \n\nLanguage geography\n\nLinguistic rights\n\nLanguage policy\n", "id": "3560440", "title": "Ecolinguistics"}
{"url": "https://en.wikipedia.org/wiki?curid=9503180", "text": "Generation time\n\nIn population biology and demography, the generation time is the average time between two consecutive generations in the lineages of a population. In human populations, the generation time typically ranges from 22 to 33 years. Historians sometimes use this to date events, by converting generations into years to obtain rough estimates of time.\n\nThe existing definitions of the generation time fall into two categories: those that treat the generation time as a renewal time of the population, and those that focus on the distance between individuals of one generation and the next. Below are the three most commonly used definitions:\n\nThe net reproductive rate \"R\" is the number of offspring an individual is expected to produce during its lifetime (a net reproductive rate of 1 means that the population is at its demographic equilibrium). This definition envisions the generation time as a renewal time of the population. It justifies the very simple definition used in microbiology (\"the time it takes for the population to double\", or doubling time) since one can consider that during the exponential phase of bacterial growth mortality is very low and as a result a bacterium is expected to be replaced by two bacteria in the next generation (the mother cell and the daughter cell). If the population dynamic is exponential with a growth rate \"r\" (i.e. \"n\"(\"t\") ~ α.e, where \"n\"(\"t\") is the size of the population at time \"t\"), then this measure of the generation time is \ngiven by:\nIndeed, formula_2 is such that \"n\"(\"t\" + \"T\") = \"R\" \"n\"(\"t\"), i.e. e = \"R\".\n\nThis definition is a measure of the distance between generations rather than a renewal time of the population. Since many demographic models are female-based (that is, they only take females into account), this definition is often expressed as a mother-daughter distance (the \"average age of mothers at birth of their daughters\"). However, it is also possible to define a father-son distance (average age of fathers at the birth of their sons) or not to take sex into account at all in the definition. In age-structured population models, an expression is given by:\nwhere \"r\" is the growth rate of the population, \"ℓ\"(\"x\") is the survivorship function (probability that an individual survives to age \"x\") and \"m\"(\"x\") the maternity function (or birth function, or age-specific fertility). For matrix population models, there is a general formula:\nwhere \"λ\" = e is the discrete-time growth rate of the population, F = (\"f\") is its fertility matrix, v its reproductive value (row-vector) and w its stable stage distribution (column-vector); the formula_5 are the elasticities of \"λ\" to the fertilities.\n\nThis definition is very similar to the previous one but the population need not be at its stable age distribution. Moreover, it can be computed for different cohorts and thus provides more information about the generation time in the population. This measure is given by:\nIndeed, the numerator is the sum of the ages at which a member of the cohort reproduces, and the denominator is \"R\", the average number of offspring it produces.\n", "id": "9503180", "title": "Generation time"}
{"url": "https://en.wikipedia.org/wiki?curid=38454300", "text": "Assisted colonization\n\nAssisted colonization, also known as assisted migration or managed relocation, is the act of deliberately moving plants or animals to a different habitat. The destination habitat may have either historically held the species or it may not have hosted the species, but the habitat provides the bioclimatic requirements to support it. Assisted colonization may also supplement an existing population in a site where their numbers are dwindling. All species have some natural capacity to disperse into new habitats and adapt to change, but ongoing climate change is so rapid that many species are unable to keep pace naturally. In order to prevent extinctions, some scientists and practitioners are considering assisting the dispersal of species that have poor natural dispersal ability. This idea has sparked intense debate over the potential benefits, including avoiding many species extinctions, and the risks, including accidentally introducing new invasive species. Although the debate remains primarily conceptual with few real-world applications, scientists and land managers have already begun to consider several specific assisted colonization projects.\n\nClimate change is expected to drive many species out of parts of their current ranges while creating new suitable habitats elsewhere. In order to avoid population declines and extinction due to climate change, many species will need to adapt or colonize newly suitable areas. Using a niche modeling approach, scientists have predicted that failure to migrate or adapt would result in eventual extinction of about a quarter of the world’s species this century under moderate climate change. The natural dispersal rates of many species are far slower than those needed to keep pace with projected habitat shifts in many regions of the world. Prehistoric climatic changes have resulted in massive global extinctions, and the rate of warming projected for the near future is many times faster than changes in the past 10,000 years, likely resulting in high rates of extinction by the end of this century in the absence of management. The inability of species to migrate in response to human-caused climate change has led some to consider exploring assisted colonization as a means for preventing extinctions.\n\nAssisted colonization is a specific type of species introduction. An introduction is any act of establishing a species in a habitat it does not currently occupy. It often refers to a long-distance relocation, such as the accidental introduction of an invasive species from one continent to another, or the intentional relocation of a species in decline to a habitat where it can persist. By contrast, assisted colonization acknowledges that the natural dispersal rate of many species may be too slow to naturally respond to rapid human-caused environmental change and asks, “if this species could disperse fast enough to keep pace with the changing environment, where would it establish?” Assisted colonization practitioners consider helping the species disperse into such sites, which are often immediately adjacent to the species’ historical range. Assisted colonization thus represents a small artificial boost to an otherwise natural process, acknowledging that the threat—rapid human-caused environmental change—was produced by humans in the first place. Confusion of assisted colonization with species introduction in general—often much larger in scale and with greater risk of adverse impacts—may be the principal reason why some are reluctant to consider assisted colonization (see Controversy, below).\n\nWhen first proposed, the idea was referred to as “assisted migration”. The terminology was later criticized for being reminiscent of natural, cyclic animal migrations in response to changing seasons. It was renamed “assisted colonization,” as colonization more accurately describes the natural phenomenon that management would seek to assist. Others have sought to further distinguish this idea from any natural process by referring to it as “managed relocation.” No specific name has yet been unanimously adopted, but within the scientific and conservation community, “assisted migration,” “managed relocation,” and “assisted colonization” are often used interchangeably and are understood to refer to the same idea.\n\nEven under rapid climate change, dispersal into new areas may not be necessary for some species to persist. Instead of tracking climate shifts through space, some species may be able to survive in their present locations by developing tolerance to new conditions through acclimatization and/or adaptation. The potential for acclimatization or adaptation to allow persistence in the face of climate change varies by species and is generally poorly understood. One study determined that evolution of higher temperature tolerance in some species of amphibians and reptiles will likely occur fast enough to allow these species to survive a 3 °C temperature increase over 100 years, consistent with low- to mid-range projections of global warming. By contrast, many species, such as most temperate trees, have longer generation times and therefore may adapt more slowly; they may take thousands of years to evolve a similar increase in temperature tolerance. Adaptation this slow would be insufficient for keeping up with expected future global warming if colonization of new habitats is not an option.\n\nGenerally speaking, there are three accepted ways that assisted colonization can take place, each one of them with specific benefits and situations in which it applies. They can be defined as reintroduction, introduction and augmentation processes.\n\nIn augmentation, a population is identified with a small number of mating individuals. This can lead to many problems, including inbreeding depression, and often leads to a dwindling number of individuals. Further complicating matters, with such a small population and consistent inbreeding depression, genetic drift is of worry as well, leading to high levels of homozygosity. To combat these problems, individuals are reintroduced to the population. This can be done via \"ex situ\" breeding of individuals or by physically relocating a separate population to join the identified, problematic population.\n\nIn introduction, a species is brought to a habitat in which it has never before existed. This can be done for a number of reasons, ranging from climate change associated habitat loss to the introduction of predator species that cannot be controlled. Generally speaking, this is the type of assisted colonization that contains the most potential for harmful effects, like those described elsewhere in this article. Currently, a number of introductions of endangered populations from Australia have been made with varying degrees of success to small islands near the mainland where the only reason that the population had not dispersed before was due to the physical waterway.\n\nReintroductions involve restoring a species to its native range. The species may no longer be found there due to any number of reasons, though most common is often the introduction of predators or habitat loss due to either climate change or other human factors. This is generally done to broaden the range of threatened populations and to reconnect fragmented populations.\n\nSignificant controversy has developed around the idea of assisted colonization since it was first put forth in the scientific literature in 2007. The two sides can be separated roughly as follows. Supports generally believe that the expected benefits of assisted colonization, including saving and strengthening species, outweighs the potential harm of any project. Detractors generally believe that other conservation techniques which do not include the high risk of invasive species are not only better suited but are also more likely to succeed. This debate continues throughout the literature generally due to a lack of real-world applications and follow-ups. Though these conservation efforts are becoming increasingly common, few long term looks at their success have been conducted.\n\nPerhaps the principal concern scientists have expressed over assisted colonization is the potential for relocated species to be invasive in their new habitats, driving out native species. The fear that assisted colonization will facilitate invasions stems mostly from observations of the vast numbers of species that have become invasive outside their native ranges by (often inadvertent) introduction by humans. Although most agree that assisted colonization efforts, unlike accidental introductions, should involve detailed planning and risk assessment, for some, any threat of introducing invasive species, no matter how small, disqualifies assisted colonization as a viable management response to climate change.\n\nThose who wish to keep assisted colonization on the table often note that the vast majority of historical species invasions have resulted from continent-to-continent or continent-to-island transportation of species and that very few invasions have resulted from the comparatively short-distance, within-continent movement of species proposed for assisted colonization. For example, Mueller and Hellman reviewed 468 documented species invasions and found that only 14.7% occurred on the same continent where the species originated. Of the 14.7%, the vast majority were fish and crustaceans. Terrestrial species that became invasive on the same continent where they originated were often transported across large biogeographic barriers, such as mountain ranges. These long-distance, within-continent translocations are unlike expected uses of assisted colonization, which generally involve helping species colonize habitats immediately adjacent to their current ranges.\n\nTo identify populations at risk and locate new potential habitats, conservationists often use Niche models. These models predict the suitability of habitats in the future based on how closely their climates resemble the climate currently inhabited by the species. Though useful for describing broad trends, these models make a number of unrealistic assumptions that restrict the usefulness of their predictions. For instance, they do not consider the possibility that species may be able to develop tolerance of new climates through acclimatization or adaptation.<ref name=\"doi10.1111/j.1461-0248.2005.00792.x\"></ref> Further, they do not account for the fact that a given species may perform better (e.g., become invasive) or worse (e.g., fail to establish) in a new habitat than in its current range if the community of competitor, predator, and mutualist species is different there. Additionally, because different climate variables (e.g., minimum January temperature, average annual precipitation) rarely shift in unison, it is possible that few areas will exactly match the historical climates of species threatened by climate change. Such multi-directional climate shifts will make it especially difficult to determine the species that are at greatest risk of habitat loss due to climate change and to predict future suitable habitat. The uncertainties in predictions of future suitable habitat limits confidence in assisted colonization decisions and has led some to reject assisted colonization entirely.\n\nDespite the uncertainty inherent in predictions of future suitable habitat, some studies have demonstrated that predictions can be quite accurate. A study of Hesperia comma butterflies in Britain identified unoccupied habitat sites that were likely to support the species under a warmer climate based on their similarity to occupied sites. As the climate warmed, the butterfly colonized many of the sites; most of the sites it did not colonize were located far from existing populations, suggesting they were uncolonized because the butterfly could not reach them on its own. The data suggested that the suitable, uncolonized sites could be good targets for assisted colonization. The results suggested that if investigators can demonstrate their model makes reliable predictions with real-world data, models might be trusted for informing assisted colonization decisions.\n\nThe science is clear that climate change will drive many species extinct, and a traditional, land-preservation ethic will not prevent extinctions. Those wary of moving species instead suggest expanding networks of habitat corridors, allowing species to naturally migrate into newly suitable areas. Under the rates of climate change projected for the coming decades, however, even perfectly connected habitats will probably be insufficient. Species that cannot naturally keep pace with shifting climates will be at risk regardless of habitat connectivity. Evidence suggests that slowly evolving and slowly dispersing species (including species that are dispersal-limited due to habitat fragmentation) will decline or go extinct in the absence of assisted colonization programs.\n\nIn their rejection of assisted colonization, Ricciardi and Simberloff cite the precautionary principle, stating that any unknown risk, no matter how small, of assisted colonization resulting in the creation of new invasive species is enough to require that it not be undertaken. Many scientists reject this position, however, noting that in many cases where extinctions due to climate change are likely, the risks of extinction from not facilitating colonization are probably far worse than the risks of facilitating colonization. They argue that the precautionary principle cuts both ways, and the risks of inaction must be compared against the risks of action. Others note that the ethics of assisting colonization will depend on the values of the stakeholders involved in a specific decision rather than the position of scientists on assisted colonization in general. At the very least, some note, scientists should conduct further research into assisted colonization and improve our capacity to predict specific outcomes instead of outright rejecting it.\n\nBecause confidence in expected outcomes is often greater in the short-term (e.g., 20 years) than the long-term future, it may be more reasonable to use short-term projections to guide actions. However, it is also important to consider whether the climate will remain suitable long enough for colonizing species to mature and reproduce, if that is the management goal.\n\nDue to climate change, accidental species introductions, and other global changes, there is nowhere on the planet free of human disturbance. Thus, the idea that land managers should refrain from creating human-altered communities through assisted colonization may be moot given that all communities have been altered by humans to some degree whether managers undertake assisted colonization or not. Given the reality of global change, it will be impossible to maintain past ecological communities indefinitely. Many therefore believe we should strive to maintain biodiversity and functioning ecosystems in the face of climate change, even if it means actively moving species beyond their native ranges. In the absence of assisted colonization, climate change is already causing many highly mobile species, such as butterflies, to colonize areas they have not previously inhabited. Through assisted colonization, managers could help rare or less-mobile species keep pace, possibly preventing future extinctions due to a their inability to colonize new areas fast enough. Though some argue that nature often responds to challenges more effectively in the absence of human intervention, others note that current climate change, itself, is a human intervention. Many species that would have been effective dispersers under slower, natural climate change may be left behind by more mobile species under current rates of human-caused climate change. Thus, through changing the climate, humans may already be artificially segregating species even without actively relocating them.\n\nCritics may also have major concerns about different genetic issues when considering assisted colonization such as maladaptation to novel environmental conditions and hybridization with similar species. These often depend on the genetic structure and level of genetic variation in the source populations. The environmental conditions in which these populations are being introduced must also be taken into account. In order to enhance genetic variation, and thus adaptive potential, material could be sourced from multiple populations. This is known as composite provenancing. However, if the environmental gradient is well known, such as predictable changes in elevation or aridity, source populations should be ‘genetically matched’ to recipient sites as best as possible to ensure that the translocated individuals ae not maladapted. This strategy of moving species beyond their current range has been suggested for those that are severely threatened or endangered. By moving them outside their native range, hopefully the immediate threats of predation, disease, and habitat loss can be avoided. However, these species are usually already suffering from some sort of genetic issue resulting from low effective population size such as inbreeding depression, loss in genetic diversity, or maladaptation. Therefore, caution must be taken with what few individuals remain and rapid population growth must be the primary goal. In the case of some species, this can be accomplished with a captive breeding program \n\nThe British Columbia Ministry of Forests, Lands, and Natural Resource Operations has acknowledged that climate change will likely threaten the health of the millions of trees that are planted in the province every year, with potential environmental and economic consequences:\nApproximately 300 million tree seedlings are planted in the western USA, British Columbia (BC) and Yukon each year. Many climatologists are predicting that the climate could be 3–4°C warmer when those trees are harvested 60-80 years after planting. These changes to climate will expose trees to increased stress and health risks, compromising the many goods and services from our forests.\n\nIn response to this threat, the Ministry has initiated a large-scale study to determine the long-term health of seedlings of 16 tree species planted beyond their native ranges, into areas expected to become suitable due to changes in climate this century. Results from the study will be used to develop guidelines for when and how assisted colonization of trees should be conducted.\n\nIn 2009, British Columbia also altered guidelines for selecting seeds for replanting forests after a timber harvest. Previously, foresters were required to use seeds from within 200 meters downhill and 300 meters uphill, but the new policy allows foresters to obtain seeds from up to 500 meters downhill, taking advantage of the fact that populations in warmer habitats downhill may be better adapted to the future climate of the restoration site.\n\nAlthough not actively engaging in assisted colonization, the Dixon National Tallgrass Prairie Seed Bank seeks to collect seeds from populations of species expected to decline or disappear due to climate change. They prioritize collections from populations at greatest risk of disappearance and for which suitable habitat is projected to occur elsewhere in the general region, keeping open the possibility of using collected seeds for assisted colonization projects in the future.\n\n", "id": "38454300", "title": "Assisted colonization"}
{"url": "https://en.wikipedia.org/wiki?curid=21410579", "text": "Chesson's index\n\nChesson's Index refers to a lookup table of feeding selectivity described by Jean Chesson in the early 1980s. and, according to a 2006 book, is based on ecologist Dr. Bryan F. J. Manly's \"alpha section index which allows to rank plants in order according to frequency in the diet. This index is intended to show whether a preference for a food item or resource exists by comparing the availability and use of that food item. The use of this index has been widespread with more than 400 citations in the scientific literature.\n", "id": "21410579", "title": "Chesson's index"}
{"url": "https://en.wikipedia.org/wiki?curid=12305602", "text": "Ecological relationship\n\nAn ecological relationship is the relationship between an organism in its ecosystem. All organisms in an ecosystem are connected in one way or another. Each interaction depends on the one before it. Each population interacts with one another in a complex web of relations. Ecological relationships help better to describe how they are connected.\n\nThere are ecological relationships in which two are oppositional and four are symbiotic. The oppositional relationships are predation and competition. The symbiotic relationships are mutualism, commensalism, amensalism , neutralism , cooperation and parasitism.\n\nThe ecological relationship an organism has depends on the way the organism adapted to its environmental pressures on evolutionary basis.\n\nThis is where one organism captures, kills and eats the other organism. The organism hunting is called the predator, while the organism being hunted is called the prey. Energy received from the Sun is transferred from animals when the prey is eaten by the predator. The predator now has its prey's energy.\n\nA predator is usually a carnivore that hunts, kills and eats other animals. For example, a snake eating a mouse: the snake is considered the predator because it is consuming the mouse. In another example, a striped marlin is a predator. It lives in the Pacific Ocean and preys on sardines, also a Pacific animal. Similarly, various birds eat earthworms.\n\nHowever, a predator can become the prey of another larger predator; for instance, a snake may become a meal for a hawk.\n\n\"In ecology, predation is a mechanism of population control. Thus, when the number of predators is scarce, the number of prey should rise. When this happens, the predators would be able to reproduce more and possibly change their hunting habits. As the number of predators rise, the number of prey decline. This results in food scarcity for predators that can eventually lead to the death of many predators.\"\n\nBecause of this, predation is called a \"positive-negative\" relationship. (Campbell) There is also Cannibalism. It is a more grade of predation. This is where in one population the organisms eat each other due to scarcity of food sources. (Lurdes Isufaj) Ex. Frogs are known for cannibalism too.\n\nThe prey does not necessarily have to be an animal, but can also be a plant. When prey is a plant, the relationship would be called an herbivore plant relationship.\n\nA perfect example of this would be,\" Galapagos tortoises \neat cactus plants that grow on the Galapagos Islands.\" (Bar-Yam, 2011).\n\nAnother example are the koalas. They have a special digestive system that allows them to break down tough eucalyptus leaves and remain unharmed by its poison (National Geographic).\n\nFinally, a squirrel is the herbivore (predator) and the nuts he eats are the plant (prey).\n\n\n\nCompetition is when organisms compete for the same resources like food, shelter,or mate. This is a negative relationship because both organisms are harming each other (Campbell).\nOrganisms competing can be from within the same species for example, two male elk fighting for a female mate. Elephants also fight each other so that the dominant elephant will get to breed with the female.\n\nAnother species that shows great competition between each other are the dolphins. Dolphins go along together and play with each other, but when it is time to eat; all dolphins have to compete for a meal.\n\nCompetition can be also found in two different species. A lizard and a frog can compete for a similar food they eat such as a small insect. This type of competition is only found when two different species share an ecological niche that they must compete over.\n\n\"Direct competition between different species almost always produces a winner and a loser- and the losing species dies out,\" or is forced to \nigrate to another ecosystem which can support them (Levine, 2010). This is the competitive exclusion principle. This principle says that two species that need the same resources cannot survive together in the same habitat. One organism will eventually die off, thus, called.\n\nThis is where both organisms participate and benefit from each other.\n\nAn example of this would be the bee and flower. Bee gets nectar and honey from flower. The bee contributes back to the flower by spreading the pollen so that the flowers can reproduce.This is a very common contribute to both the flower and the bee, they both rely on each other to survive. \n\nHumans and dogs/cats is one of the best examples of Mutualism. The human feeds and gives shelter to the dog/cat, then in exchange the dog/cat protects and loves the human.\n\nAnother example would be when the ox pecker lands on an impalas back and eats the ticks that are a parasite to the impala. The ox pecker is benefited because it gets a meal from the tick and the impala gets benefited because the tick is no longer on it. Similarly, monkeys pick fleas from other monkeys which benefits both because its like a treat.\n\nThere is a mutualistic relationship between spider crabs and algae. The algae live on the crabs' backs, allowing the spider crab to blend in with its environment, so that predators can't find them. The algae get a nice place to live, while in turn, the spider crab gets camouflaged. Thus, both organisms are benefited. \nThe Clownfish and Anemone would also be a good fit for mutualism because the Anemone protects the clownfish while the clownfish protects the Anemone. \"The clownfish benefits by having a protected home territory.\" \n\nFinally, there is even a mutualistic relationship within the human body. Bacteria live inside our intestines (getting a good place to live) and help us break down our food and get vitamins.\n\nCommensalism is a relationship in which one organism benefits from another organism that is not affected. This is a positive, neutral relationship. (Campbell)\n\nFor example, a small fish called the Pilot Fish follows underneath a shark and when the shark eats something the pilot fish eats the scrap pieces of the shark original kill.(Blue Planet BBC Documentary 2001). Also a shark and a remora. The remora eats the scrap pieces of the shark original kill.\n\nAnother example is of a birds nest in a tree. The bird is benefitting because the tree is giving the bird shelter and the tree is not getting anything in return.\n\nSimilarly, the transparent shrimp benefits from a reef because it hides within it (camouflaging), but the coral is not affected.\n\nAdditionally, the relationship between an infectious disease and its carrier, an animal such as a mosquito, could be classified as commensalism because the mosquito is unaffected by the presence of the disease, but the mosquito transfers it to a host in which the disease can reproduce or spread more easily to others.\n\n\"Often, the host species provid=nsportation for the other species.\" (www.Biology-Online.org) The whale and barnacles are a perfect example of this. \"Barnacles are crustaceans that have jointed legs and shells of connected overlapping plates. Instead of crawling after food, they glue themselves to rocks, ships, pillings, abalones, and maybe even whales and wait for food to wash by.\" (Oracle, 2000). The barnacles attach themselves to the whale. This way, the barnacle can get food faster. This does not affect the whale so he does not take the barnacle off.\n\nParasitism is a relationship in which one organism (the parasite) benefits while the other(the host) is harmed. This is a positive, negative relationship. (Campbell)( Dionne L Rice Jr)\n\nThe parasite usually lives on or inside the other organism.\n\nFor example, mosquito is a parasite, feeding on a human while transferring the disease called Malaria. Other examples would be ticks or fleas that live off of many large mammals. Similarly, head lice are an example of parasitism because they feed on blood from the humans head.\n\nIn Colorado, the pine bark beetle is a common parasite. The pine beetles lays its eggs in the pine trees, and then when the babies are born, they eat the layers of the tree which stops the tree from growing. (Robbins)\n\n\"Natural Selection favors parasites that are best able to locate hosts and feed on them.\"(Cambell, 1996).\n\n\n\n", "id": "12305602", "title": "Ecological relationship"}
{"url": "https://en.wikipedia.org/wiki?curid=5533009", "text": "Landscape connectivity\n\nLandscape connectivity in ecology is, broadly, \"\"the degree to which the landscape facilitates or impedes movement among resource patches\"\". Alternatively, connectivity may be a continuous property of the landscape and independent of patches and paths. Connectivity includes both structural connectivity (the physical arrangements of disturbance and/or patches) and functional connectivity (the movement of individuals across contours of disturbance and/or among patches). The degree to which a landscape is connected determines the amount of dispersal there is among patches, which influences gene flow, local adaptation, extinction risk, colonization probability, and the potential for organisms to move as they cope with climate change.\n\nAlthough connectivity is an intuitive concept, there is no single consistently-used metric of connectivity. Theories of connectivity include consideration of both binary representations of connectivity through \"corridors\" and \"linkages\" and continuous representations of connectivity, which include the binary condition as a sub-set \n\nGenerally, connectivity metrics fall into three categories:\n\n\nTypically, the \"natural\" form of connectivity as an ecological property perceived by organisms is modeled as a continuous surface of permeability, which is the corollary to disturbance. This can be accomplished by most geographic information systems (GIS) able to model in grid/raster format. A critical component of this form of modeling is the recognition that connectivity and disturbance are perceived and responded to differently by different organisms and ecological processes. This variety in responses is one of the most challenging parts of attempting to represent connectivity in spatial modeling. Typically, the most accurate connectivity models are for single species/processes and are developed based on information about the species/process. There is little, and often no evidence that spatial models, including those described here, can represent connectivity for the many species or processes that occupy many natural landscapes. The disturbance-based models are used as the basis for the binary representations of connectivity as paths/corridor/linkages through landscapes described below.\n\nCircuitscape is an open source program that uses circuit theory to predict connectivity in heterogeneous landscapes for individual movement, gene flow, and conservation planning. Circuit theory offers several advantages over common analytic connectivity models, including a theoretical basis in random walk theory and an ability to evaluate contributions of multiple dispersal pathways. Landscapes are represented as conductive surfaces, with low resistances assigned to habitats that are most permeable to movement or best promote gene flow, and high resistances assigned to poor dispersal habitat or to movement barriers. Effective resistances, current densities, and voltages calculated across the landscapes can then be related to ecological processes, such as individual movement and gene flow. \n\nGraphab is a software application devoted to the modelling of landscape networks. It is composed of four main modules: graph building, including loading the initial landscape data and identification of the patches and the links; computation of the connectivity metrics from the graph; connection between the graph and exogenous point data set; visual and cartographical interface.\nGraphab runs on any computer supporting Java 1.6 or later (PC under Linux, Windows, Mac...). It is distributed free of charge for non-commercial use.\n\nLandscape Ecology\n", "id": "5533009", "title": "Landscape connectivity"}
{"url": "https://en.wikipedia.org/wiki?curid=28267409", "text": "Janzen–Connell hypothesis\n\nThe Janzen–Connell hypothesis is a widely accepted explanation for the maintenance of tree species biodiversity in tropical rainforests. It was published independently in the early 1970s by Daniel Janzen and Joseph Connell. According to their hypothesis, host-specific herbivores, pathogens, or other natural enemies (often referred to as predators) make the areas near a parent tree (the seed producing tree) inhospitable for the survival of seedlings. These natural enemies are referred to as 'distance-responsive predators' if they kill seeds or seedlings near the parent tree, or 'density-dependent predators' if they kill seeds or seedlings where they are most abundant (which is typically near the parent tree). Such predators can prevent any one species from dominating the landscape, because if that species is too common, there will be few safe places for its seedlings to survive. However, because the predators are host-specific (also called specialists), they will not harm other tree species. As a result, if a species becomes very rare, then more predator-free areas will become available, giving that species' seedlings a competitive advantage. This negative feedback allows the tree species to coexist, and can be classified as a stabilizing mechanism.\n\nThe Janzen-Connell hypothesis has been called a special case of keystone predation, predator partitioning or the pest pressure hypothesis. The pest pressure hypothesis states that plant diversity is maintained by specialist natural enemies. The Janzen-Connell hypothesis expands on this, by claiming that the natural enemies are not only specialists, but also are distance-responsive or density-responsive.\n\nThis mechanism has been proposed as promoting diversity of forests as it promotes survival of a number of different plant species within one localized region. While previously thought to explain the high diversity of tropical forests in particular, subsequent research has demonstrated the applicability of the Janzen–Connell hypothesis in temperate settings as well. The Black Cherry is one such example of a temperate forest species whose growth patterns can still be explained by the Janzen–Connell hypothesis.\n\nDaniel Janzen published his hypothesis in 1970 in \"The American Naturalist\" under the article \"Herbivores and the Number of Tree Species in Tropical Forests.\" His hypothesis was based on the observation that in tropical forests (when compared to temperate forests), there were few new adult trees in the immediate vicinity of their parent tree. He explained the low density of tropical trees and lack of \"bunching\" of tree types around parent trees for two reasons: (1) the number of seeds decline with distance from the parent tree and (2) that the adult tree, its seeds, and seedlings are a source of food for host-specific parasites and diseases.\nUsing his observations, Janzen created a model demonstrating the probability of a seed maturation or a seedling survival as a function of distance from the parent tree (as well as total seed count, dispersal mechanism, and predatorial activity).\n\nJoseph Connell published his hypothesis in 1971 in Dynamics of Populations. Unlike Janzen, Connell proposed experiments that focused on the key prediction that exclusion of host-specific predators would cause a decrease in diversity as tree species with greater establishment or competitive ability formed low-diversity seedling and sapling communities where dominance was concentrated in a few species.\n\nHe formed his hypothesis through observations in Queensland, Australia. Along with Jack Greening Tracey and Larry Johnson Webb, he mapped trees in two rainforests and observed that smaller seedlings tended to occur in single-species clumps. Smaller seedlings also exhibited greater mortality, especially when their nearest neighbor was an individual of the same species. This pattern lessened with growth and age until seedlings exhibited similar pattern diversity to adults. To reinforce these observations, Connell ran an experiment showing that adult trees have a deleterious effect on smaller trees of the same species. In another experiment, Connell found that pre-germination predation was greater on seeds near adults of the same species than those near adults of others. Through these observations, Connell suggests that each tree species has host-specific enemies that attack it and any of its offspring which are close to the parent. This emphasizes the importance of the role of predation in preventing trees from forming single-species groves, which is probably the only way in which one species of tree could exclude others by interspecies competition.\n\nPlant pathogens follow infectious disease dynamics. The basic reproductive rate formula_1 of a disease is dependent on three variables such that:\n\n<br><br>\n<br>Where β is the transmission rate or infectiousness of the disease, \"L\" is the average infection time of the host, and \"S\" is the density of the host population. By decreasing any one of the variables, the reproduction rate of the disease decreases. Since seed dispersal is such that the highest density of seeds is around the parent with density decreasing with distance from the parent, the reproduction rate of a disease infecting seeds and seedlings will be highest around the parent and decrease with distance. Thus, seedlings close to the parent are likely to die due to the disease prevalence. However, seedlings farther away are less likely to encounter the disease and therefore will more likely grow into adults.\n\nSpecialist herbivores who consume plant matter can also be thought of as having a \"transmission rate\" between individuals similarly to a disease. Tree predators (especially herbivorous insects) are limited by the ease of movement. When individuals are closer together at high density, movement between trees is easier and the predators quickly spread out. However, at low tree density, predators can not find the next individual with as much ease and thus often have low transmission rates leading to less specialist predation.\n\nMany studies examining the Janzen–Connell hypothesis have shown supporting patterns with a number of tree species, but despite this there are also problematic aspects of the hypothesis.\n\nThere have been over 50 studies designed to test predictions of this hypothesis in tropical and other settings and most show that many tree species exhibit patterns consistent with Janzen–Connell effects. Studies that have supported the Janzen–Connell hypothesis:\n\nStudies questioning the Janzen–Connell hypothesis:\n\nIt is tricky to form conclusions regarding the accuracy of the Janzen–Connell hypothesis as it is difficult to falsify. This is because:\n\nIt is likely that a number of mechanisms underscore the coexistence of similar species and thus cause biodiversity in ecosystems. It is possible the Janzen–Connell hypothesis is applicable only for some species depending on species characteristics. The hypothesis may also be affected by the kind of predator or pathogen as preliminary research has shown that the hypothesis is true only when host-specific predators have limited mobility with a range less than the seed dispersal range.\n", "id": "28267409", "title": "Janzen–Connell hypothesis"}
{"url": "https://en.wikipedia.org/wiki?curid=39651706", "text": "Subterranean fauna\n\nSubterranean fauna is referred to animal species adapted to live in underground environment. Troglofauna and stygofauna are the two types of subterranean fauna. Both are associated with hypogean habitats – troglofauna is associated with terrestrial subterranean environment (caves and underground spaces above the water table), and stygofauna with all kind of subterranean waters (groundwater, aquifers, subterranean rivers, dripping bowls, gours, etc.). \n\nSubterranean fauna is found worldwide and includes representatives of many animal groups, mostly arthropods and other invertebrates. However, there is a number of vertebrates (such as cavefishes and cave salamanders), although they are less common. Because of the complexity in exploring underground environments, many subterranean species are yet to be discovered and described. \n\nPeculiarities of underground habitat make it an extreme environment and, consequently, underground species are usually less than species living in epigean habitats. The main characteristic of underground environment is the lack of sunlight. Climatic values, like temperature and relative humidity, are generally almost stable – temperature corresponds to annual mean temperature in the place where the cavity opens, relative humidity rarely drops below 90%. Food sources are limited and localized. The lack of sunlight inhibits photosynthetic processes, so food comes only from epigean environment (through percolating water, gravity, or passive transport by animals). Important food sources in underground habitat are animals being decomposed and bat guano, that creates large invertebrate communities in such caves. \n\nCave dwelling animals show different levels of adaptations to underground environment. According to a recent classification, animals living in terrestrial subterranean habitats can be classified into 3 categories, based on their ecology:\nRegarding stygofauna, the corresponding words stygobionts (or stygobites), stygophiles and stygoxenes are used.\n\nCharacteristics of underground environment caused cave dwelling animals to evolve a number of adaptations, both morphological and physiological. Examples of morphological adaptations include depigmentation (loss of external pigmentation), a reduction of cuticle thickness and the often extreme decrease of eyesight culminating in anophthalmia (complete loss of eyes). Exceptions, however, are harvestmen (Opiliones) in New Zealand caves, which possess large, functional eyes, presumably because these spider-like chelicerates feed on cave-dwelling, light-emitting glowworm larvae \"Arachnocampa\" which they detect visually . Other adaptations include the development and elongation of antennal and locomotory appendages, in order to better move around and respond to environmental stimuli. These structures are well endowed with chemical, tactile and humidity receptors (such as Hamann's organ in the cave beetle \"Leptodirus\" \"hochenwartii\"). \n\nPhysiological adaptations include slow metabolism and reduced energy consumption, due to limited food supply and low energy efficiency. This is likely to be realized through reducing movements, erasing aggressive interactions, improving feeding capability and food usage efficiency, and through ectothermy. As a consequence, cave dwelling animals can resist without eating for long time, live more than comparable epigean species, reproduce late in their lifespan, and produce less and bigger eggs.\n\nSubterranean fauna have evolved in isolation. Stratigraphic barriers, such as rock walls and layers, and fluvial barriers, such as rivers and streams, prevent or hinder the dispersal of these animals. Consequently, subterranean fauna habitat and food availability can be very disjunct and precludes the great range of observed diversity across landscapes. \n\nFloodwaters can be detrimental to subterranean species, by dramatically changing the availability of habitat, food and connectivity to other habitats and oxygen. Many subterranean fauna are likely to be sensitive to changes in their environment and floods, which can accompany a drop in temperature, may adversely affect some animals.\n\nHumans also pose a threat to troglofauna. Mismanagement of contaminants (e.g. pesticides and sewage) may poison subterranean fauna communities and removal of habitat (e.g. rising/lowering of the watertable or various forms of mining) can also be a major threat.\n\n", "id": "39651706", "title": "Subterranean fauna"}
{"url": "https://en.wikipedia.org/wiki?curid=40005621", "text": "Mesoamerican Society for Ecological Economics\n\nThe Mesoamerican Society for Ecological Economics (SMEE) is a regional chapter of the International Society for Ecological Economics (ISEE). After its foundation in 2008 at Guatemala City, the organization has already celebrated its first International Conference in 2010 at Mexico City and will carry out the second International Conference, EcoEco Alternatives, between March 4 and 8 2014 at the main campus of the University of Costa Rica.\n\nThis branch of the ISEE has a unique emphasis within ecological economics. Topics like social justice and the human value in environmental conservation prevail in this region. As a consequence of the strong influence from Joan Martinez Alier's \"environmentalism of the poor or social environmentalism\", major attention is given to ecological-distributive conflicts. Alier insists that in the South a struggle exists against these conflicts generated by economic growth, mainly by the North. These endeavors \"attempt to preserve the access of the communities to natural resources and services.\" \n\nOn top of the negative effects on the environment by economic distribution, the cultural influence is also widely debated. For instance, the anthropologist Arturo Escobar suggests that culturally-driven preferences are one of the main factors degrading the environment. For example, society naturally gives privilege to the capitalist model that distributes natural resources with the purposes of production and profit, instead of endorsing the agroforestal ecosystem model, which is less harmful to the environment. As part of this alternate perception in Mesoamerica, Ecological economics doesn't consider that the economic valuation of natural resources nor environmental norms are effective solutions to these social-environmental conflicts. On the other hand, an alternative based on community-based conservation and the management of sustainability is more advocated upon. By adding the latter cultural perspective, the three pillars of sustainable development (the social, environmental, and economic) end up being addressed by these proponents.\n\nAfter the second biennial meeting of the International Society for Ecological Economics in 1994 at San José, Costa Rica, several professionals in the region became interested in creating a branch of this organization in their own countries to respond to the increasing development and worsening of social-environmental conflicts by the conventional-economics-based policies.\n\nHowever, it wasn't until 2008 that the efforts of the Latin American Social Sciences Institute in Guatemala, the International Center for Political Economy at the National University of Costa Rica, and the Metropolitan Autonomous University of Mexico resulted in the Ecological Economics Forum, May 26 and 27 2008 at Guatemala City, with the participation of zealous youth, students, and 50 professionals of Mesoamerica.\n\nHighly-recognized experts spoke, such as Alejandro Nadal, Coordinator of the working group on the Environment, Macroeconomics, Trade and Investments of the International Union for Conservation of Nature (IUCN); David Barkin and Roberto Constantino from the Metropolitan Autonomous University of Mexico; Eduardo García Frapolli from the Center for Ecosystem Research of the National Autonomous University of Mexico; Bernardo Aguilar of Prescott College, AZ, U.S. and Executive Director of the Fundacion Neotropica in Costa Rica; Miguel Martínez of the World Wide Fund for Nature (WWF Guatemala), and Juan Pablo Castañeda of the Institute of Agriculture, Natural Resources, and the Environment of the Rafael Landívar University in Guatemala.\n\nThis meeting undertook the writing of the organization's Constitution and the election of the first Board of Directors. Under the lead of the first President, M. Sc. Iliana Monterroso of Guatemala, the consolidation of the legal inscription and statutes took place.\n\nAccording to the Forum's participants, the main objectives of the SMEE are to create an open field for discussion of the methodological and theoretical development of Ecological economics, to promote interdisciplinary, multidisciplinary, and transdisciplinary scientific research, and to support academic initiatives related to this thematic in the region.\n\nIn 2010, the First International (and Biennial) Conference of the SMEE was celebrated at the Ecological Park of Xochimilco, Mexico City, from November 22 to the 26th. Very influential speakers such as Fander Falconí; David Barkin; Mario Pérez, and Carlos Muñóz Piña lectured about and discussed the Ecological economics platform for the advancement of social justice, environmental justice, and the principles of sustainability.\n\nSince then, the new Board of Directors has had to deal with a shortage of memberships and the last financial crisis; but despite these challenges, it has achieved important progress in creating its website and completing several ecological economics studies and projects with the Fundacion Neotropica. Furthermore, the organization foresees the inauguration of a professional Master's program on ecological economics and political ecology at the University for International Cooperation and the proceeding of the 2014 EcoEco Alternatives Biennial Conference.\n\nThe Board of Directors rotates every two years and is usually elected around the biennial conference. The next election will take place in March, 2014.\n\nFirst Board of Directors (2008-2011):\nSecond Board of Directors (2011-2014):\nCurrent Board of Directors (2014-2016):\n\nThe Second International Conference of the Mesoamerican Society for Ecological Economics will take place at the Rodrigro Facio campus of the University of Costa Rica from March 4 to the 8th, 2014, with the support of the School of Biology and the Fundacion Neotropica. Its purpose is to further the debate on Ecological economics and to sensitize more people about the importance of the ecological crisis and the solutions proposed by this school of thought.\n\nThe Conference's thematic will be \"Advancing Towards Alternatives for People and Ecosystems in Latin America\". It will include multidisciplinary, interdisciplinary, and transdisciplinary debates about the resolution of social-environmental conflicts, the alternatives within the ecological economics model for handling production and services, and the social conflicts related to the distribution of wealth and gender.\n\n", "id": "40005621", "title": "Mesoamerican Society for Ecological Economics"}
{"url": "https://en.wikipedia.org/wiki?curid=2636160", "text": "Kīpuka\n\nA kīpuka is an area of land surrounded by one or more younger lava flows. A kīpuka forms when lava flows on either side of a hill, ridge, or older lava dome as it moves downslope or spreads from its source. Older and more weathered than their surroundings, kīpukas often appear to be like islands within a sea of lava flows. They are often covered with soil and late ecological successional vegetation that provide visual contrast as well as habitat for animals in an otherwise inhospitable environment.\n\n\"Kīpuka\", along with \"aā\" and \"pāhoehoe\", are Hawaiian words related to volcanology that have entered the lexicon of geology. Some have used the word informally as applying to any place where biological life endures the encroachment of civilization, an \"island of life.\"\n\n\"Kīpuka\" provides useful study sites for ecological research because they facilitate replication; multiple \"kīpuka\" in a system (isolated by the same lava flow) will tend to have uniform substrate age and successional characteristics, but are often isolated-enough from their neighbors to provide meaningful, comparable differences in size, invasion, etc. They are also receptive to experimental treatments. \"Kīpuka\" along Saddle Road on Hawaii have served as the natural laboratory for a variety of studies, examining ecological principles like island biogeography, food web control, and biotic resistance to invasiveness.\n\n\n", "id": "2636160", "title": "Kīpuka"}
{"url": "https://en.wikipedia.org/wiki?curid=40399359", "text": "Bioeffector\n\nA Bioeffector is a viable microorganism or active natural compound which directly or indirectly affects plant performance (Biofertilizer), and thus has the potential to reduce fertilizer and pesticide use in crop production.\n\nBioeffectors have a direct or indirect effect on plant performance by influencing the functional implementation or activation of biological mechanisms, particularly those interfering with soil-plant-microbe interactions.\nIn contrast to conventional fertilizers and pesticides, the effectiveness of bioeffectors is not based on a substantial direct input of mineral plant nutrients, either in inorganic or organic forms.\n\n\nUnder the Acronym \"Biofector\" the European Union supports the Research of Bioeffectors under the leadership of the University of Hohenheim (Coordinator Guenter Neumann).\nThe results of the project will be evaluated by the members of the Association Biostimulants in Agriculture (ABISTA) and provided agriculture for use and EU institutions for the legislative and registration procedures. \n\nOther Biostimulants Organisations are European Biostimulant Industry Council, International Biocontrol Manufacturers' Association and Annual Biocontrol Industry Meeting.\n\n", "id": "40399359", "title": "Bioeffector"}
{"url": "https://en.wikipedia.org/wiki?curid=40565660", "text": "Checkerboard score\n\nIn biodiversity studies, the checkerboard score or C-score is a statistic which determines the randomness of the distribution of two or more species through a collection of biomes. The statistic, first published by Stone and Roberts in 1990, expands on the earlier work of Diamond that defined a notion of \"checkerboard distributions\" as an indicator of species competition.\n\nA low c-score indicates a higher randomness, i.e. a greater likelihood that the distribution of one species has not been directly affected by the presence of other species.\n\nGiven two species \"sp\", \"sp\" and \"n\" islands, an incident matrix is built.\nIn the 2xn incident matrix, each row represents one of the two species and each column represents a different island.\nThe matrix is then filled with each cell being set to either 0 or 1. Cell with the value of 0 means that a given species doesn't exist in the given island whilst the value of 1 means that the species do exist in the given island.\n\nThe calculation of the co-occurrence of two species \"sp\", \"sp\" in the given set of islands is done as follows:\n\nThe checkerboard score (c-score) for the colonisation pattern is then calculated as the mean number of checkerboard units per species-pair in the community:\n\nFor M species, there are species-pairs, so C-score is calculated:\n\nThe C-score is sensitive to the proportion of islands that are occupied, thereby confounding comparisons between matrices or sets of species pairs within them. An extension of the C-score therefore standardizes by the number of islands each species-pair occupies using:\n", "id": "40565660", "title": "Checkerboard score"}
{"url": "https://en.wikipedia.org/wiki?curid=1871862", "text": "Foundation species\n\nIn ecology, the term foundation species is used to refer to a species that has a strong role in structuring a community. A foundation species can occupy any trophic level in a food web (i.e., they can be primary producers, herbivores or predators). The term was coined by Paul K. Dayton in 1972, who applied it to certain members of marine invertebrate and algae communities. It was clear from studies in several locations that there were a small handful of species whose activities had a disproportionate effect on the rest of the marine community and they were therefore key to the resilience of the community. Dayton’s view was that focusing on foundation species would allow for a simplified approach to more rapidly understand how a community as a whole would react to disturbances, such as pollution, instead of attempting the extremely difficult task of tracking the responses of all community members simultaneously. The term has since been applied to range of organisms in ecosystems around the world, in both aquatic and terrestrial environments. Aaron Ellison \"et al.\" introduced the term to terrestrial ecology by applying the term foundation species to tree species that define and structure certain forest ecosystems through their influences on associated organisms and modulation of ecosystem processes.\n\nA study conducted at the McKenzie Flats at the Sevilleta National Wildlife Refuge in New Mexico, a semi-arid biome transition zone, observed the result of loss of a variety of different dominant and codominant foundation species of plants on the growth of other species. This transition zone consists of two Chihuahuan Desert species, black grama (\"Bouteloua eriopoda)\" and creosote bush (\"Larrea tridentata)\", and a Shortgrass Steppe species, blue grama (\"Bouteloua gracillis)\". Each species dominates an area with a specific soil environment. Black grama dominates sandy soils, while blue grama dominates in soils with high clay content, and creosote bush dominates fine-textured soil with surface gravel. This study noted that responses to the loss of foundation species is dependent on a variety of different factors from the ability of a species to recover to the climate conditions of the ecosystem to the patterns in dominance and explored the possible reasons for the outcomes of the study. The results indicated that in areas with just one dominant foundation species, its loss caused a shift in dominance to a mixed dominant community. For example, the creosote bush dominated shrubland saw a shift in dominance to 32% by other shrubs, 26% by perennial grasses, and 22% by perennial forbs following the removal of creosote bush. Another finding was that regardless of the community type and the species removed, the loss of foundation species resulted in an overall increase in black grama supporting the notion that the outcome is greatly affected by recovery ability of species removed or loss.\n\nAnother study observed the effects of loss of foundation Eastern hemlocks (\"Tsuga canadensis\") in a forest ecosystem. Eastern hemlocks are a foundation species in eastern North American forests, but have been threatened by the accidental introduction of woolly adelgid. This study observed the effects that a loss in Eastern Hemlocks would have on the populations of arthropods, such as ants, beetles, and spiders, since these species are known indicators of environmental change. The results found that in areas of hemlock removal, there was an overall increase and influx of arthropod species. Researchers suggested that this was due to an increase in open habitats from the loss of the hemlocks. The results of this hemlock study corroborated with those from the previous McKenzie Flats study discussed in that the loss of foundation species led to a proliferation of species diversity in the affected area. These results seem to contradict a long-standing belief that foundation species play a vital role in communities and ecosystems by creating habitats for organisms, suggesting that in some circumstances they bottleneck species diversity.\n\nFoundation species play a vital role in structuring a community; however, this can be in a variety of different ways. The presence of a foundation species has the ability to either reduce or increase species diversity depending on its particular role in a specific ecosystem. The studies discussed highlighted examples in which foundation species limited species diversity in a similar and differing taxa (McKenzie Flats study and Eastern hemlock study, respectively); however, there are many other examples in which removal of foundation species could decrease species diversity within the same or differing taxa.\n\n", "id": "1871862", "title": "Foundation species"}
{"url": "https://en.wikipedia.org/wiki?curid=40878571", "text": "Vertical ecosystem\n\nA vertical ecosystem is an architectural gardening system developed by Ignacio Solano from the mur vegetalise created by Patrick Blanc. This new approach enhances the previous archetype of mur vegetal and considers the relationship that exists between a set of living organisms, biocenosis, inhabiting a physical component, biotope. The system is based on the automated control of nutrients and plant parameters of the original wall, adding strains of bacteria, mycorrhizal fungi and interspecific symbiosis in plant selection, creating an artificial ecosystem from inert substrates. The system was created in 2007 and patented in 2010.\n\nAmongst abiotic factors that influence vertical ecosystems, namely the substrate and its environmental conditions, the physio-chemical characteristics possessed by the means are decisive. The texture, porosity and depth of the substrate, those that in a natural ecosystem are edaphic factors, have been tested to the point of finding fitogenerate materials with perfect levels of absorption and humidity for the development of more than forty living families of plants represented by around 120 species. Moreover, the substrate used in the system developed by Ignacio Solano provides the ecosystem with the necessary resistance to serve as a high-durability biotope.\n\nEnvironmental factors such as light, temperature and humidity are controlled by automated systems in interior vertical ecosystems. Ecosystems that are situated outside require study and analysis of the natural variables of their particular area, combined with a study of the behaviour of the numerous plant species in the biotope in each location. The selection and combination of species is one of the key factors for correct development. This is known as positive allelopathy.\n\nHydrological factors, such as pH levels, the conductivity of the water, dissolved gases and salinity, are balanced with precision so that the hydroponic system functions at its maximum capacity. The objective required by this system is to incorporate all the nutrients and micronutrients necessary for the health of the plants, and therefore the whole ecosystem, in a constant manner. To control these variables, the vertical ecosystem implements a system of sensors and warnings that inform of any anomaly of measurements in real time, allowing remote monitoring and control of the system.\n\nVertical ecosystems enable plant species, fungi, and bacteria to live in an environment of almost unlimited resources, generating interactions favourable to the system. In this way, they encourage healthy and exponential growth in their evolutionary stages, until they manage to adjust to their maximum value, known as the load capacity: the optimum capacity of living species interacting without stress in a limited space in search of mutualisms and intraspecific associations that benefit all the species involved. The success of a vertical ecosystem depends on the control of abiotic and biotic factors that limit the growth of plant populations, the control of \"environmental resistance\".\n\nVertical ecosystems aim to prolong the life of planted species and bring the benefits of a traditional vertical garden, including: absorption of CO2, heavy metals and dust, natural thermal insulation, and reduction of noise pollution.\n\n", "id": "40878571", "title": "Vertical ecosystem"}
{"url": "https://en.wikipedia.org/wiki?curid=41387300", "text": "Empty forest\n\nEmpty forest is a term coined by Kent H. Redford in his 1992 article \"The Empty Forest\" published in \"BioScience\". Empty forest refers to ecosystems that is void of large mammals. Empty forests often have large, fully grown trees, but lack large mammals as a result of human impact. Empty forests are characterized by an otherwise excellent habitat, except for the absence of all large mammals. Simply because a forest is full of trees, does not mean it is a healthy forest. Empty forests are a type of ecosystem that shows that human impact can destroy an ecosystem from within as well as from without.\n\nMany large mammals that are disappearing, such as deer and tapirs, are important for seed dispersion. Many tree species who are very localized in their dispersion rely on mammals rather than the wind to disperse their seeds. Furthermore, when seed predation is down, trees with large seeds begin to completely dominate those with small seeds, changing the balance of plant life in an area.\n\nPredatory large mammals are important for increasing overall diversity by making sure that smaller predators and herbivores do not become overabundant and dominate. An absence of large predators seems to result in uneven densities of prey species. Even though certain animals may not have become completely extinct, they may have lowered in numbers to the point that they have suffered an ecological extinction. The animals that have most likely suffered an ecological extinction in neotropical forests are the ones who are the most important predators, large seed dispersers, and seed predators.\n\nThe defaunation of large mammals can be done by direct or indirect means. Any type of human activity not aimed at the animals in question that results in the defaunation of those animals is indirect. The most common means of indirect defaunation is habitat destruction. However, other examples of indirect means of defaunation of large mammals would be the over-collection of fruits and nuts or over-hunting of prey that large mammals need for food. Another example of an indirect means of the defaunation of large mammals is through the by-products of modern human activities such as mercury and smoke, or even noise pollution.\n\nThere are two categories of direct defaunation. They include subsistence hunting and commercial hunting. The most common species of animals hunted are typically the largest species in their area. The large mammals in an area are often represented by only a few species, but make up a major part of the overall biomass. In areas with only moderate hunting, the biomass of mammalian game species decreases by 80.7%. In areas with heavy hunting, the biomass of mammalian game species can decrease by 93.7%.\n", "id": "41387300", "title": "Empty forest"}
{"url": "https://en.wikipedia.org/wiki?curid=41450867", "text": "Centre for Ecology &amp; Rural Development\n\nThe Centre of Ecology & Rural Development (CERD) is an Indian organisation which is part of the Pondicherry Science Forum. It was exclusively formed for taking up meaningful interventions in Health, Sanitation, Natural Resource Management, Energy, Watershed management and ICT for development.\n\nCERD was set up in the year 1994 jointly by the Pondicherry Science Forum and Tamil Nadu Science Forum to take up S&T based development initiatives improving the rural livelihoods of weaker sections. The earlier works included interventions in sericulture, vegetable leather tanning, fish aggregation device etc.\n\nCERD has a field station at Bahoor called the Kalanjiyam (meaning Granary in Tamil) which acts has a hub of agriculture and technology options for the surrounding area.\n\nCERD has a full-time manpower structure with a committed team of scientists working on a variety of areas ranging from women’s technology, science communication, Continuing Education, Participatory Irrigation management through local democratic people’s institutions, women’s micro credit networks etc.\n\nThe latest of the projects that CERD is now implementing includes the Women’s Technology Park (WTP), an AICP Project on BIOFARM, a watershed development project in Sedappatti Block of Madurai funded by NABARD, the Tank Rehabilitation Project-Pondicherry etc.\n\nR&D Work on Alternate Soil Fertility Management Strategies\nSystems for Irrigated and dry land crops.\nDeveloped Decision System (DSS) for Soil Fertility Mgmt.\n\nReduction of external inputs.\nIncreasing internal resource flows in the farming system.\nEnsuring nutritional security of the whole farming system.\n\nInitiated programmes in Madurai district.\nParticipatory planning, implementation and management of the Watershed through people’s organizations.\n\nPilot work on irrigation tanks in Pondicherry.\nEvolved guidelines for sustainable institutional structures.\nAll stakeholder participation ensured including women, dalits of landless communities.\nLarge scale encroachment eviction through participatory approach leading to Participatory Irrigation Mgmt.\nWorked in low energy technologies for water system development (Oorani – drinking water pond) in Ramanathapuram\n\nEvolved successful models for participatory wasteland reclamation through coalition \nbetween landless SHG women and farmers’ groups.\nSustainable income for landless Self-help Group (SHG) women through collective farming.\n\nEstablished the first successful model of Village Information Centre known as Samadhan Kendra through \nunique content creation in local language.\nSoftware creation for local planning and for primary production in local language \nincluding Decision Support Systems.\n\nCERD will expand its activities in this area by constructing more stoves and also by expanding the works to other areas like Tamil Nadu etc. CERD construction of a fuel efficient Tawa for making dosa/parotta also more of this also will be done during the coming years. Subsidies from the Renewable Energy Agency will be sought for the Tawa stove also and that will be another recognition for the work being carried out.\n\nWith technical collaboration from IISc. Bangalore, CERD will be constructing \nbiogas units and this will be a new area that CERD will be treading to. \nThe units are not gobar based but instead will be based on biomass\ndecomposition and tapping the biogas for cooking purposes.\n\nAlready an Organic Farmers’ Association has been formed and CERD will be extending full \nsupport to expanding this network including getting organic certification processes \nfor the farmers and for arranging marketing linkages for their organic produce. \nThis will have full backward and forward linkages starting from seeds, \nplant protection, harvest and post harvest options.\n\nThis will be mainly women-focused especially for women under SHGs \nsince the malnutrition levels of women in Pondicherry \nare very high and it is estimated that about 80% women face malnutrition. \nThis programme also will have complete backward and forward linkages from seeds, \nbiomanures, bio pesticides, processing and value addition etc.\n\nCERD will be concentrating more on viable village level enterprises for improved livelihood options for women, dalits and other weaker sections with providing necessary S&T inputs and EDP skills.\n\n", "id": "41450867", "title": "Centre for Ecology &amp; Rural Development"}
{"url": "https://en.wikipedia.org/wiki?curid=41532403", "text": "Potential natural vegetation\n\nIn ecology, potential natural vegetation (PNV) is the vegetation that would be expected given environmental constraints (climate, geomorphology, geology) without human intervention or a hazard event.\n\nThe concept has been developed in the mid 1950s by phytosociologist Reinhold Tüxen, partly expanding on the concept of climax.\n\nPNV is widely used in modern conservation and renaturation projects to predict the most adapted species for a definite ecotope. Native species being considered having optimum ecological resilience for their native environment, and the best potential to enhance biodiversity.\n\nTo determine \"natural\" vegetation, scientists research the original vegetation of a land through retrospective ecology.\n\nStudy of past ecosystems allowed to demonstrate, for instance, that numerous contemporary biotopes (like the \"wild\" Slovenian forests for instance), supposedly largely untouched, were in fact very remote from their natural vegetation. (No citation)\n\nIn Japan Prof. Akira Miyawaki, demonstrated after study that, on the one hand, long supposed \"native species\" had in fact been introduced on account of human intervention since over 1000 years (especially, coniferous being privileged over deciduous). On the other hand, that reforestation with \"original\" species gives good and often spectacular results. (No citation)\n\nMaps of potential natural vegetation are used worldwide for improved ecosystem comprehension and management.US PNV map\n\nHowever the concept is subject to debate, on similar grounds as for the climax theory. Critics argue that ecosystems are not static but ever dynamic: as bioclimatic conditions constantly evolve, it is illusory to define either a final or a primary stage of vegetation.\n", "id": "41532403", "title": "Potential natural vegetation"}
{"url": "https://en.wikipedia.org/wiki?curid=41871131", "text": "Wooded meadow\n\nWooded meadows (also named \"wood-meadows\", \"park meadows\", etc.) are ecosystems in temporal forest regions. They are sparse natural stands with a regularly mown herbaceous layer.\n\nWhile frequent throughout Europe during the Medieval period and before, wooded meadows have largely disappeared. Wooded meadows originated from the practices of hunter-gatherer communities. They were important in terms of social organization around a natural resource and determined much of the community's interactions with the natural world. In the early 20th century, wooded meadows were used for fruit cultivation in Sweden, however their prevalence has decreased substantially due to changes in land management and a movement toward more intensive types of agroecosystems. The more typical, calcicolous wooded meadows are common around the Baltic Sea.\n\nWooded meadows have high species richness. In some of the current Estonian wooded meadows, world record species densities have been recorded (up to 76 species of vascular plants per square meter).\n\n\n", "id": "41871131", "title": "Wooded meadow"}
{"url": "https://en.wikipedia.org/wiki?curid=624313", "text": "Mating system\n\nA mating system is a way in which a group is structured in relation to sexual behaviour. The precise meaning depends upon the context. With respect to animals, the term describes which males and females mate, under which circumstances; recognised systems include monogamy, polygamy (which includes polygyny, polyandry, and polygynandry), and promiscuity, all of which lead to different mate choice outcomes and thus these systems affect how sexual selection works in the species which practice them. In plants, the term refers to the degree and circumstances of outcrossing. In human sociobiology, the terms have been extended to encompass the formation of relationships such as marriage.\n\nThe primary mating systems in plants are outcrossing (cross-fertilisation), autogamy (self-fertilisation) and apomixis (asexual reproduction without fertilization, but only when arising by modification of sexual function). Mixed mating systems, in which plants use two or even all three mating systems, are not uncommon.\n\nA number of models have been used to describe the parameters of plant mating systems. The basic model is the mixed mating model, which is based on the assumption that every fertilisation is either self-fertilisation or completely random cross-fertilisation. More complex models relax this assumption; for example, the effective selfing model recognises that mating may be more common between pairs of closely related plants than between pairs of distantly related plants.\n\nThe following are some of the mating systems generally recognized in animals:\n\nThese mating relationships may or may not be associated with social relationships, in which the sexual partners stay together to become parenting partners. As the alternative term \"pair bonding\" implies, this is usual in monogamy. In many polyandrous systems, the males and the female stay together to rear the young. In polygynous systems where the number of females paired with each male is low and the male will often stay with one female to help rear the young, while the other females rear their young on their own. In polygynandry, each of the males may assist one female; if all adults help rear all the young, the system is more usually called \"communal breeding\". In highly polygynous systems, and in promiscuous systems, paternal care of young is rare, or there may be no parental care at all.\n\nThese descriptions are idealized, and the social partnerships are often easier to observe than the mating relationships. In particular:\n\n\n", "id": "624313", "title": "Mating system"}
{"url": "https://en.wikipedia.org/wiki?curid=583598", "text": "Oxygen cycle\n\nThe oxygen cycle is the biogeochemical cycle of oxygen within its four main reservoirs: the atmosphere (air), the total content of biological matter within the biosphere (the global sum of all ecosystems), the hydrosphere (the combined mass of water found on, under, and over the surface of planet Earth), and the lithosphere/Earth's crust. The main driving factor of the oxygen cycle is photosynthesis, which is responsible for the modern Earth's atmosphere and life on Earth (see the Great Oxygenation Event).\n\nBy far the largest reservoir of Earth's oxygen is within the silicate and oxide minerals of the crust and mantle (99.5% by weight). The Earth's atmosphere, hydrosphere and biosphere together weigh less than 0.05% of the Earth's total mass. Oxygen is one of the most abundant elements on Earth and represents a large portion of each main reservoir:\n\nMovement of oxygen between the reservoirs is facilitated in large part by the presence of atmospheric free oxygen. The main source of atmospheric free oxygen is photosynthesis, which produces sugars and free oxygen from carbon dioxide and water:\n\nPhotosynthesizing organisms include the plant life of the land areas as well as the phytoplankton of the oceans. The tiny marine cyanobacterium Prochlorococcus was discovered in 1986 and accounts for more than half of the photosynthesis of the open ocean.\nAn additional source of atmospheric free oxygen comes from photolysis, whereby high-energy ultraviolet radiation breaks down atmospheric water and nitrous oxide into component atoms. The free H and escape into space, leaving O in the atmosphere: \nThe main way free oxygen is lost from the atmosphere is via respiration and decay, mechanisms in which animal life and bacteria consume oxygen and release carbon dioxide.\n\nThe lithosphere also consumes atmospheric free oxygen by chemical weathering and surface reactions. An example of surface weathering chemistry is formation of iron oxides (rust): \nOxygen is also cycled between the biosphere and lithosphere. Marine organisms in the biosphere create calcium carbonate shell material (CaCO) that is rich in oxygen. When the organism dies, its shell is deposited on the shallow sea floor and buried over time to create the limestone sedimentary rock of the lithosphere. Weathering processes initiated by organisms can also free oxygen from the lithosphere. Plants and animals extract nutrient minerals from rocks and release oxygen in the process.\n\nThe following tables offer estimates of oxygen cycle reservoir capacities and fluxes. These numbers are based primarily on estimates from (Walker, J. C. G.):\n\nTable 1: Major reservoirs involved in the oxygen cycle\n<br>\nTable 2: Annual gain and loss of atmospheric oxygen (Units of 10 kg O per year)\n\nThe presence of atmospheric oxygen has led to the formation of ozone (O) and the ozone layer within the stratosphere:\n\nThe ozone layer is extremely important to modern life as it absorbs harmful ultraviolet radiation:\n\n, http://paos.colorado.edu/~fasullo/pjw_class/oxygencycle.html\n", "id": "583598", "title": "Oxygen cycle"}
{"url": "https://en.wikipedia.org/wiki?curid=12563713", "text": "High production volume chemicals\n\nHigh production volume chemicals, also referred to as HPV chemicals, are produced or imported into the United States in quantities of 1 million pounds or 500 tons per year. In OECD countries, HPV chemicals are defined as being produced at levels greater than 1,000 metric tons per producer/importer per year in at least one member country/region. A list of HPV chemicals serves as an overall priority list, from which chemicals are selected to gather data for a screening information dataset (SIDS), for testing and for initial hazard assessment.\n\nIn 1987, member countries of the Organisation for Economic Co-operation and Development decided to investigate existing chemicals. In 1991, they agreed to begin by focusing on High production volume (HPV) chemicals, where production volume was used as a surrogate for data on occupational, consumer, and environmental exposure. Each country agreed to \"sponsor\" the assessment of a proportion of the HPV chemicals. Countries also agreed on a minimum set of required information, the screening information dataset (SIDS). Six tests are: acute toxicity, chronic toxicity, developmental toxicity/reproductive toxicity, mutagenicity, ecotoxicity and environmental fate. Using SIDS and detailed exposure data OECD's High Production Volume Chemicals Programme conducted initial risk assessments to screen and to identify any need for further work.\n\nDuring the late 1990s, OECD member countries began to assess chemical categories and to use quantitative structure–activity relationship (QSAR) results to create OECD guidance documents, as well as a computerized QSAR toolbox. In 1998, the global chemical industry, organized in the International Council of Chemical Associations (ICCA) initiative, offered to join OECD efforts. The ICCA promised to sponsor by 2013 about 1,000 substances from the OECD's HPV chemicals list \"to establish as priorities for investigation\", based on \"presumed wide dispersive use, production in two or more global regions or similarity to another chemical, which met either of these criteria\". OECD in turn agreed to refocus and to \"increase transparency, efficiency and productivity and allow longer-term planning for governments and industry\". The OECD refocus was on initial hazard assessments of HPV chemicals only, and no longer extensive exposure information gathering and evaluation. Detailed exposure assessments within national (or regional) programmes and priority setting activities were postponed as post-SIDS work.\n\nOn October 9, 1998, EPA Administrator Carol Browner sent letters to the CEOs of more than 900 chemical companies that manufacture HPV chemicals, asking them to participate in EPA's voluntary testing initiative, the so-called \"HPV Challenge Program\". The Environmental Defense Fund, the American Petroleum Institute, and American Chemistry Council joined in the effort.\n\nThe OECD list of HPV chemicals keeps changing. A 2004 list of 143 pages contained 4,842 entries. A 2007 list was published in 2009.\n\nThe EPA has published an online list of HPV chemicals since 2010. The list is not numerated and without footnotes.\n\nThe \"Strategic Approach to International Chemicals Management\" (SAICM) is a policy for achieving safe production and use of chemicals worldwide by 2020, developed with stakeholders from more than 140 countries, signed by 100 governments, adopted by the UNEP Governing Council in February 2006. \nThe Registration, Evaluation, Authorisation and Restriction of Chemicals (REACH) proposal and the European Chemicals Agency will help the EU to fulfill objectives of SAICM.\nThe Stockholm Convention on Persistent Organic Pollutants has aimed to control production, use, trade, disposal and release of twelve Persistent organic pollutants (POPs); the European Community has proposed five additional chemicals. The Convention bans deliberate production and use of POPs, bans the development of new POPs, and aims at minimizing releases of unintentionally produced POPs. The Convention has so far been ratified by the European Community, 18 member states and the two accession countries.\n\nThe 1976 Toxic Substances Control Act requires the EPA to \"compile, keep current, and publish a list of each chemical substance that is manufactured or processed in the United States\". In 1998, the EPA reported the most heavily used HPV chemicals in commerce were largely untested: 43% of 2,800 HPV chemicals had no basic toxicity data or screening level data at all, 50% had incomplete screening data, and only 7% of the HPV chemicals had a complete set of screening level toxicity data. However, screening level data, even if they indicated a problem, were not sufficient to restrict the use of a compound. \nIn 1986, 2003, 2005, and in 2011 EPA issued regulations to amend and update the TSCA inventory.\n\nAs of April 2010, about 84,000 chemicals were on the TSCA inventory, per a GAO report. TSCA Section 4 gives EPA the authority to demand chemical testing.\n\nIn 1982, U.S. manufacturers, processors, and importers of 75 chemicals that the International Agency for Research on Cancer had found to cause cancers in animals, but the carcinogenicity of which in humans was uncertain, were surveyed. Only for 13 of the 75 chemicals had epidemiologic studies on human health been completed or were in progress. Eighteen of the 75 were HPV chemicals and only for eight HPV chemicals had epidemiologic studies been completed or were in progress. The largest number of chemicals (19) were drugs, and none of them had been epidemiologically studied. Seven chemicals that had been studied were used as pesticides.\n\nIn 1997 the Environmental Defense Fund reported in “Toxic Ignorance” results of its analysis of the availability of basic health test data on HPV chemicals that only 29% of the HPV chemicals in the US met minimum data requirements.\nIn 1998 the EPA published a report CHEMICAL HAZARD DATA AVAILABILITY STUDY showing \"55% of TRI chemicals have had full SIDS testing, while only 7% of other chemicals have full test data\". They wrote \n\"...of the 830 companies making HPV chemicals in the US, 148 companies have NO SIDS data available on their chemicals; an additional 459 companies sell products for which, on average, half or less of SIDS tests are available. Only 21 companies (or 3% of the 830 companies) have all SIDS tests available for their chemicals. The basic set of test data costs about $200,000 per chemical.\"\nIn 1999, the European Union (EU) published a study about how many EU-HPV chemicals were publicly available in a comprehensive chemical data base called IUCLID: Only 14% of the EU-HPV chemicals had data at the level of the base-set, 65% had less than base-set, and 21% had no data available. The authors concluded, \"more data [were] publicly available than most previous studies\" had shown.\n\nIn 2004, one of the partners in EPA's HPV Challenge Program assessed 532 up to then unsponsored chemicals, whether they were \"orphaned\" or not, and found:\nSince 2009, the EPA required companies to perform toxicity testing on merely 34 chemicals. In 2011, the EPA announced, but as of 2013 had yet to finalize, plans to require testing for 23 additional chemicals, so altogether 57 chemicals. The EPA has prioritized 83 chemicals for risk assessment, and initiated seven assessments in 2012, with plans to start 18 additional assessments in 2013 and 2014.\nIn 2007, EPA began Toxcast which uses \"automated chemical screening technologies (called \"high-throughput screening assays\") to expose living cells or isolated proteins to chemicals\"., \n\nIn 2009, EPA reported that it developed a system called ACToR (Aggregated Computational Toxicology Resource) to expose living cells or isolated proteins to chemicals. It pooled chemical research, data and screening tools from multiple federal agencies including the National Toxicology Program/ National Institute of Environmental Health Science, National Center for Advancing Translational Sciences and the Food and Drug Administration. \n\n", "id": "12563713", "title": "High production volume chemicals"}
{"url": "https://en.wikipedia.org/wiki?curid=42248988", "text": "Catlin Seaview Survey\n\nThe Catlin Seaview Survey, later renamed the XL Catlin Seaview Survey, was a major scientific expedition which commenced in September 2012, whose aim was to document the composition and health of coral reefs worldwide. Specifically, the survey aimed to \"carry out a rapid assessment of the current state of coral reef systems and to make this scientific record publicly available for scientists worldwide to use\". The survey was sponsored by the Catlin Group until the survey ended when the Catlin group ended sponsorship. The original team created a film, chasing coral and a new, global initiative known as 50 reefs.\n\nThe survey started in September 2012, and was focused on sections of the Great Barrier Reef across a range of depths. Specifically, 32 reefs were sampled, which equated to approximately of reef. This produced around 105,000 images, which are currently being analysed by scientists globally, using image recognition software. In addition to imaging shallow reefs, the deeper reef was sampled. This also led to the discovery of the deepest known coral reef in the Great Barrier Reef, which is located at a depth of .\n\nThis initial success led to the continuation of the survey globally. In 2013, the survey focussed on sampling corals in the Caribbean sea and Bermuda. Other sites are also being explored in 2014.\n\nThe status of surveyed reefs is being documented using high-resolution, 360-degree panoramic vision. These images are GPS-tagged with camera direction recorded, documenting precise locations. This method of documentation is intended to form a visual record of the world's reefs, allowing different reefs to be visually compared, and individual reefs to be monitored over time. This imaging also aims to help both the general public and specific groups (e.g. policy makers) better identify and understand the threats facing coral reefs. Likewise, these images are intended to assist the formation of strategies to protect reefs.\n\nTo survey deeper reefs, specialist divers and remotely operated underwater vehicles (ROUVs) are being utilised. The temperatures of these deep reefs are also being monitored. In addition, biological samples are being collected to identify potential genetic links between shallow and deep coral systems, which could be important for conservation. Pulsed Amplitude Modulated (PAM) stress detection devices are also being used in deeper reefs to monitor stress levels.\n\nMuch of this imaging was produced using the SVII Camera. The SVII is a self-propelling underwater panoramic camera, and was designed by the survey team. The camera can be controlled by a diver, and is propelled at a constant speed. The Seaview SVII-S has also been designed, and is a lighter, human-propelled version of the SVII which can be transported by a single person. Underwater tablets are used to control the cameras and observe real-time images, and have also been used for communication, especially with social media. \n\nAs mentioned, ROUVs are used to sample deeper reefs. These are highly mobile, and can operate at low depths. These ROUVs also contain scientific equipment which can be altered depending on the sampling being carried out, and can carry out sampling. As with the low-depth cameras, these ROUVs are able to produce high definition geo-positioned images.\n\nData from the Catlin Seaview Survey has been used to construct the Catlin Global Reef Record, which was launched in 2013. This database contains images and data collected by the Catlin Seaview Survey and by other coral reef research. However, the huge photographic records generated by the Catlin Seaview Survey are the main aspect of this record. The Catlin Global Reef Record is freely available to scientists globally, and can be used to analyse these reef environments and monitor their change.\n\n", "id": "42248988", "title": "Catlin Seaview Survey"}
{"url": "https://en.wikipedia.org/wiki?curid=20286208", "text": "Society for Andaman and Nicobar Ecology\n\nThe Society for Andaman and Nicobar Ecology, also known as SANE, is an Indian environmental organization based in Port Blair city of the Andaman and Nicobar Islands union territory of India. It was formed for the preservation of the Andaman ecosystem.\n\nDue to increasingly more contact of Jarawa adivasis of the Andaman Islands, since 1996, previously who were known for their herto fiercely isolationist behaviour, started to emerged from the forest area and made contact with the non-tribal population of the andaman. Due to completion of the National Highway 223 running throughout the andaman from north to south. The organization filed a suit in Calcutta High Court, under which andamanas jurisdiction comes. The case escalated to the Supreme Court of India as a Public Interest Litigation (or PIL).\n\nSANE joined the Bombay Natural History Society and Pune-bare Kalpavriksh in this petition, whichresulted in the High Court passing a judgment in 2001, directing the administration to take steps to protect the Jarawa from encroachment and contact, as well as preemptively ruling out any program that involved relocating the Jarawa to a new reservation. Planned extensions of the highway were also prohibited by the court. However the Andaman administration decided defying the order by keeping it open and continuing construction due to being the main and important highway and for its Economical and social importance.\n\n", "id": "20286208", "title": "Society for Andaman and Nicobar Ecology"}
{"url": "https://en.wikipedia.org/wiki?curid=36344470", "text": "Centre for Marine Living Resources &amp; Ecology\n\nThe Centre for Marine Living Resources & Ecology (CMLRE), Kochi is a research institute under the Ministry of Earth Sciences (MoES), Government of India with a mandate to study the Marine Living Resources. . Today, apart from implementing various research projects of the ministry, the institute also manages and operates the Fishery Oceanographic Research Vessel (FORV) \"Sagar Sampada\".\n\nThe institute has its origins in the \"Sagar Sampada\" cell, which was established under the then Department of Ocean Development, DOD (upgraded to the Ministry of Earth Sciences in 2006) for managing and co-ordinating activities of FORV Sagar Sampada. During the beginning of the 9th Five Year Plan of the Government of India in 1998, the Marine Living Resources Programme (MLR Programme) was formulated by the DOD with a view of promoting ocean development activities in the country which inter-alia include mapping of the living resources, preparing inventory of commercially exploitable living marine resources, their optimum utilization through ecosystem management and R & D in basic sciences on Marine Living Resources & Ecology. With the objective of implementing this programme, the \"Sagar Sampada\" cell was upgraded to the Centre for Marine Living Resources and Ecology. To this date, the research vessel \"Sagar Sampada\" serves as the backbone of the MLR research activities co-ordinated by CMLRE.\n\nDuring the 9th five-year plan (1998-2002), the Centre co-ordinated the first systematic study of marine life along the Indian shelf waters, along the eastern and western coasts of India. The environmental characteristics of this region and the phytoplankton, zooplankton, marine benthos, fishery resources etc. of this region were systematically characterized for the first time. During the 10th five-year plan (2002-2007) the exploration was extended to the continental slope regions, particularly in the case of marine benthos and fisheries. Research thrust was also placed on studies of harmful algal blooms and marine mammals around the Indian subcontinent. The environmental and productivity patterns around the Indian EEZ continued to be monitored and research on the productivity and fishery resources of the Andaman and Nicobar regions was also carried out. In January 2005, after the devastating 2004 tsunami the institute along with National Institute of Oceanography and School of Marine Sciences, Cochin University of Science and Technology (CUSAT), Kochi carried out the one of the first scientific studies regarding the impact of the tsunami on marine life. In the 9th and 10th plan periods, the CMLRE served chiefly as a co-ordinating and fund granting agency, managing the projects that were granted to various other research institutes and universities.\n\nDuring the 11th five-year plan (2007-2012), the CMLRE established in-house R&D activities, apart from co-ordination of projects in other institutes. In this period, focus was placed on continued monitoring of the pelagic environment and productivity, marine benthos, harmful algal blooms, studies on reproduction and recruitment of sardines in the south-east Arabian Sea, deep-sea fisheries and myctophid resources in the Indian EEZ. Several projects during this period also focused on isolating and identifying bioactive compounds from marine organisms.\n\nThe Centre has the following mandate\n\nInstitutes associated with the MLR research programme through fund-granting from CMLRE (past and present) include\n\n", "id": "36344470", "title": "Centre for Marine Living Resources &amp; Ecology"}
{"url": "https://en.wikipedia.org/wiki?curid=39314328", "text": "Eco-industrial development\n\nEco-industrial development (EID) is a framework for industry to develop while reducing its impact on the environment. It uses a closed loop production cycle to tackle a broad set of environmental challenges such as soil and water pollution, desertification, species preservation, energy management, by-product synergy, resource efficiency, air quality, etc.\n\nMutually beneficial connections among industry, natural systems, energy, material and local communities become central factors in designing industrial production processes.\n\nThe approach itself is largely voluntary and market-driven but often pressed ahead by favorable government treatment or efforts of development co-operation.\n\nSince the early 1990s the idea of EID evolved from biological symbiosis. This concept was adapted by industrial ecologists in the search for innovative approaches to solve problems of waste, energy shortage and degradation of the environment. A continuous approach towards improving both environmental and economic outcomes is used.\n\nIn 1992, the international community officially connected development co-operation to sustainable environmental protection for the first time. At the United Nations Conference on Environment and Development (UNCED) in Rio de Janeiro, Brazil nearly 180 states signed the conference’s Rio Declaration. Although non-binding, the Rio Declaration on Environment and Development laid out 27 principles that shall guide the increasing inter-connectedness of development cooperation and sustainability. Moreover, the documents drafting was accompanied by a presentation describing the idea of eco-industrial development for the first time.\n\nIn the following years, EID became popular throughout the United States. The recently elected Clinton administration installed a summit of business, labor, government and environmental protection representatives to further develop the approach. This summit established the idea of eco-industrial parks but soon realized that at first a more efficient management of raw materials, energy and waste has to be achieved.\n\nSince then, the broad goals and application principles of EID have hardly changed and only became adapted to the rapid technological progress.\n\nIn 2012 the IGEP Foundation, for the promotion of trade, published a report called \"Pathway to Eco Industrial Development in India – Concepts and Cases\".\n\nThe field is researched by the Nation Centre for Eco-Industrial Development, a joint project by the University of Southern California and Cornell University.\n\nThe primary goal of eco-industrial development is a significant and continuous improvement in both business and environmental performance. Herein, the notion of industry not only relates to private-sector manufacturing but also covers state-owned enterprise, the service sector as well as transportation. EID’s twin guideline is reflected specifically in the “eco” of eco-industrial as it resembles ecology (decrease in pollution and waste) and economy (increase in commercial success) at the same time. In order to build a framework of defining an enterprise’s sustainable performance at the micro level, resource use optimization, minimization of waste, cleaner technologies and pollution limits are used in achieving a broad range of goals in EID: \nEco-industrial development hence explores the possibility of improvement at the local level. In unique case-to-case analyses, particular geography, human potential or business climate are investigated. In contrast to the widespread race for top-down governmental support such as tax cuts, EID emphasizes locally achievable success and rooms for improvement. As a result, purposeful enforcements of action plans can make a large difference by optimizing the interaction of business, community and ecological systems.\n\nEco-industrial development includes and employs four major conceptual instruments. Each of the approaches intends to combine the seemingly antithetic processes of industrial development and bolstering sustainability.\n\n\n\n", "id": "39314328", "title": "Eco-industrial development"}
{"url": "https://en.wikipedia.org/wiki?curid=42433033", "text": "Arcadian ecology\n\nArcadian Ecology is the school of thought that advocates for a harmonious relationship between humans and nature. It is named for the mountainous Arcady region of Greece. Gilbert White's seminal piece \"Natural History of Selbourne\" promotes a benign attitude towards nature and advocates for a peaceful coexistence between organisms. It was an individual realization of ancient arcadian ideas of harmonious interactions between humans and nature. The evolution of Arcadian ecological thought continuously reverts to the detailed letters and poems in this work.\n\nThe harmonious relationship described by Arcadian ecology establishes a responsibility to resist the domination of nature. Donald Woster in his book, \"Nature’s Economy: A History of Ecological Ideas\", uses Imperial ecology as a counterpoint to Arcadian ecology. Imperial ecology takes a different approach, and suggests that humans should attempt to manage nature, because nature exists for man's benefit (utilitarianism). This contradiction is representative of the ecologists' struggle to explain humanity's relationship with nature while considering popular theological views of the time period. The discussion of Arcadian versus Imperial ecology would continue with prominent figures of the field such as Henry Thoreau and Charles Darwin. The long term implications of this debate have the potential to shape nature in the future as humans struggle with ethical debates and laws for preservation.\n\nThe Arcadian standpoint has its roots in several historical and cultural traditions which have shaped the study of ecology. One of these such cultural traditions was the Renaissance, which cultivated the appreciation of landscape, wilderness, and nature. Environmental sociologist Kris van Koppen underscores this point by arguing, \"The social theories that belong to the arcadian approach are particularly orientated to the recognition, elaboration and extension of the intrinsic values of nature, as well as to the social organization of their preservation\".\n\nArcadian ecology can be understood by its contrasts with another prominent view, Imperial Ecology. Sociologists and historians define Imperial Ecology as the standpoint that nature is a force to be dominated in the quest for human convenience. It is in this difference that it can be clearly seen that the arcadian approach criticizes 'resourcism' and 'reductionism'. Therefore, sociologists and ecologists who subscribe to the notion of arcadian ecology view natural disasters like the Dust Bowl as stemming directly from conceptions of nature like imperial ecology.\n\nWithin arcadian ecological thought, there has been a recent focus on the relationship between humans and animals. This comes primarily from Keith Tomas and his work ‘’Man and the Natural World: Changing Attitudes in England 1500–1800’ published in 1983. This contribution began to highlight animal rights and the inhumane treatment of animals between 1500 and 1800. In a similar vein, Lynn White reflected on the shift from the biblical idea that animals were put on earth to serve man, to the realization that man must live in harmony with beast.\n\nEthical and political implications of the Arcadian Ecology viewpoint are ever popular in scholarly and media debates during the twenty-first century. The debate however, did not begin during the current time but rather has progressed over many centuries as humans attempt to grapple with their short-term and long-term environmental impact. Max Oelschlaeger remarks, “Nearly 50 years ago Aldo Leopold identified the basic problem of conservation: learn how to live on the land without spoiling it”. It would also not even be fifteen years later when Rachel Carson wrote about Neanderthal science and its unreflective practitioners.\n\nA more reflective look at the United States’ environmental practices can show in depth the struggle of a relatively new country, with substantial economic means, to come to an agreement on appropriate actions regarding nature. Historically the United States has had significant expansion and over-resourcing. The many national parks and government-protected environmental lands were in part created because there was over-framing and development. Teddy Roosevelt used his position as the United States President to set aside more than 194 million acres of park land. Karl Jacoby, an expert in environmental history, has written how the Adirondack Park in New York was created to ensure a continued water source to the New York City population and a natural environment to “recharge” from city life.\n\nNot all United States National Parks were created for reasons other than nature preservation, such as Yosemite National Park. Originally it was set aside as land to be undeveloped by those who predicted that land conservation may become important in the future. For classification purposes, those ecologists that saw a need to refuse a developmental and destructive path for Yellowstone ascribe to the arcadian ecology view. However, this originally Arcadian movement was opposed, when San Francisco need a viable water supply after a devastating earthquake. This conservation issue sparked a major debate over the Hetch Hetchy. The debate pitted major thinkers against each other including John Muir who thought there was “no holier temple than Yosemite” and Gifford Pinchot who was in favor of damming to provide water resources to San Francisco. The Hetch Hetchy examines the dichotomy of arcadian and imperial ecology.\n\nIn addition to National Parks, the United States has put many laws into motion regarding environmental protection including the National Environmental Policy Act (1969), the Wilderness Act (1964), and the Endangered Species Act (1973). These laws all celebrate the Arcadian harmony between nature and humans and ensure its preservation. Unfortunately, Americans, according to Max Oelschlaeger, are also, “the world’s leading consumers: our ecological footprints tread heavily on other parts of the planet”.\n\nOne of the major problems in determining if there has been success in terms of the environment in the United States is the subjectivity that comes with this environmental issue. A look at the work by Eliot Brownlee, a professor of economic history, will suggest that the United States is an economic success story that utilized the natural resources to the best of their abilities. The view looks at nature not as a pawn, but a means to an end in production which has advanced the human race further than ever thought possible. In opposition, a prominent environmental philosopher, Joseph Petulla, wrote a different story of the landscape of Brownlee. He saw the economic success coming at a costly price of the destruction of the American land. The Western civilization had encroached too far into nature and it was more reminiscent of Imperial Ecology rather than Arcadian Ecology.\n\n\n", "id": "42433033", "title": "Arcadian ecology"}
{"url": "https://en.wikipedia.org/wiki?curid=43225941", "text": "Marsh Award for Conservation Biology\n\nThe Marsh Award for Conservation Biology, established 1991, is an Award run in partnership between the Zoological Society of London (ZSL) and the Marsh Christian Trust that recognises an individual for his or her \"contributions of fundamental science to the conservation of animal species and habitats\".\n\n", "id": "43225941", "title": "Marsh Award for Conservation Biology"}
{"url": "https://en.wikipedia.org/wiki?curid=43667479", "text": "Massachusetts Division of Ecological Restoration\n\nThe Division of Ecological Restoration (DER) is a Division of the Massachusetts Department of Fish and Game within the Executive Office of Energy and Environmental Affairs. DER was created in 2009 with the merger of the Riverways and Wetlands Restoration Programs. DER coordinates ecological restoration to improve ecological condition and to restore important ecosystem services that improve the quality of life for all Massachusetts citizens.\n\nThe Riverways Program (MGL Chapter 21A Section 8) has been maintained within DER and coordinates outreach and technical assistance to support watershed conservation and protection.\n\nThe Division and partners facilitate capital-based projects including (but not limited to) dam removal and culvert replacement with the goal of restoring aquatic habitats (e.g. salt marshes)\nand ecosystems across the state. These projects support commercial and recreational fisheries and provide many other benefits such as reduced flooding, improved water quality, carbon sequestration and increased public safety.\n\nEcological restoration is a core component of the Commonwealth of Massachusetts efforts to build habitat resiliency to better allow fish and wildlife to adapt to climate change – including sea level rise, elevated water temperatures, and increased floods and periods of drought.\n\nTim Purinton currently serves as the Director of the Division of Ecological Restoration.\n\n\n", "id": "43667479", "title": "Massachusetts Division of Ecological Restoration"}
{"url": "https://en.wikipedia.org/wiki?curid=27164953", "text": "Numerical response\n\nThe numerical response in ecology is the change in predator density as a function of change in prey density. The term numerical response was coined by M. E. Solomon in 1949. It is associated with the functional response, which is the change in predator's rate of prey consumption with change in prey density. As Holling notes, total predation can be expressed as a combination of functional and numerical response. The numerical response has two mechanisms: the demographic response and the aggregational response. The numerical response is not necessarily proportional to the change in prey density, usually resulting in a time lag between prey and predator populations. For example, there is often a scarcity of predators when the prey population is increasing.\n\nThe demographic response consists of changes in the rates of predator reproduction or survival due to a changes in prey density. The increase in prey availability translates into higher energy intake and reduced energy output. This is different from an increase in energy intake due to increased foraging efficiency, which is considered a functional response. This concept can be articulated in the Lotka-Volterra Predator-Prey Model.\n\nformula_1\n\na = conversion efficiency: the fraction of prey energy assimilated by the predator and turned into new predators\nP = predator density\nV = prey density\nm = predator mortality\n\nDemographic response consists of a change in dP/dt due to a change in V and/or m. For example, if V increases, then predator growth rate (dP/dt) will increase. Likewise if the energy intake increases (due to greater food availability) and a decrease in energy output (from foraging), then predator mortality (m) will decrease and predator growth rate (dP/dt) will increase. In contrast, the functional response consists of a change in conversion efficiency (a) or capture rate (c).\n\nThe relationship between available energy and reproductive efforts can be explained with the life history theory in the trade-off between fecundity and growth/survival. If an organism has more net energy, then the organism will sacrifice less energy dedicated to survival per reproductive effort and will therefore increase its reproduction rate.\n\nIn parasitism, functional response is measured by the rate of infection or laying of eggs in host, rather than the rate of prey consumption as it is measured in predation. Numerical response in parasitism is still measured by the change in number of adult parasites relative to change in host density. Parasites can demonstrate a more pronounced numerical response to changes in host density since there is often a more direct connection (less time lag) between food and reproduction in that both needs are immediately satisfied by its interaction with the host. \n\nThe aggregational response, as defined by Readshaw in 1973, is a change in predator population due to immigration into an area with increased prey population. In an experiment conducted by Turnbull in 1964, he observed the consistent migration of spiders from boxes without prey to boxes with prey. He proved that hunger impacts predator movement.\n\nRiechert and Jaeger studied how predator competition interferes with the direct correlation between prey density and predator immigration. One way this can occur is through exploitation competition: the differential efficiency in use of available resources, for example, an increase in spiders' web size (functional response). The other possibility is interference competition where site owners actively prevent other foragers from coming in vicinity.\n\nThe concept of numerical response becomes practically important when trying to create a strategy for pest control. The study of spiders as a biological mechanism for pest control has driven much of the research on aggregational response. Antisocial predator populations that display territoriality, such as spiders defending their web area, may not display the expected aggregational response to increased prey density.\n\nA credible, simple alternative to the Lotka-Volterra predator-prey model and its common prey dependent generalizations is the ratio dependent or Arditi-Ginzburg model. The two are the extremes of the spectrum of predator interference models. According to the authors of the alternative view, the data show that true interactions in nature are so far from the Lotka-Volterra extreme on the interference spectrum that the model can simply be discounted as wrong. They are much closer to the ratio dependent extreme, so if a simple model is needed one can use the Arditi-Ginzburg model as the first approximation.\n", "id": "27164953", "title": "Numerical response"}
{"url": "https://en.wikipedia.org/wiki?curid=21424701", "text": "Defaunation\n\nDefaunation is the loss of animals from ecological communities. The growth of the human population, combined with advances in harvesting technologies, has led to more intense and efficient exploitation of the environment. This has resulted in the depletion of large vertebrates from ecological communities, creating what has been termed \"empty forest\". Defaunation differs from extinction; it includes both the disappearance of species and declines in abundance. Defaunation effects were first implied at the Symposium of Plant-Animal Interactions at the University of Campinas, Brazil in 1988 in the context of neotropical forests. Since then, the term has gained broader usage in conservation biology as a global phenomenon.\n\nIt is estimated that more than 50 percent of all wildlife has been lost in the last 40 years. in 2020 it is estimated that 68% of the world's wildlife will be lost. In South America, there is believed to be a 70 percent loss.\n\nIn November 2017, over 15,000 scientists around the world issued a second warning to humanity, which, among other things, urged for the development and implementation of policies to halt \"defaunation, the poaching crisis, and the exploitation and trade of threatened species.\"\n\nThe intensive hunting and harvesting of animals threatens endangered vertebrate species across the world. Game vertebrates are considered valuable products of tropical forests and savannas. In Brazilian Amazonia, 23 million vertebrates are killed every year; large-bodied primates, tapirs, white-lipped peccaries, giant armadillos, and tortoises are some of the animals most sensitive to harvest. Overhunting can reduce the local population of such species by more than half, as well as reducing population density. Populations located nearer to villages are significantly more at risk of depletion. Abundance of local game species declines as density of local settlements, such as villages, increases.\n\nHunting and poaching may lead to local population declines or extinction in some species. Most affected species undergo pressure from multiple sources but the scientific community is still unsure of the complexity of these interactions and their feedback loops.\n\nOne case study in Panama found an inverse relationship between poaching intensity and abundance for 9 of 11 mammal species studied. In addition, preferred game species experienced greater declines and had higher spatial variation in abundance.\n\nHuman population growth results in changes in land-use, which can cause natural habitats to become fragmented, altered, or destroyed. Large mammals are often more vulnerable to extinction than smaller animals because they require larger home ranges and thus are more prone to suffer the effects of deforestation. Large species such as elephants, rhinoceroses, large primates, tapirs and peccaries are the first animals to disappear in fragmented rainforests.\n\nA case study from Amazonian Ecuador analyzed two oil-road management approaches and their effects on the surrounding wildlife communities. The free-access road had forests that were cleared and fragmented and the other had enforced access control. Fewer species were found along the first road with density estimates being almost 80% lower than at the second site that which had minimal disturbance. This finding suggests that disturbances affected the local animals' willingness and ability to travel between patches.\n\nFragmentation lowers populations while increasing extinction risk when the remaining habitat size is small. When there is more unfragmented land, there is more habitat for more diverse species. A larger land patch also means it can accommodate more species with larger home ranges. However, when patch size decreases, there is an increase in the number of isolated fragments which can remain unoccupied by local fauna. If this persists, species may become extinct in the area.\n\nA study on deforestation in the Amazon looked at two patterns of habitat fragmentation: \"fish-bone\" in smaller properties and another unnamed large property pattern. The large property pattern contained fewer fragments than the smaller fish-bone pattern. The results suggested that higher levels of fragmentation within the fish-bone pattern led to the loss of species and decreased diversity of large vertebrates. Human impacts, such as the fragmentation of forests, may cause large areas to lose the ability to maintain biodiversity and ecosystem function due to loss of key ecological processes. This can consequently cause changes within environments and skew evolutionary processes.\n\nHuman influences, such as colonization and agriculture, have caused species to become distributed outside of their native ranges. Fragmentation also has cascading effects on native species, beyond reducing habitat and resource availability; it leaves areas vulnerable to non-native invasions. Invasive species can out-compete or directly prey upon native species, as well as alter the habitat so that native species can no longer survive.\n\nIn extinct animal species for which the cause of extinction is known, over 50% were affected by invasive species. For 20% of extinct animal species, invasive species are the only cited cause of extinction. Invasive species are the second-most important cause of extinction for mammals.\n\nTropical regions are the most heavily impacted by defaunation. These regions, which include the Brazilian Amazon, the Congo Basin of Central Africa, and Indonesia, experience the greatest rates of overexploitation and habitat degradation. However, specific causes are varied, and areas with one endangered group (such as birds) do not necessarily also have other endangered groups (such as mammals, insects, or amphibians).\n\nDeforestation of the Brazilian Amazon leads to habitat fragmentation and overexploitation. Hunting pressure in the Amazon rainforest has increased as traditional hunting techniques have been replaced by modern weapons such as shotguns. Access roads built for mining and logging operations fragment the forest landscape and allow hunters to move into forested areas which previously were untouched. The bushmeat trade in Central Africa incentivizes the overexploitation of local fauna. Indonesia has the most endangered animal species of any area in the world. International trade in wild animals, as well as extensive logging, mining and agriculture operations, drive the decline and extinction of numerous species.\n\nInbreeding and genetic diversity loss often occur with endangered species populations because they have small and/or declining populations. Loss of genetic diversity lowers the ability of a population to deal with change in their environment and can make individuals within the community homogeneous. If this occurs, these animals are more susceptible to disease and other occurrences that may target a specific genome. Without genetic diversity, one disease could eradicate an entire species. Inbreeding lowers reproduction and survival rates. It is suggested that these genetic factors contribute to the extinction risk in threatened/endangered species.\n\nThe consequences of defaunation can be expected to affect the plant community. There are three non-mutually exclusive conclusions as to the consequences on tropical forest plant communities:\n\n\nOne recent study analyzed seedling density and composition from two areas, Los Tuxtlas and Montes Azules. Los Tuxtlas, which is affected more by human activity, showed higher seedling density and a smaller average number of different species than in the other area. Results suggest that an absence of vertebrate dispersers can change the structure and diversity of forests. As a result, a plant community that relies on animals for dispersal could potentially have an altered biodiversity, species dominance, survival, demography, and spatial and genetic structure.\n\nPoaching is likely to alter plant composition because the interactions between game and plant species varies in strength. Some game species interact strongly, weakly, or not at all with species. A change in plant species composition is likely to be a result because the net effect removal of game species varies among the plant species they interact with.\n\nAs large-bodied vertebrates are increasingly lost from seed-dispersal networks, small-bodied seed dispersers (i.e. bats, birds, dung beetles) and seed predators (i.e. rodents) are affected. Defaunation leads to reduced species diversity. This is due to relaxed competition; small-bodied species normally compete with large-bodied vertebrates for food and other resources. As an area becomes defaunated, dominant small-bodied species take over, crowding out other similar species and leading to an overall reduced species diversity. The loss of species diversity is reflective of a larger loss of biodiversity, which has consequences for the maintenance of ecosystem services.\n\nThe quality of the physical habitat may also suffer. Bird and bat species (many of who are small bodied seed dispersers) rely on mineral licks as a source of sodium, which is not available elsewhere in their diets. In defaunated areas in the Western Amazon, mineral licks are more thickly covered by vegetation and have lower water availability. Bats were significantly less likely to visit these degraded mineral licks. The degradation of such licks will thus negatively affect the health and reproduction of bat populations.\n\nDefaunation has negative consequences for seed dispersal networks as well. In the western Amazon, birds and bats have separate diets and thus form separate guilds within the network. It is hypothesized that large-bodied vertebrates, being generalists, connect separate guilds, creating a stable, resilient network. Defaunation results in a highly modular network in which specialized frugivores instead act as the connector hubs.\n\nChanges in predation dynamics, seed predation, seed dispersal, carrion removal, dung removal, vegetation trampling, and other ecosystem processes as a result of defaunation can affect ecosystem supporting and regulatory services, such as nutrient cycling and decomposition, crop pollination, pest control, and water quality.\n\nEfforts against defaunation include wildlife overpasses and riparian corridors. Both of these can be otherwise known as wildlife crossing mechanisms. Wildlife overpasses are specifically used for the purpose of protecting many animal species from the roads. Many countries use them and they have been found to be very effective in protecting species and allowing forests to be connected. These overpasses look like bridges of forest that cross over many roads, like a walk bridge for humans, allowing animals to migrate from one side of the forest to the other safely since the road cut off the original connectivity. It was concluded in a study done by Pell and Jones, looking at bird use of these corridors in Australia, that many birds did, in fact, use these corridors to travel from one side of forest to the other and although they did not spend much time in the corridor specifically, they did commonly use them. Riparian corridors are very similar to overpasses they are just on flat land and not on bridges, however, they also work as connective \"bridges\" between fragmented pieces of forest. One study done connected the corridors with bird habitat and use for seed dispersal. The conclusions of this study showed that some species of birds are highly dependent on these corridors as connections between forest, as flying across the open land is not ideal for many species. Overall both of these studies agree that some sort of connectivity needs to be established between fragments in order to keep the forest ecosystem in the best health possible and that they have in fact been very effective.\n\nDefaunation in the ocean has occurred later and less intensely than on land. A relatively small number of marine species have been driven to extinction. However, many species have undergone local, ecological, and commercial extinction. Most large marine animal species still exist, such that the size distribution of global species assemblages has changed little since the Pleistocene, but individuals of each species are smaller on average, and overfishing has caused reductions in genetic diversity. Most extinctions and population declines to date have been driven by human overexploitation.\n\nMarine defaunation has a wide array of effects on ecosystem structure and function. The loss of animals can have both top-down (cascading) and bottom-up effects, as well as consequences for biogeochemical cycling, ecosystem connectivity, and ecosystem stability.\n\nTwo of the most important ecosystem services threatened by marine defaunation are the provision of food and coastal storm protection.\n\n\n\n", "id": "21424701", "title": "Defaunation"}
{"url": "https://en.wikipedia.org/wiki?curid=3401385", "text": "Mesoamerican Biological Corridor\n\nThe Mesoamerican Biological Corridor (MBC) is a region that consists of Belize, Guatemala, El Salvador, Honduras, Nicaragua, Costa Rica, Panama, and some southern states of Mexico. The area acts as a natural land bridge from South America to North America, which is important for species who use the bridge in migration. Due to the extensive unique habitat types, Mesoamerica contains somewhere between 7 and 10% of the world’s known species.\n\nThe corridor was originally proposed in the 1990s to facilitate animal movements along the Americas without interfering with human development and land use, while promoting ecological sustainability. The Mesoamerican Biological Corridor is made of four parts: Core Zones, Buffer Zones, Corridor Zones, and Multiple-Use Zones, each with varying availability for human use.\n\nWith the increasing conversion of natural tropical ecosystems to agricultural farms and for other human use, comes growing concern over conservation of local species. Mesoamerica is considered one of many biodiversity hotspots where extinction is a significant threat. This area is the world’s third largest biodiversity hotspot. Some efforts have been made to protect organisms in the region, however, many of these protected sites are “small, fragmented, isolated, or poorly protected”\n\nIn the late 1980s, Archie Carr III envisioned a way to protect threatened and endangered wildlife native to the region by connecting fragmented patches of habitat, and to create buffer zones to allow different levels of land use near protected areas. The corridor that eventually came to be, originally called Paseo Pantera (Spanish for Path of the Panther), follows the Atlantic coastline. The MBC began in the late 1990s, by funding from the World Bank in order to promote wildlife conservation, particularly endemic, threatened, and endangered species, and ways to use the land in a sustainable fashion. It was developed by a team of biologists from the University of Florida and the Central American Commission on Environment and Development (CCAD), and was remapped by CCAD, the United Nations Development Programme (UNDP), and the Global Environment Facility (GEF) for political reason. $4 million was invested in the corridor by United States Agency for International Development (USAID) from 1990 to 1995. In 1992, all of the countries that are part of the Mesoamerican Biological Corridor joined the Central American System of Protected Areas (SICAP), which allows each country to “maintain its own ministries of the environment.” The corridor project has been successful in providing wildlife habitat; however, regional biota remained threatened due to fragmented areas and “unevenness of the region’s protected area system”\n\nThe Mesoamerican Biological Corridor incorporates multiple diverse biomes and is bordered by the Caribbean Sea to the east and the Pacific Ocean on the west. Splitting the corridor in half is the Guatemalan Mountain range, which includes active volcanoes. These environmental forces create four terrestrial biomes and 19 terrestrial ecoregions. The biomes include, tropical dry broadleaf forest, tropical wet broadleaf forests, xeric shrub lands, and tropical coniferous forests.\n\nAccording to data from 2003, roughly 57% of the Mesoamerican biological corridor is natural vegetation, with the remaining land being used mostly for cattle and crop production. The main crops produced in the MBC include sugar cane, corn, coffee, and beans. With agricultural production being such a large part of all the nations economies, there is much emphasis on adopting sustainable agricultural practices.\n\nThe Mesoamerican Biological Corridor is made of four parts: Core Zones, Buffer Zones, Corridor Zones, and Multiple-Use Zones, each with varying availability for human use. Core Zones are protected areas whose purpose is to promote and sustain biodiversity in the areas in order to maintain ecosystem services to the local people. Buffer Zones include the areas surrounding the protected Core Zones, which are made up mostly of wild land. Pathways between zones are labeled as Corridor (or Connectivity) Zones; these zones link water and land passages, allowing movement of plants and animals throughout the corridor. Finally Multi-use Zones, separate wild and protected land from land used for forestry, agriculture, and areas of direct human impacts. “Around 10.7% of Mesoamerica is currently under some category of protection for biodiversity conservation.” \n\nThe Mesoamerican Biological Corridor is a program that “integrates protection areas into a single, functional conservation area”. Their goal is to promote “regional scale connectivity of protected areas with sustainable development and improvement of human livelihoods.” The purpose of the corridor is to emphasize the conservation movement as being a social and group effort. One issue with conservation efforts arise from the discontinuity of government and politics across the corridor; areas are often fragmented and up to 40% of protected areas go unenforced because it crosses nations barriers. The rapid increase in human population growth negatively affects conservation. Although this growth has been paired with rapid urbanization, the majority of the MBC population still resides in rural areas and “depends directly on biological resources for subsistence.” This dependency has led to exploitation that is difficult to quantify and regulate by the nations’ governments and conservation groups.\nAs of 2010, SICAP (Central American System of Protected Areas) encompasses 669 protected areas that total 124,250 square kilometers. Yet, conservation efforts are hindered and negatively impacted by the fragmentation of land parcels and cross-national political differences and tension. Most of the protected areas are roughly 18,400 hectares, while only 18 areas exceeded 1,000 square kilometers. Presently, most conservation efforts are in promoting sustainable development and mitigating the damage done to the area by deforestation. Deforestation in the Mesoamerican Biological Corridor peaked between the 1970s and the 1990s. Planting native trees is the main method of restoring ecosystems after deforestation.\n\nDue to the corridor having been recently developed there has not been any studies that specifically address the benefits. Future studies should be completed to examine the differences in animal populations prior to the corridor and after implementation.\n\nWhen the Mesoamerican Biological Corridor was in the planning process there was a lack of formal functions proposed. The stakeholders did not have a clear idea of what the exact functions of the MBC were, which led to anger and an increase in the time taken to implement the corridor. The MBC was originally conceived as a way to protect threatened and endangered wildlife by connecting fragments of habitats and forming buffer zones to limit human land use. However, many of the interested stakeholders wanted to include common livelihood problems such as pollution, water and sanitation, pesticides contamination, firewood acquisition, zoonotic and infectious disease. It was finally decided that the main goals of the corridor would be to facilitate animal movements along the Americas without interfering with human development and land use, while promoting ecological sustainability. Indigenous people were barely involved in these decisions and the zone boundaries were made without their input. This lack of input led to distrust and tension between the locals and corridor implementers.\n\nIn an effort to promote ecological sustainability, payment for various environmental services are given to landowners in order to motivate reforestation on their land. A major issue with these programs is that most small landholders do not have titles to the land. These small landholders were given plots to cultivate when they worked on larger farms or many were displaced migrants who settled in unclaimed lands. Since they have no legal documentation of land ownership they can’t apply for many of the correct land use incentives, thus little consideration of long-term effects on the land is given. Another issue is that the programs don’t differentiate between small-scale and large-scale landowners. In an effort to reduce Carbon emissions the MBC offers incentives for carbon sinks. Large-scale landowners have taken advantage of these systems by planting African Oil Palms on their lands. These plants provide them with more carbon credits whereas a small landowner who is maintaining forest will receive little to no carbon credits\n", "id": "3401385", "title": "Mesoamerican Biological Corridor"}
{"url": "https://en.wikipedia.org/wiki?curid=36081308", "text": "Monodominance\n\nMonodominance is an ecological condition in which more than 60% of the tree canopy comprises a single species of tree. Although monodominance is studied across different regions, most research focuses on the many prominent species in tropical forests. Connel and Lowman, originally called it single-dominance. Conventional explanations of biodiversity in tropical forests in the decades prior to Connel and Lowman's work either ignored monodominance entirely or predicted that it would not exist.\n\nConnel and Lowman hypothesized two contrasting mechanisms by which dominance can be attained. The first is by fast regrowth in unstable habitats with high disturbance rates. The second is through competitive exclusion in stable habitats that have low disturbance rates. Explanations of persistent monodominace include the monodominant species being more resistant than others to seasonal flooding, or that the monodominance is simply a sere. With persistent monodominance, the monodominant species successfully remains so from generation to generation.\n\nA minimum of 22 species from eight different families are known to create monodominant forests. Examples of persistent monodominance are seen in Africa, Central and South America, and Asia. \"Dipterocarpaceae\" is one example of a plant family that is recognized as persistently dominant in Asia. The ectomycorrhizal tree \"Dicymbe corymbosa\", found in central Guyana, creates wide ranges of monodominant forests containing more than 80% of the canopy tree species.\n\nDominant plants in the Neotropics and Africa are usually in the Leguminosae family. The species \"Gilbertiodendron dewevrei\", \"Cynometra alexandri\", and \"Julbernardia seretii\" are pronounced as exclusive dominants in their individual forests in equatorial Africa. \"G. dewevrei\" dominated forests are more widespread on the highlands adjacent to the central basin of the Zaire River. This species in the Ituri forest forms monodominant stands that occupy more than 90% of the canopy trees.\n\nConnel and Lowman originally hypothesized ectomycorrhizal association causing the replacement of other species as one of two mechanisms by which a species becomes persistently monodominant; the other is the simple colonization of large gaps. However, subsequent research over the years has shown that there is not a single, simple mechanism by which monodominance occurs. Monodominant species have been recorded forming at various times after forest clearance, though this has not been shown to be a predictor of monodominant species persistence. Reliance upon ectomycorrhizae and poor soils have not been demonstrated. Instead, multiple traits of adult monodominant species hinder the ability of other species to grow, including a dense canopy, a uniform canopy, deep leaf litter, slow nutrient processing, mast fruiting, and poor dispersal.\n\nSeveral causal mechanisms have been proposed for the formation of monodominant forest in tropical ecosystems, including features of the environment such as low disturbance rates, and intrinsic characteristics of the dominant species: escape from herbivores, high seedling shade-tolerance, and the formation of mycorrhizal networks between individuals of the same species.\n\nThe dense canopy of the adult trees prevents light from getting into the understory. In the Ituri Forest of the Democratic Republic of the Congo a monodominant \"Gilbertiodendron\" forest understory only receives 0.57% full sunlight while a mixed-forest understory received 1.15% full sunlight. This difference may prohibit many plant species from living in that environment due to the low light conditions and their resulting inability to sufficiently and effectively photosynthesize. Even some species that are more shade tolerant cannot survive the severe low light conditions.\n\nA monodominant forest has generally very deep leaf litter because the leaves are not decomposing as quickly as in other forests. In some monodominant forests the decomposition rates can be two to three times slower than mixed forests. Low ammonium and nitrate could be the result of this slow decomposition which in turn, means less nutrients in the soil for other plant species to use.\n\nNutrient processing is somewhat different from one forest to another. In the \"Gilbertiodendron\" forests there is low availability of nitrogen due to the low levels in the leaves that fall to the ground and the slow decomposition. This could prevent other plant species from colonizing because the soil lacks necessary nutrients. In \"Parashorea chinensis\" forests, trees are known to require more fertile soils than in other areas. There is a large amount of manganese though that prevents other plants from taking root. Manganese can poison other trees if the levels are too high and possibly cause leaf chlorosis and necrosis and prevent the nutrient uptake of calcium and magnesium.\n\nMast fruiting is a mass fruiting event that overwhelms the animals that consume fruit and helps the seeds' survival rate. Well-defended leaves also assist in the prevention of predation. In the \"Gilbertiodendron\" forests this mast fruiting does not assist in lesser predation, but in Asia and the Neotropics this does help and sometimes is actually important to monodominant maintenance.\n\nA monodominant forest has poor dispersal because of the lack of animal dispersers, so many of the seeds are just dropped from the parent tree and fall to the ground where they germinate. This can create a regular and radial path around the parent tree that results in a \"tree-by-tree replacement\" in a mixed forest. In a monodominant forest the dominant species do not need all of the described traits to overwhelm the area. Though many have a combination, all monodominant forests have at least one of these traits to create the monodominant habitat.\n\nMany of the tropical monodominant trees are associated with ectomycorrhizal (ECM) fungi networks. Mycorrhizal fungi are known to effect plant diversity trends in a variety of ecosystems around the world. Ectomycorrhizal relations with trees can increase nutrient supplies through a more effectual use of larger capacities of soils or through the direct decomposition of leaf litter. This has been suggested to provide a competitive advantage to such tree species.\n\nExamples of ectomycorrhizal trees in tropical rainforests can be found in Asia, Africa, and the Neotropics. There is a strong correlation between the ECM association in tropical trees and the occurrence of monodominance.\n\nFungi like mycorrihizae appear not to harm the leaves and even display a symbiotic relationship. ECM fungi are derived from saprotrophs and retain some ability to decompose organic material. Because tropical soils are often nutrient-poor, ECM trees are predicted to have a competitive advantage over neighboring trees because of their ability to attain more nutrients. With time this could lead to dominance in a tropical rainforest.\n\nA study of \"Dicymbe corymbosa\" individuals show that (in terms of total basal area) the adult trees dominate resources and space. Additionally, they form coppices, also known as epicormic shoots, which allow their perseverance over time. Hence, if one stem of the tree dies, it is replaced by another living stem in the canopy. This creates same-species regrowth at stem level. All of this requires high levels of carbohydrates and nutrients that are accumulated from the ECM association.\nThere is evidence that masting tree species rely on ECM associations to accumulate these requisite nutrients for reproduction during inter-mast years. Associations between resource levels stowed in plant tissue, timing of masting, and ECM patterns propose that ECM fungi are essential in the procurement of nutrients required for large masting trees.\n\nSeeds of monodominant trees typically have higher rates of germination and seedling survival when planted in monodominant forests rather than mixed forests. Monodominant seedlings planted in mixed forests have significantly lower levels of ECM colonization of roots. The lower percent of ECM colonization can cause the low survival rates of these seedlings in mixed forest. Another mechanism that can be important for seedling and growth survival is a connection to a common ECM network. By connecting their small root systems to ECM networks that emanate from larger adults, more benefits can be received.\n\nSlower decomposition rates in monodominant forests have been hypothesized to be a result of competition between saprotrophic bacteria and fungi. ECM fungi may be suppressing saprotrophs in the monodominant forest to slow decomposition and return organically bound nutrients back to the tree. This is also called the \"Gadgil\" hypothesis.\n\nAll of the traits that contribute to creating a monodominant forest over time hinder the growth of other plant species and force them to move to a more mixed forest. Even though this is inconvenient for the plant species that were there, there has not been any evidence that suggests that this is a negative effect of monodominance. Monodominant forests are also found to have significantly less nitrogen in their soil than mixed forests. In these monodominant forests there are a lot of dominant tree species from the legume family that have nitrogen fixation. Nitrogen fixation creates compounds that help a plant to grow in otherwise low nutrient conditions.\n", "id": "36081308", "title": "Monodominance"}
{"url": "https://en.wikipedia.org/wiki?curid=44654314", "text": "Vegetation classification\n\nVegetation classification is the process of classifying and mapping the vegetation over an area of the earth's surface. Vegetation classification is often performed by state based agencies as part of land use, resource and environmental management. Many different methods of vegetation classification have been used. In general, there has been a shift from structural classification used by forestry for the mapping of timber resources, to floristic community mapping for biodiversity management. Whereas older forestry-based schemes considered factors such as height, species and density of the woody canopy, floristic community mapping shifts the emphasis onto ecological factors such as climate, soil type and floristic associations. Classification mapping is usually now done using Geographic Information Systems (GIS) software.\n\nFollowing, some important classification schemes.\n\nAlthough this scheme is in fact of a climate classification, it has a deep relationship with vegetation studies:\n\nWagner & von Sydow (1888) scheme: \"Vegetationsgürtel\" (vegetation belts):\n\nWarming (1895, 1909) oecological classes:\n\nWarming's types of formations:\n\nSchimper (1898, 1903) climatic chief formation types:\n\nSchimper formation types across the zones and regions\n\nFormation-types:\n\nEllenberg and Mueller-Dombois (1967) scheme:\n\nA vegetation classification with six main criteria (\"hierarchical attributes\", with exemplified categories applicable mainly to Neotropical region):\n\nOther important schemes: Grisebach (1872), Tansley and Chipp (1926), Rübel (1930), Burtt Davy (1938), Beard (1944, 1955), André Aubréville (1956, 1957), Trochain (1955, 1957), Dansereau (1958), Küchler (1967).\n\n\n", "id": "44654314", "title": "Vegetation classification"}
{"url": "https://en.wikipedia.org/wiki?curid=44805474", "text": "List of ecoregions with high endemism\n\nThis list is for ecoregions with high endemism. According to the World Wide Fund for Nature, the following ecoregions have the highest percentage of endemic plants.\n\n", "id": "44805474", "title": "List of ecoregions with high endemism"}
{"url": "https://en.wikipedia.org/wiki?curid=45119474", "text": "Bioclaustration\n\nBioclaustration is kind of interaction when one organism (usually soft bodied) is embedded in a living substrate (i.e. skeleton of another organism); it means “biologically walled -up”. In case of symbiosis the walling-up is not complete and both organisms stay alive (Palmer and Wilson, 1988).\n\n", "id": "45119474", "title": "Bioclaustration"}
{"url": "https://en.wikipedia.org/wiki?curid=6363357", "text": "Nurse log\n\nA nurse log is a fallen tree which, as it decays, provides ecological facilitation to seedlings. Broader definitions include providing shade or support to other plants. Some of the advantages a nurse log offers to a seedling are: water, moss thickness, leaf litter, mycorrhizae, disease protection, nutrients, and sunlight. Recent research into soil pathogens suggests that in some forest communities, pathogens hostile to a particular tree species appear to gather in the vicinity of that species, and to a degree inhibit seedling growth. Nurse logs may therefore provide some measure of protection from these pathogens, thus promoting greater seedling survivorship.\n\nVarious mechanical and biological processes contribute to the breakdown of lignin in fallen trees, resulting in the formation of niches of increasing size, which tend to fill with forest litter such as soil from spring floods, needles, moss, mushrooms and other flora. Mosses also can cover the outside of a log, hastening its decay and supporting other species as rooting media and by retaining water. Small animals such as various squirrels often perch or roost on nurse logs, adding to the litter by food debris and scat. The decay of this detritus contributes to the formation of a rich humus that provides a seedbed and adequate conditions for germination.\nNurse logs often provide a seedbed to conifers in a temperate rain forest ecosystem.\n\n\n", "id": "6363357", "title": "Nurse log"}
{"url": "https://en.wikipedia.org/wiki?curid=45521521", "text": "Mesopredator\n\nA mesopredator is a medium-sized predator in the middle of a trophic level, which typically preys on smaller animals. When populations of apex predators decrease, populations of mesopredators often increase. This is the mesopredator release effect. \"Mesopredator outbreaks often lead to declining prey populations, sometimes destabilizing communities and driving local extinctions.\" Apex predators reduce mesopredator populations, and change mesopredator behaviors and habitat choices, by preying on and intimidating mesopredators.\n\n", "id": "45521521", "title": "Mesopredator"}
{"url": "https://en.wikipedia.org/wiki?curid=482629", "text": "Scavenger\n\nScavenging is both a carnivorous and a herbivorous feeding behavior in which the scavenger feeds on dead animal and plant material present in its habitat. The eating of carrion from the same species is referred to as cannibalism. Scavengers play an important role in the ecosystem by consuming the dead animal and plant material. Decomposers and detritivores complete this process, by consuming the remains left by scavengers.\n\nScavenger is an alteration of \"scavager,\" from Middle English \"skawager\" meaning \"customs collector\", from \"skawage\" meaning \"customs\", from Old North French \"escauwage\" meaning \"inspection\", from \"schauwer\" meaning \"to inspect\", of Germanic origin; akin to Old English \"scēawian\" and German \"schauen\" meaning \"to look at\", and modern English \"show\" (with semantic drift).\n\nObligate scavenging is very rare in the animal kingdom, due to the difficulty of finding enough carrion without expending too much energy. In vertebrates, only vultures and possibly some pterosaurs are obligate scavengers, as terrestrial soaring flyers are the only animals able to find enough carrion.\n\nWell-known invertebrate scavengers of animal material include burying beetles and blowflies, which are obligate scavengers, and yellowjackets.\n\nMost scavenging animals are facultative scavengers that gain most of their food through other methods, especially predation. Many large carnivores that hunt regularly, such as hyenas and jackals, but also animals rarely thought of as scavengers, such as African lions, leopards, and wolves will scavenge if given the chance. They may also use their size and ferocity to intimidate the original hunters (the cheetah is a notable exception). Almost all scavengers above insect size are predators and will hunt if not enough carrion is available, as few ecosystems provide enough dead animals year-round to keep its scavengers fed on that alone. Scavenger wild dogs and crows frequently exploit roadkill.\n\nScavengers of dead plant material include termites that build nests in grasslands and then collect dead plant material for consumption within the nest. The interaction between scavenging animals and humans is seen today most commonly in suburban settings with animals such as opossums, polecats and raccoons. In some African towns and villages, scavenging from hyenas is also common.\n\nIn the prehistoric eras, the \"Tyrannosaurus rex\" may have been an apex predator, preying upon hadrosaurs, ceratopsians, and possibly juvenile sauropods, although some experts have suggested the dinosaur was primarily a scavenger. The debate about whether \"Tyrannosaurus\" was an apex predator or scavenger was among the longest ongoing feud in paleontology; however, most scientists now agree that \"Tyrannosaurus rex\" was an opportunistic carnivore, acting mostly as a predator but scavenging when it could. Recent research also shows that while an adult Tyrannosaurus rex would energetically gain little though scavenging, smaller theropods of approximately 500 kg may have potentially gained levels similar to that of hyenas, though not enough for them to rely on scavenging.\n\nAnimals which consume feces, such as dung beetles, are referred to as coprovores. Animals that collect small particles of dead organic material of both animal and plant origin are referred to as detritivores.\n\nIn the 1970s, Louis Binford suggested that early humans were obtaining meat via scavenging, not hunting. In 2010, Dennis Bramble and Daniel Lieberman however proposed that early humans used long-distance running to hunt, pursuing a single animal until it died of exhaustion and hyperthermia. Such behavior has been suggested as an adaptation to ensure a food supply that in turn made large brains possible. However, the better term is foraging.\n\nThe eating of human meat, a practice known as anthropophagy (and known across all species more commonly as cannibalism), is extremely taboo in almost every culture.\n\nIn humans, necrophagy is taboo in most societies. Many instances have occurred in history, especially in war times, where necrophagy was a survival behavior.\n\nScavenger appears as an occupation in the 1911 Census of England and Wales. This job title was used to describe someone who cleans the streets and removes refuse, generally a workman (a modern-day garbage collector, janitor, or street cleaner) employed by the local public health authority.\n\nYoung people in developing countries revert to scavenging to develop entrepreneurship skills in order to operate in hostile economic contexts.\n\nIn India, the term \"manual scavenging\" is used to the removal of raw (fresh and untreated) human excreta from buckets or other containers that are used as toilets or from the pits of pit latrines. The excreta are piled into baskets which the workers may carry on their heads to locations sometimes several kilometers from the latrines. The employment of manual scavengers is officially prohibited in India since 1993 but is still taking place to this day.\n\nThe name is properly \"scavager\" or \"scaveger\", an official who was concerned with the receipt of custom duties and the inspection (scavage) of imported goods. The \"scavagers\" are found with such officials of the City of London as an aleconner or beadle. These officials seem to have been charged also with the cleaning of the streets, and the name superseded the older rakyer for those who performed this duty.\nThese professions are essential to urban settings operating at the highest capacity. The garbage collection jobs and scavenging professions allow urban populations to continue unhindered by outbreaks and disease most commonly brought by the build-up of physical waste. These jobs were of the most importance before the time of functional sewer systems and indoor plumbing.\n\n\n\n", "id": "482629", "title": "Scavenger"}
{"url": "https://en.wikipedia.org/wiki?curid=46504493", "text": "Australian Ecology Research Award (AERA)\n\nThe Australian Ecology Research Award (AERA) is an award presented by the Ecological Society of Australia for a specific body of recent ecological work by a mid-career researcher. Initiated in 2008, the AERA was inspired, in part, by the Robert H. MacArthur Award of the Ecological Society of America. The AERA is not restricted to any particular sector, and aims to recognize outstanding ecological research; nominations of researchers from academia, and the public and private sector agencies are invited annually.\n\nThe successful nominee is presented the AERA at the Annual Conference of the Ecological Society of Australia.\n\n2016: Jane Elith\n2015: Saul Cunningham\n2014: Melodie McGeoch \n2013: David Keith\n2012: Chris Johnson\n2011: Lesley Hughes\n2010: Corey Bradshaw\n2009: David Lindenmayer\n2008: Bob Pressey\n", "id": "46504493", "title": "Australian Ecology Research Award (AERA)"}
{"url": "https://en.wikipedia.org/wiki?curid=11724761", "text": "Trophic level\n\nThe trophic level of an organism is the position it occupies in a food chain. The word trophic derives from the Greek τροφή (trophē) referring to food or nourishment. A food chain represents a succession of organisms that eat another organism and are, in turn, eaten themselves. The number of steps an organism is from the start of the chain is a measure of its trophic level. Food chains start at trophic level 1 with primary producers such as plants, move to herbivores at level 2, predators at level 3 and typically finish with carnivores or apex predators at level 4 or 5. The path along the chain can form either a one-way flow or a food \"web\". Ecological communities with higher biodiversity form more complex trophic paths.\n\nThe concept of trophic level was developed by Raymond Lindeman (1942), based on the terminology of August Thienemann (1926): \"producers\", \"consumers\" and \"reducers\" (modified to \"decomposers\" by Lindeman).\n\nThe three basic ways in which organisms get food are as producers, consumers and decomposers.\n\nTrophic levels can be represented by numbers, starting at level 1 with plants. Further trophic levels are numbered subsequently according to how far the organism is along the food chain.\n\nIn real world ecosystems, there is more than one food chain for most organisms, since most organisms eat more than one kind of food or are eaten by more than one type of predator. A diagram that sets out the intricate network of intersecting and overlapping food chains for an ecosystem is called its food web. Decomposers are often left off food webs, but if included, they mark the end of a food chain. Thus food chains start with primary producers and end with decay and decomposers. Since decomposers recycle nutrients, leaving them so they can be reused by primary producers, they are sometimes regarded as occupying their own trophic level.\n\nIn general, each trophic level relates to the one below it by absorbing some of the energy it consumes, and in this way can be regarded as resting on, or supported by, the next lower trophic level. Food chains can be diagrammed to illustrate the amount of energy that moves from one feeding level to the next in a food chain. This is called an energy pyramid. The energy transferred between levels can also be thought of as approximating to a transfer in biomass, so energy pyramids can also be viewed as biomass pyramids, picturing the amount of biomass that results at higher levels from biomass consumed at lower levels.\n\nThe efficiency with which energy or biomass is transferred from one trophic level to the next is called the ecological efficiency. Consumers at each level convert on average only about 10% of the chemical energy in their food to their own organic tissue (the ten-percent law). For this reason, food chains rarely extend for more than 5 or 6 levels. At the lowest trophic level (the bottom of the food chain), plants convert about 1% of the sunlight they receive into chemical energy. It follows from this that the total energy originally present in the incident sunlight that is finally embodied in a tertiary consumer is about 0.001%\n\nBoth the number of trophic levels and the complexity of relationships between them evolve as life diversifies through time, the exception being intermittent mass extinction events.\n\nFood webs largely define ecosystems, and the trophic levels define the position of organisms within the webs. But these trophic levels are not always simple integers, because organisms often feed at more than one trophic level. For example, some carnivores also eat plants, and some plants are carnivores. A large carnivore may eat both smaller carnivores and herbivores; the bobcat eats rabbits, but the mountain lion eats both bobcats and rabbits. Animals can also eat each other; the bullfrog eats crayfish and crayfish eat young bullfrogs. The feeding habits of a juvenile animal, and, as a consequence, its trophic level, can change as it grows up.\n\nThe fisheries scientist Daniel Pauly sets the values of trophic levels to one in plants and detritus, two in herbivores and detritivores (primary consumers), three in secondary consumers, and so on. The definition of the trophic level, TL, for any consumer species is:\n\nwhere formula_2 is the fractional trophic level of the prey \"j\", and formula_3 represents the fraction of \"j\" in the diet of \"i\".\n\nIn the case of marine ecosystems, the trophic level of most fish and other marine consumers takes value between \n2.0 and 5.0. The upper value, 5.0, is unusual, even for large fish, though it occurs in apex predators of marine mammals, such as polar bears and killer whales.\n\nIn addition to observational studies of animal behavior, and quantification of animal stomach contents, trophic level can be quantified through stable isotope analysis of animal tissues such as muscle, skin, hair, bone collagen. This is because there is a consistent increase in the nitrogen isotopic composition at each trophic level caused by fractionations that occur with the synthesis of biomolecules; the magnitude of this increase in nitrogen isotopic composition is approximately 3–4‰.\n\nIn fisheries, the mean trophic level for the fisheries catch across an entire area or ecosystem is calculated for year y as:\n\nwhere formula_5 is the catch of the species or group i in year y, and formula_6 is the trophic level for species i as defined above.\n\nFish at higher trophic levels usually have a higher economic value, which can result in overfishing at the higher trophic levels. Earlier reports found precipitous declines in mean trophic level of fisheries catch, in a process known as fishing down the food web. However, more recent work finds no relation between economic value and trophic level; and that mean trophic levels in catches, surveys and stock assessments have not in fact declined, suggesting that fishing down the food web is not a global phenomenon. However Pauly et al. note that trophic levels peaked at 3.4 in 1970 in the northwest and west-central Atlantic, followed by a subsequent decline to 2.9 in 1994. They report a shift away from long-lived, piscivorous, high-trophic-level bottom fishes, such as cod and haddock, to short-lived, planktivorous, low-trophic-level invertebrates (e.g., shrimps) and small, pelagic fish (e.g., herrings). This shift from high-trophic-level fishes to low-trophic-level invertebrates and fishes is a response to changes in the relative abundance of the preferred catch. They argue this is part of the global fishery collapse.\n\nSince biomass transfer efficiencies are only about 10%, it follows that the rate of biological production is much greater at lower trophic levels than it is at higher levels. Fisheries catches, at least to begin with, will tend to increase as the trophic level declines. At this point the fisheries will target species lower in the food web. In 2000, this led Pauly and others to construct a \"Fisheries in Balance\" index, usually called the FiB index. The FiB index is defined, for any year y, by\n\nwhere formula_8 is the catch at year y, formula_9 is the mean trophic level of the catch at year y, formula_10 is the catch, formula_11 the mean trophic level of the catch at the start of the series being analyzed, and formula_12 is the transfer efficiency of biomass or energy between trophic levels.\n\nThe FiB index is stable (zero) over periods of time when changes in trophic levels are matched by appropriate changes in the catch in the opposite direction. The index increases if catches increase for any reason, e.g. higher fish biomass, or geographic expansion. Such decreases explain the “backward-bending” plots of trophic level versus catch originally observed by Pauly and others in 1998.\n\nOne aspect of trophic levels is called tritrophic interaction. Ecologists often restrict their research to two trophic levels as a way of simplifying the analysis; however, this can be misleading if tritrophic interactions (such as plant–herbivore–predator) are not easily understood by simply adding pairwise interactions (plant–herbivore plus herbivore–predator, for example). Significant interactions can occur between the first trophic level (plant) and the third trophic level (a predator) in determining herbivore population growth, for example. Simple genetic changes may yield morphological variants in plants that then differ in their resistance to herbivores because of the effects of the plant architecture on enemies of the herbivore. Plants can also develop defenses against herbivores such as chemical defenses.\n\nDepending on the nature of the species the precise trophic level of the species may be somewhat ambiguous and its precise value may vary depending on the source. Virtually all plants as well as phytoplankton and similar organisms are classified at level 1.0. Many worms would be typically classified at level 2.1; a typical insect 2.2; a jellyfish 3.0; a typical bird 3.6. A 2013 study published in the National Academy of Sciences estimates the average trophic level of human beings at 2.21, similar to pigs or anchovy. This is only an average, and plainly both modern and ancient human eating habits are complex and vary greatly. For example, a traditional Eskimo living on a diet consisting primarily of seals would have a trophic level of nearly 5.\n\n\n", "id": "11724761", "title": "Trophic level"}
{"url": "https://en.wikipedia.org/wiki?curid=12772746", "text": "Radioecology\n\nRadioecology is a branch of ecology, which studies how radioactive substances interact with nature; how different mechanisms affect the substances' migration and uptake in food chains and ecosystems. Investigations in radioecology might include aspects of field sampling, designed field and laboratory experiments and the development of predictive simulation models. \n\nThis science combines techniques from some of the more basic, traditional fields, such as physics, chemistry, mathematics, biology, and ecology, with applied concepts in radiation protection. Radioecological studies form the basis for estimating doses and assessing the consequences of radioactive pollution for human health and the environment.\"\n\n\n\n", "id": "12772746", "title": "Radioecology"}
{"url": "https://en.wikipedia.org/wiki?curid=47470974", "text": "Glacial refugium\n\nA glacial refugium (\"plural refugia\") is a geographic region which made possible the survival of flora and fauna in times of ice ages and allowed a post-glacial re-colonization. Different types of glacial refugia can be distinguished namely nunatak-, peripheral and lowland refugia. Glacial refugia have been suggested as a major cause of the distributions of flora and fauna in both temperate and tropical latitudes. However, in spite of the continuing use of historical refugia to explain modern-day species distributions, especially in birds, doubt has been cast on the validity of such inferences, as much of the differentiation between populations observed today may have occurred before or after their restriction to refugia.\n\n", "id": "47470974", "title": "Glacial refugium"}
{"url": "https://en.wikipedia.org/wiki?curid=11708788", "text": "Biotic component\n\nBiotic components are the living things that shape an ecosystem.\n\nBiotic components usually include:\nA biotic factor is any living component that affects the population of another organism, or the environment. This includes animals that consume the organism, and the living food that the organism consumes. Biotic factors also include human influence, pathogens, and disease outbreaks. Each biotic factor needs energy to do work and food for proper growth.\n\nAll species are influenced by biotic factors in one way or another. For example, if the number of predators will increase, the whole food web will be affected as the population number of organisms that are lower in the food web will decrease due to predation. Similarly, when organisms have more food to eat, they will grow quicker and will be more likely to reproduce, so the population size will increase. Pathogens and disease outbreaks, however, are most likely to cause a decrease in population size. Humans make the most sudden changes in an environment (e.g. building cities and factories, disposing of waste into the water). These changes are most likely to cause a decrease in the population of any species due to the sudden appearance of pollutants.\n\nBiotic components are contrasted to abiotic components, which are non-living components that influence population size and the environment. Examples of abiotic factors are: temperature, light intensity, moisture and water levels, air currents, carbon dioxide levels and the pH of water and soil. An additional abiotic factor include minerals as they are nonliving and make up the composition of the soil. \n\nThe factors mentioned above may either cause an increase or a decrease in population size, depending on the organism. For example, rainfall may encourage the growth of new plants, but too much of it may cause flooding, which may drastically decrease the population size.\n\n", "id": "11708788", "title": "Biotic component"}
{"url": "https://en.wikipedia.org/wiki?curid=44276500", "text": "Psychedelics and ecology\n\nResearchers have noted the relationship between psychedelics and ecology, particularly in relation to the altered states of consciousness (ASC) produced by psychedelic drugs and the perception of interconnectedness expressed through ecological ideas and themes produced by the psychedelic experience. This is felt through the direct experience of the unity of nature and the environment of which the individual is no longer perceived as separate but intimately connected and embedded inside. \n\nSwiss chemist Albert Hofmann, the first person to synthesize LSD, believed that the drug made one aware and sensitive to \"the magnificence of nature and of the animal and plant kingdom\" and the role of humanity in relation to nature. Stanley Krippner and David Luke have speculated that \"the consumption of psychedelic substances leads to an increased concern for nature and ecological issues\". As a result, American psychologist Ralph Metzner and several others have argued that psychedelic drug use was the impetus for the modern ecology movement in the late 1960s.\n\nIn the context of the psychedelic experience, the term ecology is used to refer to two concepts: how organisms relate to themselves and their environment and the concept of the political movement that seeks to protect the environment. The psychedelic experience is said to result in the direct realization of the fundamental concept of interconnectedness such as the kind found in ecological relationships. Subjects undergoing an LSD psychedelic therapy session in a controlled, laboratory setting report boundary dissolution and the feeling of unity with nature during a psychedelic peak experience. Vollenweider & Kometer (2010) note that measuring the \"feelings of unity with the environment\" can now be reliably assessed using the five-dimensional altered states of consciousness rating scale (5D-ASC) of which \"oceanic boundlessness\" is the primary dimension. Research by Lerner & Lyvers (2006) and Studerus et al. (2010) show that the self-reported values and beliefs of psychedelic drug users indicate a higher concern for the environment than both non-users and users of other illegal drugs. It is unclear from the research whether the concern for the environment preceded the psychedelic experience or came about as a result of it. Conversely, Lester Grinspoon reports that ecological awareness may result in psychedelic drug users forgoing the drug and non-users staying away from it entirely to remain \"pure\". In other words, ecological awareness may not precipitate psychedelic drug use, but may actually discourage it.\n\nIt is likely that humans have consumed psychoactive plants in the ritual context of shamanism for thousands of years prior to the advent of Western civilization and the supplanting of indigenous cultural values. Anthropological archaeologist Gerardo Reichel-Dolmatoff studied the shamanic rituals of the indigenous Tucano people of South America and found that their shamanic practices primarily served to maintain ecological balance in the rainforest habitat. Experts speculate that the ecological values of shamanism are an attribute of the psychedelic experience.\n\nThose who ingest psychoactive drugs often report similar experiences of ecological awareness. Swiss chemist Albert Hofmann, Norwegian philosopher Arne Næss, British religious studies scholar Graham Harvey, and American mycologist Paul Stamets have all written about the shared ecological message of the psychedelic experience. The back-to-the-land movement and the creation of rural intentional communities by the hippie counterculture of the 1960s was in part due to the wide use of psychedelic drugs which people felt helped them get in touch with nature. \nUtopian novels of the 1960s and 1970s illustrated this interrelationship between psychedelic drugs and ecological values. Aldous Huxley's novel \"Island\" (1962) portrayed a utopian society that used psychedelic mushrooms while espousing ecological beliefs. The inhabitants believed that if they treated nature well, nature would treat them well in return; and if they hurt nature, nature would destroy them. The novel, according to Ronald T. Sion, \"reflected the mood of the rebellious American youth of the 1960s, particularly in their search for a communal life that promoted ecological principles.\" Gerd Rohman called \"Island\" a \"seminal influence on modern ecological thought.\" More than a decade later, American writer Ernest Callenbach presented a similar story in \"Ecotopia\" (1975). In the novel, the members of Ecotopia secede from the United States to create an ecological utopia in the Pacific Northwest. Leslie Paul Thiele notes that in Ecotopia, the society actively uses and cultivates cannabis. \"Like Huxley’s islanders\", Thiele writes, the members of Ecotopia \"facilitate ecological attunement through higher states of consciousness.\" The notion that cannabis use is related to ecological awareness can be found in the belief systems of groups like the Rastafari movement, who maintain that cannabis use brings them \"closer to the earth\".\n\n\n", "id": "44276500", "title": "Psychedelics and ecology"}
{"url": "https://en.wikipedia.org/wiki?curid=23513601", "text": "Community greens\n\nCommunity Greens, sometimes referred to as \"backyard commons\", \"urban commons\", or pocket neighborhoods, are shared open green spaces on the inside of city blocks, created either when residents merge backyard space or reclaim underutilized urban land such as vacant lots and alleyways. These shared spaces are communally used and managed only by the residents whose homes abut them. They are not a public park, a private backyard, or a community garden; however, they can function as all three.\n\nCommunity Greens is an organization concerned with the development of shared green spaces in residential neighborhoods in American cities. These green spaces are community greens. The Community Greens movement believes that such an approach presents the best opportunity to add usable green space to American cities, by converting under utilized backyards and dysfunctional alleys into functional and beautiful shared green spaces that are owned, managed, and enjoyed by the people who live around them.\n\nThis has led communities in numerous American cities, including Boston, Sacramento, Baltimore, New York, and San Francisco, taking down their backyard fences, to create backyard commons.\n\nCommunity Greens are multi-functional spaces for gardening, recreation, and leisure which are designed to provide social, economic, and environmental benefits to urban residents. The creation of backyard commons can lead to an increased interaction with neighbors throughout the planning and implementation process, which may result in a stronger overall sense of community. Other possible social benefits that are claimed include decreased crime, from having more eyes on the street, and safe places where children can play and adults relax. Community Greens, like other types of urban green spaces, can significantly improve the ecological functioning of urban habitats. Vegetation and permeable pavement can slow storm water runoff and increase groundwater, which in turn can reduce pollutant flowing into nearby bodies of water during a storm. Urban environments are often significantly warmer than outlying suburbs, mostly due to the prevalence of heat retentive concrete surfaces. City trees can mitigate this effect through shading, etc.. The taking down of backyards fences transforms fragmented habitats to connected corridors for urban wildlife. Furthermore because city dwellers recognize value in green space, often simply from an aesthetic standpoint, and this may be reflected through increased property values.\n\n\nIn 2002, a group of residents from the Patterson Park neighborhood approached the Patterson Park Community Development Corporation (CDC) looking for a way to improve the dirty, crime-ridden alley that ran behind their homes. Simultaneously, Community Greens also approached the Patterson Park CDC looking for an alley they could use as a pilot project in Baltimore, and these two groups were put into contact. The Luzerne-Glover block was granted a temporary permit from the city to gate their alleyway, despite the fact that it was not yet legal to gate a right-of-way. Community Greens, the Patterson Park CDC, the Patterson Park Neighborhood Association and the Luzurne‐Glover block group turned to University of Maryland law professor Barbara Bezdek, who enlisted the help of her law students, who researched existing laws and current uses of Baltimore alleyways.\n\nLooking for a permanent solution, these groups aligned themselves with the Mayor's Department of Neighborhoods and took their case to Annapolis. Maryland Delegate Peter A. Hammen sponsored House Bill 1533 to amend the Baltimore City Charter, allowing the City to close alleyways and lease them to interested parties. The Luzerne-Glover group testified before the Environmental Committee of the state legislature and House Bill 1533 passed in 2004. Community Greens then worked with law firm Hogan & Hartson, in collaboration with Barbara Bezdek, to draft a city alley gating and leasing ordinance, which was then submitted to the City of Baltimore.\n\nIn April 2007, the Baltimore City Council under the leadership of newly elected Mayor Shelia Dixon, passed the Gating and Greening Alleys ordinance, enabling Baltimore residents to legally gate and green the alleys behind their homes, contingent on a requirement that 80% of the homeowners on the alley submit consent forms and 100% of property owners to approve projects that impede traffic flow. Projects requiring 100% consent include removal of existing concrete and installation of permeable pavement and large tree plantings; beautification and smaller greening projects that do not impede traffic only require 80% approval.\n\nInterested communities need approval from several Baltimore City Departments, including Solid Waste, Transportation, Fire, and Police to ensure that proposed alley projects meet the necessary infrastructural conditions. Once initial approval is received, residents submit an application to the Department of Public Works, which includes the necessary consent forms from homeowners and a signed affidavit stating that attempts were made to obtain approval from all homeowners.\n\nThe Luzerne Glover neighborhood now has their green alleyway, and is the first community in Baltimore to use the Gating and Greening Alleys ordinance. So far, seven Baltimore communities have successfully completed this process and have created eight useful Community Greens from the underutilized alleyways in their backyards.\n\nMontgomery Park is a third of an acre common space shared by 85 households in Boston's South End neighborhood. From the time the neighborhood was first developed in the 1860s through the 1970s, the park was separated from the residents' backyards by an alley and fence. In more recent years, residents began to connect the park to their individual yards by replacing the alley separating their private backyards from the park with a narrower brick walkway and tearing down backyard fences. Additionally, residents have moved garbage collection to the front street and convinced utility companies to bury service lines. Residents now enjoy greater access to the shared Community Green, and use it for gardening and recreation.\n\nStoney Creek Apartments were constructed in 1992 to address a lack of affordable housing in Livermore, California. Ten residential buildings share five courtyards, accessible from a small alleyway. Homes have front and back patios in addition to the shared courtyards, and neighbors have the opportunity to enjoy this shared outdoor space and experience a heightened sense of community. The inward-facing position of these patios allows parents to keep a watchful eye on children playing in the courtyard.\n\nLocated in the Federal Hill neighborhood of downtown Baltimore and hidden behind eleven narrow rowhouses, Chandler's Yard is a tree-shaded courtyard that was carved out of the backyards of the surrounding homes by developer Bill Struever who wanted to make living on the block more attractive to potential buyers. Struever convinced some of the property owners in this block to give up part of their backyards for this shared courtyard and pay a small construction fee. The result is a beautiful shared space for these residents, who enjoy a heightened sense of security and increased property values.\n\nThe Village Homes development is situated on a sixty-acre parcel in suburban Davis, California. While home lots are smaller than the average for Davis, clusters of eight homes share common green spaces accessible from private backyards. In addition to these courtyards, Village Homes residents share two large parks, two vineyards, and numerous small orchards and community gardens. Gardens are irrigated by naturally-flowing creeks, which also serve as natural filters that eliminate the need for an expensive storm-water sewer system. Residents enjoy environmental and aesthetic benefits from their shared spaces, and the increased sense of community is evident; Village Homes residents on average know 40 neighbors, compared to an average of 17 acquaintances reported in a nearby traditional suburban development.\n\nFor nearly nine decades, the historic neighborhood of Jackson Heights in Queens has maintained its fourteen block-long shared interior courtyards, and is considered to be the first \"garden apartments\" constructed in the United States. These spaces have helped to sustain the blocks' distinctive appeal since their development in the early decades of the last century. Over the years, Jackson Heights residents fought to hold on to their gardens and green spaces in the midst of a city where high property values create an intense pressure to develop any available open space. The preservation of these shared spaces has increased both community pride and residential property values; if these inner courtyards had been developed, Jackson Heights property values would have dropped by one-third. In 1993, Jackson Heights was officially declared a historic district by the NYC Landmark Preservation Commission, furthering sense of place for this community.\n\nA cooperative apartment community, St. Francis Square consists of 299 apartments wrapped around three shared, open spaces. These community greens are full of gardens, basketball courts, playgrounds, and quiet places to relax. St. Francis Square was established as a limited equity co-operative apartment, although it converted to market rate ownership in 2004.\n\nFifteen years ago, this community was situated in an area of Minneapolis plagued by urban flight and crime. Instrumental to the rehabilitation and renovation of this neighborhood is a local community development corporation, Hope Community, Inc. In the late 1980s, residents were selling their properties for one dollar because they had lost all value; this is when the Hope Community began purchasing houses in the hopes of developing affordable rental units clustered together on a single block. Today, nine rehabilitated houses abut community areas, a playground, and gardens. Property values are steadily increasing and the community itself is stabilizing. By following principles of Crime Prevention Through Environmental Design (CPTED) and creating defensible space, the Hope Community has created a sense of shared ownership and community in a troubled urban area.\n\nSomething similar has taken place in various cities in North America, involving the greening of back lanes or alleys. This includes Chicago, Seattle, Los Angeles, Washington, D.C., and Montréal, Canada, who have started to reclaim their alleys from garbage and crime by greening the service lanes, or back ways, that run behind some houses.\n\nChicago, Illinois has about of alleyways. In 2007, the Chicago Department of Transportation started converting conventional alleys which were paved with asphalt into so called Green Alleys. This program, called the Green Alley Program, is supposed to enable easier water runoff, as the alleyways in Chicago are not connected to the sewer system. With this program, the water will be able to seep through semi-permeable concrete or asphalt in which a colony of fungi and bacteria will establish itself. The bacteria will help breakup oils before the water is absorbed into the ground. The lighter color of the pavement will also reflect more light, making the area next to the alley cooler. The greening of such alleys or laneways can also involve the planting of native plants to further absorb rain water and moderate temperature.\n\n\n", "id": "23513601", "title": "Community greens"}
{"url": "https://en.wikipedia.org/wiki?curid=47057320", "text": "Ecosystem Functional Type\n\nEcosystem Functional Type (EFT) (Fig.1) is a new ecological concept to characterize ecosystem functioning. Ecosystem Functional Types are defined as groups of ecosystems or patches of the land surface that share similar dynamics of matter and energy exchanges between the biota and the physical environment. The EFT concept is analogous to the Plant Functional Types (PFTs) concept, but defined at a higher level of the biological organization. As plant species can be grouped according to common functional characteristics, ecosystems can be grouped according to their common functional behavior.\n\nOne of the most used approaches to implement this concept has been the identification of EFTs from the satellite-derived dynamics of primary production, an essential and integrative descriptor of ecosystem functioning.\n\nIn 1992, Soriano and Paruelo proposed the concept of Biozones to identify vegetation units that share ecosystem functional characteristics using time-series of satellite images of spectral vegetation indices. Biozones were later renamed to EFTs by Paruelo et al. (2001), using an equivalent definition and methodology.\n\nShugart (1997) was one of the first authors that used the term EFT as “aggregated components of ecosystems whose interactions with one another and with the environment produce differences in patterns of ecosystem structure and dynamics”. Walker (1997) proposed the use of a similar term, vegetation functional types, for groups of PFTs in sets that constitute the different states of vegetation succession in non-equilibrium ecosystems. The same term was applied by Scholes et al. (1997) in a wider sense for those areas having similar ecological attributes, such as PFTs composition, structure, phenology, biomass or productivity. Several studies have applied hierarchy and patch dynamic theories for the definition of ecosystem and landscape functional types at different spatial scales, by scaling-up emergent structural and functional properties from patches to regions. Valentini et al. (1999) defined land functional units by focusing on patches of the land surface that are able to exchange mass and energy with the atmosphere and show a coordinated and specific response to environmental factors.\n\nParuelo et al. (2001) and Alcaraz-Segura et al. (2006, 2013) refined the EFT concept and proposed a remote-sensing based methodology to derive them. Since then, several authors have implemented the idea under the same or similar approaches using NOAA-AVHRR, MODIS and Landsat archives. In brief, all these approaches use the seasonal dynamics of spectral indices related to key functional aspects of ecosystems such as primary production, water exchange, heat exchange and radiative balance.\n\nThe functional classification of EFTs developed by Paruelo et al. (2001) and Alcaraz-Segura et al. (2006, 2013) uses time series of spectral vegetation indexes to capture the carbon gains dynamics, the most integrative indicator of ecosystem functioning. To build EFTs, these authors derive three descriptors or metrics from the seasonal dynamics (annual curve) of spectral vegetation indexes (VI) that capture most of the variance in the time series (Fig.2): \n\n\nThe range of values of each VI metric is divided into four intervals, giving the potential number of 4x4x4=64 EFTs. Each EFT is assigned a code of two letters and a number (three characters). The first letter of the code (capital) corresponds to the VI_Mean level, ranging from A to D for low to high (increasing) VI_Mean or productivity. The second letter (small) shows the seasonal CV, ranging from a to d for high (decreasing) to low VI_sCV or seasonality. The numbers refer to DMAX or phenology and indicate the season of maximum VI (1–4: spring, summer, autumn and winter).\n\n\n", "id": "47057320", "title": "Ecosystem Functional Type"}
{"url": "https://en.wikipedia.org/wiki?curid=44421636", "text": "Relocation of Marine Corps Air Station Futenma\n\nOver the last five decades there have been various plans for the relocation of Marine Corps Air Station Futenma, a United States Marine Corps base located within the urban area of Ginowan City (pop. 93,661) in Okinawa, Japan.\n\nLocal opposition within Okinawa regarding the facility has so far hindered efforts to begin construction. , the Japanese government had agreed to halt construction activities temporarily while talks with Okinawan officials continued. Still, US sources insisted nothing about their approach had changed.\n\nIn October 2015, despite strong opposition in Okinawa, the Japanese central government began work to build the base in the Henoko Bay, in Nago. The issue has been taken to court by both parties in November 2015 and December 2015. After a tentative court-mediated settlement in March 2016, the national government sued Okinawa governor Takeshi Onaga in July, and obtained a High Court ruling in September determining that it was illegal for Onaga to revoke his predecessor's permission for landfill work at the new site. The Supreme Court of Japan indicated in December that it would let this judgment stand, opening a door for the relocation work to proceed.\n\nOkinawa prefecture constitutes 0.6% of Japan's land surface, yet as of 2006, 75% of all USFJ bases were located on Okinawa, and U.S. military bases occupied 18% of the main island.\n\nThere is local opposition in Okinawa to the construction of a new base, more than 76 per cent of the population having expressed their opposition to a relocation in Henoko.\n\nIn November 2014 Takeshi Onaga, who had run for election on an anti-base platform, was elected Governor of Okinawa. His predecessor and main opponent in the gubernatorial race, Hirokazu Nakaima, had previously opposed the relocation plans himself too; but 11 months before the 2014 election, Nakaima approved a landfill permit allowing the relocation plans to progress, two days after Tokyo earmarked 348 billion yen for Okinawa's economic development.\n\nOne of Japan's most popular filmmakers, Hayao Miyazaki, publicly spoke out in July 2015 against the facility when he argued that most Okinawans are against it.\n\nIn July 15, 2015's daily press briefing at the White House, US Navy Admiral John Kirby said in regards to opposition: \"Construction of the facility is the meaningful result of many years of sustained work between the United States and Japan, and our understanding is that construction’s going to continue. This is something we’ve talked at length about with the Government of Japan. Certainly I’ve seen the reports and understand some of the angst by people in Okinawa, but nothing’s changed about our approach or our policies with respect to that facility. We have, through many different fora, consistently talked about the importance of this relocation and the degrees to which it helps strengthen our alliance with Japan.\"\n\nDeclassified reports indicate the plan to build new runways at Heonko Bay was secretly formulated in the 1960s during the U.S. Military Occupation and Administration of the Islands. Building an expanded base at Henoko has been called the \"only solution\" to resolving the issues at Futenma. The U.S. Military had originally proposed constructing \"an offshore landfill facility with two 3,000-meter runways, a large military port and an integrated ammunition bunker capable of storing nuclear weapons.\" \n\nA separate 260-page report revealed the master plan for U.S. Navy facilities of the base expansion that was submitted by an American company under contract to the Navy in 1966.\n\nThe report states that the U.S. government “should continue to emphasize to the government of Japan that Japan’s security is in large part dependent on the maintenance of a substantial U.S. military posture.”\n\nThe base expansion plan was abandoned over local friction and criticism over the seizure of civilian-owned land and a drawdown of the War in Vietnam.\n\nIn December 1996, as part of the Defense Policy Review Initiative (DPRI), the Japanese and U.S. governments decided that the Futenma base should be relocated to an off-shore location in the Oura Bay of Henoko (\"Ourawan\" in Japanese; often called \"Henoko Bay\"), in Nago, a relatively less populated area of the northern part of the island, 'in order to reduce military impact to the populated communities of southern Okinawa'.\n\nThis was and remains a controversial decision, since the projected site involved construction on a coral reef and seagrass beds inhabited by the dugong, an endangered marine mammal protected under Japanese law and U.S. law. The environmental impact extends beyond the coral reef and seagrass beds, with there expected to be waste dumping, the disruption of fisheries, and an overall decrease in biological diversity. In October 2015, \"The Japan Times\" mentioned that 'two members of a governmental panel monitoring the environmental impact of the Futenma base relocation within Okinawa Prefecture (had) admitted to accepting donations from contractors involved.'\n\nIn a non-binding referendum conducted in December 1997, the majority of Nago residents voted against the Henoko relocation plan. However, a few days later on December 24, Nago Mayor Tetuya Higa ignored the referendum results and accepted the relocation plan, resigned, and moved to Tokyo. The next year Tateo Kishimoto was elected mayor of Nago and tried to find compromises regarding the relocation. So did his successor Yoshikazu Shimabukuro, at a time when the Prefecture Governor, Masahide Ota, was opposed to the Henoko relocation. The next mayor too, Susumu Inamine, was opposed to it and he was elected twice with a high margin on an anti-base agenda.\n\nThe Henoko Bay plan was reactivated in 2013 by the U.S. and Japanese governments after other projects were abandoned (see below) despite the continued research on the detrimental environmental effects of the base construction.\n\nThe Japanese central government began work on October 29, 2015 to build the base in the Henoko coastal area of Nago, to replace the Futenma Air Station, despite strong opposition among Okinawans and political and legal action initiated by Governor Takeshi Onaga, who insisted the relocation was 'extremely unjust'.\n\nThe opposition to the relocation has received notable support outside of Okinawa, including those of animation film maker Hayao Miyazaki, who will help 'a fund set up to oppose the relocation', of Nobel Prize winner Kenzaburo Oe and of musician Ryuichi Sakamoto. The latter, whose October 2015 single is a charity work in favor of the Henoko Fund, is \"a critic of the national security legislation enacted (in September 2015) (and) said the issue of the heavy U.S. military presence on Okinawa and the contentious security laws share the same root.\"\n\nGreenpeace too gathered signatures of people from 164 countries, in a call for the relocation to be stopped and the coral reef and dugong habitat preserved.\n\nIn November 2015, the \"Asahi Shimbun\" called Japanese Government agenda on the matter an 'obsession'.\n\nIn December 2015, a group of 70 American personalities, including the filmmaker Oliver Stone, criticized the U.S. Ambassador to Japan, Caroline Kennedy, for the support she expressed to the contentious U.S.-Japan relocation plan.\n\nIn June 2016, massive protests took place after the rape and murder of an Okinawan woman by an American base staff member: 'The incidents seem certain to complicate efforts to relocate a Marine air base at Okinawa, to a less densely populated part of the island. Onaga and a majority of Okinawa residents want the base moved off the island.', commmented USA Today.\n\nOn 26 October 2005, the governments of the United States and Japan agreed to move the relocation site for Futenma from the reef area off Henoko to the interior and coastal portions of the existing Marine base at Camp Schwab, just a few hundred meters away from the previously-planned offshore facility. One of the cited reasons for the change was to reduce the engineering challenge associated with building a runway on reefs in deep water: experts estimate that rather than the 15-plus years required to construct a new airbase at the previous reef location, the Camp Schwab plan will enable Futenma to be relocated sooner. These plans were also accelerated when a CH-53D Sea Stallion transport helicopter experienced mechanical issues and of Okinawa International University in August 2004: all three crew members were injured but there were not civilian injuries.\nThe mayor of Nago, which hosts Camp Schwab, formally agreed to accept the relocation when he signed an agreement with Defense Minister Nukaga on 8 April 2006. Mayor Shimabukuro was later joined by all five of the major mayors of northern Okinawa. Although some all-Okinawa public opinion polls indicated that majority of Okinawans wish the based moved out of the prefecture entirely, all 12 elected mayors of northern Okinawa publicly accepted the new relocation plan, exposing a range of conflicting opinions among Okinawans: those who maintain that military facilities and associated public works infrastructure benefit the island's economy, environmentalists, and those who either object or are critical to the U.S. military presence on ideological grounds or on rooted sentiments.\n\nThe relocation plans again gained national attention in 2009 when the Democratic Party of Japan included a promise to move Futenma off the island in its manifesto. After winning the election, Prime Minister Yukio Hatoyama found the promise hard to honor and resigned after only eight months in office when it was confirmed that the base would not move off Okinawa. At one point in 2009, Osaka Prefecture governor Toru Hashimoto even publicly proposed moving the base's functions to Osaka's Kansai International Airport (which is on an artificial island), remarking that \"the burden [of bases on Okinawa] should be spread more evenly throughout Japan.\"\n\nSusumu Inamine, the mayor of Nago city elected on 24 January 2010, and reelected again on 19 January 2013, is against the Henoko relocation plan and argued for the relocation of Futenma outside of Okinawa. The local assembly of Nago voted against the relocation plan, and the prefectural assembly of Okinawa also formally asked the prime minister to move the base out of the prefecture. On 17 May 2010, the anniversary of the reversion of Okinawa to Japan, an estimated 17,000 Okinawans encircled the base in protest. This was the fifth time such an action took place.\n\nIn 2011, the chairman and ranking member of the United States Senate Committee on Armed Services called for an alternative plan where Futenma aircraft would move to Kadena Air Base while the current aircraft at Kadena would move to Andersen Air Force Base. However, US and Japan governments remained with the relocation plan as previously agreed and the fate of Futenma remained unresolved through early 2012, with the U.S. insisting that the Marine Corps' aviation elements be kept on the island while the Okinawa Prefectural government and Nago City government would like the base moved off the island. The US alleged that the aviation elements should be in close proximity to the ground and logistics elements of the Marine Air Ground Task Force, and the Japanese government of the time maintained the plan to keep the replacement airbase within Okinawa.\n\nThe US and Japan delinked the relocation of Futenma from plans to decrease the number of Marines stationed on Okinawa under a troop redeployment agreement in April 2012. Under the terms of the new U.S.-Japan agreement, 5,000 U.S. Marines were to be relocated to Guam and 4,000 U.S. Marines to other Pacific locations such as Hawaii or Australia, while some 10,000 Marines would remain on Okinawa. No timetable for the Marines redeployment was announced, but the Washington Post reported that U.S. Marines would leave Futenma as soon as suitable facilities on Guam and elsewhere would be ready. The relocation move was expected to cost 8.6 billion US Dollars and included a $3.1 billion cash commitment from Japan for the move to Guam as well as for developing joint training ranges on Guam and on Tinian and Pagan in the Commonwealth of the Northern Mariana Islands.\n\nDuring this period, the US began to deploy Bell Boeing V-22 Osprey tilt rotor aircraft to Futenma in 2012, allowing the Marines (and the MV-22B Osprey aircraft) from Okinawa to train all along the length of Japan and around the entire Asia-Pacific region, with the Osprey's greatly increased speed, lift capabilities and range.\n\nIn April 2013, the United States and Japan released an \"Okinawa Consolidation Plan,\" which detailed more general positions of the 1996 DPRI and 2006 SACO plans, specifying 2,500 acres of land to be returned Japan. This included returning the entirety of MCAS Futenma by \"Japanese Fiscal Year 2022 or later\" once the \"replacement facilities in Okinawa are provided.\" As part of the original DPRI plan, Futenma's KC-130J 'Super Hercules' refueling transport squadron moved to MCAS Iwakuni on mainland Japan in July 2014. The plan also included, as in previous plans, moving Marine Corps airfield facilities to Camp Schwab at Henoko. The proposed location within Camp Schwab is insulated from potential protesters, unlike the previous proposed location in Henoko Bay where local civilians were able to enter the survey area.\n\nIn December 2013, Okinawa Governor Hirokazu Nakaima approved a landfill proposal by the Japanese government to permit construction of new military facilities in Henoko, a move praised by the US. The decision came two days after Tokyo earmarked 348 billion yen for Okinawa's economic development and despite earlier campaign promises by Nakaima to move the base outside of the prefecture all together. Over 2,000 citizens responded immediately with a protest in front of the prefectural administration building, with around 1,000 forcing their way into the building to stage a sit-in. The head of the Nago municipal assembly responded that \"what the governor has done is unforgivable. Residents who are opposed will surely resort to the use of force, such as blocking roads to stop this from happening.\" The Okinawa prefectural assembly adopted a resolution by a 24-21 vote calling for Nakaima's resignation, stating that he broke an election promise by agreeing to the move.\n\nSusumu Inamine, Mayor of Nago, where the new facility is to be built, opposed the plan, while Mayor Atsushi Sakima, of Ginowan where the current facility is located, supported the plan. Nago held a mayoral election in January 2014, in which Inamine's main rival, former Vice Mayor Bunshin Suematsu, supported the plan as \"a significant step toward reducing the dangers posed by Futenma.\" Inamine won the election and subsequently vowed to block any landfill plans in the city, but the national government said it would continue with the plan and that the authority to approve the plan rested at the time with the governor of Okinawa.\n\nTakeshi Onaga, running on an anti-base platform, won the November 2014 gubernatorial elections in Okinawa promising to veto any landfill work needed for the new base to be built. In March 2015, Onaga ordered a suspension of work on the new base, and in August 2015 the Japanese government agreed to halt construction activities temporarily while talks with Okinawan officials continued.\n\nIn November 2015, George Washington University professor Mike Mochizuki explained that 'an option of setting up a helicopter base at Marine Corps Camp Schwab in Nago could be considered instead of the current plan to build runways in the camp that would extend offshore' 'The option was included in a 1996 report by the Special Action Committee on Okinawa between the two countries.', noted the \"Japan Times\".\n\n\"Japanese officials in the ruling and opposition parties had in the past suggested Kyushu and Hokkaido as alternatives to Henoko.\" In November 2015 a group of 'traditionally anti-base activist' citizens from Kansai called for Futenma’s replacement airstrip to be built in Osaka, in 'hope to lighten Okinawa’s base-hosting burden and prevent an escalation of violence.'\n", "id": "44421636", "title": "Relocation of Marine Corps Air Station Futenma"}
{"url": "https://en.wikipedia.org/wiki?curid=25111839", "text": "Overexploitation\n\nOverexploitation, also called overharvesting, refers to harvesting a renewable resource to the point of diminishing returns. Sustained overexploitation can lead to the destruction of the resource. The term applies to natural resources such as: wild medicinal plants, grazing pastures, game animals, fish stocks, forests, and water aquifers.\n\nIn ecology, overexploitation describes one of the five main activities threatening global biodiversity. Ecologists use the term to describe populations that are harvested at a rate that is unsustainable, given their natural rates of mortality and capacities for reproduction. This can result in extinction at the population level and even extinction of whole species. In conservation biology the term is usually used in the context of human economic activity that involves the taking of biological resources, or organisms, in larger numbers than their populations can withstand. The term is also used and defined somewhat differently in fisheries, hydrology and natural resource management.\n\nOverexploitation can lead to resource destruction, including extinctions. However it is also possible for overexploitation to be sustainable, as discussed below in the section on fisheries. In the context of fishing, the term overfishing can be used instead of overexploitation, as can overgrazing in stock management, overlogging in forest management, overdrafting in aquifer management, and endangered species in species monitoring. Overexploitation is not an activity limited to humans. Introduced predators and herbivores, for example, can overexploit native flora and fauna.\n\nConcern about overexploitation is relatively recent, though overexploitation itself is not a new phenomenon. It has been observed for millennia. For example, ceremonial cloaks worn by the Hawaiian kings were made from the mamo bird; a single cloak used the feathers of 70,000 birds of this now-extinct species. The dodo, a flightless bird from Mauritius, is another well-known example of overexploitation. As with many island species, it was naive about certain predators, allowing humans to approach and kill it with ease.\n\nFrom the earliest of times, hunting has been an important human activity as a means of survival. There is a whole history of overexploitation in the form of overhunting. The overkill hypothesis (Quaternary extinction events) explains why the megafaunal extinctions occurred within a relatively short period of time. This can be traced with human migration. The most convincing evidence of this theory is that 80% of the North American large mammal species disappeared within 1000 years of the arrival of humans on the western hemisphere continents. The fastest ever recorded extinction of megafauna occurred in New Zealand, where by 1500 AD, just 200 years after settling the islands, ten species of the giant moa birds were hunted to extinction by the Māori. A second wave of extinctions occurred later with European settlement.\n\nIn more recent times, overexploitation has resulted in the gradual emergence of the concepts of sustainability and sustainable development, which has built on other concepts, such as sustainable yield, eco-development and deep ecology.\n\nOverexploitation doesn't necessarily lead to the destruction of the resource, nor is it necessarily unsustainable. However, depleting the numbers or amount of the resource can change its quality. For example, footstool palm is a wild palm tree found in Southeast Asia. Its leaves are used for thatching and food wrapping, and overharvesting has resulted in its leaf size becoming smaller.\n\nThe tragedy of the commons refers to a dilemma described in an article by that name written by Garrett Hardin and first published in the journal \"Science\" in 1968.\n\nCentral to Hardin's essay is an example which is a useful parable for understanding how overexploitation can occur. This example was first sketched in an 1833 pamphlet by William Forster Lloyd, as a hypothetical and simplified situation based on medieval land tenure in Europe, of herders sharing a common on which they are each entitled to let their cows graze. In Hardin's example, it is in each herder's interest to put each succeeding cow he acquires onto the land, even if the carrying capacity of the common is exceeded and it is temporarily or permanently damaged for all as a result. The herder receives all of the benefits from an additional cow, while the damage to the common is shared by the entire group. If all herders make this individually rational economic decision, the common will be overexploited or even destroyed to the detriment of all. However, since all herders reach the same rational conclusion, overexploitation in the form of overgrazing occurs, with immediate losses, and the pasture may be degraded to the point where it gives very little return.\n\"Therein is the tragedy. Each man is locked into a system that compels him to increase his herd without limit—in a world that is limited. Ruin is the destination toward which all men rush, each pursuing his own interest in a society that believes in the freedom of the commons.\" (Hardin, 1968)\nIn the course of his essay, Hardin develops the theme, drawing in many examples of latter day commons, such as national parks, the atmosphere, oceans, rivers and fish stocks. The example of fish stocks had led some to call this the \"tragedy of the fishers\". A major theme running through the essay is the growth of human populations, with the Earth's finite resources being the general common.\n\nThe tragedy of the commons has intellectual roots tracing back to Aristotle, who noted that \"what is common to the greatest number has the least care bestowed upon it\", as well as to Hobbes and his \"Leviathan\". The opposite situation to a tragedy of the commons is sometimes referred to as a tragedy of the anticommons: a situation in which rational individuals, acting separately, collectively waste a given resource by underutilizing it.\n\nThe tragedy of the commons can be avoided if it is appropriately regulated. Hardin's use of \"commons\" has frequently been misunderstood, leading Hardin to later remark that he should have titled his work \"The tragedy of the unregulated commons\".\n\nIn wild fisheries, overexploitation or overfishing occurs when a fish stock has been fished down \"below the size that, on average, would support the long-term maximum sustainable yield of the fishery\". However, overexploitation can be sustainable.\n\nWhen a fishery starts harvesting fish from a previously unexploited stock, the biomass of the fish stock will decrease, since harvesting means fish are being removed. For sustainability, the rate at which the fish replenish biomass through reproduction must balance the rate at which the fish are being harvested. If the harvest rate is increased, then the stock biomass will further decrease. At a certain point, the maximum harvest yield that can be sustained will be reached, and further attempts to increase the harvest rate will result in the collapse of the fishery. This point is called the maximum sustainable yield, and in practice, usually occurs when the fishery has been fished down to about 30% of the biomass it had before harvesting started.\n\nIt is possible to fish the stock down further to, say, 15% of the pre-harvest biomass, and then adjust the harvest rate so the biomass remains at that level. In this case, the fishery is sustainable, but is now overexploited, because the stock has been run down to the point where the sustainable yield is less than it could be.\n\nFish stocks are said to \"collapse\" if their biomass declines by more than 95 percent of their maximum historical biomass. Atlantic cod stocks were severely overexploited in the 1970s and 1980s, leading to their abrupt collapse in 1992. Even though fishing has ceased, the cod stocks have failed to recover. The absence of cod as the apex predator in many areas has led to trophic cascades.\n\nAbout 25% of world fisheries are now overexploited to the point where their current biomass is less than the level that maximizes their sustainable yield. These depleted fisheries can often recover if fishing pressure is reduced until the stock biomass returns to the optimal biomass. At this point, harvesting can be resumed near the maximum sustainable yield.\n\nThe tragedy of the commons can be avoided within the context of fisheries if fishing effort and practices are regulated appropriately by fisheries management. One effective approach may be assigning some measure of ownership in the form of individual transferable quotas (ITQs) to fishermen. In 2008, a large scale study of fisheries that used ITQs, and ones that didn't, provided strong evidence that ITQs help prevent collapses and restore fisheries that appear to be in decline.\n\nWater resources, such as lakes and aquifers, are usually renewable resources which naturally recharge (the term fossil water is sometimes used to describe aquifers which don't recharge). Overexploitation occurs if a water resource, such as the Ogallala Aquifer, is mined or extracted at a rate that exceeds the recharge rate, that is, at a rate that exceeds the practical sustained yield. Recharge usually comes from area streams, rivers and lakes. An aquifer which has been overexploited is said to be overdrafted or depleted. Forests enhance the recharge of aquifers in some locales, although generally forests are a major source of aquifer depletion. Depleted aquifers can become polluted with contaminants such as nitrates, or permanently damaged through subsidence or through saline intrusion from the ocean.\n\nThis turns much of the world's underground water and lakes into finite resources with peak usage debates similar to oil. These debates usually centre around agriculture and suburban water usage but generation of electricity from nuclear energy or coal and tar sands mining is also water resource intensive. A modified Hubbert curve applies to any resource that can be harvested faster than it can be replaced. Though Hubbert's original analysis did not apply to renewable resources, their overexploitation can result in a Hubbert-like peak. This has led to the concept of peak water.\n\nForests are overexploited when they are logged at a rate faster than reforestation takes place. Reforestation competes with other land uses such as food production, livestock grazing, and living space for further economic growth. Historically utilization of forest products, including timber and fuel wood, have played a key role in human societies, comparable to the roles of water and cultivable land. Today, developed countries continue to utilize timber for building houses, and wood pulp for paper. In developing countries almost three billion people rely on wood for heating and cooking. Short-term economic gains made by conversion of forest to agriculture, or overexploitation of wood products, typically leads to loss of long-term income and long term biological productivity. West Africa, Madagascar, Southeast Asia and many other regions have experienced lower revenue because of overexploitation and the consequent declining timber harvests.\n\nOverexploitation is one of the main threats to global biodiversity. Other threats include pollution, introduced and invasive species, habitat fragmentation, habitat destruction, uncontrolled hybridization, global warming, ocean acidification and the driver behind many of these, human overpopulation.\n\nOne of the key health issues associated with biodiversity is drug discovery and the availability of medicinal resources. A significant proportion of drugs are natural products derived, directly or indirectly, from biological sources. Marine ecosystems are of particular interest in this regard. However unregulated and inappropriate bioprospecting could potentially lead to overexploitation, ecosystem degradation and loss of biodiversity.\n\nOverexploitation threatens one-third of endangered vertebrates, as well as other groups. Excluding edible fish, the illegal trade in wildlife is valued at $10 billion per year. Industries responsible for this include the trade in bushmeat, the trade in Chinese medicine, and the fur trade. The Convention for International Trade in Endangered Species of Wild Fauna and Flora, or CITES was set up in order to control and regulate the trade in endangered animals. It currently protects, to a varying degree, some 33,000 species of animals and plants. It is estimated that a quarter of the endangered vertebrates in the United States of America and half of the endangered mammals is attributed to overexploitation.\n\nAll living organisms require resources to survive. Overexploitation of these resources for protracted periods can deplete natural stocks to the point where they are unable to recover within a short time frame. Humans have always harvested food and other resources they have needed to survive. Human populations, historically, were small, and methods of collection limited to small quantities. With an exponential increase in human population, expanding markets and increasing demand, combined with improved access and techniques for capture, are causing the exploitation of many species beyond sustainable levels. In practical terms, if continued, it reduces valuable resources to such low levels that their exploitation is no longer sustainable and can lead to the extinction of a species, in addition to having dramatic, unforeseen effects, on the ecosystem. Overexploitation often occurs rapidly as markets open, utilising previously untapped resources, or locally used species.\n\nToday, overexploitation and misuse of natural resources is an ever-present threat for species richness. This is more prevalent when looking at island ecology and the species that inhabit them, as islands can be viewed as the world in miniature. Island endemic populations are more prone to extinction from overexploitation, as they often exist at low densities with reduced reproductive rates. A good example of this are island snails, such as the Hawaiian \"Achatinella\" and the French Polynesian \"Partula\". Achatinelline snails have 15 species listed as extinct and 24 critically endangered while 60 species of partulidae are considered extinct with 14 listed as critically endangered. The WCMC have attributed over-collecting and very low lifetime fecundity for the extreme vulnerability exhibited among these species.\n\nAs another example, when the humble hedgehog was introduced to the Scottish island of Uist, the population greatly expanded and took to consuming and overexploiting shorebird eggs, with drastic consequences for their breeding success. Twelve species of avifauna are affected, with some species numbers being reduced by 39%.\n\nWhere there is substantial human migration, civil unrest, or war, controls may no longer exist. With civil unrest, for example in the Congo and Rwanda, firearms have become common and the breakdown of food distribution networks in such countries leaves the resources of the natural environment vulnerable. Animals are even killed as target practice, or simply to spite the government. Populations of large primates, such as gorillas and chimpanzees, ungulates and other mammals, may be reduced by 80% or more by hunting, and certain species may be eliminated altogether. This decline has been called the bushmeat crisis.\n\nOverall, 50 bird species that have become extinct since 1500 (approximately 40% of the total) have been subject to overexploitation, including:\n\n\nOther species affected by overexploitation include: \n\n\nOverexploitation of species can result in knock-on or cascade effects. This can particularly apply if, through overexploitation, a habitat loses its apex predator. Because of the loss of the top predator, a dramatic increase in their prey species can occur. In turn, the unchecked prey can then overexploit their own food resources until population numbers dwindle, possibly to the point of extinction.\n\nA classic example of cascade effects occurred with sea otters. Starting before the 17th century and not phased out until 1911, sea otters were hunted aggressively for their exceptionally warm and valuable pelts, which could fetch up to $2500 US. This caused cascade effects through the kelp forest ecosystems along the Pacific Coast of North America.\n\nOne of the sea otters’ primary food sources is the sea urchin. When hunters caused sea otter populations to decline, an ecological release of sea urchin populations occurred. The sea urchins then overexploited their main food source, kelp, creating urchin barrens, areas of seabed denuded of kelp, but carpeted with urchins. No longer having food to eat, the sea urchin became locally extinct as well. Also, since kelp forest ecosystems are homes to many other species, the loss of the kelp caused other cascade effects of secondary extinctions.\n\nIn 1911, when only one small group of 32 sea otters survived in a remote cove, an international treaty was signed to prevent further exploitation of the sea otters. Under heavy protection, the otters multiplied and repopulated the depleted areas, which slowly recovered. More recently, with declining numbers of fish stocks, again due to overexploitation, killer whales have experienced a food shortage and have been observed feeding on sea otters, again reducing their numbers.\n\n", "id": "25111839", "title": "Overexploitation"}
{"url": "https://en.wikipedia.org/wiki?curid=48660867", "text": "Myrmecophily in Staphylinidae\n\nMany species of Staphylinidae (commonly known as “Rove Beetles”) have developed complex interspecies relationships with ants, known as myrmecophily. Rove Beetles are among the most rich and diverse families of myrmecophilous beetles, with a wide variety of relationships with ants. Ant associations range from near free-living species which prey only on ants, to obligate inquilines of ants, which exhibit extreme morphological and chemical adaptations to the harsh environments of ant nests. Some species are fully integrated into the host colony, and are cleaned and fed by ants. Many of these, including species in tribe Clavigerini, are myrmecophagous, placating their hosts with glandular secretions while eating the brood\n\nStaphylinidae is currently considered to be the largest family of beetles, with over 58,000 species described. As such, many myrmecophilous species are unknown. The majority of studied myrmecophilous Rove Beetles belong to the subfamily Aleocharinae, including the commonly studied genera \"Pella\", \"Dinarda\", \"Tetradonia\", \"Ecitomorpha\", \"Ecitophya\", \"Atemeles\", and \"Limechusa\", and to the subfamily Pselaphinae, which includes \"Claviger\" and \"Adranes\". There are also representatives of Scydmaenidae, which includes 117 myrmecophilous species in 20 genera The Aleocharinae possess defensive glands on their abdomens, which are used in myrmecophilous species to prevent attacks by their host ant and in more extreme cases to integrate completely into the colony. Many Pselephinae species have trichomes, tufts of hairs which hold placating pheromones. Pselephines have evolved trichomes independently at least four times, most notably in all members of Clavigerini, but also in \"Attapsenius\" and \"Songius\" genera.\n\nDue to their large number and diversity, myrmecophilous Rove Beetles occupy an array of behaviors. Myrmecophilous interactions can be generalized into categories, in three of which Staphylinids can be found. The synecthrans, or “persecuted guests,” the synoeketes, or “tolerated guests,” and the symphiles, or “true guests.”\n\nSynecthran Staphylinids live on the periphery of the host colony and are not accepted into the colony. The majority are in the subfamily Aleocharinae, having defensive glands on their terminal abdominal segments. Species in this group, such as those in the genus \"Pella\", commonly lay their eggs in the refuse heaps of their host ant, where the larvae feed on the discarded carcasses of ants. If detected by the host ant, the larvae enters a typical defense position, facing the ant with its abdomen tip raised. Usually this behavior results in the ant palpating the beetle’s abdomen and stopping the attack. At least two members of \"Pella, P. funestus\" and \"P. humeralis\", produce several of their host ant’s alarm pheromones to avoid aggression. Other species, like members of \"Myrmechusa, Aenictonia\", and \"Anommatochara\", prey on raiding columns or on the nests of Driver ants (\"Dorylus\"). \"Myrmechusa\" species attack the ants from the rear before pulling them from the main column. If pursued, they rapidly wave their abdomens through the air, releasing a noticeable scent. Ants encountering this scent seem disoriented and take almost 20 minutes to recover.\n\nSynoeketetic Staphylinids live in close contact with their host ants but are not integrated into the colony. These species may be further categorized as neutral, mimetic, loricate, and symphiloid synoeketes. Neutral synoeketes ignore and are ignored by their host, but feed on refuse. There are few Staphylinid neutral synoeketes, but some are found in the genus \"Athetini\", which live in the debris and fungal chambers of leaf cutter ants (\"Atta\"). Mimetic synoeketes are myrmecoid, resembling their host ant morphologically. Many mimetic species are guests of Driver ants, which are blind. Driver ants however have strong senses of touch, suggesting mimics fool their hosts tactilely. It is also possible that mimicry may reduce predation from more visual animals, such as birds. Loricate, or “tear-drop shaped”, synoeketes are “defensive forms”. They typically exhibit long tapering bodies with broad thoraxes and smooth bodies, which prevent aggressing ants from gripping them. Symphiloids strongly resemble “true guests,” but are not fully integrated into the colony. They are often mimics, and in some species have developed trichomes. Syneoketes generally live on or inside of ant nests, where they feed on refuse and may steal food from their hosts. There is some overlap between synoeketes and other categories, especially in loricate species and synecthrans, and symphiloids and symphiles, where the behavior of “true guests” may be difficult to determine.\n\nSymphilic Staphylinids have been fully integrated into the host ant’s society. Symphilic species have undergone complex morphological adaptations, many becoming myrmecoid. Most have developed trichomes, which secrete appeasement pheromones. The most extreme adaptations, found in members of tribe Clavigerini, include the reduction of mouthparts for trophallaxis and the fusing of many body and antennal segments. While most symphiles use antennal contact to stimulate food giving from their host, at least one member of Clavigerini, \"Claviger testaceus\", secretes a chemical to induce regurgitation from its host ant \"Lasius flavus\". Symphiles typically take on many roles in the colony, raising young, feeding and grooming adults, and helping transport food and larvae. Many Staphylinids are capable of following ant pheromone trails, although they are not limited to following trails laid by their host ant. This allows symphiles of army ants to migrate with the colony. Most species are trophallactic, being fed by other members of the colony. Almost all species have also been observed feeding on the brood, making them obligate parasites.\n\nChemical mimicry refers to the production of one species’ chemical signals by another species. Many myrmecophilous Staphylinids have evolved chemical mimicry to deter or placate ants. Synecthrans, as non tolarated guests, primarily produce defensive secretions. \"Pella\" species produce two compounds found in their host ant \"Lasius fuliginosus\", undecane and sulcatone, which elicit aggressive and panic reactions respectively. Although it seems counterintuitive to release an aggressive alarm pheromone as a defense, the presence of sulcatone stops the aggression response to undecane. Ants exposed to the defensive secretion act less aggressively and avoid the odor.\n\nFor Staphylinids accepted into the host colony chemical mimicry is used more for camouflage. The majority of the chemical signals used are cuticular hydrocarbons, which are produced in the cuticle of the host ant at certain concentrations and are palpated to determine the identity of an ant. Species in close contact with their host ants are able to pick up the host’s hydrocarbons and imitate the ant’s hydrocarbon pattern, thus appearing in scent at least to be the same species as the host ant. As hydrocarbon patterns are specific to an individual colony, the Rove Beetles are generally restricted to one nest. The production of a new hydrocarbon pattern takes time, during which the beetle is vulnerable to detection and attack. Some species, such as \"Zyras comes\", produce volatile pheromones as well as cuticular hydrocarbons, which may provide it more protection than contact based pheromones while traveling with its host in foraging trails.\n\n", "id": "48660867", "title": "Myrmecophily in Staphylinidae"}
{"url": "https://en.wikipedia.org/wiki?curid=5509703", "text": "Species distribution\n\nSpecies distribution is the manner in which a biological taxon is spatially arranged. Species distribution is not to be confused with dispersal, which is the movement of individuals away from their area of origin or from centers of high on density. A similar concept is the species range. A species range is often represented with a species range map. Biogeographers try to understand the factors determining a species' distribution. The pattern of distribution is not permanent for each species. Distribution patterns can change seasonally, in response to the availability of resources, and also depending on the scale at which they are viewed. Dispersion usually takes place at the time of reproduction. Populations within a species are translocated through many methods, including dispersal by people, wind, water and animals. Humans are one of the largest distributors due to the current trends in globalization and the expanse of the transportation industry. For example, large tankers often fill their ballasts with water at one port and empty them in another, causing a wider distribution of aquatic species.\n\nBiogeography is the study of the distribution of biodiversity over space and time. It is very useful in understanding species distribution through factors such as speciation, extinction, continental drift, glaciation, variation of sea levels, river capture and available resources. This branch of study not only gives a description of the species distribution, but also a geographical explanation for the distribution of particular species. The traditional biogeographic regions were first modeled by Alfred Wallace in \"The Geographical Distribution of Animals\" (1876). These were based on the work of Sclater's terrestrial biogeographic regions. Wallace's system was based on both birds and vertebrates, including non-flying mammals, which better reflect the natural divisions of the Earth due to their limited dispersal abilities.\n\nClumped distribution is the most common type of dispersion found in nature. In clumped distribution, the distance between neighboring individuals is minimized. This type of distribution is found in environments that are characterized by patchy resources. Animals need certain resources to survive, and when these resources become rare during certain parts of the year animals tend to “clump” together around these crucial resources. Individuals might be clustered together in an area due to social factors such as selfish herds and family groups. Organisms that usually serve as prey form clumped distributions in areas where they can hide and detect predators easily.\n\nOther causes of clumped distributions are the inability of offspring to independently move from their habitat. This is seen in juvenile animals that are immobile and strongly dependent upon parental care. For example, the bald eagle's nest of eaglets exhibits a clumped species distribution because all the offspring are in a small subset of a survey area before they learn to fly. Clumped distribution can be beneficial to the individuals in that group. However, in some herbivore cases, such as cows and wildebeests, the vegetation around them can suffer, especially if animals target one plant in particular.\n\nClumped distribution in species acts as a mechanism against predation as well as an efficient mechanism to trap or corner prey. African wild dogs, \"Lycaon pictus\", use the technique of communal hunting to increase their success rate at catching prey. Studies have shown that larger packs of African wild dogs tend to have a greater number of successful kills. A prime example of clumped distribution due to patchy resources is the wildlife in Africa during the dry season; lions, hyenas, giraffes, elephants, gazelles, and many more animals are clumped by small water sources that are present in the severe dry season. It has also been observed that extinct and threatened species are more likely to be clumped in their distribution on a phylogeny. The reasoning behind this is that they share traits that increase vulnerability to extinction because related taxa are often located within the same broad geographical or habitat types where human-induced threats are concentrated. Using recently developed complete phylogenies for mammalian carnivores and primates it has been shown that the majority of instances threatened species are far from randomly distributed among taxa and phylogenetic clades and display clumped distribution.\n\nLess common than clumped distribution, uniform distribution, also known as even distribution, is evenly spaced. Uniform distributions are found in populations in which the distance between neighboring individuals is maximized. The need to maximize the space between individuals generally arises from competition for a resource such as moisture or nutrients, or as a result of direct social interactions between individuals within the population, such as territoriality. For example, penguins often exhibit uniform spacing by aggressively defending their territory among their neighbors. The burrows of great gerbils for example are also regularly distributed, which can be seen on satellite images. Plants also exhibit uniform distributions, like the creosote bushes in the southwestern region of the United States. \"Salvia leucophylla\" is a species in California that naturally grows in uniform spacing. This flower releases chemicals called terpenes which inhibit the growth of other plants around it and results in uniform distribution. This is an example of allelopathy, which is the release of chemicals from plant parts by leaching, root exudation, volatilization, residue decomposition and other processes. Allelopathy can have beneficial, harmful, or neutral effects on surrounding organisms. Some allelochemicals even have selective effects on surrounding organisms; for example, the tree species \"Leucaena leucocephala\" exudes a chemical that inhibits the growth of other plants but not those of its own species, and thus can affect the distribution of specific rival species. Allelopathy usually results in uniform distributions, and its potential to suppress weeds is being researched. Farming and agricultural practices often create uniform distribution in areas where it would not previously exist, for example, orange trees growing in rows on a plantation.\n\nRandom distribution, also known as unpredictable spacing, is the least common form of distribution in nature and occurs when the members of a given species are found in environments in which the position of each individual is independent of the other individuals: they neither attract nor repel one another. Random distribution is rare in nature as biotic factors, such as the interactions with neighboring individuals, and abiotic factors, such as climate or soil conditions, generally cause organisms to be either clustered or spread. Random distribution usually occurs in habitats where environmental conditions and resources are consistent. This pattern of dispersion is characterized by the lack of any strong social interactions between species. For example; When dandelion seeds are dispersed by wind, random distribution will often occur as the seedlings land in random places determined by uncontrollable factors. Oyster larvae can also travel hundreds of kilometers powered by sea currents, which can result in their random distribution.\n\nSpecies distribution can now be potentially predicted based on the pattern of biodiversity at spatial scales. A general hierarchical model can integrate disturbance, dispersal and population dynamics. Based on factors of dispersal, disturbance, resources limiting climate, and other species distribution, predictions of species distribution can create a bio-climate range, or bio-climate envelope. The envelope can range from a local to a global scale or from a density independence to dependence. The hierarchical model takes into consideration the requirements, impacts or resources as well as local extinctions in disturbance factors. Models can integrate the dispersal/migration model, the disturbance model, and abundance model. Species distribution models (SDMs) can be used to assess climate change impacts and conservation management issues. Species distribution models include: presence/absence models, the dispersal/migration models, disturbance models, and abundance models. A prevalent way of creating predicted distribution maps for different species is to reclassify a land cover layer depending on whether or not the species in question would be predicted to habit each cover type. This simple SDM is often modified through the use of range data or ancillary information- such as elevation or water distance.\n\nRecent studies have indicated that the grid size used can have an effect on the output of these species distribution models. The standard 50x50 km grid size can select up to 2.89 times more area than when modeled with a 1x1 km grid for the same species. This has several effects on the species conservation planning under climate change predictions (global climate models- which are frequently used in the creation of species distribution models- usually consists of 50–100 km size grids) which could lead to over-prediction of future ranges in species distribution modeling. This can result in the misidentification of protected areas intended for a species future habitat.\n\nThe distribution of species into clumped, uniform, or random depends on different abiotic and biotic factors. Any non-living chemical or physical factor in the environment is considered an abiotic factor. There are three main types of abiotic factors: climatic factors consist of sunlight, atmosphere, humidity, temperature, and salinity; edaphic factors are abiotic factors regarding soil, such as the coarseness of soil, local geology, soil pH, and aeration; and social factors include land use and water availability. An example of the effects of abiotic factors on species distribution can be seen in drier areas, where most individuals of a species will gather around water sources, forming a clumped distribution.\n\nBiotic factors, such as predation, disease, and competition for resources such as food, water, and mates, can also affect how a species is distributed. A biotic factor is any behavior of an organism that affects another organism, such as a predator consuming its prey. For example, biotic factors in a quail’s environment would include their prey (insects and seeds), competition from other quail, and their predators, such as the coyote. An advantage of a herd, community, or other clumped distribution allows a population to detect predators earlier, at a greater distance, and potentially mount an effective defense. Due to limited resources, populations may be evenly distributed to minimize competition, as is found in forests, where competition for sunlight produces an even distribution of trees.\n\nThe Species Distribution Grids Project is an effort led out of the University of Columbia to create maps and databases of the whereabouts of various animal species. This work is centered on preventing deforestation and prioritizing areas based on species richness. As of April 2009, data are available for global amphibian distributions, as well as birds and mammals in the Americas. The map gallery Gridded Species Distribution contains sample maps for the Species Grids data set. These maps are not inclusive but rather contain a representative sample of the types of data available for download:\n\nThere are various ways to determine the distribution pattern of species. The Clark-Evans nearest neighbor method can be used to determine if a distribution is clumped, uniform or random.\nTo utilize the Clark-Evans nearest neighbor method, researchers examine a population of a single species. The distance of an individual to its nearest neighbor is recorded for each individual in the sample. For two individuals that are each other's nearest neighbor, the distance is recorded twice, once for each individual. To receive accurate results, it is suggested that the number of distance measurements is at least 50. The average distance between nearest neighbors is compared to the expected distance in the case of random distribution to give the ratio:\n\nformula_1\n\nIf this ratio (R) is equal to 1, then the population is randomly dispersed. If R is significantly greater than 1, the population is evenly dispersed. Lastly, if R is significantly less than 1, the population is clumped. Statistical tests (such as t-test, chi squared, etc.) can then be used to determine whether R is significantly different from 1.\n\nThe Variance/Mean ratio method focuses mainly on determining whether a species fits a randomly spaced distribution, but can also be used as evidence for either an even or clumped distribution. To utilize the Variance/Mean ratio method, data is collected from several random samples of a given population. In this analysis, it is imperative that data from at least 50 sample plots is considered. The number of individuals present in each sample is compared to the expected counts in the case of random distribution. The expected distribution can be found using Poisson distribution. If the variance/mean ratio is equal to 1, the population is found to be randomly distributed. If it is significantly greater than 1, the population is found to be clumped distribution. Finally, if the ratio is significantly less than 1, the population is found to be evenly distributed. Typical statistical tests used to find the significance of the variance/mean ratio include Student's t-test and chi squared.\n\nHowever, many researchers believe that species distribution models based on statistical analysis, without including ecological models and theories, are too incomplete for prediction. Instead of conclusions based on presence-absence data, probabilities that convey the likelihood a species will occupy a given area are more preferred because these models include an estimate of confidence in the likelihood of the species being present/absent. Additionally, they are also more valuable than data collected based on simple presence or absence because models based on probability allow the formation of spatial maps that indicates how likely a species is to be found in a particular area. Similar areas can then be compared to see how likely it is that a species will occur there also; this leads to a relationship between habitat suitability and species occurrence.\n\nResearchers from the Arctic Ocean Diversity (ARCOD) project have documented rising numbers of warm-water crustaceans in the seas around Norway's Svalbard Islands. Arcod is part of the Census of Marine Life, a huge 10-year project involving researchers in more than 80 nations that aims to chart the diversity, distribution and abundance of life in the oceans. Marine Life has become largely affected by increasing effects of global warming. This study shows that as the ocean temperatures rise species are beginning to travel into the cold and harsh Arctic waters. Even the Snow Crab has extended its range 500 km north.\n\n\n", "id": "5509703", "title": "Species distribution"}
{"url": "https://en.wikipedia.org/wiki?curid=27195467", "text": "Facultative parasite\n\nA facultative parasite is an organism that may resort to parasitic activity, but does not absolutely rely on any host for completion of its life cycle.\n\nExamples of facultative parasitism occur among many species of fungi, such as family members of the genus \"Armillaria\". \"Armillaria\" species do parasitise living trees, but if the tree dies, whether as a consequence of the fungal infection or not, the fungus continues to eat the wood without further need for parasitic activity; some species even can ingest dead wood without any parasitic activity at all. As such, although they also are important ecological agents in the process of nutrient recycling by microbial decomposition, the fungi become pests in their role as destructive agents of wood rot.\n\nSimilarly, green plants in genera such as \"Rhinanthus\" and Colpoon can grow independently of any host, but they also act opportunistically as facultative root parasites of neighboring green plants.\n\nAmong animals, facultatively kleptoparasitic species generally can survive by hunting or scavenging for themselves, but it often is more profitable for them to rob food from other animals kleptoparasitically, whether their hosts are of the same species or not. Such behavior occurs in lions and hyaenas for example, and also among insects such as \"Jackal flies\" in the family Milichiidae.\n\nMore intimately, normally free-living microbes may opportunistically live as facultative parasites in other organisms.\n\nAn example of this in humans is Naegleria fowleri. As a rule this amoeboid species is a free-living predator on microbes, but occasionally it successfully infects humans as a facultative internal parasite.\n\n", "id": "27195467", "title": "Facultative parasite"}
{"url": "https://en.wikipedia.org/wiki?curid=48922696", "text": "UNECE Environmental Performance Reviews\n\nThe UNECE Environmental Performance Review (EPR) (French: Examen des performances environnementales – EPE) is an assessment process to evaluate the progress made by individual countries in improving their environmental policies. The EPRs are carried out under the auspices of the Committee on Environmental Policy of the United Nations Economic Commission for Europe (UNECE).\n\nEPRs provide countries with independent, external assessment of how they handle the pollution reduction process, manage their natural resources and protect nature and environment. EPRs also evaluate progress made by governments in meeting their international commitments on environment and sustainable development such as the Millennium Development Goals.\n\nThe UNECE Programme on EPRs was inspired by a sister programme launched by the Organisation for Economic Co-operation and Development (OECD) for its member States in 1991. In 1993 at the second \"Environment for Europe\" Ministerial Conference in Lucerne, Switzerland, UNECE was asked to run an EPR Programme for its member States that were not covered by the OECD EPR Programme. Therefore, the UNECE EPRs focus on the countries of Eastern Europe, Caucasus, Central Asia and South-Eastern Europe known as economies in transition.\n\nThe first EPR cycle established the baseline conditions regarding state of environment and national environmental policies. The second EPR cycle looked into the implementation and financing of environmental policies, integration of environmental concerns into economic sectors, and promotion of sustainable development. By now, almost all eligible UNECE member countries have been reviewed twice.\n\nThe third review cycle was initiated at the seventh “Environment for Europe” Ministerial Conference (Astana, Kazakhstan, 2011). It focuses on environmental governance and green economy. It also analyses countries’ cooperation with international community and environmental mainstreaming in priority sectors.\n\nTopics for the EPR report are selected by the country which requests an EPR. EPRs cover horizontal issues such as legislation and policy development, compliance and enforcement, use of economic instruments for environmental protection, environmental information and education. They discuss in detail the issues of water management, air protection, waste management, biodiversity and protected areas, and integration of environmental considerations into selected sectors such as agriculture, energy, forestry, industry, transport, or health. Cross-cutting issues, such as environmental monitoring and climate change, are also addressed in the EPRs.\n\nThe EPR is a voluntary exercise undertaken only at the request of a country. Once the request is received, the UNECE secretariat organizes a preparatory mission to the country during which the structure of the review is agreed.\n\nUpon completion of preparatory activities, international experts embark on a review mission to the country where they meet with national and local governmental representatives, international organizations, civil society groups and the private sector to gain an in-depth understanding of specific environmental issues. International experts are provided by governments and international organizations, such as OECD, United Nations Environment Programme (UNEP), United Nations Economic Commission for Africa (UNECA), United Nations Development Programme (UNDP), United Nations International Strategy for Disaster Reduction (UNISDR), United Nations Office for the Coordination of Humanitarian Affairs (OCHA), European Environment Agency (EEA), World Health Organization (WHO) and World Bank (WB). At the end of the review mission, the experts prepare chapters that are compiled into a draft EPR report.\n\nThe draft EPR report is first reviewed by the EPR Expert Group, which consists of representatives from ten UNECE member countries elected for three years. During the review, the members of the Expert Group discuss the draft EPR report, with particular attention given to the conclusions and recommendations. Delegation from the reviewed country is invited to participate in the meeting and interact with the Expert Group. At the end of review, the report is amended and submitted to the Committee on Environmental Policy for peer review.\n\nAt the annual session of the Committee on Environmental Policy, UNECE member States and a high-level delegation from the country discuss and review EPR recommendations. The Committee on Environmental Policy adopts the recommendations of the EPR report and the country commits to implement them.\n\nThe report is then finalized and published. An official launch event of the EPR publication usually takes place in the country under review. Typically, the launch event is accompanied by a press conference with high-level governmental representation.\n\nWhen an EPR is conducted in the country for the second or the third time, governmental officials usually prepare a self-evaluation of implementation of recommendations of the previous review. The outcomes of self-evaluation are reviewed by the team of international experts and become part of the EPR report.\n\nList of countries reviewed.\n\nIn 2012 – 2013, the UNECE EPR Programme undertook a review of a non-UNECE country – Morocco. The EPR of Morocco was carried out in cooperation with UNECA to facilitate the transfer of the EPR methodology and know-how from UNECE to UNECA.\n\nBy providing concrete, tailor-made, recommendations, the EPR reports assist countries to reconcile their economic and social development with environmental protection.\n\nUnlike for ratified international treaties, the countries do not have a formal legal obligation to implement EPR recommendations. However, governments do make serious efforts to implement the recommendations. The average rate of implementation of EPR recommendations is about 75 per cent.\n\nThe practical measures that have been implemented as a result of the EPRs include the strengthening of environmental institutions and governance, the adoption of new legislation and policy documents, introduction of economic instruments for environmental protection, better integration of environmental considerations into sectoral policies, increase of governmental expenditures for environmental protection and other measures.\n\nThe Synthesis report of the Secretary-General on the Post-2015 Sustainable Development Agenda “The Road to Dignity by 2030: ending poverty, transforming all lives and protecting the Planet” (2014) mentions the UNECE EPRs as an example of regional review mechanisms, whose experience is important for monitoring, evaluation and reporting on Sustainable Development Goals (SDGs).\n\nMr. Christian Friis Bach, UNECE Executive Secretary and Under-Secretary-General, described the role of UNECE in the implementation and review of the 2030 Agenda for Sustainable Development, highlighting the EPRs as a mechanism to support member States in the follow-up and review, and thereby implementation, of the Sustainable Development Goals (SDGs).\n\nSince 2017, EPRs include the review of relevant goals and targets of the 2030 Agenda for Sustainable Development and provide recommendations to the countries on the achievement of SDGs.\n\n", "id": "48922696", "title": "UNECE Environmental Performance Reviews"}
{"url": "https://en.wikipedia.org/wiki?curid=316915", "text": "Ecological damage\n\nEcological damage may refer to:\n", "id": "316915", "title": "Ecological damage"}
{"url": "https://en.wikipedia.org/wiki?curid=49542583", "text": "Resource consumption\n\nResource consumption is about the consumption of non-renewable, or less often, renewable resources. Specifically, it may refer to:\n\n\nMeasures of resource consumption are resource intensity and resource efficiency. Industrialization and globalized markets have increased the tendency for overconsumption of resources. The resource consumption rate of a nation does not usually correspond with the primary resource availability, this is called resource curse.\n\nUnsustainable consumption by the steadily growing human population may lead to resource depletion and a shrinking of the earth's carrying capacity.\n\n", "id": "49542583", "title": "Resource consumption"}
{"url": "https://en.wikipedia.org/wiki?curid=9619", "text": "Extremophile\n\nAn extremophile (from Latin ' meaning \"extreme\" and Greek ' () meaning \"love\") is an organism that thrives in physically or geochemically extreme conditions that are detrimental to most life on Earth. In contrast, organisms that live in more moderate environments may be termed mesophiles or neutrophiles.\n\nIn the 1980s and 1990s, biologists found that microbial life has great flexibility for surviving in extreme environments—niches that are acidic or extraordinarily hot, for example—that would be completely inhospitable to complex organisms. Some scientists even concluded that life may have begun on Earth in hydrothermal vents far under the ocean's surface. According to astrophysicist Steinn Sigurdsson, \"There are viable bacterial spores that have been found that are 40 million years old on Earth—and we know they're very hardened to radiation.\" On 6 February 2013, scientists reported that bacteria were found living in the cold and dark in a lake buried a half-mile deep under the ice in Antarctica. On 17 March 2013, researchers reported data that suggested microbial life forms thrive in the Marianas Trench, the deepest place in Earth's oceans. Other researchers reported related studies that microbes thrive inside rocks up to below the sea floor under of ocean off the coast of the northwestern United States. According to one of the researchers, \"You can find microbes everywhere—they're extremely adaptable to conditions, and survive wherever they are.\"\n\nMost known extremophiles are microorganisms. The domain Archaea contains renowned examples, but extremophiles are present in numerous and diverse genetic lineages of bacteria and archaeans. Furthermore, it is erroneous to use the term extremophile to encompass all archaeans, as some are mesophilic. Neither are all extremophiles unicellular; protostome animals found in similar environments include the Pompeii worm, the psychrophilic Grylloblattidae (insects) and Antarctic krill (a crustacean). Many would also classify tardigrades (water bears) as extremophiles but while tardigrades can survive in extreme environments, they are not considered extremophiles because they are not adapted to live in these conditions. Their chances of dying increase the longer they are exposed to the extreme environment.\n\nThere are many classes of extremophiles that range all around the globe, each corresponding to the way its environmental niche differs from mesophilic conditions. These classifications are not exclusive. Many extremophiles fall under multiple categories and are classified as polyextremophiles. For example, organisms living inside hot rocks deep under Earth's surface are thermophilic and barophilic such as \"Thermococcus barophilus\". A polyextremophile living at the summit of a mountain in the Atacama Desert might be a radioresistant xerophile, a psychrophile, and an oligotroph. Polyextremophiles are well known for their ability to tolerate both high and low pH levels.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAstrobiology is the field concerned with forming theories, such as panspermia, about the distribution, nature, and future of life in the universe. In it, microbial ecologists, astronomers, planetary scientists, geochemists, philosophers, and explorers cooperate constructively to guide the search for life on other planets. Astrobiologists are particularly interested in studying extremophiles, as many organisms of this type are capable of surviving in environments similar to those known to exist on other planets. For example, analogous deserts of Antarctica are exposed to harmful UV radiation, low temperature, high salt concentration and low mineral concentration. These conditions are similar to those on Mars. Therefore, finding viable microbes at the subsurface of Antarctica suggests that there may be microbes surviving in endolithic communities and living under Martian surface. Moreover, further researches have suggested that it is unlikely that microbes will live on neither the Martian surface nor at shallow depths, but they may be found at depths around 100 meters below the Martian surface.\n\nRecent research carried out on extremophiles in Japan involved a variety of bacteria including \"Escherichia coli\" and \"Paracoccus denitrificans\" being subject to conditions of extreme gravity. The bacteria were cultivated while being rotated in an ultracentrifuge at high speeds corresponding to 403,627 g (i.e. 403,627 times the gravity experienced on Earth). \"Paracoccus denitrificans\" was one of the bacteria which displayed not only survival but also robust cellular growth under these conditions of hyperacceleration which are usually found only in cosmic environments, such as on very massive stars or in the shock waves of supernovas. Analysis showed that the small size of prokaryotic cells is essential for successful growth under hypergravity. The research has implications on the feasibility of panspermia.\n\nOn 26 April 2012, scientists reported that lichen survived and showed remarkable results on the adaptation capacity of photosynthetic activity within the simulation time of 34 days under Martian conditions in the Mars Simulation Laboratory (MSL) maintained by the German Aerospace Center (DLR).\n\nOn 29 April 2013, scientists at Rensselaer Polytechnic Institute, funded by NASA, reported that, during spaceflight on the International Space Station, microbes seem to adapt to the space environment in ways \"not observed on Earth\" and in ways that \"can lead to increases in growth and virulence\".\n\nOn 19 May 2014, scientists announced that numerous microbes, like \"Tersicoccus phoenicis\", may be resistant to methods usually used in spacecraft assembly clean rooms. It's not currently known if such resistant microbes could have withstood space travel and are present on the \"Curiosity\" rover now on the planet Mars.\n\nOn 20 August 2014, scientists confirmed the existence of microorganisms living half a mile below the ice of Antarctica.\n\nOn September 2015, scientists from CNR-National Research Council of Italy reported that S.soflataricus was able to survive under Martian radiation at a wavelength that was considered extremely lethal to most bacteria. This discovery is significant because it indicates that not only bacterial spores, but also growing cells can be remarkably resistant to strong UV radiation.\n\nOn June 2016, scientists from Brigham Young University conclusively reported that endospores of Bacillus Subtilis were able to survive high speed impacts up to 299±28 m/s, extreme shock, and extreme deceleration. They pointed out that this feature might allow endospores to survive and to be transferred between planets by traveling within meteorites or by experiencing atmosphere disruption. Moreover, they suggested that the landing of spacecrafts may also result in interplanetary spore transfer, given that spores can survive high-velocity impact while ejected from the spacecraft onto the planet surface. This is the first study which reported that bacteria can survive in such high-velocity impact. However, the lethal speed impact is unknown, and further experiments should be done by introducing higher-velocity impact to bacterial endospores.\n\nNew sub-types of -philes are identified frequently and the sub-category list for extremophiles is always growing. For example, microbial life lives in the liquid asphalt lake, Pitch Lake. Research indicates that extremophiles inhabit the asphalt lake in populations ranging between 10 to 10 cells/gram. Likewise, until recently boron tolerance was unknown but a strong borophile was discovered in bacteria. With the recent isolation of \"Bacillus boroniphilus\", borophiles came into discussion. Studying these borophiles may help illuminate the mechanisms of both boron toxicity and boron deficiency.\n\nThe thermoalkaliphilic catalase, which initiates the breakdown of hydrogen peroxide into oxygen and water, was isolated from an organism, \"Thermus brockianus\", found in Yellowstone National Park by Idaho National Laboratory researchers. The catalase operates over a temperature range from 30 °C to over 94 °C and a pH range from 6–10. This catalase is extremely stable compared to other catalases at high temperatures and pH. In a comparative study, the \"T. brockianus\" catalase exhibited a half life of 15 days at 80 °C and pH 10 while a catalase derived from \"Aspergillus niger\" had a half life of 15 seconds under the same conditions. The catalase will have applications for removal of hydrogen peroxide in industrial processes such as pulp and paper bleaching, textile bleaching, food pasteurization, and surface decontamination of food packaging.\n\nDNA modifying enzymes such as \"Taq\" DNA polymerase and some \"Bacillus\" enzymes used in clinical diagnostics and starch liquefaction are produced commercially by several biotechnology companies.\n\nOver 65 prokaryotic species are known to be naturally competent for genetic transformation, the ability to transfer DNA from one cell to another cell followed by integration of the donor DNA into the recipient cell’s chromosome. Several extremophiles are able to carry out species-specific DNA transfer, as described below. However, it is not yet clear how common such a capability is among extremophiles.\n\nThe bacterium \"Deinococcus radiodurans\" is one of the most radioresistant organisms known. This bacterium can also survive cold, dehydration, vacuum and acid and is thus known as a polyextremophile. \"D. radiodurans\" is competent to perform genetic transformation. Recipient cells are able to repair DNA damage in donor transforming DNA that had been UV irradiated as efficiently as they repair cellular DNA when the cells themselves are irradiated. The extreme thermophilic bacterium \"Thermus thermophilus\" and other related \"Thermus\" species are also capable of genetic transformation.\n\n\"Halobacterium volcanii\", an extreme halophilic (saline tolerant) archaeon, is capable of natural genetic transformation. Cytoplasmic bridges are formed between cells that appear to be used for DNA transfer from one cell to another in either direction.\n\n\"Sulfolobus solfataricus\" and \"Sulfolobus acidocaldarius\" are hyperthermophilic archaea. Exposure of these organisms to the DNA damaging agents UV irradiation, bleomycin or mitomycin C induces species-specific cellular aggregation. UV-induced cellular aggregation of \"S. acidocaldarius\" mediates chromosomal marker exchange with high frequency. Recombination rates exceed those of uninduced cultures by up to three orders of magnitude. Frols et al. and Ajon et al. hypothesized that cellular aggregation enhances species-specific DNA transfer between \"Sulfolobus\" cells in order to repair damaged DNA by means of homologous recombination. Van Wolferen et al. noted that this DNA exchange process may be crucial under DNA damaging conditions such as high temperatures. It has also been suggested that DNA transfer in \"Sulfolobus\" may be an early form of sexual interaction similar to the more well-studied bacterial transformation systems that involve species-specific DNA transfer leading to homologous recombinational repair of DNA damage (and see Transformation (genetics)).\n\nExtracellular membrane vesicles (MVs) might be involved in DNA transfer between different hyperthermophilic archaeal species. It has been shown that both plasmids and viral genomes can be transferred via MVs. Notably, a horizontal plasmid transfer has been documented between hyperthermophilic \"Thermococcus\" and \"Methanocaldococcus\" species, respectively belonging to the orders \"Thermococcales\" and \"Methanococcales\".\n\n\n", "id": "9619", "title": "Extremophile"}
{"url": "https://en.wikipedia.org/wiki?curid=49660332", "text": "Analysis of similarities\n\nAnalysis of similarities (ANOSIM) is a non-parametric statistical test widely used in the field of ecology. The test was first suggested by K. R. Clarke as an ANOVA-like test, where instead of operating on raw data, operates on a ranked dissimilarity matrix.\n\nGiven a matrix of rank dissimilarities between a set of samples, each solely belong to one treatment group, the ANOSIM tests whether we can reject the null hypothesis that the similarity between groups is greater than or equal to the similarity within the groups.\n\nThe test statistic \"R\" is calculated in the following way:\n\nwhere is the average of rank similarities of pairs of samples (or replicates) originating from different sites, is the average of rank similarity of pairs among replicates within sites, and \"M\" = \"n\"(\"n\" − 1)/2 where \"n\" is the number of samples.\n\nThe test statistic \"R\" is constrained between the values −1 to 1, where positive numbers suggest more similarity within sites and values close to zero represent no difference between within sites and within sites similarities. Negative \"R\" values suggest more similarity between sites than within sites and may raise the possibility of wrong assignment of samples to sites.\n\nFor the purpose of hypothesis testing, where the null hypothesis is that the similarities within sites are smaller or equal to the similarities between sites, the \"R\" statistic is usually compared to a set of \"R′\" values that are achieved by means of randomly shuffling site labels between the samples and calculating the resulting \"R′\", repeated many times. The percent of times that the actual \"R\" surpassed the permutations derived \"R′\" values is the p-value for the actual \"R\" statistic.\n\nRanking of dissimilarity in ANOSIM and NMDS (non-metric multidimensional scaling) go hand in hand.\nCombining both methods complement visualisation of group differences along with significance testing.\n\nANOSIM is implemented in several statistical software including PRIMER, R Vegan package and PAST.\n\n", "id": "49660332", "title": "Analysis of similarities"}
{"url": "https://en.wikipedia.org/wiki?curid=48708073", "text": "Pumlenpat\n\nPumletnpat is a small lake situated about 68 km south of Imphal, the capital of Manipur, and about 45 km from Thoubal. This fresh-water lake is the second largest in the state after Loktak Lake. People situated around this lake depend on fishery products for their livelihood. The lake plays an important role in lives of the towns nearby. There are plenty of small islands on this lake; people started settling on these islands, and the lake is now on the verge of extinction due to human encroachment.\n\nIthai dam, one of the important dams related to the Loktak Lift Irrigation is situated at southwest corner of this lake. Pumlet lake or Pumletpat is on the verge of extinction due to human settlement and encroachments in and around this lake. The floating plankton, or phumdi as it is called locally, is one of the important source of fishery products as waterbodies and the fishes can easily get adapted to this place for food and shelter.\n\n", "id": "48708073", "title": "Pumlenpat"}
{"url": "https://en.wikipedia.org/wiki?curid=49771633", "text": "Species sorting\n\nSpecies sorting is a mechanism in the metacommunity framework of ecology whereby species abundances can be tied to the abundance of available resources at a location in the environment (environmental filtering) and the ability of a species to take advantage of a particular habitat.\n", "id": "49771633", "title": "Species sorting"}
{"url": "https://en.wikipedia.org/wiki?curid=1607622", "text": "History of ecology\n\nEcology is a new science and considered as an important branch of biological science, having only become prominent during the second half of the 20th century. Ecological thought is derivative of established currents in philosophy, particularly from ethics and politics. Its history stems all the way back to the 4th century. One of the first ecologists whose writings survive may have been Aristotle or perhaps his student, Theophrastus, both of whom had interest in many species of animals and plants. Theophrastus described interrelationships between animals and their environment as early as the 4th century BC. Ecology developed substantially in the 18th and 19th century. It began with Carl Linnaeus and his work with the economy of nature. Soon after came Alexander von Humboldt and his work with botanical geography. Alfred Russel Wallace and Karl Möbius then contributed with the notion of biocoenosis. Eugenius Warming’s work with ecological plant geography led to the founding of ecology as a discipline. Charles Darwin’s work also contributed to the science of ecology, and Darwin is often attributed with progressing the discipline more than anyone else in its young history. Ecological thought expanded even more in the early 20th century. Major contributions included: Eduard Suess’ and Vladimir Vernadsky’s work with the biosphere, Arthur Tansley’s ecosystem, Charles Elton's \"Animal Ecology\", and Henry Cowles ecological succession. Ecology influenced the social sciences and humanities. Human ecology began in the early 20th century and it recognized humans as an ecological factor. Later James Lovelock advanced views on earth as a macro-organism with the Gaia hypothesis. Conservation stemmed from the science of ecology. Important figures and movements include Shelford and the ESA, National Environmental Policy act, George Perkins Marsh, Theodore Roosevelt, Stephen A. Forbes, and post-Dust Bowl conservation. Later in the 20th century world governments collaborated on man’s effects on the biosphere and Earth’s environment.\n\nThe history of ecology is intertwined with the history of conservation efforts, in particular the founding of the Nature Conservancy.\n\nIn the early Eighteenth century, preceding Carl Linnaeus, two rival schools of thought dominated the growing scientific discipline of ecology. First, Gilbert White a “parson-naturalist” is attributed with developing and endorsing the view of Arcadian ecology. Arcadian ecology advocates for a “simple, humble life for man” and a harmonious relationship with humans and nature. Opposing the Arcadian view is Francis Bacon’s ideology, “imperial ecology”. Imperialists work “to establish through the exercise of reason and by hard work, man’s dominance over nature”. Imperial ecologists also believe that man should become a dominant figure over nature and all other organisms as “once enjoyed in the Garden of Eden”. Both views continued their rivalry through the early eighteenth century until Carl Linnaeus’s support of imperialism; and in short time due to Linnaeus’s popularity, imperial ecology became the dominant view within the discipline.\n\nCarl Linnaeus, a Swedish naturalist, is well known for his work with taxonomy but his ideas helped to lay the groundwork for modern ecology. He developed a two part naming system for classifying plants and animals. Binomial Nomenclature was used to classify, describe, and name different genera and species. The compiled editions of \"Systema Naturae\" developed and popularized the naming system for plants and animals in modern biology. Reid suggests \"Linnaeus can fairly be regarded as the originator of systematic and ecological studies in biodiversity,\" due to his naming and classifying of thousands of plant and animal species. Linnaeus also influenced the foundations of Darwinian evolution, he believed that there could be change in or between different species within fixed genera. Linnaeus was also one of the first naturalists to place men in the same category as primates.\n\nThroughout the 18th and the beginning of the 19th century, the great maritime powers such as Britain, Spain, and Portugal launched many world exploratory expeditions to develop maritime commerce with other countries, and to discover new natural resources, as well as to catalog them. At the beginning of the 18th century, about twenty thousand plant species were known, versus forty thousand at the beginning of the 19th century, and about 300,000 today.\n\nThese expeditions were joined by many scientists, including botanists, such as the German explorer Alexander von Humboldt. Humboldt is often considered a father of ecology. He was the first to take on the study of the relationship between organisms and their environment. He exposed the existing relationships between observed plant species and climate, and described vegetation zones using latitude and altitude, a discipline now known as geobotany. Von Humboldt was accompanied on his expedition by the botanist Aimé Bonpland.\n\nIn 1856, the Park Grass Experiment was established at the Rothamsted Experimental Station to test the effect of fertilizers and manures on hay yields. This is the longest-running field experiment in the world.\n\nAlfred Russel Wallace, contemporary and colleague of Darwin, was first to propose a \"geography\" of animal species. Several authors recognized at the time that species were not independent of each other, and grouped them into plant species, animal species, and later into communities of living beings or biocoenosis. The first use of this term is usually attributed to Karl Möbius in 1877, but already in 1825, the French naturalist Adolphe Dureau de la Malle used the term \"societé\" about an assemblage of plant individuals of different species.\n\nWhile Darwin focused exclusively on competition as a selective force, Eugen Warming devised a new discipline that took abiotic factors, that is drought, fire, salt, cold etc., as seriously as biotic factors in the assembly of biotic communities. Biogeography before Warming was largely of descriptive nature – faunistic or floristic. Warming’s aim was, through the study of organism (plant) morphology and anatomy, i.e. adaptation, to explain why a species occurred under a certain set of environmental conditions. Moreover, the goal of the new discipline was to explain why species occupying similar habitats, experiencing similar hazards, would solve problems in similar ways, despite often being of widely different phylogenetic descent. Based on his personal observations in Brazilian cerrado, in Denmark, Norwegian Finnmark and Greenland, Warming gave the first university course in ecological plant geography. Based on his lectures, he wrote the book ‘Plantesamfund’, which was immediate translated to German, Polish and Russian, later to English as ‘Oecology of Plants’. Through its German edition, the book had immense effect on British and North American scientist like Arthur Tansley, Henry Chandler Cowles and Frederic Clements.\n\nThomas Robert Malthus was an influential writer on the subject of population and population limits in the early 19th century. His works were very important in shaping the ways in which Darwin saw the world worked. Malthus wrote:\nIn An Essay on the Principle of Population Malthus argues for the reining in of rising population through 2 checks: Positive and Preventive checks. The first raising death rates, the later lowers birthing rates. Malthus also brings forth the idea that the world population will move past the sustainable number of people. This form of thought still continues to influences debates on birth and marriage rates to this theory brought forth by Malthus. The essay had a major influence on Charles Darwin and helped him to theories his theory of Natural Selection. This struggle proposed by Malthusian thought not only influenced the ecological work of Charles Darwin, but helped bring about an economic theory of world of ecology.\n\nIt is often held that the roots of scientific ecology may be traced back to Darwin. This contention may look convincing at first glance inasmuch as \"On the Origin of Species\" is full of observations and proposed mechanisms that clearly fit within the boundaries of modern ecology (e.g. the cat-to-clover chain – an ecological cascade) and because the term ecology was coined in 1866 by a strong proponent of Darwinism, Ernst Haeckel. However, Darwin never used the word in his writings after this year, not even in his most \"ecological\" writings such as the foreword to the English edition of Hermann Müller’s \"The Fertilization of Flowers\" (1883) or in his own treatise of earthworms and mull formation in forest soils (The formation of vegetable mould through the action of worms, 1881). Moreover, the pioneers founding ecology as a scientific discipline, such as Eugen Warming, A. F. W. Schimper, Gaston Bonnier, F.A. Forel, S.A. Forbes and Karl Möbius, made almost no reference to Darwin’s ideas in their works. This was clearly not out of ignorance or because the works of Darwin were not widespread. Some such as S.A.Forbes studying intricate food webs asked questions as yet unanswered about the instability of food chains that might persist if dominant competitors were not adapted to have self-constraint. Others focused on the dominant themes at the beginning, concern with the relationship between organism morphology and physiology on one side and environment on the other, mainly abiotic environment, hence environmental selection. Darwin’s concept of natural selection on the other hand focused primarily on competition. The mechanisms other than competition that he described, primarily the divergence of character which can reduce competition and his statement that \"struggle\" as he used it was metaphorical and thus included environmental selection, were given less emphasis in the Origin than competition. Despite most portrayals of Darwin conveying him as a non-aggressive recluse who let others fight his battles, Darwin remained all his life a man nearly obsessed with the ideas of competition, struggle and conquest – with all forms of human contact as confrontation.\n\nBy the 19th century, ecology blossomed due to new discoveries in chemistry by Lavoisier and de Saussure, notably the nitrogen cycle. After observing the fact that life developed only within strict limits of each compartment that makes up the atmosphere, hydrosphere, and lithosphere, the Austrian geologist Eduard Suess proposed the term biosphere in 1875. Suess proposed the name biosphere for the conditions promoting life, such as those found on Earth, which includes flora, fauna, minerals, matter cycles, et cetera.\n\nIn the 1920s Vladimir I. Vernadsky, a Russian geologist who had defected to France, detailed the idea of the biosphere in his work \"The biosphere\" (1926), and described the fundamental principles of the biogeochemical cycles. He thus redefined the biosphere as the sum of all ecosystems.\n\nFirst ecological damages were reported in the 18th century, as the multiplication of colonies caused deforestation. Since the 19th century, with the industrial revolution, more and more pressing concerns have grown about the impact of human activity on the environment. The term ecologist has been in use since the end of the 19th century.\n\nOver the 19th century, botanical geography and zoogeography combined to form the basis of biogeography. This science, which deals with habitats of species, seeks to explain the reasons for the presence of certain species in a given location.\n\nIt was in 1935 that Arthur Tansley, the British ecologist, coined the term ecosystem, the interactive system established between the biocoenosis (the group of living creatures), and their biotope, the environment in which they live. Ecology thus became the science of ecosystems.\n\nTansley's concept of the ecosystem was adopted by the energetic and influential biology educator Eugene Odum. Along with his brother, Howard T. Odum, Eugene P. Odum wrote a textbook which (starting in 1953) educated more than one generation of biologists and ecologists in North America.\n\nAt the turn of the 20th century, Henry Chandler Cowles was one of the founders of the emerging study of \"dynamic ecology\", through his study of ecological succession at the Indiana Dunes, sand dunes at the southern end of Lake Michigan. Here Cowles found evidence of ecological succession in the vegetation and the soil with relation to age. Cowles was very much aware of the roots of the concept and of his (primordial) predecessors. Thus, he attributes the first use of the word to the French naturalist Adolphe Dureau de la Malle, who had described the vegetation development after forest clear-felling, and the first comprehensive study of successional processes to the Finnish botanist Ragnar Hult (1881).\n\n20th century English zoologist and ecologist, Charles Elton, is commonly credited as “the father of animal ecology”. Elton influenced by Victor Shelford’s \"Animal Communities in Temperate America\" began his research on animal ecology as an assistant to his colleague, Julian Huxley, on an ecological survey of the fauna in Spitsbergen in 1921. Elton’s most famous studies were conducted during his time as a biological consultant to the Hudson Bay Company to help understand the fluctuations in the company’s fur harvests. Elton studied the population fluctuations and dynamics of snowshoe hare, Canadian lynx, and other mammals of the region. Elton is also considered the first to coin the terms, food chain and food cycle in his famous book \"Animal Ecology\". Elton is also attributed with contributing to disciplines of: invasion ecology, community ecology, and wildlife disease ecology.\n\nGeorge “G” Evelyn Hutchinson was a 20th-century ecologist who is commonly recognized as the “Father of Modern Ecology”. Hutchinson is of English descent but spent most of professional career studying in New Haven, Connecticut at Yale University. Throughout his career, over six decades, Hutchinson contributed to the sciences of limnology, entomology, genetics, biogeochemistry, mathematical theory of population dynamics and many more. Hutchinson is also attributed as being the first to infuse science with theory within the discipline of ecology. Hutchinson was also one of the first credited with combining ecology with mathematics. Another major contribution of Hutchinson was his development of the current definition of an organism’s “niche” – as he recognized the role of an organism within its community. Finally, along with his great impact within the discipline of ecology throughout his professional years, Hutchinson also left a lasting impact in ecology through his many students he inspired.\n\nHuman ecology began in the 1920s, through the study of changes in vegetation succession in the city of Chicago. It became a distinct field of study in the 1970s. This marked the first recognition that humans, who had colonized all of the Earth's continents, were a major ecological factor. Humans greatly modify the environment through the development of the habitat (in particular urban planning), by intensive exploitation activities such as logging and fishing, and as side effects of agriculture, mining, and industry. Besides ecology and biology, this discipline involved many other natural and social sciences, such as anthropology and ethnology, economics, demography, architecture and urban planning, medicine and psychology, and many more. The development of human ecology led to the increasing role of ecological science in the design and management of cities.\n\nIn recent years human ecology has been a topic that has interested organizational researchers. Hannan and Freeman (\"Population Ecology of Organizations (1977)\", American Journal of Sociology) argue that organizations do not only adapt to an environment. Instead it is also the environment that selects or rejects populations of organizations. In any given environment (in equilibrium) there will only be one form of organization (isomorphism). Organizational ecology has been a prominent theory in accounting for diversities of organizations and their changing composition over time.\n\nThe Gaia theory, proposed by James Lovelock, in his work \"Gaia: A New Look at Life on Earth\", advanced the view that the Earth should be regarded as a single living macro-organism. In particular, it argued that the ensemble of living organisms has jointly evolved an ability to control the global environment — by influencing major physical parameters as the composition of the atmosphere, the evaporation rate, the chemistry of soils and oceans — so as to maintain conditions favorable to life. The idea has been supported by Lynn Margulis who extended her endosymbiotic theory which suggests that cell organelles originated from free living organisms to the idea that individual organisms of many species could be considered as symbionts within a larger metaphorical \"super-organism\".\n\nThis vision was largely a sign of the times, in particular the growing perception after the Second World War that human activities such as nuclear energy, industrialization, pollution, and overexploitation of natural resources, fueled by exponential population growth, were threatening to create catastrophes on a planetary scale, and has influenced many in the environmental movement since then.\n\nEnvironmentalists and other conservationists have used ecology and other sciences (e.g., climatology) to support their advocacy positions. Environmentalist views are often controversial for political or economic reasons. As a result, some scientific work in ecology directly influences policy and political debate; these in turn often direct ecological research.\n\nThe history of ecology, however, should not be conflated with that of environmental thought. Ecology as a modern science traces only from Darwin’s publication of Origin of Species and Haeckel’s subsequent naming of the science needed to study Darwin’s theory. Awareness of humankind’s effect on its environment has been traced to Gilbert White in 18th-century Selborne, England. Awareness of nature and its interactions can be traced back even farther in time. Ecology before Darwin, however, is analogous to medicine prior to Pasteur’s discovery of the infectious nature of disease. The history is there, but it is only partly relevant.\n\nNeither Darwin nor Haeckel, it is true, did self-avowed ecological studies. The same can be said for researchers in a number of fields who contributed to ecological thought well into the 1940s without avowedly being ecologists. Raymond Pearl’s population studies are a case in point. Ecology in subject matter and techniques grew out of studies by botanists and plant geographers in the late 19th and early 20th centuries that paradoxically lacked Darwinian evolutionary perspectives. Until Mendel’s studies with peas were rediscovered and melded into the Modern Synthesis, Darwinism suffered in credibility. Many early plant ecologists had a Lamarckian view of inheritance, as did Darwin, at times. Ecological studies of animals and plants, preferably live and in the field, continued apace however.\n\nWhen the Ecological Society of America (ESA) was chartered in 1915, it already had a conservation perspective. Victor E. Shelford, a leader in the society’s formation, had as one of its goals the preservation of the natural areas that were then the objects of study by ecologists, but were in danger of being degraded by human incursion. Human ecology had also been a visible part of the ESA at its inception, as evident by publications such as: \"The Control of Pneumonia and Influenza by the Weather,\" \"An Overlook of the Relations of Dust to Humanity,\" \"The Ecological Relations of the Polar Eskimo,\" and \"City Street Dust and Infectious Diseases,\" in early pages of Ecology and Ecological Monographs. The ESA’s second president, Ellsworth Huntington, was a human ecologist. Stephen Forbes, another early president, called for \"humanizing\" ecology in 1921, since man was clearly the dominant species on the Earth.\n\nThis auspicious start actually was the first of a series of fitful progressions and reversions by the new science with regard to conservation. Human ecology necessarily focused on man-influenced environments and their practical problems. Ecologists in general, however, were trying to establish ecology as a basic science, one with enough prestige to make inroads into Ivy League faculties. Disturbed environments, it was thought, would not reveal nature’s secrets.\n\nInterest in the environment created by the American Dust Bowl produced a flurry of calls in 1935 for ecology to take a look at practical issues. Pioneering ecologist C. C. Adams wanted to return human ecology to the science. Frederic E. Clements, the dominant plant ecologist of the day, reviewed land use issues leading to the Dust Bowl in terms of his ideas on plant succession and climax. Paul Sears reached a wide audience with his book, \"Deserts on the March\". World War II, perhaps, caused the issue to be put aside.\n\nThe tension between pure ecology, seeking to understand and explain, and applied ecology, seeking to describe and repair, came to a head after World War II. Adams again tried to push the ESA into applied areas by having it raise an endowment to promote ecology. He predicted that \"a great expansion of ecology\" was imminent \"because of its integrating tendency.\" Ecologists, however, were sensitive to the perception that ecology was still not considered a rigorous, quantitative science. Those who pushed for applied studies and active involvement in conservation were once more discreetly rebuffed. Human ecology became subsumed by sociology. It was sociologist Lewis Mumford who brought the ideas of George Perkins Marsh to modern attention in the 1955 conference, \"Man’s Role in Changing the Face of the Earth.\" That prestigious conclave was dominated by social scientists. At it, ecology was accused of \"lacking experimental methods\" and neglecting \"man as an ecological agent.\" One participant dismissed ecology as \"archaic and sterile.\" Within the ESA, a frustrated Shelford started the Ecologists’ Union when his Committee on Preservation of Natural Conditions ceased to function due to the political infighting over the ESA stance on conservation. In 1950, the fledgling organization was renamed and incorporated as the Nature Conservancy, a name borrowed from the British government agency for the same purpose.\n\nTwo events, however, brought ecology’s course back to applied problems. One was the Manhattan Project. It had become the Nuclear Energy Commission after the war. It is now the Department of Energy (DOE). Its ample budget included studies of the impacts of nuclear weapon use and production. That brought ecology to the issue, and it made a \"Big Science\" of it. Ecosystem science, both basic and applied, began to compete with theoretical ecology (then called evolutionary ecology and also mathematical ecology). Eugene Odum, who published a very popular ecology textbook in 1953, became the champion of the ecosystem. In his publications, Odum called for ecology to have an ecosystem and applied focus.\n\nThe second event was the publication of Silent Spring. Rachel Carson’s book brought ecology as a word and concept to the public. Her influence was instant. A study committee, prodded by the publication of the book, reported to the ESA that their science was not ready to take on the responsibility being given to it.\n\nCarson’s concept of ecology was very much that of Gene Odum. As a result, ecosystem science dominated the International Biological Program of the 1960s and 1970s, bringing both money and prestige to ecology. Silent Spring was also the impetus for the environmental protection programs that were started in the Kennedy and Johnson administrations and passed into law just before the first Earth Day. Ecologists’ input was welcomed. Former ESA President Stanley Cain, for example, was appointed an Assistant Secretary in the Department of the Interior.\n\nThe environmental assessment requirement of the 1969 National Environmental Policy Act (NEPA), \"legitimized ecology,\" in the words of one environmental lawyer. An ESA President called it \"an ecological ‘Magna Carta.’\" A prominent Canadian ecologist declared it a \"boondoggle.\" NEPA and similar state statutes, if nothing else, provided much employment for ecologists. Therein was the issue. Neither ecology nor ecologists were ready for the task. Not enough ecologists were available to work on impact assessment, outside of the DOE laboratories, leading to the rise of \"instant ecologists,\" having dubious credentials and capabilities. Calls began to arise for the professionalization of ecology. Maverick scientist Frank Egler, in particular, devoted his sharp prose to the task. Again, a schism arose between basic and applied scientists in the ESA, this time exacerbated by the question of environmental advocacy. The controversy, whose history has yet to receive adequate treatment, lasted through the 1970s and 1980s, ending with a voluntary certification process by the ESA, along with lobbying arm in Washington.\n\nPost-Earth Day, besides questions of advocacy and professionalism, ecology also had to deal with questions having to do with its basic principles. Many of the theoretical principles and methods of both ecosystem science and evolutionary ecology began to show little value in environmental analysis and assessment. Ecologist, in general, started to question the methods and logic of their science under the pressure of its new notoriety. Meanwhile, personnel with government agencies and environmental advocacy groups were accused of religiously applying dubious principles in their conservation work. Management of endangered Spotted Owl populations brought the controversy to a head.\n\nConservation for ecologists created travails paralleling those nuclear power gave former Manhattan Project scientists. In each case, science had to be reconciled with individual politics, religious beliefs, and worldviews, a difficult process. Some ecologists managed to keep their science separate from their advocacy; others unrepentantly became avowed environmentalists.\n\nTheodore Roosevelt was interested in nature from a young age. He carried his passion for nature into his political policies. Roosevelt felt it was necessary to preserve the resources of the nation and its environment. In 1902 he created the federal reclamation service, which reclaimed land for agriculture. He also created the Bureau of Forestry. This organization, headed by Gifford Pinchot, was formed to manage and maintain the nations timberlands. Roosevelt signed the Act for the Preservation of American Antiquities in 1906. This act allowed for him to \"declare by public proclamation historic landmarks, historic and prehistoric structures, and other objects of historic and scientific interest that are situated upon lands owned or controlled by the Government of the United States to be National Monuments.\" Under this act he created up to 18 national monuments. During his presidency, Roosevelt established 51 Federal Bird Reservations, 4 National Game Preserves, 150 National Forests, and 5 National Parks. Overall he protected over 200 million acres of land.\n\nEcology became a central part of the World's politics as early as 1971, UNESCO launched a research program called \"Man and Biosphere\", with the objective of increasing knowledge about the mutual relationship between humans and nature. A few years later it defined the concept of Biosphere Reserve.\n\nIn 1972, the United Nations held the first international Conference on the Human Environment in Stockholm, prepared by Rene Dubos and other experts. This conference was the origin of the phrase \"Think Globally, Act Locally\". The next major events in ecology were the development of the concept of biosphere and the appearance of terms \"biological diversity\"—or now more commonly biodiversity—in the 1980s. These terms were developed during the Earth Summit in Rio de Janeiro in 1992, where the concept of the biosphere was recognized by the major international organizations, and risks associated with reductions in biodiversity were publicly acknowledged.\n\nThen, in 1997, the dangers the biosphere was facing were recognized all over the world at the conference leading to the Kyoto Protocol. In particular, this conference highlighted the increasing dangers of the greenhouse effect – related to the increasing concentration of greenhouse gases in the atmosphere, leading to global changes in climate. In Kyoto, most of the world's nations recognized the importance of looking at ecology from a global point of view, on a worldwide scale, and to take into account the impact of humans on the Earth's environment.\n\n\n", "id": "1607622", "title": "History of ecology"}
{"url": "https://en.wikipedia.org/wiki?curid=48588126", "text": "Stephen Waite\n\nDr Stephen Waite is a retired, previous Vice-Chancellor of Writtle University College (near Chelmsford, Essex) one of the largest land-based university colleges in the UK. Dr Waite lives in Hassocks with his wife and has two daughters.\n\nBefore he joined Writtle he was Vice Principal (Higher Education) at Hartpury College and Associate Dean at University of the West of England. Dr Waite has been instrumental in a number of global joint education ventures with visits/projects in India, Malaysia, China and Vietnam. He has taught for the Mongolian National University and carried out project work in the Ukraine.\n\nHe is a board director of Landex. Waite is also a noted author in the field of Ecology. (A Textbook of Agroecology – 2010)\n", "id": "48588126", "title": "Stephen Waite"}
{"url": "https://en.wikipedia.org/wiki?curid=35946562", "text": "Culmicole\n\nA culmicole is an organism that lives on the apexes of grass leaves and stems. An example of a culmicole are species of planthoppers, which spend their lives perched on grass blades. The name was first coined by Lincoln et al. in 1985.\n", "id": "35946562", "title": "Culmicole"}
{"url": "https://en.wikipedia.org/wiki?curid=45318437", "text": "Ecosystem decay\n\nEcosystem decay is a term coined by Thomas Lovejoy to define the process of which species become extinct locally based on habitat fragmentation. This process is what led to the extinction of several species, including the Irish Elk. Ecosystem decay can be mainly attributed to population isolation, leading to inbreeding, leading to a decrease in the population of local species. Another factor is the absence of competition, preventing the mechanisms of natural selection to benefit the population. This leads to a lack of a skill set for the animal to adjust and adapt to a new environment. \n\nAlthough similar to forest fragmentation and island biogeography, ecosystem decay is what results in the event of forest fragmentation. \n\nEcosystem decay is a natural phenomenon that has several resulting features.\n\nThe process through which ecosystem decay occurs can be long and complicated or short and hasty. Overall, it still follows some basic guidelines. First, a piece of habitat is surrounded and thus isolated by farmland or cities.\nSecondly, pollination of the plants immediately ceases and the number of species thins out. Thirdly, through generations of inbreeding and thus higher birth mortality than birth survival rate and infertile dirt, the forest fragment will slowly decline to nothing.\n\nEcosystem decay is commonly caused by the harvesting of rain forest in appliance to certain laws or illegally for profit by humans. Certain countries such as Brazil prohibit the harvesting of Brazil nut trees and groves of this species causing forest fragmentation and thus causing ecosystem decay to occur. Cities, roads, farms and any other substantial barrier impeding and animals habitat can be a direct or an indirect cause. Naturally, fires and rising sea levels on low land can also cause habitat fragmentation and thus ecosystem decay. Although this process is much more lengthy, many species such as the Irish Elk and several species of ancient Australian Marsupials have been indirectly killed this way with contributions by Climate Change, Glaciation and Forest Fires.\n\nEleonore Setz was studying a patch of equatorial rainforest named reserve #1202 containing \"Pithecia pithecia (\"white-faced sakis), to study the effects of ecosystem decay. The 9.2 hectare (less than 25 acre) area had been isolated for five years when David Quammen noted results on the fragmentation of their habitat which resulted in them being stranded. The population of \"P. Pithecia\" was slowly declining at the time of the study and the population had declined to six.\n\n", "id": "45318437", "title": "Ecosystem decay"}
{"url": "https://en.wikipedia.org/wiki?curid=14017274", "text": "Ecotoxicity\n\nEcotoxicity, the subject of study of the field of ecotoxicology (a portmanteau of Ecology and Toxicology) refers to the potential for biological, chemical or physical stressors to affect ecosystems. Such stressors might occur in the natural environment at densities, concentrations or levels high enough to disrupt the natural biochemistry, physiology, behavior and interactions of the living organisms that comprise the ecosystem.\n\nEcotoxicology has been defined as, \"the branch of toxicology concerned with the study of toxic effects, caused by natural or synthetic pollutants, to the constituents of ecosystems, animal (including human), vegetable and microbial, in an integral context\".\n\n\nIn Canada, there is no law requiring manufactures to state the health and environmental hazards associated with their cleaning products. Many people buy such products to support a clean and healthy home, often unaware of the products ability to harm both their own health and the surrounding environment. \"Canadians spend more than $275 million on household cleaning products in a year\" Chemicals from these cleaners enter our bodies through air passageways and absorption through the skin and when these cleaning products are washed down the drain they negatively affect aquatic ecosystems. There are also no regulations in place stating that the ingredients be listed on labels of cleaning products leading the users to be ultimately unaware of the chemicals they expose themselves and their surrounding environments to.\n\nThe organic compound 2-Butoxyethanol, commonly found in glass cleaners, laundry stain removers, windshield wiper fluid, oven cleaners, and rust removers has been proven to cause reproductive problems in laboratory experiments.\n\nThe compound ammonia is found in many window cleaners, drain cleaners, bathroom cleaners, oven cleaners, car polish, and all-purpose cleaners. Its vapour is particularly harmful to people with asthma and it may also cause kidney and liver damage. When ammonia is mixed with products containing chlorine bleach, highly poisonous chloramine gas is formed. This poisonous gas often forms when cleaners are mixed in the home forming strong irritants.\n\nFragrance chemicals are found in most cleaning products, perfumes, and personal care products. More than 3000 chemicals are used in these fragrance mixtures. The synthetic musks used in detergents accumulate in the environment and are harmful to aquatic organisms. Certain musks are possible endocrine disruptors that interfere with hormone functioning. Phthalates are a common ingredient in these fragrance mixtures found in laundry detergents and fabric softeners. These phthalates are suspected endocrine disrupters that affect reproduction rates including reduced sperm count in males. Certain glass cleaners and floor polishes contain dibutyl phthalate (DBP). The European Union classifies DBP as very toxic to aquatic organisms, posing a huge danger as these cleaners, especially the floor polishes are often rinsed down the drain and into aquatic environments.\n\nPhosphates are found in many dishwasher detergents, laundry detergents, and bathroom cleaners. They act as a fertilizer in water and in high concentrations can promote algae blooms and increase weed growth. When water containing phosphates are washed into water areas they carry with them fertilizers, nutrients, and wastes from the land. Phytoplankton and algae flourish at the surface due to increased phosphates. Dead phytoplankton and other organisms sink to the bottom giving rise to large numbers of decomposers due to increased food supply (dead organisms, phytoplankton). Due to the increased number of decomposers that use more oxygen, fish and shrimp at the lower layers of the ocean become oxygen-starved and hypoxic zones become apparent.\n\nQuats are anti-microbial agents that are found in bathroom cleaners, fabric softeners, and degreasers. They are a class of irritants and sensitizers that negatively affect people who suffer from asthma. Chemicals in this class are persistent in aquatic environments, and toxic to the organisms that live in these environments. Many researchers are concerned that their widespread use in everyday household disinfectants and cosmetics are contributing to antibiotic resistant bacteria, thus limiting microbial infection treatment options.\n\nTrisodium nitrilotriacetate is found in bathroom cleaners and possibly some laundry detergents although more actively used in industrial formulations. Small amounts add up in the environment and add to an overall toxic issue. In aquatic ecosystems these chemicals cause heavy metals in sediment to redisolve and many of these metals are toxic to fish and other wildlife.\n\nPhthalates and BPA date back to the 1920s and 1930s. Phthalates have been applied as polyvinyl chloride (PVC) additives since 1926, but were also used for health care purposes as insect repellents and cercaricides. BPA is present in most aquatic environments, entering water systems through landfills and sewage treatment plant runoff allowing for bioaccumulation in aquatic organisms. These endocrine disrupters are a large group of chemicals that enter into the aquatic environment through the manufacturing of various industrial and consumer products, agriculture and food/drug processing, waste water treatment plants and human wastes. Phthalate esters are common additives that soften and make PVC more flexible. It is used in many everyday items such as medical devices, packaging for fragrances and cosmetics, ropes and varnishes, in plastic used to wrap food, and shower curtains. These Phthalate esters have been found in areas of water, air, sediment, and in gulfs and rivers around the world, Giam et al. as cited by. Phalates and BPA affect reproduction in animal groups such as Molluscs, crustaceans, amphibians and fish. Most of these plasticizers affect hormone systems, and some phthalates have even larger pathways of disruption. Phthalates and BPA have been proven to affect development and reproduction in a variety of species. Disturbances include changes in the number of offspring produced and reduced hatching success. In amphibians for example, phthalates and BPA disrupt thyroid functioning which in turn impacts larval development. Molluscs, crustaceans and amphibians appear to be more responsive than fish, with most effects being induced in low concentration ranges with the exception of disrupted spermatogenesis in fish in the low range. \nA Phthalate referred to as diethyl phthalate (DEP) enters the aquatic environment through industries that manufacture cosmetics, plastics and many commercial products that pose hazards to aquatic organisms and human health. Through exposing an adult male common Carp (Cyprinus carpio) to LC50 doses it was evident that a bioaccumulation of DEP in testis, liver, brain, gills and muscle tissue was present. Fish exposed to 20 ppm of DEP became drowsy and discolored during the onset of the fourth week. \nSources of DEP contamination and accumulation in humans include cosmetic products and dietary meat of fish, Persky et al. This DEP acts as a cosmetic ingredient and vehicle for fragrances, both which come in contact with the skin. \nMany countries around the world including India practice sewage fed fisheries where waste waters are used for the purpose of culturing fish. Endocrine disruption and a presence of phthalate residue is highly likely to be observable in these sewage fed fish. This is the case as waste water from various industries and garbage containing DEP are released into these waters. Through a DEP treatment with Cyprinus carpio, liver size was observed to increase and testis size decreased. In fish, muscle ALT and AST activities decreased as it was effected by DEP treatment. Like many toxic chemicals DEP has been known to affect metabolic enzyme profiles and activities of phosphatases and transaminases, Ghorpade et al. as cited by. A decrease in immunity of M. rosenbergii after exposure to DEP was also noted. \nGiven that biological effect concentrations for plasticizers used in the laboratory coincide with concentrations present in the environment, it seems that some wildlife species must be negatively impacted.\n\nPersonal care products can reach the environment through drainage from waste water treatment plants and digested sludge. Recently, the anti-dandruff and antimycotic, Climbazole, was detected in waste water treatment drainages. Climbazole is readily used in cosmetics, and is an ingredient in anti-dandruff shampoos. Shampoos contain formulations of up to 2.0% which is the equivalent of approximately 15g/L. Climbazole is classified as very toxic to aquatic organisms. It affects the growth of green algae Pseudokirchneriella subcapitata at very low concentrations. Zebrafish experienced lethal effects after exposure to climbazole in laboratory testing. Effects included thickening of fertilized eggs, lack of somite formation, lack of detachment of the tail bud from the yolk sac, and lack of a heartbeat were evaluated after 48 hours. Along with Danio rerio, Lemna minor, Navicula pelliculosa, Pseudokirchneriella subcapitata, and Daphnia magna were tested and all were found to be negatively affected by climbazole in a concentration-dependant manner with highest toxicity observed in L. minor. Effects included stunted colony growth and darkening in color. Effects of climbazole on oats and turnip included retarded, stunted growth of the leaves and shoot as well as turning darker in color. The aquatic ecotoxicity of climbazole can be classified as very toxic to Lemna and algae, toxic to fish and harmful to Daphnia.\n\nPesticides often pose serious problems as they kill not only targeted organisms but also non-targeted organisms in the process. They are released into the natural environment intentionally by people who are often unaware that the chemicals will travel further than anticipated, Hatakeyama et al. as cited in. Thus the pesticides largely affect the natural communities in which they are used. They negatively effect multiple levels ranging from molecules to tisues to organs to individuals to populations and onto communities. In the natural environment, a combination of pesticide exposure and natural stressors such as fluctuating temperature, food shortage or decreased oxygen availability are worse than when presented alone. Pesticides can affect the feeding rates of zoo-plankton. In the presence of pesticides zoo-plankton display lower feeding rates which result in reduced growth and reproduction. Swimming may also be affected by pesticides which poses a life-threatening issue for zoo-plankton as they swim to obtain food and nutrients and avoid predators. Such changes may alter predator-prey relationships. A spinning behavior became apparent in Daphnia induced by carbaryl which increased the probability of the Daphnia being eaten by other fish, Dodson et al. as cited by. The toxicant pentachlorophenol increases swimming speed in the rotifer Brachionus calyciflorus, in turn increasing the encounter rate of the prey with their predators, Preston et al. as cited by.\n\nOne of the major environmental impacts of oil exploration on the environment is the contamination of aquatic ecosystems from oil spills and oil seepages from pits. Oftentimes, as is the case in the Ecuadorian Amazon, oil is used to control dust on roadways, causing the precipitation runoff from these roads to also be contaminated. Direct human health hazards occur since many people, including children walk barefoot on these oiled roads putting them in direct contact with the crude oil. Other hazards to humans include seepages into ponds that provide drinking water for the population. \nDuring the exploration for oil, mud that has been drilled is deposited into pits. These production pits are often not lined risking the possibility for contaminants to leak into the surrounding environment. Environmental concerns are primarily focused on a group of polycyclic aromatic hydrocarbons (PAHs). “PAHs accumulate on particles and sediments, which tend to protect them from biodegrading processes\", Green and Trett as cited in. During the exploration for oil, mud that has been drilled is deposited into pits. These production pits are often not lined risking the possibility for contaminants to leak into the surrounding environment. \nSamples were collected from four sites (13 stations) in the Ecuadorian Amazon where crude oil was the main pollutant. The water collected from Site B, a drinking water pond located 100m from an in use pit, had the highest total petroleum hydrocarbon (THP) concentration. Sediments were found to be acutely phototoxic. This area which has poorly developed infrastructure is one where residents collect water for drinking, cooking and bathing from the rivers and ponds nearby. “A recent study observed excess cancer rates in a village in this region” Sebastian et. Al, as cited in. Not only were excess cancer rates apparent but many people in this area that were consuming the water for drinking purposes became ill.\nIn Wernersson’s study, toxicity of water and sediment samples were studied on Daphnia magna (a crustacean zoo-plankton species) and Hyalella azteca (an amphipod). These samples were collected from four sites where crude oil was the main source of pollution. 1-4 day old organisms of both species were used in the tests. Immobility of D. magna was recorded after 24 hours of exposure indoors. They were then moved outdoors where they were exposed to sunlight. After 1–2 hours the samples were removed from the sunlight and it was found that D. Magna often recovered within an hour after UV exposure.\nHyalella azteca was cultured in the same medium as was used for the D. Magna species. To minimize stress shade was provided. 16 hours of light and 8 hours of darkness were provided. Lethality was recorded after 96 hours of exposure.\n\n\n", "id": "14017274", "title": "Ecotoxicity"}
{"url": "https://en.wikipedia.org/wiki?curid=50431941", "text": "Cognitive ecology\n\nCognitive ecology is the study of cognitive phenomena within social and natural contexts. It is an integrative perspective drawing from aspects of ecological psychology, cognitive science, evolutionary ecology and anthropology. Notions of domain-specific modules in the brain and the cognitive biases they create are central to understanding the enacted nature of cognition within a cognitive ecological framework. This means that cognitive mechanisms not only shape the characteristics of thought, but they dictate the success of culturally transmitted ideas. Because culturally transmitted concepts can often inform ecological decision-making behaviors, group-level trends in cognition (i.e., culturally salient concepts) are hypothesized to address ecologically relevant challenges.\n\nCognitive ecology explores the interactive relationship between organism-environment interactions and its impact on cognitive phenomena. Human cognition in this framework is multimodal and viewed similarly to enactivist perspectives on cognitive processing. For cultural concepts, this emphasizes cognitive distribution across an ecosystem, which is predicated on models of the extended mind thesis.\n\nWhile the multi-faceted nature of cognitive ecology is a consequence of its interdisciplinary history, it primarily derives from early work in ecological psychology. Paradigm shifts from behaviorist orientations of psychology to cognition, or the \"cognitive revolution\", gave rise to the ecological psychology approach, which distanced itself from mainstream cognitivist views by breaking down the common mind-environment dichotomy of psychological theory.\n\nOne particularly influential progenitor of this work was ecological psychologist James Gibson, whose legacy is marked by his ideas on ecological and social affordances. These are the opportunistic features of environmental objects that can be exploited for human use, and are therefore particularly perceptible (e.g., a knob affords twisting, an agreeable social cue affords a warm reaction). Gibson argued further that organisms cannot be disentangled from their environments, and that their cognitive constraints were consequences of a limited set of environmental invariants which shaped them over evolutionary time. An illustrative example for Gibson is the human capacity for three-dimensional visual perception, which he argues is a cognitive concept resulting from the way that people interact with their environment.\n\nAnother foreshadowed element of cognitive ecological theory comes from ecological anthropologist Gregory Bateson, who considered the notion of informational feedback loops between mind and environment, particularly their role in generating meaning and awareness of one's surroundings. In an essay, he speculates on how an observer might best delineate the \"self\" of a blind man. In his treatment, he questions whether one may arbitrarily choose to carve out the man's informational processing loop at his brain or his hands or his walking stick without offering an incomplete view of his cognitive process. This discussion of concept remains influential in modern cognitive ecological considerations of the densely interconnected elements of ecology that play relevant roles in cognition.\n\nAn enactive perspective of cognition is fundamental to a cognitive ecological view. Rather than a passive interpretation of internally represented information, cognition is considered to be an active process involving the transformation of information into meaningful relationships between the organism and its environment. For humans then, a perceived environment is only constructed insofar as cognitive constraints will allow. In other words, they \"enact a world\" by building perspectives out of ecological information, using their evolved cognitive equipment.\n\nCognitive ecology borrows ideas from views of extended cognition, as articulated by Chalmers and Clark (1998). They argue that humans cognitively utilize elements of their environment to aid the cognitive process and further entangle the mind-environment relationship as a result. They illustrate their claim with a hypothetical example of two people who achieve the same navigational success through a museum by different means; a person with Alzheimer's may use a notebook with written directions, while another may use her memory. The primary difference between the two people is that the former outsourced his memory to readily available external representations of information about the museum, whereas the latter relied on internal representations. A variant of this concept they also consider is socially extended cognition, which is a similar outsourcing of cognitive representations into other peoples' minds. These ideas elaborate a cognitive interpretation of broader anthropological notions maintaining that humans are a species deeply entangled in social and material elements of culture.\n\nDistributed cognition is an important model of the extended mind thesis for cognitive ecological theory put forth by Edwin Hutchins. This conceptualizes human groups as active networks with cognitive properties of their own, much like neural networks themselves yield emergent cognitive properties. For a social group, cognitive properties are disseminated into an individual's surrounding network. The cognitive properties of a group, Hutchins notes, is completely distinct from a given those of an individual. Distributed cognition is fundamentally contingent on and emergent from trending ideas among a collection of brains and artefacts.\n\nThis is conceptually similar to models of collective cognition in other social animal groups, which use agent based models to understanding insect swarming, fish schooling, bird flocking and baboon pack behaviors. Collective cognition in social animal groups is adaptive because the group can amplify its overall responsiveness to ecological cues. Likewise, the computational power of a human group can be more effective than that of even its best individuals. This idea is echoed by anthropologists noting the collective intentionality of cultural institutions.\n\nExisting models of cultural learning dynamics seem to articulate the mechanisms by which information is acquired by and distributed within groups. In particular, cultural evolution theorists assert that individual learning is required for tracking environmental dynamics, but this information is retained in culture by social learning. For Hutchins, this theoretical similarity is not a coincidence. After describing distributed cognitive networks and their relationships with ecological dynamics as \"cognitive ecosystems\", he defines culture as a \"shorthand way of referring to a complex cognitive ecosystem.\"\n\nReligious behaviors typically exist in the form of ritual and correspond to religious god concepts. These behaviors are phenotypic outcomes of god concepts that are ultimately subject to natural selection. Cognitive ecologists who study religion predict that god concepts across cultures can be linked to coordination solutions for local socioecological challenges, such as large-scale cooperation, intragroup cohesion and commitment, and resource management. For example, an omniscient and morally punitive \"Big God\" may be adaptive for large-scale populations by motivating prosocial behavior, whereas gods associated with small-scale societies are often concerned about the stability of local resources.\n\nSocial contracts and their associated fairness norms are thought by many economists to be contingent on means of production. A hunter-gatherer society, for instance, may operate at an equilibrium where each person contributes to the best of his or her ability and receives according to need. But if this society were to shift toward larger-scale agricultural practices, this equilibrium would be destabilized by increases in free riding and general temptations to profit by defecting. This has been supported empirically in cross-cultural studies using experimental economic game data, which showed a wide range of variance in fairness expectations between populations based on culturally-specific exchange concepts.\n\nThis shift in fairness expectations has also been implicated in archaeological data. In particular, the relaxed sharing norms hypothesized to be built upon periods of successful maize exploitation in the pre-Hispanic Pueblo Southwest seemed to be eroded by decreases in agricultural success. In other words, when crops began to fail and supply became low, cultural exchange norms became more stringent, kin-based and based on reciprocity.\n", "id": "50431941", "title": "Cognitive ecology"}
{"url": "https://en.wikipedia.org/wiki?curid=32086877", "text": "Novel ecosystem\n\nNovel ecosystems are human-built, modified, or engineered niches of the Anthropocene. They exist in places that have been altered in structure and function by human agency. Novel ecosystems are part of the human environment and niche (including urban, suburban, and rural), they lack natural analogs, and they have extended an influence that has converted more than three-quarters of wild Earth. These anthropogenic biomes include technoecosystems that are fuelled by powerful energy sources (fossil and nuclear) including ecosystems populated with technodiversity, such as roads and unique combinations of soils called technosols. Vegetation associations on old buildings or along field boundary stone walls in old agricultural landscapes are examples of sites where research into novel ecosystem ecology is developing.\n\nHuman society has transformed the planet to such an extent that we may have ushered in a new epoch known as the \"anthropocene\". The ecological niche of the anthropocene contains entirely novel ecosystems that include technosols, technodiversity, anthromes, and the technosphere. These terms describe the human ecological phenomena marking this unique turn in the evolution of Earth's history. The total human ecosystem (or anthrome) describes the relationship of the industrial technosphere to the ecosphere.\n\nTechnoecosystems interface with natural life-supporting ecosystems in competitive and parasitic ways.\n\nNovel ecosystems \"differ in composition and/or function from present and past systems\". Novel ecosystems are the hallmark of the recently proposed anthropocene epoch. They have no natural analogs due to human alterations on global climate systems, invasive species, a global mass extinction, and disruption of the global nitrogen cycle. Novel ecosystems are creating many different kinds of dilemmas for conservation biologists. On a more local scale, abandoned lots, agricultural land, old buildings, field boundary stone walls or residential gardens provide study sites on the history and dynamics of ecology in novel ecosystems.\n\nEllis (2008) identifies twenty-one different kinds of anthropogenic biomes that sort into the following groups: 1) dense settlements, 2) villages, 3) croplands, 4) rangeland, 5) forested, and 6) wildlands. These anthropogenic biomes (or anthromes for short) create the technosphere that surrounds us and are populated with diverse technologies (or technodiversity for short). Within these anthromes the human species (one species out of billions) appropriates 23.8% of the global net primary production. \"This is a remarkable impact on the biosphere caused by just one species.\"\n\nNoosphere (sometimes noösphere) is the \"sphere of human thought\". The word is derived from the Greek \"νοῦς\" (nous \"mind\") + \"σφαῖρα\" (sphaira \"sphere\"), in lexical analogy to \"atmosphere\" and \"biosphere\". Introduced by Pierre Teilhard de Chardin 1922 in his Cosmogenesis\". Another possibility is the first use of the term by Édouard Le Roy, who together with Chardin was listening to lectures of Vladimir Vernadsky at Sorbonne. In 1936 Vernadsky presented on the idea of the Noosphere in a letter to Boris Leonidovich Lichkov (though, he states that the concept derives from Le Roy).\n\nThe technosphere is the part of the environment on Earth where technodiversity extends its influence into the biosphere. \"For the development of suitable restoration strategies, a clear distinction has to be made between different functional classes of natural and cultural solar-powered biosphere and fossil-powered technosphere landscapes, according to their inputs and throughputs of energy and materials, their organisms, their control by natural or human information, their internal self-organization and their regenerative capacities.\" The weight of Earth's technosphere has been calculated as 30 trillion tons, a mass greater than 50 kilos for every square metre of the planet's surface.\n\nThe concept of technoecosystems has been pioneered by ecologists Howard T. Odum and Zev Naveh. Technoecosystems interface with and are competitive toward natural systems. They have advanced technology (or technodiversity) money-based market economies and have a large ecological footprints. Technoecosystems have far greater energy requirements than natural ecosystems, excessive water consumption, and release toxic and eutrophicating chemicals. Other ecologists have defined the extensive global network of road systems as a type of technoecosystem.\n\n\"Bio-agro- and techno-ecotopes are spatially integrated in larger, regional landscape units, but they are not structurally and functionally integrated in the ecosphere. Because of the adverse impacts of the latter and the great human pressures on bio-ecotopes, they are even antagonistically related and therefore cannot function together as a coherent, sustainable ecological system.\"\n\nTechnosols are a new form of ground group in the World Reference Base for Soil Resources (WRB). Technosols are \" mainly characterised by anthropogenic parent material of organic and mineral nature and which origin can be either natural or technogenic.\"\n\nTechnodiversity refers to the varied diversity of technological artifacts that exist in technoecosystems.\n", "id": "32086877", "title": "Novel ecosystem"}
{"url": "https://en.wikipedia.org/wiki?curid=47211913", "text": "Von Foerster equation\n\nThe McKendrick–von Foerster equation is a linear first-order partial differential equation encountered in several areas of mathematical biology – for example, cell proliferation modeling; it is applied when age structure is an important feature in the mathematical model. It was presented by biophysics professor Heinz von Foerster.\n\nThe mathematical formula can be derived from first principles. It reads:\n\nwhere the population density \"n\"(\"t\",\"a\") is a function of age \"a\" and time \"t\", and \"m\"(\"a\") is the death function.\n\nWhen \"m\"(\"a\") = 0, we have:\n\nIt relates that a population ages, and that fact is the only one that influences change in population density; the negative sign shows that time flows in just one direction, that there is no birth and the population is going to die out.\n\nThe von Foerster equation is a transport equation; it can be solved using a characteristics method. Another way is by similarity solution; and a third is a numerical approach such as finite differences.\n\nTo get the solution, the following boundary conditions should be added:\n\nwhich states that the initial births should be conserved (see Sharpe–Lotka–McKendrick’s equation for otherwise), and that\n\nwhich states that the initial population must be given; then it will evolve according to the partial differential equation.\n\nIn Sebastian Anita, Viorel Arnautu, Vincenzo Capasso. \"An Introduction to Optimal Control Problems in Life Sciences and Economics\" (Birkhouser. 2011), this equation appears as a special case of the Sharpe–Lotka–McKendrick’s equation; in the latter there is inflow, and the math is based on directional derivative.\n\n", "id": "47211913", "title": "Von Foerster equation"}
{"url": "https://en.wikipedia.org/wiki?curid=50702025", "text": "Material passport\n\nA material passport is a document consisting of all the materials that are included in a product or construction. It consist of a set of data describing defined characteristics of materials in products, which give them value for recovery, recycling and re-use.\n\nThe core idea behind the concept is that a material passport will contribute to a more \"circular economy\", in which materials are being recovered, recycled and/or re-used in an open traded material market. The concept of the 'material passport’ is currently being developed by multiple parties in mainly European countries. A possible second-hand material market or material-bank could become a reality in the future.\n\nSimilar concepts are being developed by several parties. Other names for the material passport are:\n\n\"According to United Nations estimates, construction accounts for some 50 percent of raw material consumption in Europe and 60 percent of waste\" \n\nAssuming that the earth is a closed system, this situation is objectively untenable. There is an urgent need to go about raw materials in a more intelligent way. A shift in the building sector would greatly benefit a situation towards needing less material, and using material more effectively, e.g. by ensuring a much longer and more useful life cycle.\nProponents of the material passport argue that it is a step towards this direction.\n\nThe material passport gives material an identity. By acknowledging that it exists, in a given form in a specific building, it ensures that material receives and keeps a value, e.g. through a possible re-use after the deconstruction of for example a building.\n\nLike a personal passport, the material passport allows the material to ‘travel’, or identifies the most useful future destination after it has served in a building. This could be in another building or in another product altogether. \n\nBy recognizing the individual materials in buildings, new ownership structures could be facilitated, that would enable more functions to be offered as a service. As we now can have lighting as a service, we could have other functions, such as \"shelter from elements\" as a service, instead of owning a roof.\n\nIn general, material passports create incentives for suppliers to produce and developers / managers / renovators to choose healthy, sustainable and circular materials/building products. They fit into a broader and growing movement that aims at developing circular building business models.\n\nThe material passport can be applied to every product or construction. There are different levels in which a product/construct can be discomposed:\n\nFor a building, a material passport could be a complete description of all products (staircase, window, furnace, …), components (iron beam, glass panel, …), and raw materials (wood, steel, …),that are present in the building. Ideally, this database is created during construction and subsequently continuously kept up to date. In case an existing building does not yet have a material passport, it can be created through various methods (e.g. plan analysis, digital 3D scanning).\n\nA material passport allows the owner of a product/construct to know exactly what it is made of. This is of importance at the end of its useful life, to enable the most effective re-use of the materials. It allows the owner to view a product/construct as a depot, inventory of valuable materials.\n\nFurthermore, the process of creating a material passport also shapes the design of the building. The easier the materials can be extracted and re-used, the better. This will lead to an increase of ‘recoverable’ or ‘reversible’ buildings, buildings that can be dis-assembled as easily as they were assembled.\n\nAnother possibility is that a material passport enables the owner to get a better overview of value of the product/construct. Besides the value of the location and of the space, it can now also improve the valuation of the materials used. A higher, or more accurate, valuation of product/construct can be made possible.\n\n\nThe first scientific publication about a material passport (2012) was written by Maayke Damen and is called \"A resources passport for a circular economy\". It provides a comprehensive overview of the advantages and disadvantages of a material passport for every actor in the supply chain. It includes an outline for the content of a material passport. \n\n\n", "id": "50702025", "title": "Material passport"}
{"url": "https://en.wikipedia.org/wiki?curid=18348855", "text": "Harmful algal bloom\n\nA harmful algal bloom (HAB) are organisms that can severely lower oxygen levels in natural waters, killing marine life. Some HABs are associated with algae-produced toxins. Blooms can last from a few days to many months. After the bloom dies, the microbes which decompose the dead algae use up even more of the oxygen, which can create fish die-offs. When these zones of depleted oxygen cover a large area for an extended period of time, they are referred to as dead zones, where neither fish nor plants are able to survive.\nHABs are induced by an overabundance of nutrients in the water. The two most common nutrients are fixed nitrogen (nitrates, ammonia, urea) and phosphate. These nutrients are emitted by agriculture and other industries. Higher water temperature and low circulation also contribute. HABs can cause significant harm to animals, the environment and economies. They have been increasing in size and frequency worldwide, a fact that many experts attribute to global climate change. The U.S. National Oceanic and Atmospheric Administration (NOAA) predicts more harmful blooms in the Pacific Ocean.\n\nHABs from blue-green algae (cyanobacteria) can appear as a foam, scum, or mat on or just below the surface of water and can take on various colors depending on their pigments. Blue-green algae blooms in freshwater lakes or rivers may appear bright green, often with surface streaks which looks like floating paint. Similarly, red tides made up of dinoflagellates, also contain photosynthetic pigments that vary in color from green to brown to red.\n\nMost blooms occur in warm waters that have excessive nutrients. The harmful effects from such blooms is due to the toxins they produce or from using up oxygen in the water which can lead to fish die-offs.\n\nNot all algal blooms are harmful, however, with some only discoloring water, producing a smelly odor, or adding a bad taste to the water. Unfortunately, it is not possible to tell if a bloom is harmful from just appearances, since sampling and microscopic examination is required.\n\nThere are three main types of algae which can form into harmful algal blooms: cyanobacteria, dinoflagellates and diatoms. All three are made up of microscopic floating organisms which, like plants, can create their own food from sunlight by means of photosynthesis. That ability makes them an essential part of the food web for small fish and other organisms.\n\nHarmful algal blooms in freshwater lakes and rivers, or at estuaries, where rivers flow into the ocean, are caused by blue-green algae, also known as cyanobacteria. They can produce hazardous toxins, such as microcystins, a neurotoxin which destroys nerve tissue of mammals. In high enough concentrations, water treatment plants may be unable to remove the toxin and will advise residents to avoid drinking tap water, as happened in Toledo, Ohio in August 2014.\n\nThey also cause harm by blocking the sunlight or by using up the oxygen needed by fish or plant life, which can lead to fish die-offs. When such oxygen-depleted water covers a large area for an extended period of time, it can become hypoxic, commonly called a dead zone. These dead zones can be the result of numerous different factors ranging from natural phenomenon to deliberate human interaction. These dead zones are not just limited to large bodies of fresh water as found in the great lakes, but are also prone to bodies of salt water as well. \n\nThe other types of algae are diatoms and dinoflagellates, found primarily in marine environments, such as ocean coastlines or bays, where they can also form algal blooms, commonly called red tides. Red tides, however, may be a natural phenomenon, although when they form close to coastlines or in estuaries. They can occur when warmer water, salinity, and nutrients reach certain levels, which then stimulates their growth. Most red tide algae are dinoflagellates. They are visible in water at a concentration of 1,000 algae cells per milliliter, while in dense blooms they can measure over 200,000 per milliliter.\n\nDiatoms produce domoic acid, another neurotoxin, which can cause seizures in higher vertebrates and birds as it concentrates up the food chain. Domoic acid readily accumulates in the bodies of shellfish, sardines, and anchovies, which if then eaten by sea lions, otters, cetaceans, birds or people, can affect the nervous system causing serious injury or death. In the summer of 2015, the state governments closed important shellfish fisheries in Washington, Oregon and California because of high concentrations of domoic acid in shellfish.\n\nAmong the causes of algal blooms are:\n\nClimate change, according to NOAA scientists, contributes to warmer waters which makes conditions more favorable for algae growth in more regions and farther north. Global warming is also considered a key factor for algal blooms in the Southern hemisphere, acknowledged by scientists in Australia. In general, still, warm, shallow water, combined with high-nutrient conditions in lakes or rivers, increases the risk of harmful algal blooms.\n\nNutrients enter freshwater or marine environments as surface runoff from agricultural pollution and urban runoff from fertilized lawns, golf courses and other landscaped properties; and from sewage treatment plants that lack nutrient control systems. Additional nutirents are introduced from atmospheric pollution. Coastal areas worldwide, especially wetlands and estuaries, coral reefs and swamps, are prone to being overloaded with those nutrients. Most of the large cities along the Mediterranean Sea, for example, discharge all of their sewage into the sea untreated. The same is true for most coastal developing countries.\n\nIn the U.S., such runoff, despite being the largest source of nutrients added to rivers and lakes, is mostly unregulated under the federal Clean Water Act. Locally developed initiatives to reduce nutrient pollution are underway in various areas of the country, such as the Great Lakes region and the Chesapeake Bay. To help reduce algal blooms in Lake Erie, the State of Ohio presented a plan in 2016 to reduce phosphorus runoff.\n\nThe Chesapeake Bay, the largest estuary in the U.S., has suffered from repeated large algal blooms for decades due to chemical runoff from multiple sources, including 9 large rivers and 141 smaller streams and creeks in parts of six states. In addition, the water is quite shallow and only 1% of the waste entering it gets flushed into the ocean.\n\nBy weight, 60% of the phosphates entering the bay in 2003 were from sewage treatment plants, while 60% of its nitrates came from fertilizer runoff, farm animal waste, and the atmosphere. About 300 million pounds (140 Gg) of nitrates are added to the bay each year. The population increase in the bay watershed, from 3.7 million people in 1940 to 18 million in 2015 is also a major factor, as economic growth leads to the increased use of fertilizers and rising emissions of industrial waste.\n\nThe six states and the local governments in the Chesapeake watershed have upgraded their sewage treatment plants to control nutrient discharges. The U.S. Environmental Protection Agency (EPA) estimates that sewage treatment plant improvements in the Chesapeake region between 1985 and 2015 have prevented the discharge of 900 million pounds (410 Gg) of nutrients, with nitrogen discharges reduced by 57% and phosphorus by 75%. Agricultural and urban runoff pollution continue to be major sources of nutrients in the bay, and efforts to manage those problems are continuing throughout the watershed.\n\nAs algal blooms grow, they deplete the oxygen in the water and block sunlight from reaching fish and plants. Such blooms can last from a few days to many months. With less light, plants beneath the bloom can die and fish can starve. And when the algae eventually die off, the microbes which decompose the dead algae use up even more oxygen, which in turn causes more fish to die or leave the area. When oxygen continues to be depleted by blooms it can lead to hypoxic dead zones, where neither fish nor plants are able to survive. These dead zones in the case of the Chesapeake Bay, where they are a normal occurrence, are also suspected of being a major source of methane.\n\nThe negative impact on fish can be even more severe when they are confined to pens, as they are in fish farms. In 2007 a fish farm in British Columbia lost 260 tons of salmon as a result of blooms, and in 2016 a farm in Chile lost 23 million salmon after an algal bloom. \n\nAccording to NOAA, less than one percent of algal blooms produce hazardous toxins, such as microcystins. Although blue-green or other algae do not usually pose a direct threat to health, the toxins (poisons) which they produce are considered dangerous to humans, land animals, sea mammals, birds and fish when the toxins are ingested. The toxins are neurotoxins which destroy nerve tissue which can affect the nervous system, brain, and liver, and can lead to death. Tests have shown some toxins near blooms can be in the air and thereby be inhaled, which could affect health.\n\nThere is no treatment available for animals, including livestock cattle, if they drink from algal blooms where such toxins are present. The Florida Department of Health recommends that people and pets be kept away from algal blooms to avoid contact.\n\nEating fish or shellfish from lakes with a bloom nearby is not recommended. A study has shown that algal toxins may be the cause for as many as 60,000 intoxication cases in the world each year. This is due to the accumulation of potent toxins in shellfish that consume those algae and then these shellfish are later consumed by humans which may result in Amnesic shellfish poisoning, Diarrhetic shellfish poisoning, Neurotoxic shellfish poisoning, and Paralytic shellfish poisoning. Toxic paralytic shellfish poisoning in the Philippines during red tides have caused at least 120 deaths over a few decades. After a HAB in Monterey Bay, California, health officials warned people not to eat certain parts of anchovy, sardines, or crab caught in the bay.In 1987 a new illness had emerged which was called amnesic shellfish poisoning. People who had eaten mussels from Prince Edward Island were found to have amnesic shellfish poisoning. The illness was caused by domoic acid, produced by a diatom found in the area where the mussels were cultivated. In 2015 most shellfish fisheries in Washington, Oregon and California were shut down because of high concentrations of toxic domoic acid in shellfish. People have been warned that inhaling vapors from waves or wind during a red tide may cause asthma attacks or lead to other respiratory ailments.\n\nAgricultural officials in Utah worried that even crops could become contaminated if irrigated with toxic water, although they admit that they can't measure contamination accurately because of so many variables in farming. They issued warnings to residents, however, out of caution.\n\nPersons are generally warned not to enter or drink water from algal blooms, or let their pets swim in the water since many pets have died from algal blooms. In at least one case, people began getting sick before warnings were issued.\n\nIn some locations visitors have been warned not to even touch the water. Boaters have been told that toxins in the water can be inhaled from the spray from wind or waves. Ocean beaches, lakes and rivers have been closed due to algal blooms. After a dog died in 2015 from swimming in a bloom in California's Russian River, officials likewise posted warnings for parts of the river. Boiling the water at home before drinking does not remove the toxins.\n\nScientists in Britain, which has seen a huge increase in toxic algae, suspect that drinking water from sources that have blue-green algae may contribute to Alzheimer’s, Parkinson’s or Lou Gehrig’s Disease. Few water treatment plants regularly test for cyanobacterial toxins, however.\n\nIn August 2014 the city of Toledo, Ohio advised its 500,000 residents to not drink tap water as the high toxin level from an algal bloom in western Lake Erie had affected their water treatment plant's ability to treat the water to a safe level. The emergency required using bottled water for all normal uses except showering, which seriously affected public services and commercial businesses. The bloom returned in 2015 and was forecast again for the summer of 2016.\n\nIn 2004, a bloom in Kisumu Bay, which is the drinking water source for 500,000 people in Kisumu, Kenya, suffered from similar water contamination. In China, water was cut off to residents in 2007 due to an algal bloom in its third largest lake, which forced 2 million people to use bottled water. A smaller water shut-down in China affected 15,000 residents two years later at a different location. Australia in 2016 also had to cut off water to farmers.\n\nAlan Steinman of Grand Valley State University has explained that among the major causes for the algal blooms in general, and Lake Erie specifically, is because blue-green algae thrive with high nutrients, along with warm and calm water. Lake Erie is more prone to blooms because it has a high nutrient level and is shallow, which causes it to warm up more quickly during the summer.\n\nSymptoms from drinking toxic water can show up within a few hours after exposure. They can include nausea, vomiting, and diarrhea, or trigger headaches and gastrointestinal problems. Although rare, liver toxicity can cause death. Those symptoms can then lead to dehydration, another major concern. In high concentrations, the toxins in the algal waters when simply touched can cause skin rashes, irritate the eyes, nose, mouth or throat. Those with suspected symptoms are told to call a doctor if symptoms persist or they can't hold down fluids after 24 hours.\n\nThe hazards which accompany harmful algal blooms have hindered visitors' enjoyment of beaches and lakes in places in the U.S. such as Florida, California Vermont, and Utah. Persons hoping to enjoy their vacations or days off have been kept away to the detriment of local economies. Lakes and rivers in North Dakota, Minnesota, Utah, California and Ohio have had signs posted warning about the potential of health risk.\n\nIn July 2016 Florida declared a state of emergency for four counties as a result of blooms. They were said to be \"destroying\" a number of businesses and affecting local economies, with many needing to shut down entirely. Some beaches were closed, and hotels and restaurants suffered a drop in business. Tourist sporting activities such as fishing and boating were also affected. Senator Marco Rubio called the situation in Florida \"a health, ecological and economic emergency.\"\nSimilar blooms have become more common in Europe, with France among the countries reporting them. In the summer of 2009, beaches in northern Brittany became covered by tonnes of potentially lethal rotting green algae. A horse being ridden along the beach collapsed and died from fumes given off by the rotting algae.\n\nThe economic damage resulting from lost business has become a serious concern. According to one report in 2016, the four main economic impacts from harmful algal blooms come from damage to human health, fisheries, tourism and recreation, and the cost of monitoring and management of area where blooms appear. EPA estimates that algal blooms impact 65 percent of the country's major estuaries, with an annual cost of $2.2 billion. In the U.S. there are an estimated 166 coastal dead zones. Because data collection has been more difficult and limited from sources outside the U.S., most of the estimates as of 2016 have been primarily for the U.S.\n\nIn port cities in the Shandong Province of eastern China, residents are no longer surprised when massive algal blooms arrive each year and inundate beaches. Prior to the Beijing Olympics in 2008, over 10,000 people worked to clear 20,000 tons of dead algae from beaches. In 2013 another bloom in China, thought to be its largest ever, covered an area of 7,500 square miles, and was followed by another in 2015 which blanketed an even greater 13,500 square miles. The blooms in China are thought to be caused by pollution from untreated agricultural and industrial discharges into rivers leading to the ocean.\n\nAs early as 1976 a short-term, relatively small, dead zone off the coasts of New York and New Jersey cost commercial and recreational fisheries over $500 million. In 1998 a red tide in Hong Kong killed over $10 million in high-value fish.\n\nIn 2009, the economic impact for the state of Washington's coastal counties dependent on its fishing industry was estimated to be $22 million. In 2016, the U.S. seafood industry expected future lost revenue could amount to $900 million annually.\n\nNOAA has provided a few cost estimates for various blooms over the past few years: $10.3 million in 2011 due to the red tide at Texas oyster landings; $2.4 million lost income by tribal commerce from 2015 fishery closures in the pacific northwest; $40 million from Washington state's loss of tourism from the same fishery closure.\n\nAlong with damage to businesses, the toll from human sickness results in lost wages and damaged health. The costs of medical treatment, investigation by health agencies through water sampling and testing, and the posting of warning signs at effected locations is also costly.\n\nThe closures applied to areas where this algae bloom occurs has a big negative impact of the fishing industries, add to that the high fish mortality that follows, the increase in price due to the shortage of fish available and decrease in the demand for seafood due to the fear of contamination by toxins.This causes a big economic loss for the industry\n\nEconomic costs are estimated to rise. In June 2015, for instance, the largest known toxic HAB forced the shutdown of the west coast shellfish industry, the first time that has ever happened. One Seattle NOAA expert commented, \"This is unprecedented in terms of the extent and magnitude of this harmful algal bloom and the warm water conditions we're seeing offshore...\" The bloom covered a range from Santa Barbara, California northward to Alaska.\n\nThe number of reported harmful algal blooms (cyanobacterial) has been increasing throughout the world. In the U.S., every coastal state has had harmful algal blooms over the last decade, and species have emerged in new locations that were not previously known to have problems. Inland, major rivers have seen an increase in their size and frequency. In 2015 the Ohio River had a bloom which stretched an \"unprecedented\" into adjoining states and tested positive for toxins, which created drinking water and recreation problems. A portion of Utah's Jordan River was closed due to toxic algal bloom in 2016.\n\nResearchers have reported the growth of HABs in Europe, Africa and Australia. Those have included blooms on some of the African Great Lakes, such as Lake Victoria, the second largest freshwater lake in the world. India has been reporting an increase in the number of blooms each year. In 1977 Hong Kong reported its first red tide. By 1987 they were getting an average of 35 per year. Additionally, there have been reports of harmful algal blooms throughout popular Canadian lakes such as Beaver Lake and Quamichan Lake. These blooms were responsible for the deaths of a few animals and led to swimming advisories. \n\nGlobal warming and pollution is causing algal blooms to form in places previously considered \"impossible\" or rare for them to exist, such as under the ice sheets in the Arctic, in Antarctica, the Himalayan Mountains, the Rocky Mountains, and in the Sierra Nevada Mountains.\n\nMassive fish die-offs have been caused by HABs. In 2016, 23 million salmon which were being farmed in Chile died from a toxic algae bloom. To get rid of the dead fish, the ones fit for consumption were made into fishmeal and the rest were dumped 60 miles offshore to avoid risks to human health. The economic cost of that die-off is estimated to have been $800 million. Environmental expert Lester Brown has written that the farming of salmon and shrimp in offshore ponds concentrates waste, which contributes to eutrophication and the creation of dead zones.\n\nOther countries have reported similar impacts, with cities such as Rio de Janeiro, Brazil seeing major fish die-offs from blooms becoming a common occurrence. In early 2015, Rio collected an estimated 50 tons of dead fish from the lagoon where water events in the 2016 Olympics were planned to take place.\n\nThe Monterey Bay has suffered from harmful algal blooms, most recently in 2015: \"Periodic blooms of toxin-producing \"Pseudo-nitzschia\" diatoms have been documented for over 25 years in Monterey Bay and elsewhere along the U.S. west coast. During large blooms, the toxin accumulates in shellfish and small fish such as anchovies and sardines that feed on algae, forcing the closure of some fisheries and poisoning marine mammals and birds that feed on contaminated fish.\" Similar fish die-offs from toxic algae or lack of oxygen have been seen in Russia, Colombia, Vietnam, China, Canada, Turkey, Indonesia, and France.\n\nLand animals, including livestock and pets have been affected. Dogs have died from the toxins after swimming in algal blooms. Warnings have come from government agencies in the state of Ohio, which noted that many dogs and livestock deaths resulted from HAB exposure in the U.S. and other countries. They also noted in a 2003 report that during the previous 30 years, they have seen more frequent and longer-lasting harmful algal blooms.\" In 50 countries and 27 states that year there were reports of human and animal illnesses linked to algal toxins. In Australia, the department of agriculture warned farmers that the toxins from a HAB had the \"potential to kill large numbers of livestock very quickly.\"\nMarine mammals have also been seriously harmed, as over 50 percent of unusual marine mammal deaths are caused by harmful algal blooms. In 1999, over 65 bottlenose dolphins died during a red tide in Florida. In 2013 a red tide in southwest Florida killed a record number of Manatee. Whales have also died in large numbers. During the period from 2005 to 2014, Argentina reported an average 65 baby whales dying which experts have linked to algal blooms. A whale expert there expects the whale population to be reduced significantly. In 2003 off Cape Cod in the North Atlantic, at least 12 humbpack whales died from toxic algae from a red tide. In 2015 Alaska and British Columbia reported many humpback whales had likely died from HAB toxins, with 30 having washed ashore in Alaska. \"Our leading theory at this point is that the harmful algal bloom has contributed to the deaths,\" said a NOAA spokesperson.\n\nBirds have died after eating dead fish contaminated with toxic algae. Rotting and decaying fish are eaten by birds such as pelicans, seagulls, cormorants, and possibly marine or land mammals, which then become poisoned. The nervous systems of dead birds were examined and had failed from the toxin's effect. On the Oregon and Washington coast, a thousand scoters, or sea ducks, were also killed in 2009. \"\"This is huge,\" said a University professor. As dying or dead birds washed up on the shore, wildlife agencies went into \"an emergency crisis mode.\"\n\nIt has even been suggested that harmful algal blooms are responsible for the deaths of animals found in fossil troves.\n\nAccording to NOAA, blooms can harm the environment even without producing toxins by depleting oxygen from the water when growing and while decaying after they die. Blooms can also block sunlight to organisms living beneath it. A record-breaking number and size of blooms have formed in the Pacific coast, in Lake Erie, in the Chesapeake Bay and in the Gulf of Mexico, where a number of dead zones were created as a result. In the 1960s the number of dead zones worldwide was 49; the number rose to over 400 by 2008. In the U.S. they are especially prevalent along the east and south coasts.\n\nVarious important natural habitats such as rivers, lakes and estuaries have continued to degrade and has contributed to creating more oxygen-deprived dead zones, including some in the Gulf of Mexico, the Chesapeake Bay, and Lake Erie. \n\nAmong the largest dead zones were those in northern Europe’s Baltic Sea and the Gulf of Mexico, which affects a $2.8 billion U.S. fish industry. Unfortunately, dead zones rarely recover and usually grow in size. One of the few dead zones to ever recover was in the Black Sea, which returned to normal fairly quickly after the collapse of the Soviet Union in the 1990s due to a resulting reduction in fertilizer use.\n\nAlthough a number of algaecides have been effective in killing algae, they have been used mostly in small bodies of water. For large algal blooms, however, adding algaecides such as silver nitrate or copper sulfate can have worse effects, such as killing fish outright and harming other wildlife. The negative effects can therefore be worse than letting the algae die off naturally.\n\nOther experts have proposed building reservoirs to prevent the movement of algae downstream. However, that can lead to the growth of algae within the reservoir, which become sediment traps with a resultant buildup of nutrients. Some researchers found that intensive blooms in reservoirs were the primary source of toxic algae observed downstream, but the movement of algae has so far been less studied, although it is considered a likely cause of algae transport.\n\nA growing number of scientists agree that there is an urgent need to protect the public by being able to forecast harmful algal blooms. One way they hope to do that is with sophisticated sensors which can help warn about potential blooms. The same types of sensors can also be used by water treatment facilities to help them prepare for higher toxic levels.\n\nThe only sensors now in use are located in the Gulf of Mexico. In 2008 similar sensors in the Gulf forewarned of an increased level of toxins which led to a shutdown of shellfish harvesting in Texas along with a recall of mussels, clams and oysters, possibly saving many lives. With an increase in the size and frequency of HABs, experts state the need for significantly more sensors located around the country. The same kinds of sensors can also be used to detect threats to drinking water from intentional contamination.\n\nFour U.S. federal agencies—EPA, the National Aeronautics and Space Administration (NASA), NOAA, and the U.S. Geological Survey (USGS)—are working on ways to detect and measure cyanobacteria blooms using satellite data. The data may help develop early-warning indicators of cyanobacteria blooms by monitoring both local and national coverage. In 2016 automated early-warning monitoring systems were successfully tested, and for the first time proven to identify the rapid growth of algae and the subsequent depletion of oxygen in the water.\n\nHowever, in the U.S. at least, funding for such warning devices has been shrinking, with approved funding down 45% over the last five years. According to one marine science professor, \"We need it more than ever, and we’ve brought ourselves to the precipice of making great forecasts, but we can’t make it happen.\"\n\nThe nitrates and phosphorus in fertilizers cause algal blooms when they run off into lakes and rivers after heavy rains. Modifications in farming methods have been suggested, such as only using fertilizer in a targeted way at the appropriate time exactly where it can do the most good for crops to reduce potential runoff. A method used successfully is drip irrigation, which instead of widely dispersing fertilizers on fields, drip-irrigates plant roots through a network of tubes and emitters, leaving no traces of fertilizer to be washed away. According to the Organisation for Economic Co-operation and Development (OECD), drip irrigation also prevents the formation of algal blooms in reservoirs for drinking water while saving up to 50% of water typically used by agriculture.\n\nA number of states in the U.S. have tried eliminating phosphates in detergent and by cleaning water treatment plants, which succeeded in reducing the amount that entered Lake Erie by 66%. However, changes in farming practices during that period increased chemical runoff, thereby offsetting the improvements.\n\nThere have also been proposals to create buffer zones of foliage and wetlands to help filter out the phosphorus before it reaches water. Other experts have suggested using conservation tillage, changing crop rotations, and restoring wetlands. \"The most important thing that can be done is to reduce agricultural runoff,\" according to a Great Lakes pollution expert. \"Prevention is better than treatment.\" Another expert states that it is possible for some dead zones to shrink within a year under proper management.\n\nThere have been a few success stories in controlling chemicals. After Norway's lobster fishery collapsed in 1986 due to low oxygen levels, for instance, the government in neighboring Denmark took action and reduced phosphorus output by 80 percent which brought oxygen levels closer to normal. Similarly, dead zones in the Black Sea and along the Danube River recovered after phosphorus applications by farmers were reduced by 60%.\n\nIn 2008, the U.S. government prepared a report on the problem, \"Harmful Algal Bloom Management and Response: Assessment and Plan\". The report recognized the seriousness of the problem:\n\nThe report suggested among other remedies, using improved monitoring methods, trying to improve predictability, and testing new potential methods of controlling HABs. Some countries surrounding the Baltic Sea, which has the world's largest dead zone, have considered using massive geoengineering options, such as forcing air into bottom layers to aerate them.\n\nIn 2015, NOAA created 12 new research grants totaling nearly $2.1 million which they would award to national organizations doing research on harmful algal blooms and hypoxia, which they consider to be \"two of the most scientifically complex and economically damaging coastal issues.\"\n\nMost countries, states and large cities have departments which will help monitor and report incidents of algal blooms. The Centers for Disease Control and Prevention (CDC) in the U.S. launched the country's first algal bloom reporting system in June 2016. Environmental agencies in individual U.S. states will accept reports of blooms from citizens and will work with cities to test and report incidents to the media. A few examples:\n\n", "id": "18348855", "title": "Harmful algal bloom"}
{"url": "https://en.wikipedia.org/wiki?curid=51388505", "text": "Community respiration\n\nCommunity respiration (CR) refers to the total amount of carbon-dioxide that is produced by individuals organisms in a given\ncommunity, originating from the cellular respiration of organic material. CR is an important ecological index as it dictates the amount\nof production for the higher trophic levels and influence biogeochemical cycles.\nCR is often used as a proxy for the biological activity of the microbial community.\n\n", "id": "51388505", "title": "Community respiration"}
{"url": "https://en.wikipedia.org/wiki?curid=1596317", "text": "Habitat\n\nA habitat is an ecological or environmental area that is inhabited by a particular species of animal, plant, or other type of organism. The term typically refers to the zone in which the organism lives and where it can find food, shelter, protection and mates for reproduction. It is the natural environment in which an organism lives, or the physical environment that surrounds a species population.\n\nA habitat is made up of physical factors such as soil, moisture, range of temperature, and light intensity as well as biotic factors such as the availability of food and the presence or absence of predators. Every organism has certain habitat needs for the conditions in which it will thrive, but some are tolerant of wide variations while others are very specific in their requirements. A habitat is not necessarily a geographical area, it can be the interior of a stem, a rotten log, a rock or a clump of moss, and for a parasitic organism it is the body of its host, part of the host's body such as the digestive tract, or a single cell within the host's body.\n\nHabitat types include polar, temperate, subtropical and tropical. The terrestrial vegetation type may be forest, steppe, grassland, semi-arid or desert. Fresh water habitats include marshes, streams, rivers, lakes, ponds and estuaries, and marine habitats include salt marshes, the coast, the intertidal zone, reefs, bays, the open sea, the sea bed, deep water and submarine vents.\n\nHabitats change over time. This may be due to a violent event such as the eruption of a volcano, an earthquake, a tsunami, a wildfire or a change in oceanic currents; or the change may be more gradual over millennia with alterations in the climate, as ice sheets and glaciers advance and retreat, and as different weather patterns bring changes of precipitation and solar radiation. Other changes come as a direct result of human activities; deforestation, the ploughing of ancient grasslands, the diversion and damming of rivers, the draining of marshland and the dredging of the seabed. The introduction of alien species can have a devastating effect on native wildlife, through increased predation, through competition for resources or through the introduction of pests and diseases to which the native species have no immunity.\n\nThe word \"habitat\" has been in use since about 1755 and derives from the Latin third-person singular present indicative of \"habitāre\", to inhabit, from \"habēre\", to have or to hold. Habitat can be defined as the natural environment of an organism, the place in which it is natural for it to live and grow. It is similar in meaning to a biotope; an area of uniform environmental conditions associated with a particular community of plants and animals.\n\nThe chief environmental factors affecting the distribution of living organisms are temperature, humidity, climate, soil type and light intensity, and the presence or absence of all the requirements that the organism needs to sustain it. Generally speaking, animal communities are reliant on specific types of plant communities.\n\nSome plants and animals are generalists, and their habitat requirements are met in a wide range of locations. The small white butterfly (\"Pieris rapae\") for example is found on all the continents of the world apart from Antarctica. Its larvae feed on a wide range of \"Brassicas\" and various other plant species, and it thrives in any open location with diverse plant associations. The large blue butterfly is much more specific in its requirements; it is found only in chalk grassland areas, its larvae feed on \"Thymus\" species and because of complex lifecycle requirements it inhabits only areas in which \"Myrmica\" ants live.\n\nDisturbance is important in the creation of biodiverse habitats. In the absence of disturbance, a climax vegetation cover develops that prevents the establishment of other species. Wildflower meadows are sometimes created by conservationists but most of the flowering plants used are either annuals or biennials and disappear after a few years in the absence of patches of bare ground on which their seedlings can grow. Lightning strikes and toppled trees in tropical forests allow species richness to be maintained as pioneering species move in to fill the gaps created. Similarly coastal habitats can become dominated by kelp until the seabed is disturbed by a storm and the algae swept away, or shifting sediment exposes new areas for colonisation. Another cause of disturbance is when an area may be overwhelmed by an invasive introduced species which is not kept under control by natural enemies in its new habitat.\n\nTerrestrial habitat types include forests, grasslands, wetlands and deserts. Within these broad biomes are more specific habitats with varying climate types, temperature regimes, soils, altitudes and vegetation types. Many of these habitats grade into each other and each one has its own typical communities of plants and animals. A habitat may suit a particular species well, but its presence or absence at any particular location depends to some extent on chance, on its dispersal abilities and its efficiency as a coloniser.\nFreshwater habitats include rivers, streams, lakes, ponds, marshes and bogs. Although some organisms are found across most of these habitats, the majority have more specific requirements. The water velocity, its temperature and oxygen saturation are important factors, but in river systems, there are fast and slow sections, pools, bayous and backwaters which provide a range of habitats. Similarly, aquatic plants can be floating, semi-submerged, submerged or grow in permanently or temporarily saturated soils besides bodies of water. Marginal plants provide important habitat for both invertebrates and vertebrates, and submerged plants provide oxygenation of the water, absorb nutrients and play a part in the reduction of pollution.\n\nMarine habitats include brackish water, estuaries, bays, the open sea, the intertidal zone, the sea bed, reefs and deep water zones. Further variations include rock pools, sand banks, mudflats, brackish lagoons, sandy and pebbly beaches, and seagrass beds, all supporting their own flora and fauna. The benthic zone or seabed provides a home for both static organisms, anchored to the substrate, and for a large range of organisms crawling on or burrowing into the surface. Some creatures float among the waves on the surface of the water, or raft on floating debris, others swim at a range of depths, including organisms in the demersal zone close to the seabed, and myriads of organisms drift with the currents and form the plankton.\nA desert is not the kind of habitat that favours the presence of amphibians, with their requirement for water to keep their skins moist and for the development of their young. Nevertheless, some frogs live in deserts, creating moist habitats underground and hibernating while conditions are adverse. Couch's spadefoot toad (\"Scaphiopus couchii\") emerges from its burrow when a downpour occurs and lays its eggs in the transient pools that form; the tadpoles develop with great rapidity, sometimes in as little as nine days, undergo metamorphosis, and feed voraciously before digging a burrow of their own.\n\nOther organisms cope with the drying up of their aqueous habitat in other ways. Vernal pools are ephemeral ponds that form in the rainy season and dry up afterwards. They have their specially-adapted characteristic flora, mainly consisting of annuals, the seeds of which survive the drought, but also some uniquely adapted perennials. Animals adapted to these extreme habitats also exist; fairy shrimps can lay \"winter eggs\" which are resistant to desiccation, sometimes being blown about with the dust, ending up in new depressions in the ground. These can survive in a dormant state for as long as fifteen years. Some killifish behave in a similar way; their eggs hatch and the juvenile fish grow with great rapidity when the conditions are right, but the whole population of fish may end up as eggs in diapause in the dried up mud that was once a pond.\n\nMany animals and plants have taken up residence in urban environments. They tend to be adaptable generalists and use the town's features to make their homes. Rats and mice have followed man around the globe, pigeons, peregrines, sparrows, swallows and house martins use the buildings for nesting, bats use roof space for roosting, foxes visit the garbage bins and squirrels, coyotes, raccoons and skunks roam the streets. About 2,000 coyotes are thought to live in and around Chicago. A survey of dwelling houses in northern European cities in the twentieth century found about 175 species of invertebrate inside them, including 53 species of beetle, 21 flies, 13 butterflies and moths, 13 mites, 9 lice, 7 bees, 5 wasps, 5 cockroaches, 5 spiders, 4 ants and a number of other groups. In warmer climates, termites are serious pests in the urban habitat; 183 species are known to affect buildings and 83 species cause serious structural damage.\n\nA microhabitat is the small-scale physical requirements of a particular organism or population. Every habitat includes large numbers of microhabitats with subtly different exposure to light, humidity, temperature, air movement, and other factors. The lichens that grow on the north face of a boulder are different to those that grow on the south face, from those on the level top and those that grow on the ground nearby; the lichens growing in the grooves and on the raised surfaces are different from those growing on the veins of quartz. Lurking among these miniature \"forests\" are the microfauna, each species of invertebrate with its own specific habitat requirements.\n\nThere are numerous different microhabitats in a wood; coniferous forest, broad-leafed forest, open woodland, scattered trees, woodland verges, clearings and glades; tree trunk, branch, twig, bud, leaf, flower and fruit; rough bark, smooth bark, damaged bark, rotten wood, hollow, groove and hole; canopy, shrub layer, plant layer, leaf litter and soil; buttress root, stump, fallen log, stem base, grass tussock, fungus, fern and moss. The greater the structural diversity in the wood, the greater the number of microhabitats that will be present. A range of tree species with individual specimens of varying sizes and ages, and a range of features such as streams, level areas, slopes, tracks, clearings and felled areas will provide suitable conditions for an enormous number of biodiverse plants and animals. For example, in Britain it has been estimated that various types of rotting wood are home to over 1700 species of invertebrate.\n\nFor a parasitic organism, its habitat is the particular part of the outside or inside of its host on or in which it is adapted to live. The life cycle of some parasites involves several different host species, as well as free-living life stages, sometimes providing vastly different microhabitats. One such organism is the trematode (flatworm) \"Microphallus turgidus\", present in brackish water marshes in the southeastern United States. Its first intermediate host is a snail and the second, a glass shrimp. The final host is the waterfowl or mammal that consumes the shrimp.\n\nAlthough the vast majority of life on Earth lives in mesophyllic (moderate) environments, a few organisms, most of them microbes, have managed to colonise extreme environments that are unsuitable for most higher life forms. There are bacteria, for example, living in Lake Whillans, half a mile below the ice of Antarctica; in the absence of sunlight, they must rely on organic material from elsewhere, perhaps decaying matter from glacier melt water or minerals from the underlying rock. Other bacteria can be found in abundance in the Mariana Trench, the deepest place in the ocean and on Earth; marine snow drifts down from the surface layers of the sea and accumulates in this undersea valley, providing nourishment for an extensive community of bacteria.\n\nOther microbes live in habitats lacking in oxygen, and are dependent on chemical reactions other than photosynthesis. Boreholes drilled into the rocky seabed have found microbial communities apparently based on the products of reactions between water and the constituents of rocks. These communities have been little studied, but may be an important part of the global carbon cycle. Rock in mines two miles deep also harbour microbes; these live on minute traces of hydrogen produced in slow oxidizing reactions inside the rock. These metabolic reactions allow life to exist in places with no oxygen or light, an environment that had previously been thought to be devoid of life.\n\nThe intertidal zone and the photic zone in the oceans are relatively familiar habitats. However the vast bulk of the ocean is unhospitable to air-breathing humans, with scuba divers limited to the upper or so. The lower limit for photosynthesis is and below that depth the prevailing conditions include total darkness, high pressure, little oxygen (in some places), scarce food resources and extreme cold. This habitat is very challenging to research, and as well as being little studied, it is vast, with 79% of the Earth's biosphere being at depths greater than . With no plant life, the animals in this zone are either detritivores, reliant on food drifting down from surface layers, or they are predators, feeding on each other. Some organisms are pelagic, swimming or drifting in mid-ocean, while others are benthic, living on or near the seabed. Their growth rates and metabolisms tend to be slow, their eyes may be very large to detect what little illumination there is, or they may be blind and rely on other sensory inputs. A number of deep sea creatures are bioluminescent; this serves a variety of functions including predation, protection and social recognition. In general, the bodies of animals living at great depths are adapted to high pressure environments by having pressure-resistant biomolecules and small organic molecules present in their cells known as piezolytes, which give the proteins the flexibility they need. There are also unsaturated fats in their membranes which prevent them from solidifying at low temperatures.\nHydrothermal vents were first discovered in the ocean depths in 1977. They result from seawater becoming heated after seeping through cracks to places where hot magma is close to the seabed. The under-water hot springs may gush forth at temperatures of over and support unique communities of organisms in their immediate vicinity. The basis for this teeming life is chemosynthesis, a process by which microbes convert such substances as hydrogen sulfide or ammonia into organic molecules. These bacteria and Archaea are the primary producers in these ecosystems and support a diverse array of life. About 350 species of organism, dominated by molluscs, polychaete worms and crustaceans, had been discovered around hydrothermal vents by the end of the twentieth century, most of them being new to science and endemic to these habitats.\n\nBesides providing locomotion opportunities for winged animals and a conduit for the dispersal of pollen grains, spores and seeds, the atmosphere can be considered to be a habitat in its own right. There are metabolically active microbes present that actively reproduce and spend their whole existence airborne, with hundreds of thousands of individual organisms estimated to be present in a cubic metre of air. The airborne microbial community may be as diverse as that found in soil or other terrestrial environments, however these organisms are not evenly distributed, their densities varying spatially with altitude and environmental conditions. Aerobiology has been little studied, but there is evidence of nitrogen fixation in clouds, and less clear evidence of carbon cycling, both facilitated by microbial activity.\n\nThere are other examples of extreme habitats where specially adapted lifeforms exist; tar pits teeming with microbial life; naturally occurring crude oil pools inhabited by the larvae of the petroleum fly; hot springs where the temperature may be as high as and cyanobacteria create microbial mats; cold seeps where the methane and hydrogen sulfide issue from the ocean floor and support microbes and higher animals such as mussels which form symbiotic associations with these anaerobic organisms; salt pans harbour salt-tolerant microorganisms and also \"Wallemia ichthyophaga\", a basidomycotous fungus; ice sheets in Antarctica which support fungi \"Thelebolus\" spp., and snowfields on which algae grow.\n\nWhether from natural processes or the activities of man, landscapes and their associated habitats change over time. There are the slow geomorphological changes associated with the geologic processes that cause tectonic uplift and subsidence, and the more rapid changes associated with earthquakes, landslides, storms, flooding, wildfires, coastal erosion, deforestation and changes in land use. Then there are the changes in habitats brought on by alterations in farming practices, tourism, pollution, fragmentation and climate change.\n\nLoss of habitat is the single greatest threat to any species. If an island on which an endemic organism lives becomes uninhabitable for some reason, the species will become extinct. Any type of habitat surrounded by a different habitat is in a similar situation to an island. If a forest is divided into parts by logging, with strips of cleared land separating woodland blocks, and the distances between the remaining fragments exceeds the distance an individual animal is able to travel, that species becomes especially vulnerable. Small populations generally lack genetic diversity and may be threatened by increased predation, increased competition, disease and unexpected catastrophe. At the edge of each forest fragment, increased light encourages secondary growth of fast-growing species and old growth trees are more vulnerable to logging as access is improved. The birds that nest in their crevices, the epiphytes that hang from their branches and the invertebrates in the leaf litter are all adversely affected and biodiversity is reduced. Habitat fragmentation can be ameliorated to some extent by the provision of wildlife corridors connecting the fragments. These can be a river, ditch, strip of trees, hedgerow or even an underpass to a highway. Without the corridors, seeds cannot disperse and animals, especially small ones, cannot travel through the hostile territory, putting populations at greater risk of local extinction.\n\nHabitat disturbance can have long-lasting effects on the environment. \"Bromus tectorum\" is a vigorous grass from Europe which has been introduced to the United States where it has become invasive. It is highly adapted to fire, producing large amounts of flammable detritus and increasing the frequency and intensity of wildfires. In areas where it has become established, it has altered the local fire regimen to such an extant that native plants cannot survive the frequent fires, allowing it to become even more dominant. A marine example is when sea urchin populations \"explode\" in coastal waters and destroy all the macroalgae present. What was previously a kelp forest becomes an urchin barren that may last for years and this can have a profound effect on the food chain. Removal of the sea urchins, by disease for example, can result in the seaweed returning, with an over-abundance of fast-growing kelp.\n\nThe protection of habitats is a necessary step in the maintenance of biodiversity because if habitat destruction occurs, the animals and plants reliant on that habitat suffer. Many countries have enacted legislation to protect their wildlife. This may take the form of the setting up of national parks, forest reserves and wildlife reserves, or it may restrict the activities of humans with the objective of benefiting wildlife. The laws may be designed to protect a particular species or group of species, or the legislation may prohibit such activities as the collecting of bird eggs, the hunting of animals or the removal of plants. A general law on the protection of habitats may be more difficult to implement than a site specific requirement. A concept introduced in the United States in 1973 involves protecting the critical habitat of endangered species, and a similar concept has been incorporated into some Australian legislation.\n\nInternational treaties may be necessary for such objectives as the setting up of marine reserves. Another international agreement, the Convention on the Conservation of Migratory Species of Wild Animals, protects animals that migrate across the globe and need protection in more than one country. However, the protection of habitats needs to take into account the needs of the local residents for food, fuel and other resources. Even where legislation protects the environment, a lack of enforcement often prevents effective protection. Faced with food shortage, a farmer is likely to plough up a level patch of ground despite it being the last suitable habitat for an endangered species such as the San Quintin kangaroo rat, and even kill the animal as a pest. In this regard, it is desirable to educate the community on the uniqueness of their flora and fauna and the benefits of ecotourism.\n\nA monotypic habitat is one in which a single species of animal or plant is so dominant as to virtually exclude all other species. An example would be sugarcane; this is planted, burnt and harvested, with herbicides killing weeds and pesticides controlling invertebrates. The monotypic habitat occurs in botanical and zoological contexts, and is a component of conservation biology. In restoration ecology of native plant communities or habitats, some invasive species create monotypic stands that replace and/or prevent other species, especially indigenous ones, from growing there. A dominant colonization can occur from retardant chemicals exuded, nutrient monopolization, or from lack of natural controls such as herbivores or climate, that keep them in balance with their native habitats. The yellow starthistle, \"Centaurea solstitialis\", is a botanical monotypic-habitat example of this, currently dominating over in California alone. The non-native freshwater zebra mussel, \"Dreissena polymorpha\", that colonizes areas of the Great Lakes and the Mississippi River watershed, is a zoological monotypic-habitat example; the predators that control it in its home-range in Russia are absent and it proliferates abundantly. Even though its name may seem to imply simplicity as compared with habitats, the monotypic habitat can be complex. Aquatic habitats, such as exotic \"Hydrilla\" beds, support a similarly rich fauna of macroinvertebrates to a more varied habitat, but the creatures present may differ between the two, affecting small fish and other animals higher up the food chain.\n\n\n\n", "id": "1596317", "title": "Habitat"}
{"url": "https://en.wikipedia.org/wiki?curid=51525633", "text": "Size-asymmetric competition\n\nSize-asymmetric competition refers to situations in which larger individuals exploit disproportionally greater amounts of resources when competing with smaller individuals. This type of competition is common among plants but also exists among animals. Size-asymmetric competition usually results from large individuals monopolizing the resource by \"pre-emption\". i.e. exploiting the resource before smaller individuals are able to obtain it. Size-asymmetric competition has major effects on population structure and diversity within ecological communities.\n\nResource competition can vary from complete symmetric (all individuals receive the same amount of resources, irrespective of their size, known also as scramble competition) to perfectly size symmetric (all individuals exploit the same amount of resource per unit biomass) to absolutely size asymmetric (the largest individuals exploit all the available resource). The degree of size asymmetry can be described by the parameter θ in the following equation focusing on the partition of the resource r among n individuals of sizes Bj.\n\nri refers to the amount of resource consumed by individual i in the neighbourhood of j. When θ =1, competition is perfectly size symmetric, e.g. if a large individual is twice the size of its smaller competitor, the large individual will acquire twice the amount of that resource (i.e. both individuals will exploit the same amount of resource per biomass unit). When θ >1 competition is size-asymmetric, e.g. if large individual is twice the size of its smaller competitor and θ =2, the large individual will acquire four times the amount of that resource (i.e. the large individual will exploit twice the amount of resource per biomass unit). As θ increases, competition becomes more size-asymmetric and larger plants get larger amounts of resource per unit biomass compared with smaller plants.\n\nCompetition among plants for light is size-asymmetric because of the directionality of its supply. Higher leaves shade lower leaves but not vice versa. Competition for nutrients appears to be relatively size-symmetric, although it has been hypothesized that a patchy distribution of nutrients in the soil may lead to size-asymmetry in competition among roots. Nothing is known about the size-asymmetry of competition for water.\n\nVarious ecological processes and patterns have been shown to be affected by the degree of size-asymmetry e.g. succession, biomass distribution, grazing response, population growth, ecosystem functioning, coexistence and species richness. A large body of evidence shows that species loss following nutrient enrichment (eutrophication) is related to light competition (5, 15, 16). However, there is still a debate whether this phenomenon is related to the size-asymmetry of light competition or to other factors.\n\nContrasting assumptions about size-asymmetry characterise the two leading and competing theories in plant ecology, the R* theory and the CSR theory. The R* theory assumes that competition is size-symmetric and therefore predicts that competitive ability in nature results from the ability to withstand low level of resources (known as the R* rule). In contrast the CSR theory assumes that competition is size-asymmetric and therefore predicts that competitive ability in nature results from the ability to grow fast and attain a large size.\n\nSize-asymmetric competition affects also several evolutionary processes in relation to trait selection. Evolution of plant height is highly affected by asymmetric light competition. Theory predicts that only under asymmetric light competition, plants will grow upward and invest in wood production at the expense of investment in leaves, or in reproductive organs (flowers and fruits). Consistent with this, there is evidence that plant height increases as water availability increases, presumably due to increase in the relative importance of size-asymmetric competition for light. Similarly, investment in the size of seeds at the expense of their number may be more effective undersize-asymmetric resource competition, since larger seeds tend to produce larger seedlings that are better competitors.\nSize-asymmetric competition can be exploited in managing plant communities, such as the suppression of weed in crop fields. Weeds are a greater problem for farmer in dry than in moist environments, in large part because crops can suppress weeds much more effectively undersize-asymmetric competition for light than under more size-symmetric competition below ground.\n\n", "id": "51525633", "title": "Size-asymmetric competition"}
{"url": "https://en.wikipedia.org/wiki?curid=32148878", "text": "Social metabolism\n\nSocial metabolism or socioeconomic metabolism is the set of flows of materials and energy that occur between Nature and society, between different societies, and within societies. These human-controlled material and energy flows are a basic feature of all societies but their magnitude and diversity largely depend on specific cultures, or sociometabolic regimes.\nSocial or socioeconomic metabolism is also described as \"the self-reproduction and evolution of the biophysical structures of human society. It comprises those biophysical transformation processes, distribution processes, and flows, which are controlled by humans for their purposes. The biophysical structures of society (‘in use stocks’) and socioeconomic metabolism together form the biophysical basis of society.\"\nSocial metabolic processes begin with the human \"appropriation\" of materials and energy from nature. These can be \"transformed\" and \"circulated\" to be \"consumed\" and \"excreted\" finally back to Nature itself. Each of these processes has a different environmental impact depending on how it is performed, the amount of materials and energy involved in the process, the area where it occurs, the time available or the Nature's regenerative capacity.\n\nSocial metabolism represents an extension of the metabolism concept from human bodies to the biophysical basis of society. Humans build and operate mines and farms, oil refineries and power stations, factories and infrastructure to supply the energy and material flows needed for the physical reproduction of a specific culture. In-use stocks, which comprise buildings, vehicles, appliances, infrastructure, etc., are built up and maintained by the different industrial processes that are part of social metabolism. These stocks then provide service to people in form of shelter, transportation, or communication.\n\nSociety and its metabolism together form an autopoietic system, a complex system that reproduces itself. Neither culture nor social metabolism can reproduce themselves in isolation. Humans need food and shelter, which is delivered by social metabolism, and the latter needs humans to operate it.\n\nStudies of social metabolism can be carried out at different levels of system aggregation, see material flow analysis. In material flow accounting, for example, the inputs and outputs of materials and energy of a particular state or region, as well as imports and exports, are analysed. Such studies are facilitated by the ease of access to information about commercial transactions. \n\nSocial or socioeconomic metabolism stipulates that human society and its interaction with Nature form a complex self-reproducing system, and it can therefore be seen as paradigm for studying the biophysical basis of human societies under the aspect of self-reproduction. \"A common paradigm can facilitate model combination and integration, which can lead to more robust and comprehensive interdisciplinary assessments of sustainable development strategies. [...] The use of social or socioeconomic metabolism as paradigm can help to justify alternative economic concepts.\" \n", "id": "32148878", "title": "Social metabolism"}
