[{"url":"https://en.wikipedia.org/wiki?curid=12589161","text":"Neural cryptography\n\nNeural cryptography is a branch of cryptography dedicated to analyzing the application of stochastic algorithms, especially artificial neural network algorithms, for use in encryption and cryptanalysis.\n\nNeural Networks are well known for their ability to selectively explore the solution space of a given problem. This feature finds a natural niche of application in the field of cryptanalysis. At the same time, Neural Networks offer a new approach to attack ciphering algorithms based on the principle that any function could be reproduced by a neural network, which is a powerful proven computational tool that can be used to find the inverse-function of any cryptographic algorithm.\n\nThe ideas of mutual learning, self learning, and stochastic behavior of neural networks and similar algorithms can be used for different aspects of cryptography, like public-key cryptography, solving the key distribution problem using neural network mutual synchronization, hashing or generation of pseudo-random numbers.\n\nAnother idea is the ability of a neural network to separate space in non-linear pieces using \"bias\". It gives different probabilities of activating the neural network or not. This is very useful in the case of Cryptanalysis.\n\nTwo names are used to design the same domain of research: Neuro-Cryptography and Neural Cryptography.\n\nThe first work that it is known on this topic can be traced back to 1995 in an IT Master Thesis.\n\nThere are currently no practical applications due to the recent development of the field, but it could be used specifically where the keys are continually generated and the system (both pairs and the insecure media) is in a continuously evolving mode.\nIn 1995, Sebastien Dourlens applied neural networks cryptanalyze DES by allowing the networks to learn how to invert the S-tables of the DES. The bias in DES studied through Differential Cryptanalysis by Adi Shamir is highlighted. The experiment shows about 50% of the key bits can be found, allowing the complete key to be found in a short time. Hardware application with multi micro-controllers have been proposed due to the easy implementation of multilayer neural networks in hardware.\nOne example of a public-key protocol is given by Khalil Shihab. He describes the decryption scheme and the public key creation that are based on a backpropagation neural network. The encryption scheme and the private key creation process are based on Boolean algebra. This technique has the advantage of small time and memory complexities. A disadvantage is the property of backpropagation algorithms: because of huge training sets, the learning phase of a neural network is very long. Therefore, the use of this protocol is only theoretical so far.\n\nThe most used protocol for key exchange between two parties A and B in the practice is Diffie-Hellman protocol. Neural key exchange, which is based on the synchronization of two tree parity machines, should be a secure replacement for this method.\nSynchronizing these two machines is similar to synchronizing two chaotic oscillators in chaos communications.\n\nThe tree parity machine is a special type of multi-layer feed-forward neural network.\n\nIt consists of one output neuron, K hidden neurons and K*N input neurons. Inputs to the network take 3 values: \nThe weights between input and hidden neurons take the values: \nOutput value of each hidden neuron is calculated as a sum of all multiplications of input neurons and these weights: \nSignum is a simple function, which returns -1,0 or 1: <br>\n\nIf the scalar product is 0, the output of the hidden neuron is mapped to -1 in order to ensure a binary output value. The output of neural network is then computed as the multiplication of all values produced by hidden elements: <br>\nOutput of the tree parity machine is binary.\n\nEach party (A and B) uses its own tree parity machine. Synchronization of the tree parity machines is achieved in these steps\n\nAfter the full synchronization is achieved (the weights w of both tree parity machines are same), A and B can use their weights as keys.<br>\nThis method is known as a bidirectional learning.<br> \nOne of the following learning rules can be used for the synchronization:\n\nWhere:\nAnd:\n\nIn every attack it is considered, that the attacker E can eavesdrop messages between the parties A and B, but does not have an opportunity to change them.\n\nTo provide a brute force attack, an attacker has to test all possible keys (all possible values of weights wij). By K hidden neurons, K*N input neurons and boundary of weights L, this gives (2L+1) possibilities. For example, the configuration K = 3, L = 3 and N = 100 gives us 3*10 key possibilities, making the attack impossible with today’s computer power.\n\nOne of the basic attacks can be provided by an attacker, who owns the same tree parity machine as the parties A and B. He wants to synchronize his tree parity machine with these two parties. In each step there are three situations possible:\nIt has been proven, that the synchronization of two parties is faster than learning of an attacker. It can be improved by increasing of the synaptic depth L of the neural network. That gives this protocol enough security and an attacker can find out the key only with small probability.\n\nFor conventional cryptographic systems, we can improve the security of the protocol by increasing of the key length. In the case of neural cryptography, we improve it by increasing of the synaptic depth L of the neural networks. Changing this parameter increases the cost of a successful attack exponentially, while the effort for the users grows polynomially. Therefore, breaking the security of neural key exchange belongs to the complexity class NP.\n\nAlexander Klimov, Anton Mityaguine, and Adi Shamir say that the original neural synchronization scheme can be broken by at least three different attacks—geometric, probabilistic analysis, and using genetic algorithms. Even though this particular implementation is insecure, the ideas behind chaotic synchronization could potentially lead to a secure implementation.\n\nThe permutation parity machine is a binary variant of the tree parity machine.\n\nIt consists of one input layer, one hidden layer and one output layer. The number of neurons in the output layer depends on the number of hidden units K. Each hidden neuron has N binary input neurons: \nThe weights between input and hidden neurons are also binary: \n\nOutput value of each hidden neuron is calculated as a sum of all exclusive disjunctions (exclusive or) of input neurons and these weights:\n\n(⊕ means XOR).\n\nThe function formula_18 is a threshold function, which returns 0 or 1: <br>\n\nThe output of neural network with two or more hidden neurons can be computed as the exclusive or of the values produced by hidden elements: <br>\nOther configurations of the output layer for K>2 are also possible.\n\nThis machine has proven to be robust enough against some attacks so it could be used as a cryptographic mean, but it has been shown to be vulnerable to a probabilistic attack.\n\nA quantum computer is a device that uses quantum mechanisms for computation. In this device the data are stored as qubits (quantum binary digits). That gives a quantum computer in comparison with a conventional computer the opportunity to solve complicated problems in a short time, e.g. discrete logarithm problem or factorization. Algorithms that are not based on any of these number theory problems are being searched because of this property.\n\nNeural key exchange protocol is not based on any number theory.\nIt is based on the difference between unidirectional and bidirectional synchronization of neural networks.\nTherefore, something like the neural key exchange protocol could give rise to potentially faster key exchange schemes.\n\n\n","id":"12589161","title":"Neural cryptography"}]
