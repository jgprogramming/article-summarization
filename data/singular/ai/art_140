[{"url":"https://en.wikipedia.org/wiki?curid=15702071","text":"Evolutionary acquisition of neural topologies\n\nEvolutionary acquisition of neural topologies (EANT/EANT2) is an evolutionary reinforcement learning method that evolves both the topology and weights of artificial neural networks. It is closely related to the works of Angeline et al. and Stanley and Miikkulainen. Like the work of Angeline et al., the method uses a type of parametric mutation that comes from evolution strategies and evolutionary programming (now using the most advanced form of the evolution strategies CMA-ES in EANT2), in which adaptive step sizes are used for optimizing the weights of the neural networks. Similar to the work of Stanley (NEAT), the method starts with minimal structures which gain complexity along the evolution path.\n\nDespite sharing these two properties, the method has the following important features which distinguish it from previous works in neuroevolution.\n\nIt introduces a genetic encoding called common genetic encoding (CGE) that handles both direct and indirect encoding of neural networks within the same theoretical framework. The encoding has important properties that makes it suitable for evolving neural networks: \n\nThese properties have been formally proven in.\n\nFor evolving the structure and weights of neural networks, an evolutionary process is used, where the \"exploration\" of structures is executed at a larger timescale (structural exploration), and the \"exploitation\" of existing structures is done at a smaller timescale (structural exploitation). In the structural exploration phase, new neural structures are developed by gradually adding new structures to an initially minimal network that is used as a starting point. In the structural exploitation phase, the weights of the currently available structures are optimized using an evolution strategy.\n\nEANT has been tested on some benchmark problems such as the double-pole balancing problem, and the RoboCup keepaway benchmark. In all the tests, EANT was found to perform very well. Moreover, a newer version of EANT, called EANT2, was tested on a visual servoing task and found to outperform NEAT and the traditional iterative Gaussâ€“Newton method. Further experiments include results on a classification problem \n\n","id":"15702071","title":"Evolutionary acquisition of neural topologies"}]
