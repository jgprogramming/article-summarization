[{"url":"https://en.wikipedia.org/wiki?curid=1166059","text":"Boltzmann machine\n\nA Boltzmann machine (also called stochastic Hopfield network with hidden units) is a type of stochastic recurrent neural network (and Markov Random Field). \n\nBoltzmann machines can be seen as the stochastic, generative counterpart of Hopfield nets. They were one of the first neural networks capable of learning internal representations, and are able to represent and (given sufficient time) solve difficult combinatoric problems. \n\nThey are theoretically intriguing because of the locality and Hebbian nature of their training algorithm, and because of their parallelism and the resemblance of their dynamics to simple physical processes. Boltzmann machines with unconstrained connectivity have not proven useful for practical problems in machine learning or inference, but if the connectivity is properly constrained, the learning can be made efficient enough to be useful for practical problems.\n\nThey are named after the Boltzmann distribution in statistical mechanics, which is used in their sampling function. They were invented in 1985 by Geoffrey Hinton, then a Professor at Carnegie Mellon University, and Terry Sejnowski, then a Professor at Johns Hopkins University.\n\nA Boltzmann machine, like a Hopfield network, is a network of units with an \"energy\" defined for the overall network. Its units produce results. Unlike Hopfield nets, Boltzmann machine units are stochastic. The global energy, formula_1, in a Boltzmann machine is identical in form to that of a Hopfield network:\n\nWhere:\n\nOften the weights are represented as a symmetric matrix formula_12, with zeros along the diagonal.\n\nThe difference in the global energy that results from a single unit formula_5 equaling 0 (off) versus 1 (on), written formula_14, assuming a symmetric matrix of weights, is given by:\n\nSubstituting the energy of each state with its relative probability according to the Boltzmann Factor (the property of a Boltzmann distribution that the energy of a state is proportional to the negative log probability of that state) gives:\n\nwhere formula_17 is Boltzmann's constant and is absorbed into the artificial notion of temperature formula_18. We then rearrange terms and consider that the probabilities of the unit being on and off must sum to one:\n\nSolving for formula_25, the probability that the formula_5-th unit is on gives:\n\nwhere the scalar formula_18 is referred to as the temperature of the system. This relation is the source of the logistic function found in probability expressions in variants of the Boltzmann machine.\n\nThe network runs by repeatedly choosing a unit and resetting its state. After running for long enough at a certain temperature, the probability of a global state of the network depends only upon that global state's energy, according to a Boltzmann distribution, and not on the initial state from which the process was started. This means that log-probabilities of global states become linear in their energies. This relationship is true when the machine is \"at thermal equilibrium\", meaning that the probability distribution of global states has converged. Running the network beginning from a high temperature, its temperature gradually decreases until reaching a thermal equilibrium at a lower temperature. It then may converge to a distribution where the energy level fluctuates around the global minimum. This process is called simulated annealing.\n\nTo train the network so that the chance it will converge to a global state is according to an external distribution over these states, the weights must be set so that the global states with the highest probabilities get the lowest energies. This is done by training.\n\nThe units in the Boltzmann Machine are divided into 'visible' units, V, and 'hidden' units, H. The visible units are those that receive information from the 'environment', i.e. the training set is a set of binary vectors over the set V. The distribution over the training set is denoted formula_29. \nAs is discussed above, the distribution over global states converges as the Boltzmann machine reaches thermal equilibrium. We denote this distribution, after we marginalize it over the hidden units, as formula_30.\n\nOur goal is to approximate the \"real\" distribution formula_29 using the formula_30 produced (eventually) by the machine. To measure how similar the two distributions are, the Kullbackâ€“Leibler divergence, formula_33 is\n\nwhere the sum is over all the possible states of formula_35. formula_33 is a function of the weights, since they determine the energy of a state, and the energy determines formula_37, as promised by the Boltzmann distribution. Hence, we can use a gradient descent algorithm over formula_33, so a given weight, formula_3 is changed by subtracting the partial derivative of formula_33 with respect to the weight.\n\nThere are two alternating phases to Boltzmann machine training. One is the \"positive\" phase where the visible units' states are clamped to a particular binary state vector sampled from the training set (according to formula_41). The other is the \"negative\" phase where the network is allowed to run freely, i.e. no units have their state determined by external data. Surprisingly enough, the gradient with respect to a given weight, formula_3, is given by the simple proven equation:\n\nwhere:\n\nThis result follows from the fact that at thermal equilibrium the probability formula_47 of any global state formula_48 when the network is free-running is given by the Boltzmann distribution (hence the name \"Boltzmann machine\").\n\nRemarkably, this learning rule is fairly biologically plausible because the only information needed to change the weights is provided by \"local\" information. That is, the connection (or synapse biologically speaking) does not need information about anything other than the two neurons it connects. This is far more biologically realistic than the information needed by a connection in many other neural network training algorithms, such as backpropagation.\n\nThe training of a Boltzmann machine does not use the EM algorithm, which is heavily used in machine learning. \nBy minimizing the KL-divergence, it is equivalent to maximizing the log-likelihood of the data. Therefore, the training procedure performs gradient ascent on the log-likelihood of the observed data. This is in contrast to the EM algorithm, where the posterior distribution of the hidden nodes must be calculated before the maximization of the expected value of the complete data likelihood during the M-step.\n\nTraining the biases is similar, but uses only single node activity:\n\nThe Boltzmann machine would theoretically be a rather general computational medium. For instance, if trained on photographs, the machine would theoretically model the distribution of photographs, and could use that model to, for example, complete a partial photograph.\n\nUnfortunately, there is a serious practical problem with the Boltzmann machine, namely that it seems to stop learning correctly when the machine is scaled up to anything larger than a trivial machine. This is due to a number of effects, the most important of which are:\n\n\nAlthough learning is impractical in general Boltzmann machines, it can be made quite efficient in \nan architecture called the \"restricted Boltzmann machine\" or \"RBM\" which does not allow intralayer connections between hidden units. After training one RBM, the activities of its hidden units can be treated as data for training a higher-level RBM. This method of stacking RBMs makes it possible to train many layers of hidden units efficiently and is one of the most common deep learning strategies. As each new layer is added the overall generative model gets better.\n\nThere is an extension to the restricted Boltzmann machine that affords using real valued data rather than binary data. Along with higher order Boltzmann machines, it is outlined here .\n\nOne example of a practical application of Restricted Boltzmann machines is the performance improvement of speech recognition software.\n\nA deep Boltzmann machine (DBM) is a type of binary pairwise Markov random field (undirected probabilistic graphical model) with multiple layers of hidden random variables. It is a network of symmetrically coupled stochastic binary units. It comprises a set of visible units formula_50 and layers of hidden units formula_51. No connection links units of the same layer (like RBM). For the , the probability assigned to vector is\nwhere formula_53 are the set of hidden units, and formula_54 are the model parameters, representing visible-hidden and hidden-hidden interactions. Only the top two layers form a restricted Boltzmann machine (which is an undirected graphical model), while lower layers form a directed generative model.\n\nLike DBNs, DBMs can learn complex and abstract internal representations of the input in tasks such as object or speech recognition, using limited, labeled data to fine-tune the representations built using a large supply of unlabeled sensory input data. However, unlike and deep convolutional neural networks, they adopt the inference and training procedure in both directions, bottom-up and top-down pass, which allow the to better unveil the representations of the input structures.\n\nHowever, the slow speed of DBMs limits their performance and functionality. Because exact maximum likelihood learning is intractable for DBMs, only approximate maximum likelihood learning is possible. Another option is to use mean-field inference to estimate data-dependent expectations and approximate the expected sufficient statistics by using \"Markov chain Monte Carlo\" \"(MCMC)\". This approximate inference, which must be done for each test input, is about 25 to 50 times slower than a single bottom-up pass in DBMs. This makes joint optimization impractical for large data sets, and restricts the use of DBMs for tasks such as feature representation.\n\nThe Boltzmann machine is a Monte Carlo version of the Hopfield network.\n\nThe idea of using stochastic weights in Ising models considered by:\n\nHowever, in cognitive sciences, it is often thought to have been first described by:\n\nHowever, it should be noted that these articles appeared after the seminal publication by John Hopfield, where the connection to physics and statistical mechanics was made in the first place, mentioning spin glasses:\n\n\nThe idea of applying the Ising model with annealed Gibbs sampling is also present in Douglas Hofstadter's Copycat project:\n\n\nSimilar ideas (with a change of sign in the energy function) are also found in Paul Smolensky's \"Harmony Theory\".\n\nThe explicit analogy drawn with statistical mechanics in the Boltzmann Machine formulation led to the use of terminology borrowed from physics (e.g., \"energy\" rather than \"harmony\"), which has become standard in the field. The widespread adoption of this terminology may have been encouraged by the fact that its use led to the importation of a variety of concepts and methods from statistical mechanics.\nHowever, there is no reason to think that the various proposals to use simulated annealing for inference described above were not independent.\n\nIsing models are now considered to be a special case of Markov random fields, which find widespread application in various fields, including linguistics, robotics, computer vision, and artificial intelligence.\n\n\n\n","id":"1166059","title":"Boltzmann machine"}]
