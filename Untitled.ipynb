{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4549\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "data_dir = '/home/jagr/Documents/studia/article-summarization/data/cat_data'\n",
    "\n",
    "categories = os.listdir(data_dir)\n",
    "data = {}\n",
    "\n",
    "for category in categories:\n",
    "    data[category] = []\n",
    "\n",
    "\n",
    "    \n",
    "for category in categories:\n",
    "    for file in os.listdir(os.path.join(data_dir, category)):\n",
    "        doc_path = os.path.join(data_dir, category, file)\n",
    "        d = open(doc_path)\n",
    "        j = json.loads(d.read())\n",
    "        for document in j:\n",
    "            doc = {\"title\":document[\"title\"], \"text\":document[\"text\"]}\n",
    "            data[category].append(doc)\n",
    "\n",
    "corpus_size = 0\n",
    "for category in categories:\n",
    "    corpus_size += len(data[category])\n",
    "            \n",
    "print(corpus_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import nltk\n",
    "\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "\n",
    "stemmer = LancasterStemmer()\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stems = stem_tokens(tokens, stemmer)\n",
    "    stems = [word.lower() for word in stems if word.isalpha()]\n",
    "    return stems\n",
    "\n",
    "bayes = {}\n",
    "for category in categories:\n",
    "    bayes[category] = {}\n",
    "    bayes[category][\"prob\"] = len(data[category])/corpus_size\n",
    "    bow = CountVectorizer(input='content', tokenizer=tokenize, stop_words='english')\n",
    "    korpus = \"\"\n",
    "    for entry in data[category]:\n",
    "        korpus += entry[\"text\"]\n",
    "        korpus += \" \"\n",
    "    bow = bow.fit([korpus])\n",
    "    \n",
    "    bayes[category][\"count\"] = bow.transform([korpus]).toarray()[0]\n",
    "    bayes[category][\"features\"] = bow.get_feature_names()\n",
    "    bayes[category][\"sum\"] = sum(bayes[category][\"count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "       \n",
    "import sys\n",
    "def calculate_prob(text, category):\n",
    "    prob = math.log(bayes[category][\"prob\"])\n",
    "    \n",
    "    features = bayes[category][\"features\"]\n",
    "    count = bayes[category][\"count\"]\n",
    "    suma = bayes[category][\"sum\"]\n",
    "    \n",
    "    for word in tokenize(text):\n",
    "        try:\n",
    "            indx = features.index(word)\n",
    "            c = count[indx]\n",
    "        except:\n",
    "            c = 1\n",
    "        prob += math.log(c/suma)\n",
    "    return prob\n",
    "\n",
    "def predict_category(text):\n",
    "    value = -sys.maxsize -1\n",
    "    cat = None\n",
    "    \n",
    "    for category in categories:\n",
    "        prob = calculate_prob(text, category)\n",
    "        if  prob > value:\n",
    "            value = prob\n",
    "            cat = category\n",
    "    return cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = \"The Loebner Prize is an annual competition in artificial intelligence that awards prizes to the computer programs considered by the judges to be the most human-like. The format of the competition is that of a standard Turing test. In each round, a human judge simultaneously holds textual conversations with a computer program and a human being via computer. Based upon the responses, the judge must decide which is which.\\n\\nThe contest was launched in 1990 by Hugh Loebner in conjunction with the Cambridge Center for Behavioral Studies, Massachusetts, United States. It has since been associated with Flinders University, Dartmouth College, the Science Museum in London, University of Reading and Ulster University, Magee Campus, Derry, UK City of Culture. In 2004 and 2005, it was held in Loebner's apartment in New York City. Within the field of artificial intelligence, the Loebner Prize is somewhat controversial; the most prominent critic, Marvin Minsky, called it a publicity stunt that does not help the field along.\\n\\nOriginally, $2,000 was awarded for the most human-seeming program in the competition. The prize was $3,000 in 2005 and $2,250 in 2006. In 2008, $3,000 was awarded.\\n\\nIn addition, there are two one-time-only prizes that have never been awarded. $25,000 is offered for the first program that judges cannot distinguish from a real human and which can convince judges that the human is the computer program. $100,000 is the reward for the first program that judges cannot distinguish from a real human in a Turing test that includes deciphering and understanding text, visual, and auditory input. Once this is achieved, the annual competition will end.\\n\\nThe rules have varied over the years and early competitions featured restricted conversation Turing tests but since 1995 the discussion has been unrestricted.\\n\\nFor the three entries in 2007, Robert Medeksza, Noah Duncan and Rollo Carpenter, some basic \\\"screening questions\\\" were used by the sponsor to evaluate the state of the technology. These included simple questions about the time, what round of the contest it is, etc.; general knowledge (\\\"What is a hammer for?\\\"); comparisons (\\\"Which is faster, a train or a plane?\\\"); and questions demonstrating memory for preceding parts of the same conversation. \\\"All nouns, adjectives and verbs will come from a dictionary suitable for children or adolescents under the age of 12.\\\" Entries did not need to respond \\\"intelligently\\\" to the questions to be accepted.\\n\\nFor the first time in 2008 the sponsor allowed introduction of a preliminary phase to the contest opening up the competition to previously disallowed web-based entries judged by a variety of invited interrogators. The available rules do not state how interrogators are selected or instructed. Interrogators (who judge the systems) have limited time: 5 minutes per entity in the 2003 competition, 20+ per pair in 2004â€“2007 competitions, 5 minutes to conduct \\\"simultaneous\\\" conversations with a human and the program in 2008-2009, increased to 25 minutes of simultaneous conversation since 2010.\\n\\nThe prize has long been scorned by experts in the field, for a variety of reasons.\\n\\nIt is regarded by many as a publicity stunt. Marvin Minsky scathingly offered a \\\"prize\\\" to anyone who could stop the competition. Loebner responded by jokingly observing that Minsky's offering a prize to stop the competition effectively made him a co-sponsor.\\n\\nThe rules of the competition have encouraged poorly qualified judges to make rapid judgements. Interactions between judges and competitors was originally very brief, for example effectively 2.5 mins of questioning, which permitted only a few questions. Questioning was initially restricted to \\\"whimsical conversation\\\", a domain suiting standard chatbot tricks.\\n\\nCompetition entrants do not aim at understanding or intelligence but resort to basic ELIZA style tricks, and successful entrants find deception and pretense is rewarded.\\n\\nReporting of the annual competition often confuses the imitation test with intelligence, a typical example being Brian Christian's introduction to his article \\\"Mind vs. Machine\\\" in The Atlantic, March 2011, stating that \\\"in the race to build computers that \\\"can think like humans\\\", the proving ground is the Turing Test\\\".\\n\\nIn 2006, the contest was organised by Tim Child (CEO of Televirtual) and Huma Shah. On August 30, the four finalists were announced:\\n\\nThe contest was held on 17 September in the VR theatre, Torrington Place campus of University College London. The judges included the University of Reading's cybernetics professor, Kevin Warwick, a professor of artificial intelligence, John Barnden (specialist in metaphor research at the University of Birmingham), a barrister, Victoria Butler-Cole and a journalist, Graham Duncan-Rowe. The latter's experience of the event can be found in an article in \\\"Technology Review\\\". The winner was 'Joan', based on Jabberwacky, both created by Rollo Carpenter.\\n\\nThe 2007 competition was held on October 21 in New York City. The judges were: computer science professor Russ Abbott, philosophy professor Hartry Field, psychology assistant professor Clayton Curtis and English lecturer Scott Hutchins.\\n\\nNo bot passed the Turing test, but the judges ranked the three contestants as follows:\\n\\nThe winner received $2,250 and the annual medal. The runners-up received $250 each.\\n\\nThe 2008 competition was organised by professor Kevin Warwick, coordinated by Huma Shah and held on October 12 at the University of Reading, UK. After testing by over one hundred judges during the preliminary phase, in June and July 2008, six finalists were selected from thirteen original entrants - artificial conversational entity (ACE). Five of those invited competed in the finals:\\n\\nIn the finals, each of the judges was given five minutes to conduct simultaneous, split-screen conversations with two hidden entities. Elbot of Artificial Solutions won the 2008 Loebner Prize bronze award, for \\\"most human-like\\\" artificial conversational entity, through fooling three of the twelve judges who interrogated it (in the human-parallel comparisons) into believing it was human. This is coming very close to the 30% traditionally required to consider that a program has actually passed the Turing test. Eugene Goostman and Ultra Hal both deceived one judge each that it was the human.\\n\\nWill Pavia, a journalist for The Times, has written about his experience; a Loebner finals' judge, he was deceived by Elbot and Eugene. Kevin Warwick and Huma Shah have reported on the parallel-paired Turing tests.\\n\\nThe 2009 Loebner Prize Competition was held September 6, 2009 at the Brighton Centre, Brighton UK in conjunction with the Interspeech 2009 conference. The prize amount for 2009 was $3,000.\\n\\nEntrants were David Levy, Rollo Carpenter, and Mohan Embar, who finished in that order.\\n\\nThe writer Brian Christian participated in the 2009 Loebner Prize Competition as a human confederate, and described his experiences at the competition in his book \\\"The Most Human Human\\\".\\n\\nThe 2010 Loebner Prize Competition was held on October 23 at California State University, Los Angeles. The 2010 competition was the 20th running of the contest. The winner was Bruce Wilcox with Suzette.\\n\\nThe 2011 Loebner Prize Competition was held on October 19 at the University of Exeter, Devon, United Kingdom. The prize amount for 2011 was $4,000.\\n\\nThe four finalists and their chatterbots were Bruce Wilcox (Rosette), Adeena Mignogna (Zoe), Mohan Embar (Chip Vivant) and Ron Lee (Tutor), who finished in that order.\\n\\nThat year there was an addition of a panel of junior judges, namely Jean-Paul Astal-Stain, William Dunne, Sam Keat and Kirill Jerdev. The results of the junior contest were markedly different from the main contest, with chatterbots Tutor and Zoe tying for first place and Chip Vivant and Rosette coming in third and fourth place, respectively.\\n\\nThe 2012 Loebner Prize Competition was held on the 15th of May in Bletchley Park in Bletchley, Buckinghamshire, England, in honor of the Alan Turing centenary celebrations. The prize amount for 2012 was $5,000. The local arrangements organizer was David Levy, who won the Loebner Prize in 1997 and 2009.\\n\\nThe four finalists and their chatterbots were Mohan Embar (Chip Vivant), Bruce Wilcox (Angela), Daniel Burke (Adam), M. Allan (Linguo), who finished in that order.\\n\\nThat year, a team from the University of Exeter's computer science department (Ed Keedwell, Max Dupenois and Kent McClymont) conducted the first-ever live webcast of the conversations.\\n\\nThe 2013 Loebner Prize Competition was held, for the first time on the Island of Ireland, on September 14 at the Ulster University, Magee College, Derry, Northern Ireland, UK.\\n\\nThe four finalists and their chatbots were Steve Worswick (Mitsuku), Dr. Ron C. Lee (Tutor), Bruce Wilcox (Rose) and Brian Rigsby (Izar), who finished in that order.\\n\\nThe judges were Professor Roger Schank (Socratic Arts), Professor Noel Sharkey (Sheffield University), Professor Minhua (Eunice) Ma (Huddersfield University, then University of Glasgow)\\nand Professor Mike McTear (Ulster University).\\n\\nFor the 2013 Junior Loebner Prize Competition the chatbots Mitsuku and Tutor tied for first place with Rose and Izar in 3rd and 4th place respectively.\\n\\nThe 2014 Loebner Prize Competition was held at Bletchley Park, England, on Saturday 15 November 2014. The event was filmed live by Sky News. The guest judge was television presenter and broadcaster James May.\\n\\nAfter 2 hours of judging, 'Rose' by Bruce Wilcox was declared the winner. Bruce will receive a cheque for $4000 and a bronze medal. The ranks were as follows:\\n\\nRose - Rank 1 ($4000 & Bronze Medal); \\nIzar - Rank 2.25 ($1500); \\nUberbot - Rank 3.25 ($1000); and \\nMitsuku - Rank 3.5 ($500).\\n\\nThe Judges were Dr Ian Hocking, Writer & Senior Lecturer in Psychology, Christ Church College, Canterbury; \\nDr Ghita Kouadri-Mostefaoui, Lecturer in Computer Science and Technology, University of Bedfordshire; \\nMr James May, Television Presenter and Broadcaster; and \\nDr Paul Sant, Dean of UCMK, University of Bedfordshire.\\n\\nThe 2015 Loebner Prize Competition was again won by 'Rose' by Bruce Wilcox.\\n\\nThe judges were Jacob Aaron, Physical sciences reporter for New Scientist; Rory Cellan-Jones, Technology correspondent for the BBC; Brett Marty, Film Director and Photographer; Ariadne Tampion, Writer.\\n\\nThe 2016 Loebner Prize was held at Bletchley Park on 17 September 2016. After 2 hours of judging the final results were announced. \\nThe ranks were as follows:\\n\\n\\nOfficial list of winners.\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ai'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_category(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Loebner Prize is an annual competition in artificial intelligence that awards prizes to the computer programs considered by the judges to be the most human-like.',\n",
       " 'The format of the competition is that of a standard Turing test.',\n",
       " 'In each round, a human judge simultaneously holds textual conversations with a computer program and a human being via computer.',\n",
       " 'Based upon the responses, the judge must decide which is which.',\n",
       " 'The contest was launched in 1990 by Hugh Loebner in conjunction with the Cambridge Center for Behavioral Studies, Massachusetts, United States.',\n",
       " 'It has since been associated with Flinders University, Dartmouth College, the Science Museum in London, University of Reading and Ulster University, Magee Campus, Derry, UK City of Culture.',\n",
       " \"In 2004 and 2005, it was held in Loebner's apartment in New York City.\",\n",
       " 'Within the field of artificial intelligence, the Loebner Prize is somewhat controversial; the most prominent critic, Marvin Minsky, called it a publicity stunt that does not help the field along.',\n",
       " 'Originally, $2,000 was awarded for the most human-seeming program in the competition.',\n",
       " 'The prize was $3,000 in 2005 and $2,250 in 2006.',\n",
       " 'In 2008, $3,000 was awarded.',\n",
       " 'In addition, there are two one-time-only prizes that have never been awarded.',\n",
       " '$25,000 is offered for the first program that judges cannot distinguish from a real human and which can convince judges that the human is the computer program.',\n",
       " '$100,000 is the reward for the first program that judges cannot distinguish from a real human in a Turing test that includes deciphering and understanding text, visual, and auditory input.',\n",
       " 'Once this is achieved, the annual competition will end.',\n",
       " 'The rules have varied over the years and early competitions featured restricted conversation Turing tests but since 1995 the discussion has been unrestricted.',\n",
       " 'For the three entries in 2007, Robert Medeksza, Noah Duncan and Rollo Carpenter, some basic \"screening questions\" were used by the sponsor to evaluate the state of the technology.',\n",
       " 'These included simple questions about the time, what round of the contest it is, etc.',\n",
       " '; general knowledge (\"What is a hammer for?',\n",
       " '\"); comparisons (\"Which is faster, a train or a plane?',\n",
       " '\"); and questions demonstrating memory for preceding parts of the same conversation.',\n",
       " '\"All nouns, adjectives and verbs will come from a dictionary suitable for children or adolescents under the age of 12.\"',\n",
       " 'Entries did not need to respond \"intelligently\" to the questions to be accepted.',\n",
       " 'For the first time in 2008 the sponsor allowed introduction of a preliminary phase to the contest opening up the competition to previously disallowed web-based entries judged by a variety of invited interrogators.',\n",
       " 'The available rules do not state how interrogators are selected or instructed.',\n",
       " 'Interrogators (who judge the systems) have limited time: 5 minutes per entity in the 2003 competition, 20+ per pair in 2004â€“2007 competitions, 5 minutes to conduct \"simultaneous\" conversations with a human and the program in 2008-2009, increased to 25 minutes of simultaneous conversation since 2010.',\n",
       " 'The prize has long been scorned by experts in the field, for a variety of reasons.',\n",
       " 'It is regarded by many as a publicity stunt.',\n",
       " 'Marvin Minsky scathingly offered a \"prize\" to anyone who could stop the competition.',\n",
       " \"Loebner responded by jokingly observing that Minsky's offering a prize to stop the competition effectively made him a co-sponsor.\",\n",
       " 'The rules of the competition have encouraged poorly qualified judges to make rapid judgements.',\n",
       " 'Interactions between judges and competitors was originally very brief, for example effectively 2.5 mins of questioning, which permitted only a few questions.',\n",
       " 'Questioning was initially restricted to \"whimsical conversation\", a domain suiting standard chatbot tricks.',\n",
       " 'Competition entrants do not aim at understanding or intelligence but resort to basic ELIZA style tricks, and successful entrants find deception and pretense is rewarded.',\n",
       " 'Reporting of the annual competition often confuses the imitation test with intelligence, a typical example being Brian Christian\\'s introduction to his article \"Mind vs. Machine\" in The Atlantic, March 2011, stating that \"in the race to build computers that \"can think like humans\", the proving ground is the Turing Test\".',\n",
       " 'In 2006, the contest was organised by Tim Child (CEO of Televirtual) and Huma Shah.',\n",
       " 'On August 30, the four finalists were announced:\\n\\nThe contest was held on 17 September in the VR theatre, Torrington Place campus of University College London.',\n",
       " \"The judges included the University of Reading's cybernetics professor, Kevin Warwick, a professor of artificial intelligence, John Barnden (specialist in metaphor research at the University of Birmingham), a barrister, Victoria Butler-Cole and a journalist, Graham Duncan-Rowe.\",\n",
       " 'The latter\\'s experience of the event can be found in an article in \"Technology Review\".',\n",
       " \"The winner was 'Joan', based on Jabberwacky, both created by Rollo Carpenter.\",\n",
       " 'The 2007 competition was held on October 21 in New York City.',\n",
       " 'The judges were: computer science professor Russ Abbott, philosophy professor Hartry Field, psychology assistant professor Clayton Curtis and English lecturer Scott Hutchins.',\n",
       " 'No bot passed the Turing test, but the judges ranked the three contestants as follows:\\n\\nThe winner received $2,250 and the annual medal.',\n",
       " 'The runners-up received $250 each.',\n",
       " 'The 2008 competition was organised by professor Kevin Warwick, coordinated by Huma Shah and held on October 12 at the University of Reading, UK.',\n",
       " 'After testing by over one hundred judges during the preliminary phase, in June and July 2008, six finalists were selected from thirteen original entrants - artificial conversational entity (ACE).',\n",
       " 'Five of those invited competed in the finals:\\n\\nIn the finals, each of the judges was given five minutes to conduct simultaneous, split-screen conversations with two hidden entities.',\n",
       " 'Elbot of Artificial Solutions won the 2008 Loebner Prize bronze award, for \"most human-like\" artificial conversational entity, through fooling three of the twelve judges who interrogated it (in the human-parallel comparisons) into believing it was human.',\n",
       " 'This is coming very close to the 30% traditionally required to consider that a program has actually passed the Turing test.',\n",
       " 'Eugene Goostman and Ultra Hal both deceived one judge each that it was the human.',\n",
       " \"Will Pavia, a journalist for The Times, has written about his experience; a Loebner finals' judge, he was deceived by Elbot and Eugene.\",\n",
       " 'Kevin Warwick and Huma Shah have reported on the parallel-paired Turing tests.',\n",
       " 'The 2009 Loebner Prize Competition was held September 6, 2009 at the Brighton Centre, Brighton UK in conjunction with the Interspeech 2009 conference.',\n",
       " 'The prize amount for 2009 was $3,000.',\n",
       " 'Entrants were David Levy, Rollo Carpenter, and Mohan Embar, who finished in that order.',\n",
       " 'The writer Brian Christian participated in the 2009 Loebner Prize Competition as a human confederate, and described his experiences at the competition in his book \"The Most Human Human\".',\n",
       " 'The 2010 Loebner Prize Competition was held on October 23 at California State University, Los Angeles.',\n",
       " 'The 2010 competition was the 20th running of the contest.',\n",
       " 'The winner was Bruce Wilcox with Suzette.',\n",
       " 'The 2011 Loebner Prize Competition was held on October 19 at the University of Exeter, Devon, United Kingdom.',\n",
       " 'The prize amount for 2011 was $4,000.',\n",
       " 'The four finalists and their chatterbots were Bruce Wilcox (Rosette), Adeena Mignogna (Zoe), Mohan Embar (Chip Vivant) and Ron Lee (Tutor), who finished in that order.',\n",
       " 'That year there was an addition of a panel of junior judges, namely Jean-Paul Astal-Stain, William Dunne, Sam Keat and Kirill Jerdev.',\n",
       " 'The results of the junior contest were markedly different from the main contest, with chatterbots Tutor and Zoe tying for first place and Chip Vivant and Rosette coming in third and fourth place, respectively.',\n",
       " 'The 2012 Loebner Prize Competition was held on the 15th of May in Bletchley Park in Bletchley, Buckinghamshire, England, in honor of the Alan Turing centenary celebrations.',\n",
       " 'The prize amount for 2012 was $5,000.',\n",
       " 'The local arrangements organizer was David Levy, who won the Loebner Prize in 1997 and 2009.',\n",
       " 'The four finalists and their chatterbots were Mohan Embar (Chip Vivant), Bruce Wilcox (Angela), Daniel Burke (Adam), M. Allan (Linguo), who finished in that order.',\n",
       " \"That year, a team from the University of Exeter's computer science department (Ed Keedwell, Max Dupenois and Kent McClymont) conducted the first-ever live webcast of the conversations.\",\n",
       " 'The 2013 Loebner Prize Competition was held, for the first time on the Island of Ireland, on September 14 at the Ulster University, Magee College, Derry, Northern Ireland, UK.',\n",
       " 'The four finalists and their chatbots were Steve Worswick (Mitsuku), Dr. Ron C. Lee (Tutor), Bruce Wilcox (Rose) and Brian Rigsby (Izar), who finished in that order.',\n",
       " 'The judges were Professor Roger Schank (Socratic Arts), Professor Noel Sharkey (Sheffield University), Professor Minhua (Eunice) Ma (Huddersfield University, then University of Glasgow)\\nand Professor Mike McTear (Ulster University).',\n",
       " 'For the 2013 Junior Loebner Prize Competition the chatbots Mitsuku and Tutor tied for first place with Rose and Izar in 3rd and 4th place respectively.',\n",
       " 'The 2014 Loebner Prize Competition was held at Bletchley Park, England, on Saturday 15 November 2014.',\n",
       " 'The event was filmed live by Sky News.',\n",
       " 'The guest judge was television presenter and broadcaster James May.',\n",
       " \"After 2 hours of judging, 'Rose' by Bruce Wilcox was declared the winner.\",\n",
       " 'Bruce will receive a cheque for $4000 and a bronze medal.',\n",
       " 'The ranks were as follows:\\n\\nRose - Rank 1 ($4000 & Bronze Medal); \\nIzar - Rank 2.25 ($1500); \\nUberbot - Rank 3.25 ($1000); and \\nMitsuku - Rank 3.5 ($500).',\n",
       " 'The Judges were Dr Ian Hocking, Writer & Senior Lecturer in Psychology, Christ Church College, Canterbury; \\nDr Ghita Kouadri-Mostefaoui, Lecturer in Computer Science and Technology, University of Bedfordshire; \\nMr James May, Television Presenter and Broadcaster; and \\nDr Paul Sant, Dean of UCMK, University of Bedfordshire.',\n",
       " \"The 2015 Loebner Prize Competition was again won by 'Rose' by Bruce Wilcox.\",\n",
       " 'The judges were Jacob Aaron, Physical sciences reporter for New Scientist; Rory Cellan-Jones, Technology correspondent for the BBC; Brett Marty, Film Director and Photographer; Ariadne Tampion, Writer.',\n",
       " 'The 2016 Loebner Prize was held at Bletchley Park on 17 September 2016.',\n",
       " 'After 2 hours of judging the final results were announced.',\n",
       " 'The ranks were as follows:\\n\\n\\nOfficial list of winners.']"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def tokenize_sent(text, title):\n",
    "    tCopy = text\n",
    "    if tCopy.startswith(title):\n",
    "         tCopy = tCopy[len(title):]\n",
    "    return nltk.sent_tokenize(tCopy.lstrip()) \n",
    "\n",
    "tokenize_sent(text, \"Winner-take-all (computing)\")\n",
    "\n",
    "# nltk.sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
