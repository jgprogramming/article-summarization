{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361\n",
      "304\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "data_dir = '/home/jagr/Documents/studia/article-summarization/data/small'\n",
    "\n",
    "categories = os.listdir(data_dir)\n",
    "data = {}\n",
    "\n",
    "for category in categories:\n",
    "    data[category] = []\n",
    "\n",
    "\n",
    "    \n",
    "for category in categories:\n",
    "    for file in os.listdir(os.path.join(data_dir, category)):\n",
    "        doc_path = os.path.join(data_dir, category, file)\n",
    "        d = open(doc_path)\n",
    "        j = json.loads(d.read())\n",
    "        for document in j:\n",
    "            doc = {\"title\":document[\"title\"], \"text\":document[\"text\"]}\n",
    "            data[category].append(doc)\n",
    "\n",
    "print(len(data[\"ai\"]))\n",
    "print(len(data[\"biology\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1961', '2014', 'ability', 'about', 'absent', 'abstract', 'abstraction', 'accessible', 'accuracy', 'acknowledged', 'acknowledgement', 'acquire', 'action', 'actions', 'age', 'ai', 'all', 'already', 'also', 'ambiguities', 'ambiguity', 'among', 'amount', 'an', 'analogical', 'analogous', 'analyzed', 'analyzing', 'and', 'anecdotal', 'animals', 'another', 'any', 'appear', 'applied', 'applies', 'approaches', 'appropriate', 'are', 'area', 'areas', 'arise', 'art', 'artificial', 'as', 'aspects', 'assigning', 'assume', 'assumed', 'assumptions', 'at', 'attaining', 'attempt', 'attempting', 'automated', 'autonomous', 'avoid', 'aware', 'background', 'bar', 'based', 'basic', 'basin', 'basis', 'bathroom', 'bathtub', 'be', 'because', 'becomes', 'been', 'beethoven', 'before', 'behavior', 'behavioral', 'being', 'below', 'benchmark', 'between', 'biology', 'bird', 'body', 'born', 'branches', 'broad', 'broken', 'build', 'but', 'by', 'can', 'canfly', 'cannot', 'capable', 'carry', 'cases', 'categories', 'certain', 'challenge', 'challenging', 'change', 'characteristics', 'characters', 'close', 'coaster', 'cocktail', 'collect', 'collection', 'collective', 'combination', 'coming', 'commercial', 'common', 'commonsense', 'communication', 'compared', 'competency', 'complete', 'complex', 'complexity', 'comprehensive', 'computer', 'computers', 'concepts', 'concerned', 'conclusion', 'conclusions', 'concrete', 'considered', 'consist', 'constraints', 'construct', 'contain', 'contains', 'contemporary', 'context', 'corpora', 'correctly', 'could', 'cover', 'create', 'crowd', 'crowdsourcing', 'culture', 'current', 'data', 'database', 'day', 'de', 'death', 'decreases', 'deduce', 'deeper', 'delimiting', 'demonstrated', 'dependent', 'depending', 'determine', 'developed', 'device', 'died', 'different', 'difficult', 'direction', 'discern', 'discussed', 'displays', 'divided', 'do', 'documents', 'does', 'domains', 'don', 'done', 'down', 'drawing', 'due', 'durations', 'each', 'earlier', 'easily', 'easy', 'ecology', 'ecosystem', 'electrician', 'elements', 'empirical', 'encounter', 'engineering', 'english', 'ensure', 'environment', 'essence', 'established', 'etc', 'even', 'events', 'every', 'everybody', 'evident', 'example', 'examples', 'exhibits', 'existing', 'expected', 'experiencing', 'expert', 'experts', 'expressions', 'extracting', 'extremely', 'fails', 'far', 'few', 'field', 'fifth', 'figure', 'first', 'firstly', 'five', 'focus', 'folk', 'follows', 'for', 'form', 'forms', 'formulated', 'formulating', 'found', 'fourth', 'frequent', 'frequently', 'from', 'function', 'functioning', 'further', 'gathering', 'general', 'german', 'given', 'glass', 'go', 'goes', 'going', 'grounded', 'group', 'had', 'has', 'have', 'he', 'highly', 'hillel', 'him', 'his', 'how', 'however', 'human', 'humans', 'identify', 'if', 'image', 'images', 'importance', 'impossible', 'in', 'include', 'including', 'individual', 'individuals', 'inequalities', 'inference', 'inferences', 'informal', 'information', 'infrequent', 'inheritance', 'innate', 'input', 'instance', 'instead', 'integrate', 'intelligence', 'intelligent', 'intended', 'intentions', 'interactions', 'interfere', 'interlocutor', 'interpersonal', 'interpretation', 'interrelated', 'intervals', 'into', 'intuition', 'involve', 'involved', 'involves', 'is', 'isolated', 'issue', 'issues', 'it', 'items', 'johan', 'judgments', 'kind', 'kleer', 'know', 'knowledge', 'known', 'knows', 'laboring', 'lambs', 'language', 'large', 'learning', 'level', 'life', 'limited', 'linear', 'linking', 'liquid', 'listed', 'logic', 'logical', 'looking', 'lot', 'lotions', 'machine', 'made', 'major', 'make', 'manage', 'manipulate', 'manipulating', 'many', 'mapping', 'marked', 'matching', 'mathematical', 'mathematically', 'meanings', 'means', 'memorized', 'methods', 'mind', 'mining', 'mistakes', 'modern', 'moments', 'monotonic', 'more', 'most', 'movie', 'movies', 'moving', 'mozart', 'naive', 'natural', 'need', 'networks', 'non', 'not', 'number', 'object', 'objects', 'obstacles', 'obtain', 'obvious', 'of', 'offer', 'often', 'on', 'one', 'ones', 'online', 'only', 'or', 'order', 'ordinary', 'other', 'others', 'out', 'outcomes', 'outlining', 'over', 'paper', 'particular', 'partly', 'party', 'people', 'perform', 'photograph', 'phrases', 'physical', 'physics', 'pick', 'picked', 'plausible', 'poorly', 'popular', 'possess', 'possible', 'pour', 'practical', 'predicted', 'predicting', 'pressumptions', 'presumption', 'presumptions', 'price', 'principle', 'printed', 'probabilistic', 'probably', 'problem', 'problematic', 'problems', 'procedures', 'processes', 'processing', 'producing', 'program', 'programmed', 'programming', 'programs', 'progress', 'project', 'properly', 'properties', 'property', 'prove', 'proxy', 'psychology', 'purely', 'purpose', 'purposes', 'qualitative', 'quantities', 'range', 'rate', 'read', 'real', 'reason', 'reasonable', 'reasoner', 'reasoning', 'recognition', 'recognizable', 'recognizes', 'reduce', 'referred', 'reflected', 'relations', 'represented', 'require', 'required', 'requires', 'research', 'resolve', 'resolved', 'resource', 'result', 'results', 'robin', 'robot', 'robots', 'roller', 'room', 'rules', 'same', 'satisfactory', 'satisfy', 'say', 'scale', 'scenes', 'schema', 'scope', 'second', 'seem', 'seen', 'sees', 'semantic', 'sentences', 'separate', 'separated', 'serves', 'set', 'shared', 'short', 'should', 'significance', 'significant', 'similar', 'simple', 'simply', 'simulating', 'since', 'situations', 'small', 'sold', 'solving', 'some', 'sometimes', 'sourcing', 'specific', 'specifically', 'sphere', 'spheres', 'state', 'statistical', 'stock', 'stocks', 'structures', 'studied', 'study', 'subset', 'success', 'such', 'suggest', 'surrounding', 'synthesize', 'systems', 'takes', 'task', 'tasks', 'taxonomic', 'taxonomies', 'taxonomizes', 'taxonomy', 'techniques', 'telephone', 'templates', 'temporal', 'term', 'tests', 'text', 'texts', 'than', 'that', 'the', 'their', 'them', 'themselves', 'theoretical', 'theories', 'theory', 'there', 'these', 'they', 'third', 'this', 'three', 'thus', 'time', 'times', 'timestamps', 'to', 'together', 'toilet', 'total', 'towels', 'track', 'transitivity', 'translate', 'translates', 'translating', 'translation', 'translators', 'true', 'trying', 'tweety', 'two', 'type', 'types', 'uncontrolled', 'understand', 'understanding', 'understood', 'unknown', 'unreliable', 'up', 'usable', 'use', 'used', 'using', 'vast', 'viewer', 'vision', 'waiter', 'was', 'wash', 'way', 'web', 'well', 'what', 'when', 'where', 'whereas', 'which', 'who', 'whose', 'wide', 'will', 'winograd', 'with', 'wolves', 'wordnet', 'words', 'work', 'working', 'works', 'world', 'would', 'years', 'younger']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<1x614 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 614 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "data[\"ai\"][0][\"text\"]\n",
    "\n",
    "count_vect = CountVectorizer(input='content')\n",
    "count_vect = count_vect.fit([data[\"ai\"][0][\"text\"]])\n",
    "freq_term_matrix = count_vect.transform([data[\"ai\"][0][\"text\"]])\n",
    "print(count_vect.get_feature_names())\n",
    "freq_term_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
